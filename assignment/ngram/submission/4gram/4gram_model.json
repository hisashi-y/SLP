{
    "<s> natural language processing": 0.14285714285714285,
    "natural language processing -lrb-": 0.10714285714285714,
    "language processing -lrb- nlp": 0.6,
    "processing -lrb- nlp -rrb-": 1.0,
    "-lrb- nlp -rrb- is": 0.3333333333333333,
    "nlp -rrb- is a": 1.0,
    "-rrb- is a field": 0.25,
    "is a field of": 1.0,
    "a field of computer": 0.3333333333333333,
    "field of computer science": 0.5,
    "of computer science ,": 1.0,
    "computer science , artificial": 0.3333333333333333,
    "science , artificial intelligence": 1.0,
    ", artificial intelligence -lrb-": 0.5,
    "artificial intelligence -lrb- also": 1.0,
    "intelligence -lrb- also called": 1.0,
    "-lrb- also called machine": 1.0,
    "also called machine learning": 1.0,
    "called machine learning -rrb-": 1.0,
    "machine learning -rrb- ,": 1.0,
    "learning -rrb- , and": 1.0,
    "-rrb- , and linguistics": 0.09090909090909091,
    ", and linguistics concerned": 1.0,
    "and linguistics concerned with": 1.0,
    "linguistics concerned with the": 1.0,
    "concerned with the interactions": 0.5,
    "with the interactions between": 1.0,
    "the interactions between computers": 1.0,
    "interactions between computers and": 1.0,
    "between computers and human": 1.0,
    "computers and human -lrb-": 1.0,
    "and human -lrb- natural": 1.0,
    "human -lrb- natural -rrb-": 1.0,
    "-lrb- natural -rrb- languages": 1.0,
    "natural -rrb- languages .": 1.0,
    "<s> specifically , it": 1.0,
    "specifically , it is": 1.0,
    ", it is the": 0.07692307692307693,
    "it is the process": 0.3333333333333333,
    "is the process of": 1.0,
    "the process of a": 0.09090909090909091,
    "process of a computer": 1.0,
    "of a computer extracting": 0.3333333333333333,
    "a computer extracting meaningful": 1.0,
    "computer extracting meaningful information": 1.0,
    "extracting meaningful information from": 1.0,
    "meaningful information from natural": 1.0,
    "information from natural language": 1.0,
    "from natural language input": 1.0,
    "natural language input and\\/or": 0.25,
    "language input and\\/or producing": 1.0,
    "input and\\/or producing natural": 1.0,
    "and\\/or producing natural language": 1.0,
    "producing natural language output": 1.0,
    "natural language output .": 1.0,
    "<s> in theory ,": 1.0,
    "in theory , natural": 0.5,
    "theory , natural language": 1.0,
    ", natural language processing": 1.0,
    "natural language processing is": 0.07142857142857142,
    "language processing is a": 1.0,
    "processing is a very": 0.5,
    "is a very attractive": 0.3333333333333333,
    "a very attractive method": 1.0,
    "very attractive method of": 1.0,
    "attractive method of human": 1.0,
    "method of human --": 1.0,
    "of human -- computer": 1.0,
    "human -- computer interaction": 1.0,
    "-- computer interaction .": 1.0,
    "<s> natural language understanding": 0.5714285714285714,
    "natural language understanding is": 0.16666666666666666,
    "language understanding is sometimes": 0.5,
    "understanding is sometimes referred": 1.0,
    "is sometimes referred to": 1.0,
    "sometimes referred to as": 0.6666666666666666,
    "referred to as an": 0.5,
    "to as an ai-complete": 0.5,
    "as an ai-complete problem": 1.0,
    "an ai-complete problem because": 1.0,
    "ai-complete problem because it": 1.0,
    "problem because it seems": 1.0,
    "because it seems to": 1.0,
    "it seems to require": 1.0,
    "seems to require extensive": 1.0,
    "to require extensive knowledge": 1.0,
    "require extensive knowledge about": 1.0,
    "extensive knowledge about the": 1.0,
    "knowledge about the outside": 1.0,
    "about the outside world": 1.0,
    "the outside world and": 1.0,
    "outside world and the": 1.0,
    "world and the ability": 1.0,
    "and the ability to": 1.0,
    "the ability to manipulate": 0.5,
    "ability to manipulate it": 1.0,
    "to manipulate it .": 1.0,
    "<s> whether nlp is": 1.0,
    "whether nlp is distinct": 1.0,
    "nlp is distinct from": 1.0,
    "is distinct from ,": 1.0,
    "distinct from , or": 1.0,
    "from , or identical": 1.0,
    ", or identical to": 1.0,
    "or identical to ,": 1.0,
    "identical to , the": 1.0,
    "to , the field": 1.0,
    ", the field of": 1.0,
    "the field of computational": 0.1111111111111111,
    "field of computational linguistics": 1.0,
    "of computational linguistics is": 0.3333333333333333,
    "computational linguistics is a": 1.0,
    "linguistics is a matter": 1.0,
    "is a matter of": 1.0,
    "a matter of perspective": 1.0,
    "matter of perspective .": 1.0,
    "<s> the association for": 1.0,
    "the association for computational": 1.0,
    "association for computational linguistics": 1.0,
    "for computational linguistics defines": 1.0,
    "computational linguistics defines the": 1.0,
    "linguistics defines the latter": 1.0,
    "defines the latter as": 1.0,
    "the latter as focusing": 1.0,
    "latter as focusing on": 1.0,
    "as focusing on the": 1.0,
    "focusing on the theoretical": 1.0,
    "on the theoretical aspects": 1.0,
    "the theoretical aspects of": 1.0,
    "theoretical aspects of nlp": 1.0,
    "aspects of nlp .": 1.0,
    "<s> on the other": 1.0,
    "on the other hand": 1.0,
    "the other hand ,": 1.0,
    "other hand , the": 0.2,
    "hand , the open-access": 1.0,
    ", the open-access journal": 1.0,
    "the open-access journal ``": 1.0,
    "open-access journal `` computational": 1.0,
    "journal `` computational linguistics": 1.0,
    "`` computational linguistics ''": 1.0,
    "computational linguistics '' ,": 1.0,
    "linguistics '' , styles": 1.0,
    "'' , styles itself": 1.0,
    ", styles itself as": 1.0,
    "styles itself as ``": 1.0,
    "itself as `` the": 1.0,
    "as `` the longest": 1.0,
    "`` the longest running": 1.0,
    "the longest running publication": 1.0,
    "longest running publication devoted": 1.0,
    "running publication devoted exclusively": 1.0,
    "publication devoted exclusively to": 1.0,
    "devoted exclusively to the": 1.0,
    "exclusively to the design": 1.0,
    "to the design and": 1.0,
    "the design and analysis": 1.0,
    "design and analysis of": 1.0,
    "and analysis of natural": 1.0,
    "analysis of natural language": 1.0,
    "of natural language processing": 0.5882352941176471,
    "natural language processing systems": 0.10714285714285714,
    "language processing systems ''": 0.3333333333333333,
    "processing systems '' -lrb-": 1.0,
    "systems '' -lrb- computational": 1.0,
    "'' -lrb- computational linguistics": 1.0,
    "-lrb- computational linguistics -lrb-": 1.0,
    "computational linguistics -lrb- journal": 1.0,
    "linguistics -lrb- journal -rrb-": 1.0,
    "-lrb- journal -rrb- -rrb-": 1.0,
    "journal -rrb- -rrb- modern": 1.0,
    "-rrb- -rrb- modern nlp": 1.0,
    "-rrb- modern nlp algorithms": 1.0,
    "modern nlp algorithms are": 1.0,
    "nlp algorithms are grounded": 1.0,
    "algorithms are grounded in": 1.0,
    "are grounded in machine": 1.0,
    "grounded in machine learning": 1.0,
    "in machine learning ,": 0.5,
    "machine learning , especially": 0.3333333333333333,
    "learning , especially statistical": 1.0,
    ", especially statistical machine": 1.0,
    "especially statistical machine learning": 1.0,
    "statistical machine learning .": 1.0,
    "<s> research into modern": 1.0,
    "research into modern statistical": 1.0,
    "into modern statistical nlp": 1.0,
    "modern statistical nlp algorithms": 1.0,
    "statistical nlp algorithms requires": 1.0,
    "nlp algorithms requires an": 1.0,
    "algorithms requires an understanding": 1.0,
    "requires an understanding of": 1.0,
    "an understanding of a": 0.5,
    "understanding of a number": 1.0,
    "of a number of": 1.0,
    "a number of disparate": 0.045454545454545456,
    "number of disparate fields": 1.0,
    "of disparate fields ,": 1.0,
    "disparate fields , including": 1.0,
    "fields , including linguistics": 1.0,
    ", including linguistics ,": 1.0,
    "including linguistics , computer": 0.5,
    "linguistics , computer science": 1.0,
    ", computer science ,": 1.0,
    "computer science , and": 0.3333333333333333,
    "science , and statistics": 1.0,
    ", and statistics .": 1.0,
    "<s> for a discussion": 0.5,
    "for a discussion of": 1.0,
    "a discussion of the": 1.0,
    "discussion of the types": 1.0,
    "of the types of": 1.0,
    "the types of algorithms": 0.5,
    "types of algorithms currently": 1.0,
    "of algorithms currently used": 1.0,
    "algorithms currently used in": 1.0,
    "currently used in nlp": 1.0,
    "used in nlp ,": 1.0,
    "in nlp , see": 1.0,
    "nlp , see the": 1.0,
    ", see the article": 1.0,
    "see the article on": 1.0,
    "the article on pattern": 1.0,
    "article on pattern recognition": 1.0,
    "on pattern recognition .": 1.0,
    "<s> an automated online": 1.0,
    "an automated online assistant": 1.0,
    "automated online assistant providing": 1.0,
    "online assistant providing customer": 1.0,
    "assistant providing customer service": 1.0,
    "providing customer service on": 1.0,
    "customer service on a": 1.0,
    "service on a web": 1.0,
    "on a web page": 1.0,
    "a web page ,": 1.0,
    "web page , an": 1.0,
    "page , an example": 1.0,
    ", an example of": 1.0,
    "an example of an": 0.3333333333333333,
    "example of an application": 0.5,
    "of an application where": 1.0,
    "an application where natural": 1.0,
    "application where natural language": 1.0,
    "where natural language processing": 1.0,
    "processing is a major": 0.5,
    "is a major component": 1.0,
    "a major component .": 1.0,
    "<s> in 1950 ,": 1.0,
    "in 1950 , alan": 0.5,
    "1950 , alan turing": 1.0,
    ", alan turing published": 1.0,
    "alan turing published his": 1.0,
    "turing published his famous": 1.0,
    "published his famous article": 1.0,
    "his famous article ``": 1.0,
    "famous article `` computing": 1.0,
    "article `` computing machinery": 1.0,
    "`` computing machinery and": 1.0,
    "computing machinery and intelligence": 1.0,
    "machinery and intelligence ''": 1.0,
    "and intelligence '' which": 1.0,
    "intelligence '' which proposed": 1.0,
    "'' which proposed what": 1.0,
    "which proposed what is": 1.0,
    "proposed what is now": 1.0,
    "what is now called": 1.0,
    "is now called the": 1.0,
    "now called the turing": 1.0,
    "called the turing test": 1.0,
    "the turing test as": 1.0,
    "turing test as a": 1.0,
    "test as a criterion": 1.0,
    "as a criterion of": 1.0,
    "a criterion of intelligence": 1.0,
    "criterion of intelligence .": 1.0,
    "<s> this criterion depends": 1.0,
    "this criterion depends on": 1.0,
    "criterion depends on the": 1.0,
    "depends on the ability": 0.2,
    "on the ability of": 1.0,
    "the ability of a": 1.0,
    "ability of a computer": 1.0,
    "of a computer program": 0.3333333333333333,
    "a computer program to": 0.3333333333333333,
    "computer program to impersonate": 1.0,
    "program to impersonate a": 1.0,
    "to impersonate a human": 1.0,
    "impersonate a human in": 1.0,
    "a human in a": 1.0,
    "human in a real-time": 1.0,
    "in a real-time written": 1.0,
    "a real-time written conversation": 1.0,
    "real-time written conversation with": 1.0,
    "written conversation with a": 1.0,
    "conversation with a human": 0.5,
    "with a human judge": 1.0,
    "a human judge ,": 1.0,
    "human judge , sufficiently": 1.0,
    "judge , sufficiently well": 1.0,
    ", sufficiently well that": 1.0,
    "sufficiently well that the": 1.0,
    "well that the judge": 1.0,
    "that the judge is": 1.0,
    "the judge is unable": 1.0,
    "judge is unable to": 1.0,
    "is unable to distinguish": 1.0,
    "unable to distinguish reliably": 1.0,
    "to distinguish reliably --": 1.0,
    "distinguish reliably -- on": 1.0,
    "reliably -- on the": 1.0,
    "-- on the basis": 1.0,
    "on the basis of": 1.0,
    "the basis of the": 0.3333333333333333,
    "basis of the conversational": 1.0,
    "of the conversational content": 1.0,
    "the conversational content alone": 1.0,
    "conversational content alone --": 1.0,
    "content alone -- between": 1.0,
    "alone -- between the": 1.0,
    "-- between the program": 1.0,
    "between the program and": 1.0,
    "the program and a": 1.0,
    "program and a real": 1.0,
    "and a real human": 1.0,
    "a real human .": 1.0,
    "<s> the georgetown experiment": 1.0,
    "the georgetown experiment in": 0.3333333333333333,
    "georgetown experiment in 1954": 1.0,
    "experiment in 1954 involved": 1.0,
    "in 1954 involved fully": 1.0,
    "1954 involved fully automatic": 1.0,
    "involved fully automatic translation": 1.0,
    "fully automatic translation of": 1.0,
    "automatic translation of more": 0.5,
    "translation of more than": 1.0,
    "of more than sixty": 1.0,
    "more than sixty russian": 1.0,
    "than sixty russian sentences": 1.0,
    "sixty russian sentences into": 1.0,
    "russian sentences into english": 1.0,
    "sentences into english .": 1.0,
    "<s> the authors claimed": 0.6666666666666666,
    "the authors claimed that": 1.0,
    "authors claimed that within": 1.0,
    "claimed that within three": 1.0,
    "that within three or": 0.5,
    "within three or five": 1.0,
    "three or five years": 1.0,
    "or five years ,": 1.0,
    "five years , machine": 1.0,
    "years , machine translation": 1.0,
    ", machine translation would": 0.6666666666666666,
    "machine translation would be": 1.0,
    "translation would be a": 1.0,
    "would be a solved": 0.6666666666666666,
    "be a solved problem": 1.0,
    "a solved problem .": 1.0,
    "<s> however , real": 0.03125,
    "however , real progress": 1.0,
    ", real progress was": 1.0,
    "real progress was much": 1.0,
    "progress was much slower": 1.0,
    "was much slower ,": 1.0,
    "much slower , and": 0.5,
    "slower , and after": 1.0,
    ", and after the": 1.0,
    "and after the alpac": 1.0,
    "after the alpac report": 1.0,
    "the alpac report in": 0.5,
    "alpac report in 1966": 1.0,
    "report in 1966 ,": 1.0,
    "in 1966 , which": 1.0,
    "1966 , which found": 1.0,
    ", which found that": 1.0,
    "which found that ten": 0.5,
    "found that ten years": 1.0,
    "that ten years long": 1.0,
    "ten years long research": 1.0,
    "years long research had": 1.0,
    "long research had failed": 1.0,
    "research had failed to": 1.0,
    "had failed to fulfill": 1.0,
    "failed to fulfill the": 0.5,
    "to fulfill the expectations": 1.0,
    "fulfill the expectations ,": 1.0,
    "the expectations , funding": 1.0,
    "expectations , funding for": 0.5,
    ", funding for machine": 1.0,
    "funding for machine translation": 1.0,
    "for machine translation was": 0.3333333333333333,
    "machine translation was dramatically": 0.5,
    "translation was dramatically reduced": 1.0,
    "was dramatically reduced .": 1.0,
    "<s> little further research": 1.0,
    "little further research in": 1.0,
    "further research in machine": 1.0,
    "research in machine translation": 1.0,
    "in machine translation was": 0.5,
    "machine translation was conducted": 0.5,
    "translation was conducted until": 1.0,
    "was conducted until the": 1.0,
    "conducted until the late": 1.0,
    "until the late 1980s": 1.0,
    "the late 1980s ,": 0.75,
    "late 1980s , when": 0.3333333333333333,
    "1980s , when the": 1.0,
    ", when the first": 0.3333333333333333,
    "when the first statistical": 1.0,
    "the first statistical machine": 1.0,
    "first statistical machine translation": 1.0,
    "statistical machine translation systems": 0.25,
    "machine translation systems were": 1.0,
    "translation systems were developed": 1.0,
    "systems were developed .": 0.5,
    "<s> some notably successful": 1.0,
    "some notably successful nlp": 1.0,
    "notably successful nlp systems": 1.0,
    "successful nlp systems developed": 1.0,
    "nlp systems developed in": 1.0,
    "systems developed in the": 1.0,
    "developed in the 1960s": 0.3333333333333333,
    "in the 1960s were": 0.5,
    "the 1960s were shrdlu": 1.0,
    "1960s were shrdlu ,": 1.0,
    "were shrdlu , a": 1.0,
    "shrdlu , a natural": 1.0,
    ", a natural language": 1.0,
    "a natural language system": 0.25,
    "natural language system working": 1.0,
    "language system working in": 1.0,
    "system working in restricted": 1.0,
    "working in restricted ``": 1.0,
    "in restricted `` blocks": 1.0,
    "restricted `` blocks worlds": 1.0,
    "`` blocks worlds ''": 1.0,
    "blocks worlds '' with": 1.0,
    "worlds '' with restricted": 1.0,
    "'' with restricted vocabularies": 1.0,
    "with restricted vocabularies ,": 1.0,
    "restricted vocabularies , and": 1.0,
    "vocabularies , and eliza": 1.0,
    ", and eliza ,": 1.0,
    "and eliza , a": 1.0,
    "eliza , a simulation": 1.0,
    ", a simulation of": 1.0,
    "a simulation of a": 1.0,
    "simulation of a rogerian": 1.0,
    "of a rogerian psychotherapist": 1.0,
    "a rogerian psychotherapist ,": 1.0,
    "rogerian psychotherapist , written": 1.0,
    "psychotherapist , written by": 1.0,
    ", written by joseph": 1.0,
    "written by joseph weizenbaum": 1.0,
    "by joseph weizenbaum between": 1.0,
    "joseph weizenbaum between 1964": 1.0,
    "weizenbaum between 1964 to": 1.0,
    "between 1964 to 1966": 1.0,
    "1964 to 1966 .": 1.0,
    "<s> using almost no": 1.0,
    "using almost no information": 1.0,
    "almost no information about": 1.0,
    "no information about human": 1.0,
    "information about human thought": 1.0,
    "about human thought or": 1.0,
    "human thought or emotion": 1.0,
    "thought or emotion ,": 1.0,
    "or emotion , eliza": 1.0,
    "emotion , eliza sometimes": 1.0,
    ", eliza sometimes provided": 1.0,
    "eliza sometimes provided a": 1.0,
    "sometimes provided a startlingly": 1.0,
    "provided a startlingly human-like": 1.0,
    "a startlingly human-like interaction": 1.0,
    "startlingly human-like interaction .": 1.0,
    "<s> when the ``": 1.0,
    "when the `` patient": 1.0,
    "the `` patient ''": 1.0,
    "`` patient '' exceeded": 1.0,
    "patient '' exceeded the": 1.0,
    "'' exceeded the very": 1.0,
    "exceeded the very small": 1.0,
    "the very small knowledge": 1.0,
    "very small knowledge base": 1.0,
    "small knowledge base ,": 1.0,
    "knowledge base , eliza": 0.5,
    "base , eliza might": 1.0,
    ", eliza might provide": 1.0,
    "eliza might provide a": 1.0,
    "might provide a generic": 1.0,
    "provide a generic response": 1.0,
    "a generic response ,": 1.0,
    "generic response , for": 1.0,
    "response , for example": 1.0,
    ", for example ,": 0.5,
    "for example , responding": 0.02127659574468085,
    "example , responding to": 1.0,
    ", responding to ``": 1.0,
    "responding to `` my": 1.0,
    "to `` my head": 1.0,
    "`` my head hurts": 1.0,
    "my head hurts ''": 1.0,
    "head hurts '' with": 1.0,
    "hurts '' with ``": 1.0,
    "'' with `` why": 1.0,
    "with `` why do": 1.0,
    "`` why do you": 1.0,
    "why do you say": 1.0,
    "do you say your": 1.0,
    "you say your head": 1.0,
    "say your head hurts": 1.0,
    "your head hurts ?": 1.0,
    "head hurts ? ''": 1.0,
    "hurts ? '' .": 1.0,
    "<s> during the 70": 0.5,
    "during the 70 's": 1.0,
    "the 70 's many": 1.0,
    "70 's many programmers": 1.0,
    "'s many programmers began": 1.0,
    "many programmers began to": 1.0,
    "programmers began to write": 1.0,
    "began to write `": 1.0,
    "to write ` conceptual": 1.0,
    "write ` conceptual ontologies": 1.0,
    "` conceptual ontologies '": 1.0,
    "conceptual ontologies ' ,": 1.0,
    "ontologies ' , which": 1.0,
    "' , which structured": 1.0,
    ", which structured real-world": 1.0,
    "which structured real-world information": 1.0,
    "structured real-world information into": 1.0,
    "real-world information into computer-understandable": 1.0,
    "information into computer-understandable data": 1.0,
    "into computer-understandable data .": 1.0,
    "<s> examples are margie": 0.5,
    "examples are margie -lrb-": 1.0,
    "are margie -lrb- schank": 1.0,
    "margie -lrb- schank ,": 1.0,
    "-lrb- schank , 1975": 1.0,
    "schank , 1975 -rrb-": 1.0,
    ", 1975 -rrb- ,": 1.0,
    "1975 -rrb- , sam": 1.0,
    "-rrb- , sam -lrb-": 1.0,
    ", sam -lrb- cullingford": 1.0,
    "sam -lrb- cullingford ,": 1.0,
    "-lrb- cullingford , 1978": 1.0,
    "cullingford , 1978 -rrb-": 1.0,
    ", 1978 -rrb- ,": 1.0,
    "1978 -rrb- , pam": 0.5,
    "-rrb- , pam -lrb-": 1.0,
    ", pam -lrb- wilensky": 1.0,
    "pam -lrb- wilensky ,": 1.0,
    "-lrb- wilensky , 1978": 1.0,
    "wilensky , 1978 -rrb-": 1.0,
    "1978 -rrb- , talespin": 0.5,
    "-rrb- , talespin -lrb-": 1.0,
    ", talespin -lrb- meehan": 1.0,
    "talespin -lrb- meehan ,": 1.0,
    "-lrb- meehan , 1976": 1.0,
    "meehan , 1976 -rrb-": 1.0,
    ", 1976 -rrb- ,": 1.0,
    "1976 -rrb- , qualm": 1.0,
    "-rrb- , qualm -lrb-": 1.0,
    ", qualm -lrb- lehnert": 1.0,
    "qualm -lrb- lehnert ,": 1.0,
    "-lrb- lehnert , 1977": 1.0,
    "lehnert , 1977 -rrb-": 1.0,
    ", 1977 -rrb- ,": 1.0,
    "1977 -rrb- , politics": 1.0,
    "-rrb- , politics -lrb-": 1.0,
    ", politics -lrb- carbonell": 1.0,
    "politics -lrb- carbonell ,": 1.0,
    "-lrb- carbonell , 1979": 1.0,
    "carbonell , 1979 -rrb-": 1.0,
    ", 1979 -rrb- ,": 1.0,
    "1979 -rrb- , and": 1.0,
    "-rrb- , and plot": 0.09090909090909091,
    ", and plot units": 1.0,
    "and plot units -lrb-": 1.0,
    "plot units -lrb- lehnert": 1.0,
    "units -lrb- lehnert 1981": 1.0,
    "-lrb- lehnert 1981 -rrb-": 1.0,
    "lehnert 1981 -rrb- .": 1.0,
    "<s> during this time": 1.0,
    "during this time ,": 1.0,
    "this time , many": 0.5,
    "time , many chatterbots": 1.0,
    ", many chatterbots were": 1.0,
    "many chatterbots were written": 1.0,
    "chatterbots were written including": 1.0,
    "were written including parry": 1.0,
    "written including parry ,": 1.0,
    "including parry , racter": 1.0,
    "parry , racter ,": 1.0,
    ", racter , and": 1.0,
    "racter , and jabberwacky": 1.0,
    ", and jabberwacky .": 1.0,
    "<s> up to the": 1.0,
    "up to the 1980s": 1.0,
    "to the 1980s ,": 1.0,
    "the 1980s , most": 1.0,
    "1980s , most nlp": 1.0,
    ", most nlp systems": 1.0,
    "most nlp systems were": 1.0,
    "nlp systems were based": 1.0,
    "systems were based on": 1.0,
    "were based on complex": 1.0,
    "based on complex sets": 1.0,
    "on complex sets of": 1.0,
    "complex sets of hand-written": 1.0,
    "sets of hand-written rules": 1.0,
    "of hand-written rules .": 0.3333333333333333,
    "<s> starting in the": 1.0,
    "starting in the late": 1.0,
    "in the late 1980s": 0.6,
    "late 1980s , however": 0.3333333333333333,
    "1980s , however ,": 1.0,
    ", however , there": 0.09090909090909091,
    "however , there was": 0.3333333333333333,
    ", there was a": 1.0,
    "there was a revolution": 0.5,
    "was a revolution in": 1.0,
    "a revolution in nlp": 1.0,
    "revolution in nlp with": 1.0,
    "in nlp with the": 1.0,
    "nlp with the introduction": 1.0,
    "with the introduction of": 1.0,
    "the introduction of machine": 1.0,
    "introduction of machine learning": 1.0,
    "of machine learning algorithms": 0.4,
    "machine learning algorithms for": 0.3333333333333333,
    "learning algorithms for language": 1.0,
    "algorithms for language processing": 1.0,
    "for language processing .": 1.0,
    "<s> this was due": 1.0,
    "this was due both": 1.0,
    "was due both to": 1.0,
    "due both to the": 0.5,
    "both to the steady": 0.5,
    "to the steady increase": 1.0,
    "the steady increase in": 1.0,
    "steady increase in computational": 1.0,
    "increase in computational power": 1.0,
    "in computational power resulting": 1.0,
    "computational power resulting from": 1.0,
    "power resulting from moore": 1.0,
    "resulting from moore 's": 1.0,
    "from moore 's law": 1.0,
    "moore 's law and": 1.0,
    "'s law and the": 1.0,
    "law and the gradual": 1.0,
    "and the gradual lessening": 1.0,
    "the gradual lessening of": 1.0,
    "gradual lessening of the": 1.0,
    "lessening of the dominance": 1.0,
    "of the dominance of": 1.0,
    "the dominance of chomskyan": 1.0,
    "dominance of chomskyan theories": 1.0,
    "of chomskyan theories of": 1.0,
    "chomskyan theories of linguistics": 1.0,
    "theories of linguistics -lrb-": 1.0,
    "of linguistics -lrb- e.g.": 1.0,
    "linguistics -lrb- e.g. transformational": 1.0,
    "-lrb- e.g. transformational grammar": 1.0,
    "e.g. transformational grammar -rrb-": 1.0,
    "transformational grammar -rrb- ,": 1.0,
    "grammar -rrb- , whose": 1.0,
    "-rrb- , whose theoretical": 1.0,
    ", whose theoretical underpinnings": 1.0,
    "whose theoretical underpinnings discouraged": 1.0,
    "theoretical underpinnings discouraged the": 1.0,
    "underpinnings discouraged the sort": 1.0,
    "discouraged the sort of": 1.0,
    "the sort of corpus": 1.0,
    "sort of corpus linguistics": 1.0,
    "of corpus linguistics that": 1.0,
    "corpus linguistics that underlies": 1.0,
    "linguistics that underlies the": 1.0,
    "that underlies the machine-learning": 1.0,
    "underlies the machine-learning approach": 1.0,
    "the machine-learning approach to": 1.0,
    "machine-learning approach to language": 1.0,
    "approach to language processing": 1.0,
    "to language processing .": 1.0,
    "<s> some of the": 1.0,
    "some of the earliest-used": 0.2,
    "of the earliest-used machine": 0.5,
    "the earliest-used machine learning": 1.0,
    "earliest-used machine learning algorithms": 1.0,
    "machine learning algorithms ,": 0.3333333333333333,
    "learning algorithms , such": 1.0,
    "algorithms , such as": 1.0,
    ", such as decision": 0.09090909090909091,
    "such as decision trees": 1.0,
    "as decision trees ,": 1.0,
    "decision trees , produced": 0.6666666666666666,
    "trees , produced systems": 1.0,
    ", produced systems of": 1.0,
    "produced systems of hard": 1.0,
    "systems of hard if-then": 1.0,
    "of hard if-then rules": 1.0,
    "hard if-then rules similar": 1.0,
    "if-then rules similar to": 1.0,
    "rules similar to existing": 0.5,
    "similar to existing hand-written": 1.0,
    "to existing hand-written rules": 1.0,
    "existing hand-written rules .": 1.0,
    "<s> increasingly , however": 1.0,
    "increasingly , however ,": 1.0,
    ", however , research": 0.18181818181818182,
    "however , research has": 1.0,
    ", research has focused": 1.0,
    "research has focused on": 1.0,
    "has focused on statistical": 0.5,
    "focused on statistical models": 1.0,
    "on statistical models ,": 1.0,
    "statistical models , which": 1.0,
    "models , which make": 1.0,
    ", which make soft": 1.0,
    "which make soft ,": 1.0,
    "make soft , probabilistic": 1.0,
    "soft , probabilistic decisions": 1.0,
    ", probabilistic decisions based": 1.0,
    "probabilistic decisions based on": 1.0,
    "decisions based on attaching": 1.0,
    "based on attaching real-valued": 1.0,
    "on attaching real-valued weights": 1.0,
    "attaching real-valued weights to": 1.0,
    "real-valued weights to the": 0.5,
    "weights to the features": 1.0,
    "to the features making": 1.0,
    "the features making up": 1.0,
    "features making up the": 1.0,
    "making up the input": 1.0,
    "up the input data": 1.0,
    "the input data .": 1.0,
    "<s> the cache language": 1.0,
    "the cache language models": 1.0,
    "cache language models upon": 1.0,
    "language models upon which": 1.0,
    "models upon which many": 1.0,
    "upon which many speech": 1.0,
    "which many speech recognition": 1.0,
    "many speech recognition systems": 1.0,
    "speech recognition systems now": 0.1111111111111111,
    "recognition systems now rely": 1.0,
    "systems now rely are": 1.0,
    "now rely are examples": 1.0,
    "rely are examples of": 1.0,
    "are examples of such": 0.3333333333333333,
    "examples of such statistical": 0.5,
    "of such statistical models": 1.0,
    "such statistical models .": 1.0,
    "<s> such models are": 0.5,
    "such models are generally": 1.0,
    "models are generally more": 1.0,
    "are generally more robust": 1.0,
    "generally more robust when": 1.0,
    "more robust when given": 1.0,
    "robust when given unfamiliar": 1.0,
    "when given unfamiliar input": 1.0,
    "given unfamiliar input ,": 1.0,
    "unfamiliar input , especially": 1.0,
    "input , especially input": 1.0,
    ", especially input that": 1.0,
    "especially input that contains": 1.0,
    "input that contains errors": 1.0,
    "that contains errors -lrb-": 1.0,
    "contains errors -lrb- as": 1.0,
    "errors -lrb- as is": 1.0,
    "-lrb- as is very": 1.0,
    "as is very common": 1.0,
    "is very common for": 1.0,
    "very common for real-world": 1.0,
    "common for real-world data": 1.0,
    "for real-world data -rrb-": 1.0,
    "real-world data -rrb- ,": 0.5,
    "data -rrb- , and": 1.0,
    "-rrb- , and produce": 0.09090909090909091,
    ", and produce more": 1.0,
    "and produce more reliable": 1.0,
    "produce more reliable results": 0.5,
    "more reliable results when": 1.0,
    "reliable results when integrated": 0.5,
    "results when integrated into": 1.0,
    "when integrated into a": 1.0,
    "integrated into a larger": 1.0,
    "into a larger system": 1.0,
    "a larger system comprising": 0.5,
    "larger system comprising multiple": 1.0,
    "system comprising multiple subtasks": 1.0,
    "comprising multiple subtasks .": 1.0,
    "<s> many of the": 0.5,
    "many of the notable": 0.3333333333333333,
    "of the notable early": 1.0,
    "the notable early successes": 1.0,
    "notable early successes occurred": 1.0,
    "early successes occurred in": 1.0,
    "successes occurred in the": 1.0,
    "occurred in the field": 1.0,
    "in the field of": 0.4166666666666667,
    "the field of machine": 0.1111111111111111,
    "field of machine translation": 1.0,
    "of machine translation ,": 0.3333333333333333,
    "machine translation , due": 0.14285714285714285,
    "translation , due especially": 1.0,
    ", due especially to": 1.0,
    "due especially to work": 1.0,
    "especially to work at": 1.0,
    "to work at ibm": 1.0,
    "work at ibm research": 1.0,
    "at ibm research ,": 1.0,
    "ibm research , where": 1.0,
    "research , where successively": 1.0,
    ", where successively more": 1.0,
    "where successively more complicated": 1.0,
    "successively more complicated statistical": 1.0,
    "more complicated statistical models": 1.0,
    "complicated statistical models were": 1.0,
    "statistical models were developed": 1.0,
    "models were developed .": 1.0,
    "<s> these systems were": 0.25,
    "these systems were able": 1.0,
    "systems were able to": 1.0,
    "were able to take": 1.0,
    "able to take advantage": 1.0,
    "to take advantage of": 1.0,
    "take advantage of existing": 0.25,
    "advantage of existing multilingual": 1.0,
    "of existing multilingual textual": 1.0,
    "existing multilingual textual corpora": 1.0,
    "multilingual textual corpora that": 1.0,
    "textual corpora that had": 1.0,
    "corpora that had been": 1.0,
    "that had been produced": 1.0,
    "had been produced by": 1.0,
    "been produced by the": 1.0,
    "produced by the parliament": 1.0,
    "by the parliament of": 1.0,
    "the parliament of canada": 1.0,
    "parliament of canada and": 1.0,
    "of canada and the": 1.0,
    "canada and the european": 1.0,
    "and the european union": 1.0,
    "the european union as": 1.0,
    "european union as a": 1.0,
    "union as a result": 1.0,
    "as a result of": 0.3333333333333333,
    "a result of laws": 1.0,
    "result of laws calling": 1.0,
    "of laws calling for": 1.0,
    "laws calling for the": 1.0,
    "calling for the translation": 1.0,
    "for the translation of": 1.0,
    "the translation of all": 0.3333333333333333,
    "translation of all governmental": 1.0,
    "of all governmental proceedings": 1.0,
    "all governmental proceedings into": 1.0,
    "governmental proceedings into all": 1.0,
    "proceedings into all official": 1.0,
    "into all official languages": 1.0,
    "all official languages of": 1.0,
    "official languages of the": 1.0,
    "languages of the corresponding": 1.0,
    "of the corresponding systems": 1.0,
    "the corresponding systems of": 1.0,
    "corresponding systems of government": 1.0,
    "systems of government .": 1.0,
    "<s> however , most": 0.03125,
    "however , most other": 0.5,
    ", most other systems": 1.0,
    "most other systems depended": 1.0,
    "other systems depended on": 1.0,
    "systems depended on corpora": 1.0,
    "depended on corpora specifically": 1.0,
    "on corpora specifically developed": 1.0,
    "corpora specifically developed for": 1.0,
    "specifically developed for the": 1.0,
    "developed for the tasks": 1.0,
    "for the tasks implemented": 1.0,
    "the tasks implemented by": 1.0,
    "tasks implemented by these": 1.0,
    "implemented by these systems": 1.0,
    "by these systems ,": 1.0,
    "these systems , which": 1.0,
    "systems , which was": 1.0,
    ", which was -lrb-": 0.25,
    "which was -lrb- and": 1.0,
    "was -lrb- and often": 1.0,
    "-lrb- and often continues": 1.0,
    "and often continues to": 1.0,
    "often continues to be": 1.0,
    "continues to be -rrb-": 1.0,
    "to be -rrb- a": 1.0,
    "be -rrb- a major": 1.0,
    "-rrb- a major limitation": 1.0,
    "a major limitation in": 1.0,
    "major limitation in the": 1.0,
    "limitation in the success": 1.0,
    "in the success of": 1.0,
    "the success of these": 0.3333333333333333,
    "success of these systems": 1.0,
    "of these systems .": 1.0,
    "<s> as a result": 1.0,
    "as a result ,": 0.6666666666666666,
    "a result , a": 0.5,
    "result , a great": 1.0,
    ", a great deal": 1.0,
    "a great deal of": 1.0,
    "great deal of research": 1.0,
    "deal of research has": 1.0,
    "of research has gone": 1.0,
    "research has gone into": 1.0,
    "has gone into methods": 1.0,
    "gone into methods of": 1.0,
    "into methods of more": 1.0,
    "methods of more effectively": 1.0,
    "of more effectively learning": 1.0,
    "more effectively learning from": 1.0,
    "effectively learning from limited": 1.0,
    "learning from limited amounts": 1.0,
    "from limited amounts of": 1.0,
    "limited amounts of data": 1.0,
    "amounts of data .": 1.0,
    "<s> recent research has": 0.5,
    "recent research has increasingly": 1.0,
    "research has increasingly focused": 1.0,
    "has increasingly focused on": 1.0,
    "increasingly focused on unsupervised": 1.0,
    "focused on unsupervised and": 1.0,
    "on unsupervised and semi-supervised": 1.0,
    "unsupervised and semi-supervised learning": 1.0,
    "and semi-supervised learning algorithms": 1.0,
    "semi-supervised learning algorithms .": 1.0,
    "<s> such algorithms are": 1.0,
    "such algorithms are able": 1.0,
    "algorithms are able to": 1.0,
    "are able to learn": 0.3333333333333333,
    "able to learn from": 1.0,
    "to learn from data": 1.0,
    "learn from data that": 1.0,
    "from data that has": 1.0,
    "data that has not": 1.0,
    "that has not been": 1.0,
    "has not been hand-annotated": 1.0,
    "not been hand-annotated with": 1.0,
    "been hand-annotated with the": 1.0,
    "hand-annotated with the desired": 0.5,
    "with the desired answers": 1.0,
    "the desired answers ,": 1.0,
    "desired answers , or": 1.0,
    "answers , or using": 1.0,
    ", or using a": 0.5,
    "or using a combination": 1.0,
    "using a combination of": 1.0,
    "a combination of annotated": 1.0,
    "combination of annotated and": 1.0,
    "of annotated and non-annotated": 1.0,
    "annotated and non-annotated data": 1.0,
    "and non-annotated data .": 1.0,
    "<s> generally , this": 0.3333333333333333,
    "generally , this task": 1.0,
    ", this task is": 1.0,
    "this task is much": 0.5,
    "task is much more": 1.0,
    "is much more difficult": 1.0,
    "much more difficult than": 0.6666666666666666,
    "more difficult than supervised": 0.3333333333333333,
    "difficult than supervised learning": 1.0,
    "than supervised learning ,": 1.0,
    "supervised learning , and": 1.0,
    "learning , and typically": 1.0,
    ", and typically produces": 1.0,
    "and typically produces less": 1.0,
    "typically produces less accurate": 1.0,
    "produces less accurate results": 1.0,
    "less accurate results for": 1.0,
    "accurate results for a": 1.0,
    "results for a given": 1.0,
    "for a given amount": 1.0,
    "a given amount of": 1.0,
    "given amount of input": 1.0,
    "amount of input data": 1.0,
    "of input data .": 1.0,
    "<s> however , there": 0.0625,
    "however , there is": 0.3333333333333333,
    ", there is an": 0.16666666666666666,
    "there is an enormous": 1.0,
    "is an enormous amount": 1.0,
    "an enormous amount of": 1.0,
    "enormous amount of non-annotated": 1.0,
    "amount of non-annotated data": 1.0,
    "of non-annotated data available": 1.0,
    "non-annotated data available -lrb-": 1.0,
    "data available -lrb- including": 1.0,
    "available -lrb- including ,": 1.0,
    "-lrb- including , among": 1.0,
    "including , among other": 1.0,
    ", among other things": 1.0,
    "among other things ,": 0.5,
    "other things , the": 1.0,
    "things , the entire": 1.0,
    ", the entire content": 1.0,
    "the entire content of": 1.0,
    "entire content of the": 1.0,
    "content of the world": 1.0,
    "of the world wide": 0.5,
    "the world wide web": 1.0,
    "world wide web -rrb-": 0.25,
    "wide web -rrb- ,": 1.0,
    "web -rrb- , which": 1.0,
    "-rrb- , which can": 0.3333333333333333,
    ", which can often": 0.5,
    "which can often make": 1.0,
    "can often make up": 1.0,
    "often make up for": 1.0,
    "make up for the": 1.0,
    "up for the inferior": 1.0,
    "for the inferior results": 1.0,
    "the inferior results .": 1.0,
    "<s> nlp using machine": 1.0,
    "nlp using machine learning": 1.0,
    "using machine learning as": 1.0,
    "machine learning as described": 1.0,
    "learning as described above": 1.0,
    "as described above ,": 0.5,
    "described above , modern": 1.0,
    "above , modern approaches": 1.0,
    ", modern approaches to": 1.0,
    "modern approaches to natural": 1.0,
    "approaches to natural language": 1.0,
    "to natural language processing": 1.0,
    "-lrb- nlp -rrb- are": 0.3333333333333333,
    "nlp -rrb- are grounded": 1.0,
    "-rrb- are grounded in": 1.0,
    "in machine learning .": 0.5,
    "<s> the paradigm of": 1.0,
    "the paradigm of machine": 1.0,
    "paradigm of machine learning": 1.0,
    "of machine learning is": 0.2,
    "machine learning is different": 1.0,
    "learning is different from": 1.0,
    "is different from that": 1.0,
    "different from that of": 1.0,
    "from that of most": 1.0,
    "that of most prior": 1.0,
    "of most prior attempts": 1.0,
    "most prior attempts at": 1.0,
    "prior attempts at language": 1.0,
    "attempts at language processing": 1.0,
    "at language processing .": 1.0,
    "<s> prior implementations of": 1.0,
    "prior implementations of language-processing": 1.0,
    "implementations of language-processing tasks": 1.0,
    "of language-processing tasks typically": 1.0,
    "language-processing tasks typically involved": 1.0,
    "tasks typically involved the": 1.0,
    "typically involved the direct": 1.0,
    "involved the direct hand": 1.0,
    "the direct hand coding": 1.0,
    "direct hand coding of": 1.0,
    "hand coding of large": 1.0,
    "coding of large sets": 1.0,
    "of large sets of": 1.0,
    "large sets of rules": 1.0,
    "sets of rules .": 1.0,
    "<s> the machine-learning paradigm": 1.0,
    "the machine-learning paradigm calls": 1.0,
    "machine-learning paradigm calls instead": 1.0,
    "paradigm calls instead for": 1.0,
    "calls instead for using": 1.0,
    "instead for using general": 1.0,
    "for using general learning": 1.0,
    "using general learning algorithms": 1.0,
    "general learning algorithms --": 1.0,
    "learning algorithms -- often": 1.0,
    "algorithms -- often ,": 1.0,
    "-- often , although": 1.0,
    "often , although not": 1.0,
    ", although not always": 1.0,
    "although not always ,": 1.0,
    "not always , grounded": 1.0,
    "always , grounded in": 1.0,
    ", grounded in statistical": 1.0,
    "grounded in statistical inference": 1.0,
    "in statistical inference --": 1.0,
    "statistical inference -- to": 1.0,
    "inference -- to automatically": 1.0,
    "-- to automatically learn": 1.0,
    "to automatically learn such": 0.5,
    "automatically learn such rules": 1.0,
    "learn such rules through": 1.0,
    "such rules through the": 1.0,
    "rules through the analysis": 1.0,
    "through the analysis of": 1.0,
    "the analysis of large": 0.5,
    "analysis of large corpora": 0.5,
    "of large corpora of": 1.0,
    "large corpora of typical": 1.0,
    "corpora of typical real-world": 1.0,
    "of typical real-world examples": 1.0,
    "typical real-world examples .": 1.0,
    "<s> a corpus -lrb-": 1.0,
    "a corpus -lrb- plural": 1.0,
    "corpus -lrb- plural ,": 1.0,
    "-lrb- plural , ``": 1.0,
    "plural , `` corpora": 1.0,
    ", `` corpora ''": 1.0,
    "`` corpora '' -rrb-": 1.0,
    "corpora '' -rrb- is": 1.0,
    "'' -rrb- is a": 1.0,
    "-rrb- is a set": 0.25,
    "is a set of": 1.0,
    "a set of documents": 0.21428571428571427,
    "set of documents -lrb-": 0.3333333333333333,
    "of documents -lrb- or": 1.0,
    "documents -lrb- or sometimes": 1.0,
    "-lrb- or sometimes ,": 1.0,
    "or sometimes , individual": 1.0,
    "sometimes , individual sentences": 1.0,
    ", individual sentences -rrb-": 1.0,
    "individual sentences -rrb- that": 1.0,
    "sentences -rrb- that have": 1.0,
    "-rrb- that have been": 1.0,
    "that have been hand-annotated": 0.3333333333333333,
    "have been hand-annotated with": 1.0,
    "hand-annotated with the correct": 0.5,
    "with the correct values": 1.0,
    "the correct values to": 1.0,
    "correct values to be": 1.0,
    "values to be learned": 1.0,
    "to be learned .": 1.0,
    "<s> consider the task": 0.3333333333333333,
    "consider the task of": 1.0,
    "the task of part": 0.16666666666666666,
    "task of part of": 1.0,
    "of part of speech": 1.0,
    "part of speech tagging": 0.14285714285714285,
    "of speech tagging ,": 1.0,
    "speech tagging , i.e.": 0.5,
    "tagging , i.e. determining": 1.0,
    ", i.e. determining the": 1.0,
    "i.e. determining the correct": 1.0,
    "determining the correct part": 1.0,
    "the correct part of": 1.0,
    "correct part of speech": 1.0,
    "part of speech of": 0.07142857142857142,
    "of speech of each": 1.0,
    "speech of each word": 1.0,
    "of each word in": 0.5,
    "each word in a": 1.0,
    "word in a given": 0.3333333333333333,
    "in a given sentence": 0.5,
    "a given sentence ,": 0.5,
    "given sentence , typically": 1.0,
    "sentence , typically one": 0.5,
    ", typically one that": 1.0,
    "typically one that has": 1.0,
    "one that has never": 1.0,
    "that has never been": 1.0,
    "has never been seen": 0.5,
    "never been seen before": 1.0,
    "been seen before .": 0.5,
    "<s> a typical machine-learning-based": 0.5,
    "a typical machine-learning-based implementation": 1.0,
    "typical machine-learning-based implementation of": 1.0,
    "machine-learning-based implementation of a": 1.0,
    "implementation of a part": 1.0,
    "of a part of": 1.0,
    "a part of speech": 0.5,
    "part of speech tagger": 0.07142857142857142,
    "of speech tagger proceeds": 1.0,
    "speech tagger proceeds in": 1.0,
    "tagger proceeds in two": 1.0,
    "proceeds in two steps": 1.0,
    "in two steps ,": 1.0,
    "two steps , a": 1.0,
    "steps , a training": 1.0,
    ", a training step": 1.0,
    "a training step and": 1.0,
    "training step and an": 1.0,
    "step and an evaluation": 1.0,
    "and an evaluation step": 1.0,
    "an evaluation step .": 1.0,
    "<s> the first step": 0.16666666666666666,
    "the first step --": 1.0,
    "first step -- the": 1.0,
    "step -- the training": 1.0,
    "-- the training step": 1.0,
    "the training step --": 1.0,
    "training step -- makes": 1.0,
    "step -- makes use": 1.0,
    "-- makes use of": 1.0,
    "makes use of a": 1.0,
    "use of a corpus": 0.25,
    "of a corpus of": 1.0,
    "a corpus of training": 1.0,
    "corpus of training data": 1.0,
    "of training data ,": 0.3333333333333333,
    "training data , which": 0.3333333333333333,
    "data , which consists": 1.0,
    ", which consists of": 1.0,
    "which consists of a": 1.0,
    "consists of a large": 1.0,
    "of a large number": 1.0,
    "a large number of": 1.0,
    "large number of sentences": 0.5,
    "number of sentences ,": 0.5,
    "of sentences , each": 0.5,
    "sentences , each of": 1.0,
    ", each of which": 1.0,
    "each of which has": 0.25,
    "of which has the": 1.0,
    "which has the correct": 1.0,
    "has the correct part": 1.0,
    "part of speech attached": 0.07142857142857142,
    "of speech attached to": 1.0,
    "speech attached to each": 1.0,
    "attached to each word": 1.0,
    "to each word .": 1.0,
    "<s> -lrb- an example": 0.5,
    "-lrb- an example of": 1.0,
    "an example of such": 0.3333333333333333,
    "example of such a": 1.0,
    "of such a corpus": 0.3333333333333333,
    "such a corpus in": 1.0,
    "a corpus in common": 1.0,
    "corpus in common use": 1.0,
    "in common use is": 1.0,
    "common use is the": 1.0,
    "use is the penn": 1.0,
    "is the penn treebank": 1.0,
    "the penn treebank .": 0.3333333333333333,
    "<s> this includes -lrb-": 1.0,
    "this includes -lrb- among": 1.0,
    "includes -lrb- among other": 1.0,
    "-lrb- among other things": 1.0,
    "among other things -rrb-": 0.5,
    "other things -rrb- a": 1.0,
    "things -rrb- a set": 1.0,
    "-rrb- a set of": 1.0,
    "a set of 500": 0.07142857142857142,
    "set of 500 texts": 1.0,
    "of 500 texts from": 1.0,
    "500 texts from the": 1.0,
    "texts from the brown": 1.0,
    "from the brown corpus": 1.0,
    "the brown corpus ,": 0.09090909090909091,
    "brown corpus , containing": 1.0,
    "corpus , containing examples": 1.0,
    ", containing examples of": 1.0,
    "containing examples of various": 1.0,
    "examples of various genres": 1.0,
    "of various genres of": 1.0,
    "various genres of text": 1.0,
    "genres of text ,": 1.0,
    "of text , and": 0.2,
    "text , and 2500": 0.3333333333333333,
    ", and 2500 articles": 1.0,
    "and 2500 articles from": 1.0,
    "2500 articles from the": 1.0,
    "articles from the wall": 1.0,
    "from the wall street": 1.0,
    "the wall street journal": 1.0,
    "wall street journal .": 0.5,
    "street journal . -rrb-": 1.0,
    "<s> this corpus is": 0.5,
    "this corpus is analyzed": 1.0,
    "corpus is analyzed and": 1.0,
    "is analyzed and a": 1.0,
    "analyzed and a learning": 1.0,
    "and a learning model": 1.0,
    "a learning model is": 1.0,
    "learning model is generated": 1.0,
    "model is generated from": 1.0,
    "is generated from it": 1.0,
    "generated from it ,": 1.0,
    "from it , consisting": 1.0,
    "it , consisting of": 1.0,
    ", consisting of automatically": 1.0,
    "consisting of automatically created": 1.0,
    "of automatically created rules": 1.0,
    "automatically created rules for": 1.0,
    "created rules for determining": 1.0,
    "rules for determining the": 1.0,
    "for determining the part": 1.0,
    "determining the part of": 1.0,
    "the part of speech": 1.0,
    "part of speech for": 0.21428571428571427,
    "of speech for a": 0.25,
    "speech for a word": 1.0,
    "for a word in": 1.0,
    "a word in a": 1.0,
    "word in a sentence": 0.3333333333333333,
    "in a sentence ,": 0.5,
    "a sentence , typically": 0.5,
    "sentence , typically based": 0.5,
    ", typically based on": 1.0,
    "typically based on the": 1.0,
    "based on the nature": 0.09090909090909091,
    "on the nature of": 1.0,
    "the nature of the": 0.8,
    "nature of the word": 0.2,
    "of the word in": 0.25,
    "the word in question": 1.0,
    "word in question ,": 1.0,
    "in question , the": 1.0,
    "question , the nature": 0.5,
    ", the nature of": 1.0,
    "the nature of surrounding": 0.2,
    "nature of surrounding words": 1.0,
    "of surrounding words ,": 1.0,
    "surrounding words , and": 1.0,
    "words , and the": 0.3333333333333333,
    ", and the most": 0.1,
    "and the most likely": 1.0,
    "the most likely part": 0.5,
    "most likely part of": 1.0,
    "likely part of speech": 1.0,
    "of speech for those": 0.25,
    "speech for those surrounding": 1.0,
    "for those surrounding words": 1.0,
    "those surrounding words .": 1.0,
    "<s> the model that": 1.0,
    "the model that is": 0.3333333333333333,
    "model that is generated": 1.0,
    "that is generated is": 1.0,
    "is generated is typically": 1.0,
    "generated is typically the": 1.0,
    "is typically the best": 1.0,
    "typically the best model": 1.0,
    "the best model that": 1.0,
    "best model that can": 1.0,
    "model that can be": 1.0,
    "that can be found": 0.2,
    "can be found that": 0.3333333333333333,
    "be found that simultaneously": 1.0,
    "found that simultaneously meets": 1.0,
    "that simultaneously meets two": 1.0,
    "simultaneously meets two conflicting": 1.0,
    "meets two conflicting objectives": 1.0,
    "two conflicting objectives :": 1.0,
    "conflicting objectives : to": 1.0,
    "objectives : to perform": 1.0,
    ": to perform as": 1.0,
    "to perform as well": 1.0,
    "perform as well as": 1.0,
    "as well as possible": 0.15384615384615385,
    "well as possible on": 0.5,
    "as possible on the": 1.0,
    "possible on the training": 1.0,
    "on the training data": 1.0,
    "the training data ,": 0.6666666666666666,
    "training data , and": 0.3333333333333333,
    "data , and to": 0.3333333333333333,
    ", and to be": 0.25,
    "and to be as": 1.0,
    "to be as simple": 1.0,
    "be as simple as": 1.0,
    "as simple as possible": 0.5,
    "simple as possible -lrb-": 1.0,
    "as possible -lrb- so": 1.0,
    "possible -lrb- so that": 1.0,
    "-lrb- so that the": 1.0,
    "so that the model": 0.5,
    "that the model avoids": 1.0,
    "the model avoids overfitting": 1.0,
    "model avoids overfitting the": 1.0,
    "avoids overfitting the training": 1.0,
    "overfitting the training data": 1.0,
    "training data , i.e.": 0.3333333333333333,
    "data , i.e. so": 1.0,
    ", i.e. so that": 1.0,
    "i.e. so that it": 1.0,
    "so that it generalizes": 1.0,
    "that it generalizes as": 1.0,
    "it generalizes as well": 1.0,
    "generalizes as well as": 1.0,
    "well as possible to": 0.5,
    "as possible to new": 1.0,
    "possible to new data": 1.0,
    "to new data rather": 1.0,
    "new data rather than": 1.0,
    "data rather than only": 1.0,
    "rather than only succeeding": 0.5,
    "than only succeeding on": 1.0,
    "only succeeding on sentences": 1.0,
    "succeeding on sentences that": 1.0,
    "on sentences that have": 1.0,
    "sentences that have already": 1.0,
    "that have already been": 1.0,
    "have already been seen": 1.0,
    "already been seen -rrb-": 1.0,
    "been seen -rrb- .": 1.0,
    "<s> in the second": 0.08333333333333333,
    "in the second step": 1.0,
    "the second step -lrb-": 1.0,
    "second step -lrb- the": 1.0,
    "step -lrb- the evaluation": 1.0,
    "-lrb- the evaluation step": 1.0,
    "the evaluation step -rrb-": 1.0,
    "evaluation step -rrb- ,": 1.0,
    "step -rrb- , the": 1.0,
    "-rrb- , the model": 0.2,
    ", the model that": 1.0,
    "the model that has": 0.6666666666666666,
    "model that has been": 1.0,
    "that has been learned": 0.5,
    "has been learned is": 0.5,
    "been learned is used": 1.0,
    "learned is used to": 1.0,
    "is used to process": 0.14285714285714285,
    "used to process new": 1.0,
    "to process new sentences": 1.0,
    "process new sentences .": 1.0,
    "<s> an important part": 0.5,
    "an important part of": 1.0,
    "important part of the": 1.0,
    "part of the development": 0.5,
    "of the development of": 1.0,
    "the development of any": 0.2,
    "development of any learning": 1.0,
    "of any learning algorithm": 1.0,
    "any learning algorithm is": 1.0,
    "learning algorithm is testing": 1.0,
    "algorithm is testing the": 1.0,
    "is testing the model": 1.0,
    "testing the model that": 1.0,
    "has been learned on": 0.5,
    "been learned on new": 1.0,
    "learned on new ,": 1.0,
    "on new , previously": 1.0,
    "new , previously unseen": 1.0,
    ", previously unseen data": 1.0,
    "previously unseen data .": 1.0,
    "<s> it is critical": 0.05263157894736842,
    "it is critical that": 1.0,
    "is critical that the": 1.0,
    "critical that the data": 1.0,
    "that the data used": 1.0,
    "the data used for": 1.0,
    "data used for testing": 0.5,
    "used for testing is": 1.0,
    "for testing is not": 1.0,
    "testing is not the": 1.0,
    "is not the same": 1.0,
    "not the same as": 1.0,
    "the same as the": 1.0,
    "same as the data": 0.5,
    "as the data used": 1.0,
    "data used for training": 0.5,
    "used for training ;": 1.0,
    "for training ; otherwise": 1.0,
    "training ; otherwise ,": 1.0,
    "; otherwise , the": 1.0,
    "otherwise , the testing": 1.0,
    ", the testing accuracy": 1.0,
    "the testing accuracy will": 1.0,
    "testing accuracy will be": 1.0,
    "accuracy will be unrealistically": 1.0,
    "will be unrealistically high": 1.0,
    "be unrealistically high .": 1.0,
    "<s> many different classes": 0.5,
    "many different classes of": 1.0,
    "different classes of machine": 1.0,
    "classes of machine learning": 1.0,
    "machine learning algorithms have": 0.3333333333333333,
    "learning algorithms have been": 1.0,
    "algorithms have been applied": 0.5,
    "have been applied to": 1.0,
    "been applied to nlp": 0.2,
    "applied to nlp tasks": 1.0,
    "to nlp tasks .": 1.0,
    "<s> in common to": 1.0,
    "in common to all": 1.0,
    "common to all of": 1.0,
    "to all of these": 1.0,
    "all of these algorithms": 1.0,
    "of these algorithms is": 1.0,
    "these algorithms is that": 1.0,
    "algorithms is that they": 1.0,
    "is that they take": 0.5,
    "that they take as": 1.0,
    "they take as input": 1.0,
    "take as input a": 1.0,
    "as input a large": 1.0,
    "input a large set": 1.0,
    "a large set of": 1.0,
    "large set of ``": 1.0,
    "set of `` features": 1.0,
    "of `` features ''": 1.0,
    "`` features '' that": 1.0,
    "features '' that are": 1.0,
    "'' that are generated": 1.0,
    "that are generated from": 1.0,
    "are generated from the": 1.0,
    "generated from the input": 1.0,
    "from the input data": 1.0,
    "<s> as an example": 1.0,
    "as an example ,": 1.0,
    "an example , for": 0.5,
    "example , for a": 1.0,
    ", for a part-of-speech": 0.5,
    "for a part-of-speech tagger": 1.0,
    "a part-of-speech tagger ,": 1.0,
    "part-of-speech tagger , typical": 1.0,
    "tagger , typical features": 1.0,
    ", typical features might": 1.0,
    "typical features might be": 1.0,
    "features might be the": 1.0,
    "might be the identity": 1.0,
    "be the identity of": 1.0,
    "the identity of the": 0.5,
    "identity of the word": 0.5,
    "of the word being": 0.25,
    "the word being processed": 0.5,
    "word being processed ,": 1.0,
    "being processed , the": 1.0,
    "processed , the identity": 1.0,
    ", the identity of": 1.0,
    "identity of the words": 0.5,
    "of the words immediately": 0.3333333333333333,
    "the words immediately to": 1.0,
    "words immediately to the": 1.0,
    "immediately to the left": 1.0,
    "to the left and": 0.5,
    "the left and right": 1.0,
    "left and right ,": 0.5,
    "and right , the": 1.0,
    "right , the part-of-speech": 1.0,
    ", the part-of-speech tag": 1.0,
    "the part-of-speech tag of": 1.0,
    "part-of-speech tag of the": 1.0,
    "tag of the word": 1.0,
    "of the word to": 0.25,
    "the word to the": 1.0,
    "word to the left": 1.0,
    "to the left ,": 0.5,
    "the left , and": 1.0,
    "left , and whether": 1.0,
    ", and whether the": 1.0,
    "and whether the word": 1.0,
    "whether the word being": 1.0,
    "the word being considered": 0.5,
    "word being considered or": 1.0,
    "being considered or its": 1.0,
    "considered or its immediate": 1.0,
    "or its immediate neighbors": 1.0,
    "its immediate neighbors are": 1.0,
    "immediate neighbors are content": 1.0,
    "neighbors are content words": 1.0,
    "are content words or": 1.0,
    "content words or function": 1.0,
    "words or function words": 1.0,
    "or function words .": 1.0,
    "<s> the algorithms differ": 0.5,
    "the algorithms differ ,": 1.0,
    "algorithms differ , however": 1.0,
    "differ , however ,": 1.0,
    ", however , in": 0.09090909090909091,
    "however , in the": 0.5,
    ", in the nature": 0.125,
    "in the nature of": 1.0,
    "nature of the rules": 0.2,
    "of the rules generated": 0.5,
    "the rules generated .": 1.0,
    "of the earliest-used algorithms": 0.5,
    "the earliest-used algorithms ,": 1.0,
    "earliest-used algorithms , such": 1.0,
    "rules similar to the": 0.5,
    "similar to the systems": 0.2,
    "to the systems of": 1.0,
    "the systems of hand-written": 1.0,
    "systems of hand-written rules": 1.0,
    "of hand-written rules that": 0.6666666666666666,
    "hand-written rules that were": 0.5,
    "rules that were then": 1.0,
    "that were then common": 1.0,
    "were then common .": 1.0,
    "real-valued weights to each": 0.5,
    "weights to each input": 1.0,
    "to each input feature": 1.0,
    "each input feature .": 1.0,
    "<s> such models have": 0.5,
    "such models have the": 1.0,
    "models have the advantage": 1.0,
    "have the advantage that": 1.0,
    "the advantage that they": 1.0,
    "advantage that they can": 1.0,
    "that they can express": 0.3333333333333333,
    "they can express the": 0.5,
    "can express the relative": 0.5,
    "express the relative certainty": 1.0,
    "the relative certainty of": 1.0,
    "relative certainty of many": 1.0,
    "certainty of many different": 1.0,
    "of many different possible": 0.5,
    "many different possible answers": 1.0,
    "different possible answers rather": 1.0,
    "possible answers rather than": 1.0,
    "answers rather than only": 1.0,
    "rather than only one": 0.5,
    "than only one ,": 1.0,
    "only one , producing": 1.0,
    "one , producing more": 1.0,
    ", producing more reliable": 1.0,
    "producing more reliable results": 1.0,
    "reliable results when such": 0.5,
    "results when such a": 1.0,
    "when such a model": 1.0,
    "such a model is": 1.0,
    "a model is included": 1.0,
    "model is included as": 1.0,
    "is included as a": 1.0,
    "included as a component": 1.0,
    "as a component of": 1.0,
    "a component of a": 1.0,
    "component of a larger": 0.5,
    "of a larger system": 0.5,
    "a larger system .": 0.5,
    "<s> in addition ,": 0.6666666666666666,
    "in addition , models": 0.5,
    "addition , models that": 1.0,
    ", models that make": 1.0,
    "models that make soft": 1.0,
    "that make soft decisions": 1.0,
    "make soft decisions are": 0.5,
    "soft decisions are generally": 1.0,
    "decisions are generally more": 1.0,
    "real-world data -rrb- .": 0.5,
    "<s> systems based on": 1.0,
    "systems based on machine-learning": 0.2,
    "based on machine-learning algorithms": 1.0,
    "on machine-learning algorithms have": 1.0,
    "machine-learning algorithms have many": 1.0,
    "algorithms have many advantages": 1.0,
    "have many advantages over": 1.0,
    "many advantages over hand-produced": 1.0,
    "advantages over hand-produced rules": 1.0,
    "over hand-produced rules :": 1.0,
    "hand-produced rules : the": 1.0,
    "rules : the learning": 1.0,
    ": the learning procedures": 1.0,
    "the learning procedures used": 1.0,
    "learning procedures used during": 1.0,
    "procedures used during machine": 1.0,
    "used during machine learning": 1.0,
    "during machine learning automatically": 1.0,
    "machine learning automatically focus": 1.0,
    "learning automatically focus on": 1.0,
    "automatically focus on the": 1.0,
    "focus on the most": 1.0,
    "on the most common": 1.0,
    "the most common cases": 0.16666666666666666,
    "most common cases ,": 1.0,
    "common cases , whereas": 1.0,
    "cases , whereas when": 1.0,
    ", whereas when writing": 1.0,
    "whereas when writing rules": 1.0,
    "when writing rules by": 1.0,
    "writing rules by hand": 1.0,
    "rules by hand it": 1.0,
    "by hand it is": 1.0,
    "hand it is often": 1.0,
    "it is often not": 0.16666666666666666,
    "is often not obvious": 0.5,
    "often not obvious at": 1.0,
    "not obvious at all": 1.0,
    "obvious at all where": 1.0,
    "at all where the": 1.0,
    "all where the effort": 1.0,
    "where the effort should": 1.0,
    "the effort should be": 1.0,
    "effort should be directed": 1.0,
    "should be directed .": 1.0,
    "<s> automatic learning procedures": 1.0,
    "automatic learning procedures can": 1.0,
    "learning procedures can make": 1.0,
    "procedures can make use": 1.0,
    "can make use of": 1.0,
    "make use of statistical": 1.0,
    "use of statistical inference": 1.0,
    "of statistical inference algorithms": 1.0,
    "statistical inference algorithms to": 1.0,
    "inference algorithms to produce": 1.0,
    "algorithms to produce models": 1.0,
    "to produce models that": 1.0,
    "produce models that are": 1.0,
    "models that are robust": 1.0,
    "that are robust to": 1.0,
    "are robust to unfamiliar": 1.0,
    "robust to unfamiliar input": 1.0,
    "to unfamiliar input -lrb-": 1.0,
    "unfamiliar input -lrb- e.g.": 1.0,
    "input -lrb- e.g. containing": 0.5,
    "-lrb- e.g. containing words": 1.0,
    "e.g. containing words or": 1.0,
    "containing words or structures": 1.0,
    "words or structures that": 1.0,
    "or structures that have": 1.0,
    "structures that have not": 1.0,
    "that have not been": 1.0,
    "have not been seen": 1.0,
    "not been seen before": 1.0,
    "been seen before -rrb-": 0.5,
    "seen before -rrb- and": 1.0,
    "before -rrb- and to": 1.0,
    "-rrb- and to erroneous": 1.0,
    "and to erroneous input": 1.0,
    "to erroneous input -lrb-": 1.0,
    "erroneous input -lrb- e.g.": 1.0,
    "input -lrb- e.g. with": 0.5,
    "-lrb- e.g. with misspelled": 1.0,
    "e.g. with misspelled words": 1.0,
    "with misspelled words or": 1.0,
    "misspelled words or words": 1.0,
    "words or words accidentally": 1.0,
    "or words accidentally omitted": 1.0,
    "words accidentally omitted -rrb-": 1.0,
    "accidentally omitted -rrb- .": 1.0,
    "<s> generally , handling": 0.3333333333333333,
    "generally , handling such": 1.0,
    ", handling such input": 1.0,
    "handling such input gracefully": 1.0,
    "such input gracefully with": 1.0,
    "input gracefully with hand-written": 1.0,
    "gracefully with hand-written rules": 1.0,
    "with hand-written rules --": 1.0,
    "hand-written rules -- or": 1.0,
    "rules -- or more": 1.0,
    "-- or more generally": 1.0,
    "or more generally ,": 1.0,
    "more generally , creating": 1.0,
    "generally , creating systems": 1.0,
    ", creating systems of": 1.0,
    "creating systems of hand-written": 1.0,
    "hand-written rules that make": 0.5,
    "rules that make soft": 1.0,
    "make soft decisions --": 0.5,
    "soft decisions -- is": 1.0,
    "decisions -- is extremely": 1.0,
    "-- is extremely difficult": 1.0,
    "is extremely difficult ,": 1.0,
    "extremely difficult , error-prone": 1.0,
    "difficult , error-prone and": 1.0,
    ", error-prone and time-consuming": 1.0,
    "error-prone and time-consuming .": 1.0,
    "systems based on automatically": 0.2,
    "based on automatically learning": 1.0,
    "on automatically learning the": 1.0,
    "automatically learning the rules": 1.0,
    "learning the rules can": 1.0,
    "the rules can be": 1.0,
    "rules can be made": 0.5,
    "can be made more": 0.5,
    "be made more accurate": 1.0,
    "made more accurate simply": 0.5,
    "more accurate simply by": 1.0,
    "accurate simply by supplying": 1.0,
    "simply by supplying more": 1.0,
    "by supplying more input": 1.0,
    "supplying more input data": 1.0,
    "more input data .": 1.0,
    "<s> however , systems": 0.03125,
    "however , systems based": 1.0,
    ", systems based on": 1.0,
    "systems based on hand-written": 0.2,
    "based on hand-written rules": 1.0,
    "on hand-written rules can": 1.0,
    "hand-written rules can only": 1.0,
    "rules can only be": 1.0,
    "can only be made": 1.0,
    "only be made more": 1.0,
    "made more accurate by": 0.5,
    "more accurate by increasing": 1.0,
    "accurate by increasing the": 1.0,
    "by increasing the complexity": 1.0,
    "increasing the complexity of": 1.0,
    "the complexity of the": 0.75,
    "complexity of the rules": 0.16666666666666666,
    "of the rules ,": 0.5,
    "the rules , which": 1.0,
    "rules , which is": 0.5,
    ", which is a": 0.14285714285714285,
    "which is a much": 0.5,
    "is a much more": 1.0,
    "a much more difficult": 1.0,
    "much more difficult task": 0.3333333333333333,
    "more difficult task .": 1.0,
    "<s> in particular ,": 1.0,
    "in particular , there": 0.3333333333333333,
    "particular , there is": 1.0,
    ", there is a": 0.3333333333333333,
    "there is a limit": 0.25,
    "is a limit to": 1.0,
    "a limit to the": 1.0,
    "limit to the complexity": 1.0,
    "to the complexity of": 1.0,
    "the complexity of systems": 0.125,
    "complexity of systems based": 1.0,
    "of systems based on": 1.0,
    "systems based on hand-crafted": 0.2,
    "based on hand-crafted rules": 1.0,
    "on hand-crafted rules ,": 1.0,
    "hand-crafted rules , beyond": 1.0,
    "rules , beyond which": 1.0,
    ", beyond which the": 1.0,
    "beyond which the systems": 1.0,
    "which the systems become": 1.0,
    "the systems become more": 1.0,
    "systems become more and": 1.0,
    "become more and more": 1.0,
    "more and more unmanageable": 0.5,
    "and more unmanageable .": 1.0,
    "<s> however , creating": 0.03125,
    "however , creating more": 1.0,
    ", creating more data": 1.0,
    "creating more data to": 1.0,
    "more data to input": 1.0,
    "data to input to": 1.0,
    "to input to machine-learning": 1.0,
    "input to machine-learning systems": 1.0,
    "to machine-learning systems simply": 1.0,
    "machine-learning systems simply requires": 1.0,
    "systems simply requires a": 1.0,
    "simply requires a corresponding": 1.0,
    "requires a corresponding increase": 1.0,
    "a corresponding increase in": 1.0,
    "corresponding increase in the": 1.0,
    "increase in the number": 1.0,
    "in the number of": 1.0,
    "the number of man-hours": 0.2,
    "number of man-hours worked": 1.0,
    "of man-hours worked ,": 1.0,
    "man-hours worked , generally": 1.0,
    "worked , generally without": 1.0,
    ", generally without significant": 1.0,
    "generally without significant increases": 1.0,
    "without significant increases in": 1.0,
    "significant increases in the": 1.0,
    "increases in the complexity": 1.0,
    "in the complexity of": 1.0,
    "complexity of the annotation": 0.16666666666666666,
    "of the annotation process": 1.0,
    "the annotation process .": 1.0,
    "<s> major tasks in": 1.0,
    "major tasks in nlp": 1.0,
    "tasks in nlp the": 0.5,
    "in nlp the following": 0.5,
    "nlp the following is": 1.0,
    "the following is a": 1.0,
    "following is a list": 1.0,
    "is a list of": 1.0,
    "a list of some": 0.16666666666666666,
    "list of some of": 1.0,
    "of some of the": 1.0,
    "some of the most": 0.1,
    "of the most commonly": 0.16666666666666666,
    "the most commonly researched": 1.0,
    "most commonly researched tasks": 1.0,
    "commonly researched tasks in": 1.0,
    "researched tasks in nlp": 1.0,
    "tasks in nlp .": 0.5,
    "<s> note that some": 0.2857142857142857,
    "note that some of": 0.5,
    "that some of these": 1.0,
    "some of these tasks": 0.5,
    "of these tasks have": 1.0,
    "these tasks have direct": 1.0,
    "tasks have direct real-world": 1.0,
    "have direct real-world applications": 1.0,
    "direct real-world applications ,": 1.0,
    "real-world applications , while": 1.0,
    "applications , while others": 1.0,
    ", while others more": 0.3333333333333333,
    "while others more commonly": 1.0,
    "others more commonly serve": 1.0,
    "more commonly serve as": 1.0,
    "commonly serve as subtasks": 1.0,
    "serve as subtasks that": 1.0,
    "as subtasks that are": 1.0,
    "subtasks that are used": 1.0,
    "that are used to": 1.0,
    "are used to aid": 0.5,
    "used to aid in": 1.0,
    "to aid in solving": 1.0,
    "aid in solving larger": 1.0,
    "in solving larger tasks": 1.0,
    "solving larger tasks .": 1.0,
    "<s> what distinguishes these": 1.0,
    "what distinguishes these tasks": 1.0,
    "distinguishes these tasks from": 1.0,
    "these tasks from other": 1.0,
    "tasks from other potential": 1.0,
    "from other potential and": 1.0,
    "other potential and actual": 1.0,
    "potential and actual nlp": 1.0,
    "and actual nlp tasks": 1.0,
    "actual nlp tasks is": 1.0,
    "nlp tasks is not": 1.0,
    "tasks is not only": 1.0,
    "is not only the": 1.0,
    "not only the volume": 0.5,
    "only the volume of": 1.0,
    "the volume of research": 1.0,
    "volume of research devoted": 1.0,
    "of research devoted to": 1.0,
    "research devoted to them": 1.0,
    "devoted to them but": 1.0,
    "to them but the": 1.0,
    "them but the fact": 1.0,
    "but the fact that": 1.0,
    "the fact that for": 0.2,
    "fact that for each": 1.0,
    "that for each one": 1.0,
    "for each one there": 1.0,
    "each one there is": 1.0,
    "one there is typically": 1.0,
    "there is typically a": 1.0,
    "is typically a well-defined": 1.0,
    "typically a well-defined problem": 1.0,
    "a well-defined problem setting": 1.0,
    "well-defined problem setting ,": 1.0,
    "problem setting , a": 1.0,
    "setting , a standard": 1.0,
    ", a standard metric": 1.0,
    "a standard metric for": 1.0,
    "standard metric for evaluating": 1.0,
    "metric for evaluating the": 1.0,
    "for evaluating the task": 1.0,
    "evaluating the task ,": 1.0,
    "the task , standard": 1.0,
    "task , standard corpora": 1.0,
    ", standard corpora on": 1.0,
    "standard corpora on which": 1.0,
    "corpora on which the": 1.0,
    "on which the task": 1.0,
    "which the task can": 1.0,
    "the task can be": 1.0,
    "task can be evaluated": 1.0,
    "can be evaluated ,": 0.5,
    "be evaluated , and": 1.0,
    "evaluated , and competitions": 1.0,
    ", and competitions devoted": 1.0,
    "and competitions devoted to": 1.0,
    "competitions devoted to the": 1.0,
    "devoted to the specific": 1.0,
    "to the specific task": 1.0,
    "the specific task .": 1.0,
    "<s> automatic summarization :": 0.5,
    "automatic summarization : produce": 1.0,
    "summarization : produce a": 1.0,
    ": produce a readable": 1.0,
    "produce a readable summary": 1.0,
    "a readable summary of": 1.0,
    "readable summary of a": 1.0,
    "summary of a chunk": 1.0,
    "of a chunk of": 1.0,
    "a chunk of text": 0.8333333333333334,
    "chunk of text .": 0.16666666666666666,
    "<s> often used to": 1.0,
    "often used to provide": 1.0,
    "used to provide summaries": 1.0,
    "to provide summaries of": 1.0,
    "provide summaries of text": 1.0,
    "summaries of text of": 1.0,
    "of text of a": 1.0,
    "text of a known": 1.0,
    "of a known type": 1.0,
    "a known type ,": 1.0,
    "known type , such": 1.0,
    "type , such as": 1.0,
    ", such as articles": 0.030303030303030304,
    "such as articles in": 1.0,
    "as articles in the": 1.0,
    "articles in the financial": 1.0,
    "in the financial section": 1.0,
    "the financial section of": 1.0,
    "financial section of a": 1.0,
    "section of a newspaper": 1.0,
    "of a newspaper .": 1.0,
    "<s> coreference resolution :": 1.0,
    "coreference resolution : given": 1.0,
    "resolution : given a": 1.0,
    ": given a sentence": 0.2222222222222222,
    "given a sentence or": 0.5,
    "a sentence or larger": 0.5,
    "sentence or larger chunk": 1.0,
    "or larger chunk of": 1.0,
    "larger chunk of text": 1.0,
    "chunk of text ,": 0.6666666666666666,
    "of text , determine": 0.2,
    "text , determine which": 0.6666666666666666,
    ", determine which words": 0.5,
    "determine which words -lrb-": 1.0,
    "which words -lrb- ``": 1.0,
    "words -lrb- `` mentions": 1.0,
    "-lrb- `` mentions ''": 1.0,
    "`` mentions '' -rrb-": 1.0,
    "mentions '' -rrb- refer": 1.0,
    "'' -rrb- refer to": 1.0,
    "-rrb- refer to the": 1.0,
    "refer to the same": 0.5,
    "to the same objects": 1.0,
    "the same objects -lrb-": 1.0,
    "same objects -lrb- ``": 1.0,
    "objects -lrb- `` entities": 1.0,
    "-lrb- `` entities ''": 1.0,
    "`` entities '' -rrb-": 1.0,
    "entities '' -rrb- .": 1.0,
    "<s> anaphora resolution is": 1.0,
    "anaphora resolution is a": 1.0,
    "resolution is a specific": 1.0,
    "is a specific example": 1.0,
    "a specific example of": 1.0,
    "specific example of this": 1.0,
    "example of this task": 1.0,
    "of this task ,": 0.5,
    "this task , and": 1.0,
    "task , and is": 0.5,
    ", and is specifically": 0.3333333333333333,
    "and is specifically concerned": 1.0,
    "is specifically concerned with": 1.0,
    "specifically concerned with matching": 1.0,
    "concerned with matching up": 1.0,
    "with matching up pronouns": 1.0,
    "matching up pronouns with": 1.0,
    "up pronouns with the": 1.0,
    "pronouns with the nouns": 1.0,
    "with the nouns or": 1.0,
    "the nouns or names": 1.0,
    "nouns or names that": 1.0,
    "or names that they": 1.0,
    "names that they refer": 1.0,
    "that they refer to": 1.0,
    "they refer to .": 0.5,
    "<s> for example ,": 0.9142857142857143,
    "for example , in": 0.06382978723404255,
    "example , in a": 0.6666666666666666,
    ", in a sentence": 0.3333333333333333,
    "in a sentence such": 0.5,
    "a sentence such as": 1.0,
    "sentence such as ``": 1.0,
    "such as `` he": 0.125,
    "as `` he entered": 1.0,
    "`` he entered john": 1.0,
    "he entered john 's": 1.0,
    "entered john 's house": 1.0,
    "john 's house through": 0.5,
    "'s house through the": 1.0,
    "house through the front": 1.0,
    "through the front door": 1.0,
    "the front door ''": 0.6666666666666666,
    "front door '' ,": 0.5,
    "door '' , ``": 1.0,
    "'' , `` the": 0.09090909090909091,
    ", `` the front": 1.0,
    "`` the front door": 1.0,
    "front door '' is": 0.5,
    "door '' is a": 1.0,
    "'' is a referring": 0.3333333333333333,
    "is a referring expression": 1.0,
    "a referring expression and": 1.0,
    "referring expression and the": 1.0,
    "expression and the bridging": 0.5,
    "and the bridging relationship": 1.0,
    "the bridging relationship to": 1.0,
    "bridging relationship to be": 1.0,
    "relationship to be identified": 1.0,
    "to be identified is": 1.0,
    "be identified is the": 1.0,
    "identified is the fact": 1.0,
    "is the fact that": 1.0,
    "the fact that the": 0.4,
    "fact that the door": 0.5,
    "that the door being": 1.0,
    "the door being referred": 1.0,
    "door being referred to": 1.0,
    "being referred to is": 1.0,
    "referred to is the": 1.0,
    "to is the front": 1.0,
    "is the front door": 1.0,
    "the front door of": 0.3333333333333333,
    "front door of john": 1.0,
    "door of john 's": 1.0,
    "of john 's house": 1.0,
    "john 's house -lrb-": 0.5,
    "'s house -lrb- rather": 1.0,
    "house -lrb- rather than": 1.0,
    "-lrb- rather than of": 1.0,
    "rather than of some": 1.0,
    "than of some other": 1.0,
    "of some other structure": 0.5,
    "some other structure that": 1.0,
    "other structure that might": 1.0,
    "structure that might also": 1.0,
    "that might also be": 1.0,
    "might also be referred": 1.0,
    "also be referred to": 1.0,
    "be referred to -rrb-": 1.0,
    "referred to -rrb- .": 1.0,
    "<s> discourse analysis :": 0.3333333333333333,
    "discourse analysis : this": 0.5,
    "analysis : this rubric": 1.0,
    ": this rubric includes": 1.0,
    "this rubric includes a": 1.0,
    "rubric includes a number": 1.0,
    "includes a number of": 1.0,
    "a number of related": 0.045454545454545456,
    "number of related tasks": 1.0,
    "of related tasks .": 0.5,
    "<s> one task is": 1.0,
    "one task is identifying": 1.0,
    "task is identifying the": 1.0,
    "is identifying the discourse": 1.0,
    "identifying the discourse structure": 1.0,
    "the discourse structure of": 1.0,
    "discourse structure of connected": 1.0,
    "structure of connected text": 1.0,
    "of connected text ,": 1.0,
    "connected text , i.e.": 1.0,
    "text , i.e. the": 1.0,
    ", i.e. the nature": 0.5,
    "i.e. the nature of": 1.0,
    "nature of the discourse": 0.2,
    "of the discourse relationships": 1.0,
    "the discourse relationships between": 1.0,
    "discourse relationships between sentences": 1.0,
    "relationships between sentences -lrb-": 1.0,
    "between sentences -lrb- e.g.": 1.0,
    "sentences -lrb- e.g. elaboration": 0.5,
    "-lrb- e.g. elaboration ,": 1.0,
    "e.g. elaboration , explanation": 1.0,
    "elaboration , explanation ,": 1.0,
    ", explanation , contrast": 1.0,
    "explanation , contrast -rrb-": 1.0,
    ", contrast -rrb- .": 1.0,
    "<s> another possible task": 1.0,
    "another possible task is": 1.0,
    "possible task is recognizing": 1.0,
    "task is recognizing and": 1.0,
    "is recognizing and classifying": 1.0,
    "recognizing and classifying the": 1.0,
    "and classifying the speech": 1.0,
    "classifying the speech acts": 1.0,
    "the speech acts in": 1.0,
    "speech acts in a": 1.0,
    "acts in a chunk": 1.0,
    "in a chunk of": 1.0,
    "chunk of text -lrb-": 0.16666666666666666,
    "of text -lrb- e.g.": 1.0,
    "text -lrb- e.g. yes-no": 1.0,
    "-lrb- e.g. yes-no question": 1.0,
    "e.g. yes-no question ,": 1.0,
    "yes-no question , content": 1.0,
    "question , content question": 1.0,
    ", content question ,": 1.0,
    "content question , statement": 1.0,
    "question , statement ,": 1.0,
    ", statement , assertion": 1.0,
    "statement , assertion ,": 1.0,
    ", assertion , etc.": 1.0,
    "assertion , etc. -rrb-": 1.0,
    ", etc. -rrb- .": 0.2222222222222222,
    "<s> machine translation :": 0.3333333333333333,
    "machine translation : automatically": 0.5,
    "translation : automatically translate": 1.0,
    ": automatically translate text": 1.0,
    "automatically translate text from": 1.0,
    "translate text from one": 1.0,
    "text from one human": 1.0,
    "from one human language": 1.0,
    "one human language to": 1.0,
    "human language to another": 1.0,
    "language to another .": 1.0,
    "<s> this is one": 0.07142857142857142,
    "this is one of": 1.0,
    "is one of the": 0.6666666666666666,
    "one of the most": 0.16666666666666666,
    "of the most difficult": 0.16666666666666666,
    "the most difficult problems": 1.0,
    "most difficult problems ,": 1.0,
    "difficult problems , and": 1.0,
    "problems , and is": 1.0,
    ", and is a": 0.3333333333333333,
    "and is a member": 1.0,
    "is a member of": 1.0,
    "a member of a": 1.0,
    "member of a class": 1.0,
    "of a class of": 1.0,
    "a class of problems": 1.0,
    "class of problems colloquially": 1.0,
    "of problems colloquially termed": 1.0,
    "problems colloquially termed ``": 1.0,
    "colloquially termed `` ai-complete": 1.0,
    "termed `` ai-complete ''": 1.0,
    "`` ai-complete '' ,": 0.5,
    "ai-complete '' , i.e.": 1.0,
    "'' , i.e. requiring": 1.0,
    ", i.e. requiring all": 1.0,
    "i.e. requiring all of": 1.0,
    "requiring all of the": 1.0,
    "all of the different": 0.3333333333333333,
    "of the different types": 1.0,
    "the different types of": 1.0,
    "different types of knowledge": 0.25,
    "types of knowledge that": 1.0,
    "of knowledge that humans": 1.0,
    "knowledge that humans possess": 1.0,
    "that humans possess -lrb-": 1.0,
    "humans possess -lrb- grammar": 1.0,
    "possess -lrb- grammar ,": 1.0,
    "-lrb- grammar , semantics": 1.0,
    "grammar , semantics ,": 1.0,
    ", semantics , facts": 0.3333333333333333,
    "semantics , facts about": 1.0,
    ", facts about the": 1.0,
    "facts about the real": 1.0,
    "about the real world": 1.0,
    "the real world ,": 0.5,
    "real world , etc.": 1.0,
    "world , etc. -rrb-": 1.0,
    ", etc. -rrb- in": 0.1111111111111111,
    "etc. -rrb- in order": 1.0,
    "-rrb- in order to": 1.0,
    "in order to solve": 0.125,
    "order to solve properly": 1.0,
    "to solve properly .": 1.0,
    "<s> morphological segmentation :": 1.0,
    "morphological segmentation : separate": 1.0,
    "segmentation : separate words": 0.5,
    ": separate words into": 1.0,
    "separate words into individual": 1.0,
    "words into individual morphemes": 1.0,
    "into individual morphemes and": 1.0,
    "individual morphemes and identify": 1.0,
    "morphemes and identify the": 1.0,
    "and identify the class": 0.5,
    "identify the class of": 1.0,
    "the class of the": 1.0,
    "class of the morphemes": 1.0,
    "of the morphemes .": 1.0,
    "<s> the difficulty of": 0.6666666666666666,
    "the difficulty of this": 0.6666666666666666,
    "difficulty of this task": 0.5,
    "of this task depends": 0.5,
    "this task depends greatly": 1.0,
    "task depends greatly on": 1.0,
    "depends greatly on the": 1.0,
    "greatly on the complexity": 1.0,
    "on the complexity of": 1.0,
    "complexity of the morphology": 0.16666666666666666,
    "of the morphology -lrb-": 1.0,
    "the morphology -lrb- i.e.": 1.0,
    "morphology -lrb- i.e. the": 1.0,
    "-lrb- i.e. the structure": 0.3333333333333333,
    "i.e. the structure of": 1.0,
    "the structure of words": 0.3333333333333333,
    "structure of words -rrb-": 1.0,
    "of words -rrb- of": 0.5,
    "words -rrb- of the": 1.0,
    "-rrb- of the language": 0.3333333333333333,
    "of the language being": 0.3333333333333333,
    "the language being considered": 0.5,
    "language being considered .": 1.0,
    "<s> english has fairly": 1.0,
    "english has fairly simple": 1.0,
    "has fairly simple morphology": 1.0,
    "fairly simple morphology ,": 1.0,
    "simple morphology , especially": 1.0,
    "morphology , especially inflectional": 1.0,
    ", especially inflectional morphology": 1.0,
    "especially inflectional morphology ,": 1.0,
    "inflectional morphology , and": 0.5,
    "morphology , and thus": 0.5,
    ", and thus it": 0.5,
    "and thus it is": 1.0,
    "thus it is often": 1.0,
    "it is often possible": 0.16666666666666666,
    "is often possible to": 1.0,
    "often possible to ignore": 1.0,
    "possible to ignore this": 1.0,
    "to ignore this task": 1.0,
    "ignore this task entirely": 1.0,
    "this task entirely and": 1.0,
    "task entirely and simply": 1.0,
    "entirely and simply model": 1.0,
    "and simply model all": 1.0,
    "simply model all possible": 1.0,
    "model all possible forms": 1.0,
    "all possible forms of": 1.0,
    "possible forms of a": 1.0,
    "forms of a word": 1.0,
    "of a word -lrb-": 0.3333333333333333,
    "a word -lrb- e.g.": 1.0,
    "word -lrb- e.g. ``": 1.0,
    "-lrb- e.g. `` open": 1.0,
    "e.g. `` open ,": 1.0,
    "`` open , opens": 1.0,
    "open , opens ,": 1.0,
    ", opens , opened": 1.0,
    "opens , opened ,": 1.0,
    ", opened , opening": 1.0,
    "opened , opening ''": 1.0,
    ", opening '' -rrb-": 1.0,
    "opening '' -rrb- as": 1.0,
    "'' -rrb- as separate": 1.0,
    "-rrb- as separate words": 1.0,
    "as separate words .": 1.0,
    "<s> in languages such": 1.0,
    "in languages such as": 1.0,
    "languages such as turkish": 0.25,
    "such as turkish ,": 1.0,
    "as turkish , however": 1.0,
    "turkish , however ,": 1.0,
    ", however , such": 0.09090909090909091,
    "however , such an": 0.5,
    ", such an approach": 1.0,
    "such an approach is": 1.0,
    "an approach is not": 0.5,
    "approach is not possible": 1.0,
    "is not possible ,": 1.0,
    "not possible , as": 1.0,
    "possible , as each": 0.5,
    ", as each dictionary": 1.0,
    "as each dictionary entry": 1.0,
    "each dictionary entry has": 1.0,
    "dictionary entry has thousands": 1.0,
    "entry has thousands of": 1.0,
    "has thousands of possible": 1.0,
    "thousands of possible word": 1.0,
    "of possible word forms": 1.0,
    "possible word forms .": 1.0,
    "<s> named entity recognition": 1.0,
    "named entity recognition -lrb-": 0.5,
    "entity recognition -lrb- ner": 1.0,
    "recognition -lrb- ner -rrb-": 1.0,
    "-lrb- ner -rrb- :": 1.0,
    "ner -rrb- : given": 1.0,
    "-rrb- : given a": 0.6666666666666666,
    ": given a stream": 0.1111111111111111,
    "given a stream of": 1.0,
    "a stream of text": 1.0,
    "stream of text ,": 1.0,
    ", determine which items": 0.5,
    "determine which items in": 1.0,
    "which items in the": 1.0,
    "items in the text": 1.0,
    "in the text map": 0.125,
    "the text map to": 1.0,
    "text map to proper": 1.0,
    "map to proper names": 1.0,
    "to proper names ,": 1.0,
    "proper names , such": 1.0,
    "names , such as": 1.0,
    ", such as people": 0.030303030303030304,
    "such as people or": 1.0,
    "as people or places": 1.0,
    "people or places ,": 1.0,
    "or places , and": 1.0,
    "places , and what": 1.0,
    ", and what the": 1.0,
    "and what the type": 1.0,
    "what the type of": 1.0,
    "the type of each": 0.25,
    "type of each such": 1.0,
    "of each such name": 1.0,
    "each such name is": 1.0,
    "such name is -lrb-": 1.0,
    "name is -lrb- e.g.": 1.0,
    "is -lrb- e.g. person": 0.5,
    "-lrb- e.g. person ,": 1.0,
    "e.g. person , location": 1.0,
    "person , location ,": 1.0,
    ", location , organization": 1.0,
    "location , organization -rrb-": 1.0,
    ", organization -rrb- .": 1.0,
    "<s> note that ,": 0.14285714285714285,
    "note that , although": 1.0,
    "that , although capitalization": 1.0,
    ", although capitalization can": 1.0,
    "although capitalization can aid": 1.0,
    "capitalization can aid in": 1.0,
    "can aid in recognizing": 1.0,
    "aid in recognizing named": 1.0,
    "in recognizing named entities": 1.0,
    "recognizing named entities in": 1.0,
    "named entities in languages": 1.0,
    "entities in languages such": 1.0,
    "languages such as english": 0.25,
    "such as english ,": 0.3333333333333333,
    "as english , this": 1.0,
    "english , this information": 0.5,
    ", this information can": 1.0,
    "this information can not": 1.0,
    "information can not aid": 1.0,
    "can not aid in": 1.0,
    "not aid in determining": 1.0,
    "aid in determining the": 1.0,
    "in determining the type": 1.0,
    "determining the type of": 1.0,
    "the type of named": 0.25,
    "type of named entity": 1.0,
    "of named entity ,": 1.0,
    "named entity , and": 1.0,
    "entity , and in": 1.0,
    ", and in any": 0.5,
    "and in any case": 1.0,
    "in any case is": 0.3333333333333333,
    "any case is often": 1.0,
    "case is often inaccurate": 1.0,
    "is often inaccurate or": 1.0,
    "often inaccurate or insufficient": 1.0,
    "inaccurate or insufficient .": 1.0,
    "for example , the": 0.0851063829787234,
    "example , the first": 0.25,
    ", the first word": 0.3333333333333333,
    "the first word of": 1.0,
    "first word of a": 1.0,
    "word of a sentence": 1.0,
    "of a sentence is": 0.5,
    "a sentence is also": 1.0,
    "sentence is also capitalized": 1.0,
    "is also capitalized ,": 1.0,
    "also capitalized , and": 1.0,
    "capitalized , and named": 1.0,
    ", and named entities": 1.0,
    "and named entities often": 1.0,
    "named entities often span": 1.0,
    "entities often span several": 1.0,
    "often span several words": 1.0,
    "span several words ,": 1.0,
    "several words , only": 1.0,
    "words , only some": 1.0,
    ", only some of": 1.0,
    "only some of which": 1.0,
    "some of which are": 1.0,
    "of which are capitalized": 0.25,
    "which are capitalized .": 1.0,
    "<s> furthermore , many": 0.16666666666666666,
    "furthermore , many other": 1.0,
    ", many other languages": 1.0,
    "many other languages in": 0.3333333333333333,
    "other languages in non-western": 1.0,
    "languages in non-western scripts": 1.0,
    "in non-western scripts -lrb-": 1.0,
    "non-western scripts -lrb- e.g.": 1.0,
    "scripts -lrb- e.g. chinese": 1.0,
    "-lrb- e.g. chinese or": 1.0,
    "e.g. chinese or arabic": 1.0,
    "chinese or arabic -rrb-": 1.0,
    "or arabic -rrb- do": 1.0,
    "arabic -rrb- do not": 1.0,
    "-rrb- do not have": 1.0,
    "do not have any": 0.5,
    "not have any capitalization": 1.0,
    "have any capitalization at": 1.0,
    "any capitalization at all": 1.0,
    "capitalization at all ,": 1.0,
    "at all , and": 0.5,
    "all , and even": 1.0,
    ", and even languages": 0.16666666666666666,
    "and even languages with": 1.0,
    "even languages with capitalization": 1.0,
    "languages with capitalization may": 1.0,
    "with capitalization may not": 1.0,
    "capitalization may not consistently": 1.0,
    "may not consistently use": 1.0,
    "not consistently use it": 1.0,
    "consistently use it to": 1.0,
    "use it to distinguish": 0.5,
    "it to distinguish names": 1.0,
    "to distinguish names .": 1.0,
    "for example , german": 0.02127659574468085,
    "example , german capitalizes": 1.0,
    ", german capitalizes all": 1.0,
    "german capitalizes all nouns": 1.0,
    "capitalizes all nouns ,": 1.0,
    "all nouns , regardless": 1.0,
    "nouns , regardless of": 1.0,
    ", regardless of whether": 0.3333333333333333,
    "regardless of whether they": 1.0,
    "of whether they refer": 1.0,
    "whether they refer to": 1.0,
    "they refer to names": 0.5,
    "refer to names ,": 1.0,
    "to names , and": 1.0,
    "names , and french": 1.0,
    ", and french and": 1.0,
    "and french and spanish": 1.0,
    "french and spanish do": 1.0,
    "and spanish do not": 1.0,
    "spanish do not capitalize": 1.0,
    "do not capitalize names": 1.0,
    "not capitalize names that": 1.0,
    "capitalize names that serve": 1.0,
    "names that serve as": 1.0,
    "that serve as adjectives": 1.0,
    "serve as adjectives .": 1.0,
    "<s> natural language generation": 0.2857142857142857,
    "natural language generation :": 0.2,
    "language generation : convert": 1.0,
    "generation : convert information": 1.0,
    ": convert information from": 1.0,
    "convert information from computer": 1.0,
    "information from computer databases": 1.0,
    "from computer databases into": 1.0,
    "computer databases into readable": 1.0,
    "databases into readable human": 1.0,
    "into readable human language": 1.0,
    "readable human language .": 1.0,
    "natural language understanding :": 0.08333333333333333,
    "language understanding : convert": 1.0,
    "understanding : convert chunks": 1.0,
    ": convert chunks of": 1.0,
    "convert chunks of text": 1.0,
    "chunks of text into": 1.0,
    "of text into more": 0.5,
    "text into more formal": 1.0,
    "into more formal representations": 1.0,
    "more formal representations such": 1.0,
    "formal representations such as": 1.0,
    "representations such as first-order": 1.0,
    "such as first-order logic": 1.0,
    "as first-order logic structures": 1.0,
    "first-order logic structures that": 1.0,
    "logic structures that are": 1.0,
    "structures that are easier": 1.0,
    "that are easier for": 1.0,
    "are easier for computer": 1.0,
    "easier for computer programs": 1.0,
    "for computer programs to": 1.0,
    "computer programs to manipulate": 1.0,
    "programs to manipulate .": 1.0,
    "natural language understanding involves": 0.08333333333333333,
    "language understanding involves the": 1.0,
    "understanding involves the identification": 1.0,
    "involves the identification of": 1.0,
    "the identification of the": 0.5,
    "identification of the intended": 1.0,
    "of the intended semantic": 1.0,
    "the intended semantic from": 1.0,
    "intended semantic from the": 1.0,
    "semantic from the multiple": 1.0,
    "from the multiple possible": 1.0,
    "the multiple possible semantics": 1.0,
    "multiple possible semantics which": 1.0,
    "possible semantics which can": 1.0,
    "semantics which can be": 1.0,
    "which can be derived": 0.5,
    "can be derived from": 1.0,
    "be derived from a": 0.5,
    "derived from a natural": 1.0,
    "from a natural language": 1.0,
    "a natural language expression": 0.25,
    "natural language expression which": 1.0,
    "language expression which usually": 1.0,
    "expression which usually takes": 1.0,
    "which usually takes the": 1.0,
    "usually takes the form": 1.0,
    "takes the form of": 1.0,
    "the form of organized": 1.0,
    "form of organized notations": 1.0,
    "of organized notations of": 1.0,
    "organized notations of natural": 1.0,
    "notations of natural languages": 1.0,
    "of natural languages concepts": 0.2,
    "natural languages concepts .": 1.0,
    "<s> introduction and creation": 1.0,
    "introduction and creation of": 1.0,
    "and creation of language": 1.0,
    "creation of language metamodel": 1.0,
    "of language metamodel and": 1.0,
    "language metamodel and ontology": 1.0,
    "metamodel and ontology are": 1.0,
    "and ontology are efficient": 1.0,
    "ontology are efficient however": 1.0,
    "are efficient however empirical": 1.0,
    "efficient however empirical solutions": 1.0,
    "however empirical solutions .": 1.0,
    "<s> an explicit formalization": 1.0,
    "an explicit formalization of": 1.0,
    "explicit formalization of natural": 1.0,
    "formalization of natural languages": 1.0,
    "of natural languages semantics": 0.2,
    "natural languages semantics without": 1.0,
    "languages semantics without confusions": 1.0,
    "semantics without confusions with": 1.0,
    "without confusions with implicit": 1.0,
    "confusions with implicit assumptions": 1.0,
    "with implicit assumptions such": 1.0,
    "implicit assumptions such as": 1.0,
    "assumptions such as closed": 1.0,
    "such as closed world": 1.0,
    "as closed world assumption": 1.0,
    "closed world assumption -lrb-": 1.0,
    "world assumption -lrb- cwa": 1.0,
    "assumption -lrb- cwa -rrb-": 1.0,
    "-lrb- cwa -rrb- vs.": 1.0,
    "cwa -rrb- vs. open": 1.0,
    "-rrb- vs. open world": 1.0,
    "vs. open world assumption": 1.0,
    "open world assumption ,": 1.0,
    "world assumption , or": 1.0,
    "assumption , or subjective": 1.0,
    ", or subjective yes\\/no": 1.0,
    "or subjective yes\\/no vs.": 1.0,
    "subjective yes\\/no vs. objective": 1.0,
    "yes\\/no vs. objective true\\/false": 1.0,
    "vs. objective true\\/false is": 1.0,
    "objective true\\/false is expected": 1.0,
    "true\\/false is expected for": 1.0,
    "is expected for the": 1.0,
    "expected for the construction": 1.0,
    "for the construction of": 1.0,
    "the construction of a": 1.0,
    "construction of a basis": 0.5,
    "of a basis of": 1.0,
    "a basis of semantics": 1.0,
    "basis of semantics formalization": 1.0,
    "of semantics formalization .": 1.0,
    "<s> optical character recognition": 1.0,
    "optical character recognition -lrb-": 0.4,
    "character recognition -lrb- ocr": 0.5,
    "recognition -lrb- ocr -rrb-": 1.0,
    "-lrb- ocr -rrb- :": 1.0,
    "ocr -rrb- : given": 1.0,
    "-rrb- : given an": 0.3333333333333333,
    ": given an image": 1.0,
    "given an image representing": 1.0,
    "an image representing printed": 1.0,
    "image representing printed text": 1.0,
    "representing printed text ,": 1.0,
    "printed text , determine": 1.0,
    "text , determine the": 0.3333333333333333,
    ", determine the corresponding": 0.3333333333333333,
    "determine the corresponding text": 1.0,
    "the corresponding text .": 1.0,
    "<s> part-of-speech tagging :": 1.0,
    "part-of-speech tagging : given": 1.0,
    "tagging : given a": 1.0,
    "given a sentence ,": 0.5,
    "a sentence , determine": 0.5,
    "sentence , determine the": 1.0,
    ", determine the part": 0.3333333333333333,
    "determine the part of": 1.0,
    "of speech for each": 0.25,
    "speech for each word": 1.0,
    "for each word .": 1.0,
    "<s> many words ,": 1.0,
    "many words , especially": 1.0,
    "words , especially common": 1.0,
    ", especially common ones": 1.0,
    "especially common ones ,": 1.0,
    "common ones , can": 1.0,
    "ones , can serve": 1.0,
    ", can serve as": 1.0,
    "can serve as multiple": 1.0,
    "serve as multiple parts": 1.0,
    "as multiple parts of": 1.0,
    "multiple parts of speech": 1.0,
    "parts of speech .": 0.18181818181818182,
    "for example , ``": 0.02127659574468085,
    "example , `` book": 0.5,
    ", `` book ''": 1.0,
    "`` book '' can": 1.0,
    "book '' can be": 1.0,
    "'' can be a": 0.4,
    "can be a noun": 0.6666666666666666,
    "be a noun -lrb-": 0.3333333333333333,
    "a noun -lrb- ``": 1.0,
    "noun -lrb- `` the": 1.0,
    "-lrb- `` the book": 1.0,
    "`` the book on": 1.0,
    "the book on the": 1.0,
    "book on the table": 1.0,
    "on the table ''": 1.0,
    "the table '' -rrb-": 1.0,
    "table '' -rrb- or": 1.0,
    "'' -rrb- or verb": 1.0,
    "-rrb- or verb -lrb-": 1.0,
    "or verb -lrb- ``": 1.0,
    "verb -lrb- `` to": 1.0,
    "-lrb- `` to book": 1.0,
    "`` to book a": 1.0,
    "to book a flight": 1.0,
    "book a flight ''": 1.0,
    "a flight '' -rrb-": 1.0,
    "flight '' -rrb- ;": 1.0,
    "'' -rrb- ; ``": 0.5,
    "-rrb- ; `` set": 1.0,
    "; `` set ''": 1.0,
    "`` set '' can": 1.0,
    "set '' can be": 1.0,
    "be a noun ,": 0.3333333333333333,
    "a noun , verb": 0.5,
    "noun , verb or": 0.5,
    ", verb or adjective": 1.0,
    "verb or adjective ;": 1.0,
    "or adjective ; and": 1.0,
    "adjective ; and ``": 1.0,
    "; and `` out": 1.0,
    "and `` out ''": 1.0,
    "`` out '' can": 1.0,
    "out '' can be": 1.0,
    "'' can be any": 0.2,
    "can be any of": 1.0,
    "be any of at": 1.0,
    "any of at least": 1.0,
    "of at least five": 1.0,
    "at least five different": 1.0,
    "least five different parts": 1.0,
    "five different parts of": 1.0,
    "different parts of speech": 0.5,
    "note that some languages": 0.5,
    "that some languages have": 1.0,
    "some languages have more": 1.0,
    "languages have more such": 1.0,
    "have more such ambiguity": 1.0,
    "more such ambiguity than": 1.0,
    "such ambiguity than others": 1.0,
    "ambiguity than others .": 1.0,
    "<s> languages with little": 1.0,
    "languages with little inflectional": 1.0,
    "with little inflectional morphology": 1.0,
    "little inflectional morphology ,": 1.0,
    "inflectional morphology , such": 0.5,
    "morphology , such as": 1.0,
    ", such as english": 0.030303030303030304,
    "such as english are": 0.3333333333333333,
    "as english are particularly": 1.0,
    "english are particularly prone": 1.0,
    "are particularly prone to": 1.0,
    "particularly prone to such": 1.0,
    "prone to such ambiguity": 1.0,
    "to such ambiguity .": 0.5,
    "<s> chinese is prone": 1.0,
    "chinese is prone to": 1.0,
    "is prone to such": 1.0,
    "to such ambiguity because": 0.5,
    "such ambiguity because it": 1.0,
    "ambiguity because it is": 1.0,
    "because it is a": 1.0,
    "it is a tonal": 0.16666666666666666,
    "is a tonal language": 1.0,
    "a tonal language during": 1.0,
    "tonal language during verbalization": 1.0,
    "language during verbalization .": 1.0,
    "<s> such inflection is": 1.0,
    "such inflection is not": 1.0,
    "inflection is not readily": 1.0,
    "is not readily conveyed": 1.0,
    "not readily conveyed via": 1.0,
    "readily conveyed via the": 1.0,
    "conveyed via the entities": 1.0,
    "via the entities employed": 1.0,
    "the entities employed within": 1.0,
    "entities employed within the": 1.0,
    "employed within the orthography": 1.0,
    "within the orthography to": 1.0,
    "the orthography to convey": 1.0,
    "orthography to convey intended": 1.0,
    "to convey intended meaning": 1.0,
    "convey intended meaning .": 1.0,
    "<s> parsing : determine": 1.0,
    "parsing : determine the": 1.0,
    ": determine the parse": 1.0,
    "determine the parse tree": 1.0,
    "the parse tree -lrb-": 1.0,
    "parse tree -lrb- grammatical": 1.0,
    "tree -lrb- grammatical analysis": 1.0,
    "-lrb- grammatical analysis -rrb-": 1.0,
    "grammatical analysis -rrb- of": 1.0,
    "analysis -rrb- of a": 1.0,
    "-rrb- of a given": 0.5,
    "of a given sentence": 0.5,
    "a given sentence .": 0.5,
    "<s> the grammar for": 0.5,
    "the grammar for natural": 1.0,
    "grammar for natural languages": 1.0,
    "for natural languages is": 1.0,
    "natural languages is ambiguous": 1.0,
    "languages is ambiguous and": 1.0,
    "is ambiguous and typical": 1.0,
    "ambiguous and typical sentences": 1.0,
    "and typical sentences have": 1.0,
    "typical sentences have multiple": 1.0,
    "sentences have multiple possible": 1.0,
    "have multiple possible analyses": 1.0,
    "multiple possible analyses .": 1.0,
    "<s> in fact ,": 1.0,
    "in fact , perhaps": 0.25,
    "fact , perhaps surprisingly": 1.0,
    ", perhaps surprisingly ,": 1.0,
    "perhaps surprisingly , for": 1.0,
    "surprisingly , for a": 1.0,
    ", for a typical": 0.5,
    "for a typical sentence": 1.0,
    "a typical sentence there": 1.0,
    "typical sentence there may": 1.0,
    "sentence there may be": 1.0,
    "there may be thousands": 1.0,
    "may be thousands of": 1.0,
    "be thousands of potential": 1.0,
    "thousands of potential parses": 1.0,
    "of potential parses -lrb-": 1.0,
    "potential parses -lrb- most": 1.0,
    "parses -lrb- most of": 1.0,
    "-lrb- most of which": 1.0,
    "most of which will": 1.0,
    "of which will seem": 1.0,
    "which will seem completely": 1.0,
    "will seem completely nonsensical": 1.0,
    "seem completely nonsensical to": 1.0,
    "completely nonsensical to a": 1.0,
    "nonsensical to a human": 1.0,
    "to a human -rrb-": 0.5,
    "a human -rrb- .": 0.5,
    "<s> question answering :": 0.5,
    "question answering : given": 1.0,
    "answering : given a": 1.0,
    ": given a human-language": 0.1111111111111111,
    "given a human-language question": 1.0,
    "a human-language question ,": 1.0,
    "human-language question , determine": 1.0,
    "question , determine its": 1.0,
    ", determine its answer": 1.0,
    "determine its answer .": 1.0,
    "<s> typical questions have": 1.0,
    "typical questions have a": 1.0,
    "questions have a specific": 1.0,
    "have a specific right": 1.0,
    "a specific right answer": 1.0,
    "specific right answer -lrb-": 1.0,
    "right answer -lrb- such": 1.0,
    "answer -lrb- such as": 1.0,
    "-lrb- such as ``": 0.25,
    "such as `` what": 0.25,
    "as `` what is": 1.0,
    "`` what is the": 1.0,
    "what is the capital": 0.6666666666666666,
    "is the capital of": 1.0,
    "the capital of canada": 0.5,
    "capital of canada ?": 1.0,
    "of canada ? ''": 1.0,
    "canada ? '' -rrb-": 1.0,
    "<s> , but sometimes": 1.0,
    ", but sometimes open-ended": 1.0,
    "but sometimes open-ended questions": 1.0,
    "sometimes open-ended questions are": 1.0,
    "open-ended questions are also": 1.0,
    "questions are also considered": 1.0,
    "are also considered -lrb-": 1.0,
    "also considered -lrb- such": 1.0,
    "considered -lrb- such as": 1.0,
    "what is the meaning": 0.3333333333333333,
    "is the meaning of": 1.0,
    "the meaning of life": 0.16666666666666666,
    "meaning of life ?": 1.0,
    "of life ? ''": 1.0,
    "life ? '' -rrb-": 1.0,
    "? '' -rrb- .": 1.0,
    "<s> relationship extraction :": 1.0,
    "relationship extraction : given": 1.0,
    "extraction : given a": 1.0,
    ": given a chunk": 0.3333333333333333,
    "given a chunk of": 1.0,
    "of text , identify": 0.1,
    "text , identify the": 1.0,
    ", identify the relationships": 1.0,
    "identify the relationships among": 1.0,
    "the relationships among named": 1.0,
    "relationships among named entities": 1.0,
    "among named entities -lrb-": 1.0,
    "named entities -lrb- e.g.": 1.0,
    "entities -lrb- e.g. who": 1.0,
    "-lrb- e.g. who is": 1.0,
    "e.g. who is the": 1.0,
    "who is the wife": 0.3333333333333333,
    "is the wife of": 1.0,
    "the wife of whom": 1.0,
    "wife of whom -rrb-": 1.0,
    "of whom -rrb- .": 1.0,
    "<s> sentence breaking -lrb-": 1.0,
    "sentence breaking -lrb- also": 1.0,
    "breaking -lrb- also known": 1.0,
    "-lrb- also known as": 1.0,
    "also known as sentence": 0.3333333333333333,
    "known as sentence boundary": 0.5,
    "as sentence boundary disambiguation": 1.0,
    "sentence boundary disambiguation -rrb-": 0.5,
    "boundary disambiguation -rrb- :": 1.0,
    "disambiguation -rrb- : given": 1.0,
    "of text , find": 0.1,
    "text , find the": 1.0,
    ", find the sentence": 1.0,
    "find the sentence boundaries": 1.0,
    "the sentence boundaries .": 1.0,
    "<s> sentence boundaries are": 1.0,
    "sentence boundaries are often": 1.0,
    "boundaries are often marked": 1.0,
    "are often marked by": 1.0,
    "often marked by periods": 1.0,
    "marked by periods or": 1.0,
    "by periods or other": 1.0,
    "periods or other punctuation": 1.0,
    "or other punctuation marks": 1.0,
    "other punctuation marks ,": 1.0,
    "punctuation marks , but": 1.0,
    "marks , but these": 1.0,
    ", but these same": 1.0,
    "but these same characters": 1.0,
    "these same characters can": 1.0,
    "same characters can serve": 1.0,
    "characters can serve other": 1.0,
    "can serve other purposes": 1.0,
    "serve other purposes -lrb-": 1.0,
    "other purposes -lrb- e.g.": 1.0,
    "purposes -lrb- e.g. marking": 1.0,
    "-lrb- e.g. marking abbreviations": 1.0,
    "e.g. marking abbreviations -rrb-": 1.0,
    "marking abbreviations -rrb- .": 1.0,
    "<s> sentiment analysis :": 0.2,
    "sentiment analysis : extract": 1.0,
    "analysis : extract subjective": 1.0,
    ": extract subjective information": 1.0,
    "extract subjective information usually": 0.5,
    "subjective information usually from": 1.0,
    "information usually from a": 1.0,
    "usually from a set": 1.0,
    "from a set of": 1.0,
    "set of documents ,": 0.3333333333333333,
    "of documents , often": 0.5,
    "documents , often using": 1.0,
    ", often using online": 1.0,
    "often using online reviews": 1.0,
    "using online reviews to": 1.0,
    "online reviews to determine": 1.0,
    "reviews to determine ``": 1.0,
    "to determine `` polarity": 1.0,
    "determine `` polarity ''": 1.0,
    "`` polarity '' about": 1.0,
    "polarity '' about specific": 1.0,
    "'' about specific objects": 1.0,
    "about specific objects .": 1.0,
    "<s> it is especially": 0.05263157894736842,
    "it is especially useful": 1.0,
    "is especially useful for": 1.0,
    "especially useful for identifying": 1.0,
    "useful for identifying trends": 1.0,
    "for identifying trends of": 1.0,
    "identifying trends of public": 1.0,
    "trends of public opinion": 1.0,
    "of public opinion in": 1.0,
    "public opinion in the": 1.0,
    "opinion in the social": 1.0,
    "in the social media": 1.0,
    "the social media ,": 1.0,
    "social media , for": 0.5,
    "media , for the": 1.0,
    ", for the purpose": 0.5,
    "for the purpose of": 1.0,
    "the purpose of marketing": 1.0,
    "purpose of marketing .": 1.0,
    "<s> speech recognition :": 0.14285714285714285,
    "speech recognition : given": 1.0,
    "recognition : given a": 1.0,
    ": given a sound": 0.2222222222222222,
    "given a sound clip": 1.0,
    "a sound clip of": 1.0,
    "sound clip of a": 1.0,
    "clip of a person": 1.0,
    "of a person or": 0.6666666666666666,
    "a person or people": 1.0,
    "person or people speaking": 1.0,
    "or people speaking ,": 1.0,
    "people speaking , determine": 0.5,
    "speaking , determine the": 1.0,
    ", determine the textual": 0.3333333333333333,
    "determine the textual representation": 1.0,
    "the textual representation of": 1.0,
    "textual representation of the": 1.0,
    "representation of the speech": 1.0,
    "of the speech .": 0.25,
    "<s> this is the": 0.14285714285714285,
    "this is the opposite": 0.3333333333333333,
    "is the opposite of": 1.0,
    "the opposite of text": 0.5,
    "opposite of text to": 1.0,
    "of text to speech": 1.0,
    "text to speech and": 1.0,
    "to speech and is": 1.0,
    "speech and is one": 1.0,
    "and is one of": 1.0,
    "one of the extremely": 0.08333333333333333,
    "of the extremely difficult": 1.0,
    "the extremely difficult problems": 1.0,
    "extremely difficult problems colloquially": 1.0,
    "difficult problems colloquially termed": 1.0,
    "`` ai-complete '' -lrb-": 0.5,
    "ai-complete '' -lrb- see": 1.0,
    "'' -lrb- see above": 1.0,
    "-lrb- see above -rrb-": 1.0,
    "see above -rrb- .": 1.0,
    "<s> in natural speech": 1.0,
    "in natural speech there": 1.0,
    "natural speech there are": 1.0,
    "speech there are hardly": 1.0,
    "there are hardly any": 1.0,
    "are hardly any pauses": 1.0,
    "hardly any pauses between": 1.0,
    "any pauses between successive": 1.0,
    "pauses between successive words": 1.0,
    "between successive words ,": 1.0,
    "successive words , and": 1.0,
    "words , and thus": 0.3333333333333333,
    ", and thus speech": 0.5,
    "and thus speech segmentation": 1.0,
    "thus speech segmentation is": 1.0,
    "speech segmentation is a": 0.3333333333333333,
    "segmentation is a necessary": 0.3333333333333333,
    "is a necessary subtask": 1.0,
    "a necessary subtask of": 1.0,
    "necessary subtask of speech": 1.0,
    "subtask of speech recognition": 1.0,
    "of speech recognition -lrb-": 0.07142857142857142,
    "speech recognition -lrb- see": 0.25,
    "recognition -lrb- see below": 0.5,
    "-lrb- see below -rrb-": 1.0,
    "see below -rrb- .": 1.0,
    "<s> note also that": 1.0,
    "note also that in": 1.0,
    "also that in most": 1.0,
    "that in most spoken": 1.0,
    "in most spoken languages": 1.0,
    "most spoken languages ,": 1.0,
    "spoken languages , the": 1.0,
    "languages , the sounds": 0.3333333333333333,
    ", the sounds representing": 1.0,
    "the sounds representing successive": 1.0,
    "sounds representing successive letters": 1.0,
    "representing successive letters blend": 1.0,
    "successive letters blend into": 1.0,
    "letters blend into each": 1.0,
    "blend into each other": 1.0,
    "into each other in": 1.0,
    "each other in a": 1.0,
    "other in a process": 1.0,
    "in a process termed": 1.0,
    "a process termed coarticulation": 1.0,
    "process termed coarticulation ,": 1.0,
    "termed coarticulation , so": 1.0,
    "coarticulation , so the": 1.0,
    ", so the conversion": 0.25,
    "so the conversion of": 1.0,
    "the conversion of the": 1.0,
    "conversion of the analog": 1.0,
    "of the analog signal": 1.0,
    "the analog signal to": 1.0,
    "analog signal to discrete": 1.0,
    "signal to discrete characters": 1.0,
    "to discrete characters can": 1.0,
    "discrete characters can be": 1.0,
    "characters can be a": 0.5,
    "can be a very": 0.3333333333333333,
    "be a very difficult": 1.0,
    "a very difficult process": 1.0,
    "very difficult process .": 1.0,
    "<s> speech segmentation :": 0.3333333333333333,
    "speech segmentation : given": 1.0,
    "segmentation : given a": 1.0,
    "people speaking , separate": 0.5,
    "speaking , separate it": 1.0,
    ", separate it into": 1.0,
    "separate it into words": 0.5,
    "it into words .": 1.0,
    "<s> a subtask of": 1.0,
    "a subtask of speech": 1.0,
    "of speech recognition and": 0.07142857142857142,
    "speech recognition and typically": 0.16666666666666666,
    "recognition and typically grouped": 1.0,
    "and typically grouped with": 1.0,
    "typically grouped with it": 1.0,
    "grouped with it .": 1.0,
    "<s> topic segmentation and": 1.0,
    "topic segmentation and recognition": 1.0,
    "segmentation and recognition :": 1.0,
    "and recognition : given": 1.0,
    "of text , separate": 0.1,
    "text , separate it": 1.0,
    "separate it into segments": 0.5,
    "it into segments each": 1.0,
    "into segments each of": 1.0,
    "segments each of which": 1.0,
    "each of which is": 0.75,
    "of which is devoted": 0.3333333333333333,
    "which is devoted to": 1.0,
    "is devoted to a": 1.0,
    "devoted to a topic": 1.0,
    "to a topic ,": 1.0,
    "a topic , and": 1.0,
    "topic , and identify": 1.0,
    ", and identify the": 1.0,
    "and identify the topic": 0.5,
    "identify the topic of": 1.0,
    "the topic of the": 1.0,
    "topic of the segment": 1.0,
    "of the segment .": 1.0,
    "<s> word segmentation :": 1.0,
    "word segmentation : separate": 1.0,
    "segmentation : separate a": 0.5,
    ": separate a chunk": 1.0,
    "separate a chunk of": 1.0,
    "a chunk of continuous": 0.16666666666666666,
    "chunk of continuous text": 1.0,
    "of continuous text into": 1.0,
    "continuous text into separate": 1.0,
    "text into separate words": 1.0,
    "into separate words .": 1.0,
    "<s> for a language": 0.5,
    "for a language like": 0.5,
    "a language like english": 1.0,
    "language like english ,": 1.0,
    "like english , this": 1.0,
    "english , this is": 0.5,
    ", this is fairly": 0.5,
    "this is fairly trivial": 1.0,
    "is fairly trivial ,": 1.0,
    "fairly trivial , since": 1.0,
    "trivial , since words": 1.0,
    ", since words are": 1.0,
    "since words are usually": 1.0,
    "words are usually separated": 1.0,
    "are usually separated by": 1.0,
    "usually separated by spaces": 1.0,
    "separated by spaces .": 1.0,
    "<s> however , some": 0.03125,
    "however , some written": 1.0,
    ", some written languages": 1.0,
    "some written languages like": 0.5,
    "written languages like chinese": 1.0,
    "languages like chinese ,": 1.0,
    "like chinese , japanese": 1.0,
    "chinese , japanese and": 0.5,
    ", japanese and thai": 1.0,
    "japanese and thai do": 1.0,
    "and thai do not": 1.0,
    "thai do not mark": 1.0,
    "do not mark word": 1.0,
    "not mark word boundaries": 1.0,
    "mark word boundaries in": 1.0,
    "word boundaries in such": 1.0,
    "boundaries in such a": 1.0,
    "in such a fashion": 0.5,
    "such a fashion ,": 1.0,
    "a fashion , and": 1.0,
    "fashion , and in": 1.0,
    ", and in those": 0.5,
    "and in those languages": 1.0,
    "in those languages text": 1.0,
    "those languages text segmentation": 1.0,
    "languages text segmentation is": 1.0,
    "text segmentation is a": 0.3333333333333333,
    "segmentation is a significant": 0.3333333333333333,
    "is a significant task": 1.0,
    "a significant task requiring": 1.0,
    "significant task requiring knowledge": 1.0,
    "task requiring knowledge of": 1.0,
    "requiring knowledge of the": 1.0,
    "knowledge of the vocabulary": 0.2,
    "of the vocabulary and": 1.0,
    "the vocabulary and morphology": 1.0,
    "vocabulary and morphology of": 1.0,
    "and morphology of words": 1.0,
    "morphology of words in": 1.0,
    "of words in the": 0.5,
    "words in the language": 0.25,
    "in the language .": 1.0,
    "<s> word sense disambiguation": 1.0,
    "word sense disambiguation :": 0.5,
    "sense disambiguation : many": 1.0,
    "disambiguation : many words": 1.0,
    ": many words have": 1.0,
    "many words have more": 1.0,
    "words have more than": 1.0,
    "have more than one": 1.0,
    "more than one meaning": 0.6666666666666666,
    "than one meaning ;": 0.5,
    "one meaning ; we": 1.0,
    "meaning ; we have": 1.0,
    "; we have to": 1.0,
    "we have to select": 1.0,
    "have to select the": 1.0,
    "to select the meaning": 0.5,
    "select the meaning which": 1.0,
    "the meaning which makes": 1.0,
    "meaning which makes the": 1.0,
    "which makes the most": 1.0,
    "makes the most sense": 1.0,
    "the most sense in": 1.0,
    "most sense in context": 1.0,
    "sense in context .": 1.0,
    "<s> for this problem": 0.3333333333333333,
    "for this problem ,": 1.0,
    "this problem , we": 1.0,
    "problem , we are": 1.0,
    ", we are typically": 1.0,
    "we are typically given": 1.0,
    "are typically given a": 1.0,
    "typically given a list": 1.0,
    "given a list of": 1.0,
    "a list of words": 0.16666666666666666,
    "list of words and": 1.0,
    "of words and associated": 0.3333333333333333,
    "words and associated word": 1.0,
    "and associated word senses": 1.0,
    "associated word senses ,": 1.0,
    "word senses , e.g.": 1.0,
    "senses , e.g. from": 1.0,
    ", e.g. from a": 1.0,
    "e.g. from a dictionary": 1.0,
    "from a dictionary or": 0.5,
    "a dictionary or from": 1.0,
    "dictionary or from an": 1.0,
    "or from an online": 1.0,
    "from an online resource": 1.0,
    "an online resource such": 1.0,
    "online resource such as": 1.0,
    "resource such as wordnet": 1.0,
    "such as wordnet .": 1.0,
    "<s> in some cases": 0.6666666666666666,
    "in some cases ,": 1.0,
    "some cases , sets": 0.5,
    "cases , sets of": 1.0,
    ", sets of related": 1.0,
    "sets of related tasks": 1.0,
    "of related tasks are": 0.5,
    "related tasks are grouped": 1.0,
    "tasks are grouped into": 1.0,
    "are grouped into subfields": 1.0,
    "grouped into subfields of": 1.0,
    "into subfields of nlp": 1.0,
    "subfields of nlp that": 1.0,
    "of nlp that are": 1.0,
    "nlp that are often": 1.0,
    "that are often considered": 1.0,
    "are often considered separately": 1.0,
    "often considered separately from": 1.0,
    "considered separately from nlp": 1.0,
    "separately from nlp as": 1.0,
    "from nlp as a": 1.0,
    "nlp as a whole": 1.0,
    "as a whole .": 1.0,
    "<s> examples include :": 1.0,
    "examples include : information": 1.0,
    "include : information retrieval": 1.0,
    ": information retrieval -lrb-": 1.0,
    "information retrieval -lrb- ir": 1.0,
    "retrieval -lrb- ir -rrb-": 1.0,
    "-lrb- ir -rrb- :": 1.0,
    "ir -rrb- : this": 1.0,
    "-rrb- : this is": 1.0,
    ": this is concerned": 1.0,
    "this is concerned with": 0.5,
    "is concerned with storing": 1.0,
    "concerned with storing ,": 1.0,
    "with storing , searching": 1.0,
    "storing , searching and": 1.0,
    ", searching and retrieving": 1.0,
    "searching and retrieving information": 1.0,
    "and retrieving information .": 1.0,
    "<s> it is a": 0.10526315789473684,
    "it is a separate": 0.16666666666666666,
    "is a separate field": 1.0,
    "a separate field within": 1.0,
    "separate field within computer": 1.0,
    "field within computer science": 1.0,
    "within computer science -lrb-": 1.0,
    "computer science -lrb- closer": 1.0,
    "science -lrb- closer to": 1.0,
    "-lrb- closer to databases": 1.0,
    "closer to databases -rrb-": 1.0,
    "to databases -rrb- ,": 1.0,
    "databases -rrb- , but": 1.0,
    "-rrb- , but ir": 0.3333333333333333,
    ", but ir relies": 1.0,
    "but ir relies on": 1.0,
    "ir relies on some": 1.0,
    "relies on some nlp": 1.0,
    "on some nlp methods": 1.0,
    "some nlp methods -lrb-": 1.0,
    "nlp methods -lrb- for": 1.0,
    "methods -lrb- for example": 1.0,
    "-lrb- for example ,": 1.0,
    "for example , stemming": 0.02127659574468085,
    "example , stemming -rrb-": 1.0,
    ", stemming -rrb- .": 1.0,
    "<s> some current research": 1.0,
    "some current research and": 1.0,
    "current research and applications": 0.5,
    "research and applications seek": 1.0,
    "and applications seek to": 1.0,
    "applications seek to bridge": 1.0,
    "seek to bridge the": 1.0,
    "to bridge the gap": 1.0,
    "bridge the gap between": 1.0,
    "the gap between ir": 1.0,
    "gap between ir and": 1.0,
    "between ir and nlp": 1.0,
    "ir and nlp .": 1.0,
    "<s> information extraction -lrb-": 1.0,
    "information extraction -lrb- ie": 1.0,
    "extraction -lrb- ie -rrb-": 1.0,
    "-lrb- ie -rrb- :": 0.5,
    "ie -rrb- : this": 1.0,
    "this is concerned in": 0.5,
    "is concerned in general": 1.0,
    "concerned in general with": 1.0,
    "in general with the": 1.0,
    "general with the extraction": 1.0,
    "with the extraction of": 1.0,
    "the extraction of semantic": 0.3333333333333333,
    "extraction of semantic information": 1.0,
    "of semantic information from": 1.0,
    "semantic information from text": 1.0,
    "information from text .": 1.0,
    "<s> this covers tasks": 1.0,
    "this covers tasks such": 1.0,
    "covers tasks such as": 1.0,
    "tasks such as named": 0.5,
    "such as named entity": 1.0,
    "as named entity recognition": 1.0,
    "named entity recognition ,": 0.5,
    "entity recognition , coreference": 1.0,
    "recognition , coreference resolution": 1.0,
    ", coreference resolution ,": 1.0,
    "coreference resolution , relationship": 1.0,
    "resolution , relationship extraction": 1.0,
    ", relationship extraction ,": 1.0,
    "relationship extraction , etc.": 1.0,
    "extraction , etc. .": 1.0,
    "<s> speech processing :": 1.0,
    "speech processing : this": 1.0,
    "processing : this covers": 1.0,
    ": this covers speech": 1.0,
    "this covers speech recognition": 1.0,
    "covers speech recognition ,": 1.0,
    "speech recognition , text-to-speech": 0.2,
    "recognition , text-to-speech and": 1.0,
    ", text-to-speech and related": 0.5,
    "text-to-speech and related tasks": 1.0,
    "and related tasks .": 1.0,
    "<s> other tasks include": 1.0,
    "other tasks include :": 1.0,
    "tasks include : stemming": 1.0,
    "include : stemming text": 1.0,
    ": stemming text simplification": 1.0,
    "stemming text simplification text-to-speech": 1.0,
    "text simplification text-to-speech text-proofing": 1.0,
    "simplification text-to-speech text-proofing natural": 1.0,
    "text-to-speech text-proofing natural language": 1.0,
    "text-proofing natural language search": 1.0,
    "natural language search query": 1.0,
    "language search query expansion": 1.0,
    "search query expansion automated": 1.0,
    "query expansion automated essay": 1.0,
    "expansion automated essay scoring": 1.0,
    "automated essay scoring truecasing": 1.0,
    "essay scoring truecasing statistical": 1.0,
    "scoring truecasing statistical nlp": 1.0,
    "truecasing statistical nlp main": 1.0,
    "statistical nlp main article": 1.0,
    "nlp main article :": 1.0,
    "main article : statistical": 0.16666666666666666,
    "article : statistical natural": 0.5,
    ": statistical natural language": 1.0,
    "statistical natural language processing": 1.0,
    "natural language processing statistical": 0.03571428571428571,
    "language processing statistical natural-language": 1.0,
    "processing statistical natural-language processing": 1.0,
    "statistical natural-language processing uses": 1.0,
    "natural-language processing uses stochastic": 1.0,
    "processing uses stochastic ,": 1.0,
    "uses stochastic , probabilistic": 1.0,
    "stochastic , probabilistic and": 1.0,
    ", probabilistic and statistical": 1.0,
    "probabilistic and statistical methods": 1.0,
    "and statistical methods to": 1.0,
    "statistical methods to resolve": 0.3333333333333333,
    "methods to resolve some": 1.0,
    "to resolve some of": 1.0,
    "resolve some of the": 1.0,
    "some of the difficulties": 0.1,
    "of the difficulties discussed": 1.0,
    "the difficulties discussed above": 1.0,
    "difficulties discussed above ,": 1.0,
    "discussed above , especially": 1.0,
    "above , especially those": 1.0,
    ", especially those which": 0.5,
    "especially those which arise": 1.0,
    "those which arise because": 1.0,
    "which arise because longer": 1.0,
    "arise because longer sentences": 1.0,
    "because longer sentences are": 1.0,
    "longer sentences are highly": 1.0,
    "sentences are highly ambiguous": 1.0,
    "are highly ambiguous when": 1.0,
    "highly ambiguous when processed": 1.0,
    "ambiguous when processed with": 1.0,
    "when processed with realistic": 1.0,
    "processed with realistic grammars": 1.0,
    "with realistic grammars ,": 1.0,
    "realistic grammars , yielding": 1.0,
    "grammars , yielding thousands": 1.0,
    ", yielding thousands or": 1.0,
    "yielding thousands or millions": 1.0,
    "thousands or millions of": 1.0,
    "or millions of possible": 1.0,
    "millions of possible analyses": 1.0,
    "of possible analyses .": 1.0,
    "<s> methods for disambiguation": 1.0,
    "methods for disambiguation often": 1.0,
    "for disambiguation often involve": 1.0,
    "disambiguation often involve the": 1.0,
    "often involve the use": 1.0,
    "involve the use of": 1.0,
    "the use of corpora": 0.06666666666666667,
    "use of corpora and": 1.0,
    "of corpora and markov": 1.0,
    "corpora and markov models": 1.0,
    "and markov models .": 1.0,
    "<s> statistical nlp comprises": 1.0,
    "statistical nlp comprises all": 1.0,
    "nlp comprises all quantitative": 1.0,
    "comprises all quantitative approaches": 1.0,
    "all quantitative approaches to": 1.0,
    "quantitative approaches to automated": 1.0,
    "approaches to automated language": 1.0,
    "to automated language processing": 1.0,
    "automated language processing ,": 1.0,
    "language processing , including": 0.16666666666666666,
    "processing , including probabilistic": 1.0,
    ", including probabilistic modeling": 1.0,
    "including probabilistic modeling ,": 1.0,
    "probabilistic modeling , information": 1.0,
    "modeling , information theory": 1.0,
    ", information theory ,": 1.0,
    "information theory , and": 1.0,
    "theory , and linear": 0.5,
    ", and linear algebra": 1.0,
    "and linear algebra .": 1.0,
    "<s> the technology for": 1.0,
    "the technology for statistical": 1.0,
    "technology for statistical nlp": 1.0,
    "for statistical nlp comes": 1.0,
    "statistical nlp comes mainly": 1.0,
    "nlp comes mainly from": 1.0,
    "comes mainly from machine": 1.0,
    "mainly from machine learning": 1.0,
    "from machine learning and": 0.5,
    "machine learning and data": 1.0,
    "learning and data mining": 1.0,
    "and data mining ,": 1.0,
    "data mining , both": 1.0,
    "mining , both of": 1.0,
    ", both of which": 1.0,
    "both of which are": 0.5,
    "of which are fields": 0.25,
    "which are fields of": 1.0,
    "are fields of artificial": 1.0,
    "fields of artificial intelligence": 1.0,
    "of artificial intelligence that": 1.0,
    "artificial intelligence that involve": 0.5,
    "intelligence that involve learning": 1.0,
    "that involve learning from": 1.0,
    "involve learning from data": 1.0,
    "learning from data .": 1.0,
    "<s> evaluation of natural": 1.0,
    "evaluation of natural language": 1.0,
    "natural language processing objectives": 0.03571428571428571,
    "language processing objectives the": 1.0,
    "processing objectives the goal": 1.0,
    "objectives the goal of": 1.0,
    "the goal of nlp": 0.5,
    "goal of nlp evaluation": 1.0,
    "of nlp evaluation is": 1.0,
    "nlp evaluation is to": 1.0,
    "evaluation is to measure": 1.0,
    "is to measure one": 1.0,
    "to measure one or": 1.0,
    "measure one or more": 1.0,
    "one or more qualities": 0.5,
    "or more qualities of": 1.0,
    "more qualities of an": 1.0,
    "qualities of an algorithm": 1.0,
    "of an algorithm or": 1.0,
    "an algorithm or a": 1.0,
    "algorithm or a system": 1.0,
    "or a system ,": 1.0,
    "a system , in": 0.5,
    "system , in order": 1.0,
    ", in order to": 0.6666666666666666,
    "in order to determine": 0.125,
    "order to determine whether": 1.0,
    "to determine whether -lrb-": 1.0,
    "determine whether -lrb- or": 1.0,
    "whether -lrb- or to": 1.0,
    "-lrb- or to what": 1.0,
    "or to what extent": 1.0,
    "to what extent -rrb-": 1.0,
    "what extent -rrb- the": 1.0,
    "extent -rrb- the system": 1.0,
    "-rrb- the system answers": 1.0,
    "the system answers the": 1.0,
    "system answers the goals": 1.0,
    "answers the goals of": 1.0,
    "the goals of its": 1.0,
    "goals of its designers": 1.0,
    "of its designers ,": 1.0,
    "its designers , or": 1.0,
    "designers , or meets": 1.0,
    ", or meets the": 1.0,
    "or meets the needs": 1.0,
    "meets the needs of": 1.0,
    "the needs of its": 1.0,
    "needs of its users": 1.0,
    "of its users .": 1.0,
    "<s> research in nlp": 1.0,
    "research in nlp evaluation": 1.0,
    "in nlp evaluation has": 0.5,
    "nlp evaluation has received": 1.0,
    "evaluation has received considerable": 1.0,
    "has received considerable attention": 1.0,
    "received considerable attention ,": 1.0,
    "considerable attention , because": 1.0,
    "attention , because the": 1.0,
    ", because the definition": 0.5,
    "because the definition of": 1.0,
    "the definition of proper": 0.3333333333333333,
    "definition of proper evaluation": 1.0,
    "of proper evaluation criteria": 1.0,
    "proper evaluation criteria is": 1.0,
    "evaluation criteria is one": 1.0,
    "criteria is one way": 1.0,
    "is one way to": 1.0,
    "one way to specify": 0.5,
    "way to specify precisely": 1.0,
    "to specify precisely an": 1.0,
    "specify precisely an nlp": 1.0,
    "precisely an nlp problem": 1.0,
    "an nlp problem ,": 1.0,
    "nlp problem , going": 1.0,
    "problem , going thus": 1.0,
    ", going thus beyond": 1.0,
    "going thus beyond the": 1.0,
    "thus beyond the vagueness": 1.0,
    "beyond the vagueness of": 1.0,
    "the vagueness of tasks": 1.0,
    "vagueness of tasks defined": 1.0,
    "of tasks defined only": 1.0,
    "tasks defined only as": 1.0,
    "defined only as language": 1.0,
    "only as language understanding": 1.0,
    "as language understanding or": 1.0,
    "language understanding or language": 1.0,
    "understanding or language generation": 1.0,
    "or language generation .": 1.0,
    "<s> a precise set": 1.0,
    "a precise set of": 1.0,
    "precise set of evaluation": 1.0,
    "set of evaluation criteria": 1.0,
    "of evaluation criteria ,": 1.0,
    "evaluation criteria , which": 1.0,
    "criteria , which includes": 1.0,
    ", which includes mainly": 0.5,
    "which includes mainly evaluation": 1.0,
    "includes mainly evaluation data": 1.0,
    "mainly evaluation data and": 1.0,
    "evaluation data and evaluation": 1.0,
    "data and evaluation metrics": 1.0,
    "and evaluation metrics ,": 1.0,
    "evaluation metrics , enables": 1.0,
    "metrics , enables several": 1.0,
    ", enables several teams": 1.0,
    "enables several teams to": 1.0,
    "several teams to compare": 1.0,
    "teams to compare their": 1.0,
    "to compare their solutions": 1.0,
    "compare their solutions to": 1.0,
    "their solutions to a": 1.0,
    "solutions to a given": 1.0,
    "to a given nlp": 0.3333333333333333,
    "a given nlp problem": 1.0,
    "given nlp problem .": 1.0,
    "<s> short history of": 1.0,
    "short history of evaluation": 1.0,
    "history of evaluation in": 1.0,
    "of evaluation in nlp": 1.0,
    "evaluation in nlp the": 1.0,
    "in nlp the first": 0.5,
    "nlp the first evaluation": 1.0,
    "the first evaluation campaign": 1.0,
    "first evaluation campaign on": 1.0,
    "evaluation campaign on written": 1.0,
    "campaign on written texts": 1.0,
    "on written texts seems": 1.0,
    "written texts seems to": 1.0,
    "texts seems to be": 1.0,
    "seems to be a": 1.0,
    "to be a campaign": 0.2,
    "be a campaign dedicated": 1.0,
    "a campaign dedicated to": 1.0,
    "campaign dedicated to message": 1.0,
    "dedicated to message understanding": 1.0,
    "to message understanding in": 1.0,
    "message understanding in 1987": 1.0,
    "understanding in 1987 -lrb-": 1.0,
    "in 1987 -lrb- pallet": 1.0,
    "1987 -lrb- pallet 1998": 1.0,
    "-lrb- pallet 1998 -rrb-": 1.0,
    "pallet 1998 -rrb- .": 1.0,
    "<s> then , the": 1.0,
    "then , the parseval\\/geig": 0.3333333333333333,
    ", the parseval\\/geig project": 1.0,
    "the parseval\\/geig project compared": 1.0,
    "parseval\\/geig project compared phrase-structure": 1.0,
    "project compared phrase-structure grammars": 1.0,
    "compared phrase-structure grammars -lrb-": 1.0,
    "phrase-structure grammars -lrb- black": 1.0,
    "grammars -lrb- black 1991": 1.0,
    "-lrb- black 1991 -rrb-": 1.0,
    "black 1991 -rrb- .": 1.0,
    "<s> a series of": 1.0,
    "a series of campaigns": 0.14285714285714285,
    "series of campaigns within": 1.0,
    "of campaigns within tipster": 1.0,
    "campaigns within tipster project": 1.0,
    "within tipster project were": 1.0,
    "tipster project were realized": 1.0,
    "project were realized on": 1.0,
    "were realized on tasks": 1.0,
    "realized on tasks like": 1.0,
    "on tasks like summarization": 0.5,
    "tasks like summarization ,": 1.0,
    "like summarization , translation": 1.0,
    "summarization , translation and": 1.0,
    ", translation and searching": 1.0,
    "translation and searching -lrb-": 1.0,
    "and searching -lrb- hirschman": 1.0,
    "searching -lrb- hirschman 1998": 1.0,
    "-lrb- hirschman 1998 -rrb-": 1.0,
    "hirschman 1998 -rrb- .": 1.0,
    "<s> in 1994 ,": 1.0,
    "in 1994 , in": 1.0,
    "1994 , in germany": 1.0,
    ", in germany ,": 1.0,
    "in germany , the": 1.0,
    "germany , the morpholympics": 1.0,
    ", the morpholympics compared": 1.0,
    "the morpholympics compared german": 1.0,
    "morpholympics compared german taggers": 1.0,
    "compared german taggers .": 1.0,
    "then , the senseval": 0.3333333333333333,
    ", the senseval and": 1.0,
    "the senseval and romanseval": 1.0,
    "senseval and romanseval campaigns": 1.0,
    "and romanseval campaigns were": 1.0,
    "romanseval campaigns were conducted": 1.0,
    "campaigns were conducted with": 1.0,
    "were conducted with the": 1.0,
    "conducted with the objectives": 1.0,
    "with the objectives of": 1.0,
    "the objectives of semantic": 1.0,
    "objectives of semantic disambiguation": 1.0,
    "of semantic disambiguation .": 1.0,
    "<s> in 1996 ,": 1.0,
    "in 1996 , the": 1.0,
    "1996 , the sparkle": 1.0,
    ", the sparkle campaign": 1.0,
    "the sparkle campaign compared": 1.0,
    "sparkle campaign compared syntactic": 1.0,
    "campaign compared syntactic parsers": 1.0,
    "compared syntactic parsers in": 1.0,
    "syntactic parsers in four": 1.0,
    "parsers in four different": 1.0,
    "in four different languages": 0.5,
    "four different languages -lrb-": 1.0,
    "different languages -lrb- english": 1.0,
    "languages -lrb- english ,": 1.0,
    "-lrb- english , french": 1.0,
    "english , french ,": 1.0,
    ", french , german": 1.0,
    "french , german and": 1.0,
    ", german and italian": 1.0,
    "german and italian -rrb-": 1.0,
    "and italian -rrb- .": 1.0,
    "<s> in france ,": 1.0,
    "in france , the": 0.5,
    "france , the grace": 1.0,
    ", the grace project": 1.0,
    "the grace project compared": 1.0,
    "grace project compared a": 1.0,
    "project compared a set": 1.0,
    "compared a set of": 1.0,
    "a set of 21": 0.07142857142857142,
    "set of 21 taggers": 1.0,
    "of 21 taggers for": 1.0,
    "21 taggers for french": 1.0,
    "taggers for french in": 1.0,
    "for french in 1997": 1.0,
    "french in 1997 -lrb-": 1.0,
    "in 1997 -lrb- adda": 1.0,
    "1997 -lrb- adda 1999": 1.0,
    "-lrb- adda 1999 -rrb-": 1.0,
    "adda 1999 -rrb- .": 1.0,
    "<s> in 2004 ,": 1.0,
    "in 2004 , during": 1.0,
    "2004 , during the": 1.0,
    ", during the technolangue\\/easy": 1.0,
    "during the technolangue\\/easy project": 1.0,
    "the technolangue\\/easy project ,": 1.0,
    "technolangue\\/easy project , 13": 1.0,
    "project , 13 parsers": 1.0,
    ", 13 parsers for": 1.0,
    "13 parsers for french": 1.0,
    "parsers for french were": 1.0,
    "for french were compared": 1.0,
    "french were compared .": 0.5,
    "<s> large-scale evaluation of": 1.0,
    "large-scale evaluation of dependency": 1.0,
    "evaluation of dependency parsers": 1.0,
    "of dependency parsers were": 1.0,
    "dependency parsers were performed": 1.0,
    "parsers were performed in": 1.0,
    "were performed in the": 1.0,
    "performed in the context": 1.0,
    "in the context of": 1.0,
    "the context of the": 0.2,
    "context of the conll": 1.0,
    "of the conll shared": 1.0,
    "the conll shared tasks": 1.0,
    "conll shared tasks in": 1.0,
    "shared tasks in 2006": 1.0,
    "tasks in 2006 and": 1.0,
    "in 2006 and 2007": 1.0,
    "2006 and 2007 .": 1.0,
    "<s> in italy ,": 1.0,
    "in italy , the": 0.5,
    "italy , the evalita": 1.0,
    ", the evalita campaign": 1.0,
    "the evalita campaign was": 1.0,
    "evalita campaign was conducted": 1.0,
    "campaign was conducted in": 1.0,
    "was conducted in 2007": 1.0,
    "conducted in 2007 and": 1.0,
    "in 2007 and 2009": 1.0,
    "2007 and 2009 to": 1.0,
    "and 2009 to compare": 1.0,
    "2009 to compare various": 1.0,
    "to compare various nlp": 1.0,
    "compare various nlp and": 1.0,
    "various nlp and speech": 1.0,
    "nlp and speech tools": 1.0,
    "and speech tools for": 1.0,
    "speech tools for italian": 1.0,
    "tools for italian ;": 1.0,
    "for italian ; the": 1.0,
    "italian ; the 2011": 1.0,
    "; the 2011 campaign": 1.0,
    "the 2011 campaign is": 1.0,
    "2011 campaign is in": 1.0,
    "campaign is in full": 1.0,
    "is in full progress": 1.0,
    "in full progress -": 1.0,
    "full progress - evalita": 1.0,
    "progress - evalita web": 1.0,
    "- evalita web site": 1.0,
    "evalita web site .": 1.0,
    "in france , within": 0.5,
    "france , within the": 1.0,
    ", within the anr-passage": 1.0,
    "within the anr-passage project": 1.0,
    "the anr-passage project -lrb-": 1.0,
    "anr-passage project -lrb- end": 1.0,
    "project -lrb- end of": 1.0,
    "-lrb- end of 2007": 1.0,
    "end of 2007 -rrb-": 1.0,
    "of 2007 -rrb- ,": 1.0,
    "2007 -rrb- , 10": 1.0,
    "-rrb- , 10 parsers": 1.0,
    ", 10 parsers for": 1.0,
    "10 parsers for french": 1.0,
    "french were compared -": 0.5,
    "were compared - passage": 1.0,
    "compared - passage web": 1.0,
    "- passage web site": 1.0,
    "passage web site .": 1.0,
    "<s> adda g. ,": 1.0,
    "adda g. , mariani": 1.0,
    "g. , mariani j.": 1.0,
    ", mariani j. ,": 1.0,
    "mariani j. , paroubek": 1.0,
    "j. , paroubek p.": 1.0,
    ", paroubek p. ,": 1.0,
    "paroubek p. , rajman": 1.0,
    "p. , rajman m.": 1.0,
    ", rajman m. 1999": 1.0,
    "rajman m. 1999 l'action": 1.0,
    "m. 1999 l'action grace": 1.0,
    "1999 l'action grace d'\u00e9valuation": 1.0,
    "l'action grace d'\u00e9valuation de": 1.0,
    "grace d'\u00e9valuation de l'assignation": 1.0,
    "d'\u00e9valuation de l'assignation des": 1.0,
    "de l'assignation des parties": 1.0,
    "l'assignation des parties du": 1.0,
    "des parties du discors": 1.0,
    "parties du discors pour": 1.0,
    "du discors pour le": 1.0,
    "discors pour le fran\u00e7ais": 1.0,
    "pour le fran\u00e7ais .": 1.0,
    "<s> langues vol-2 black": 1.0,
    "langues vol-2 black e.": 1.0,
    "vol-2 black e. ,": 1.0,
    "black e. , abney": 1.0,
    "e. , abney s.": 1.0,
    ", abney s. ,": 1.0,
    "abney s. , flickinger": 1.0,
    "s. , flickinger d.": 1.0,
    ", flickinger d. ,": 1.0,
    "flickinger d. , gdaniec": 1.0,
    "d. , gdaniec c.": 1.0,
    ", gdaniec c. ,": 1.0,
    "gdaniec c. , grishman": 1.0,
    "c. , grishman r.": 1.0,
    ", grishman r. ,": 1.0,
    "grishman r. , harrison": 1.0,
    "r. , harrison p.": 1.0,
    ", harrison p. ,": 1.0,
    "harrison p. , hindle": 1.0,
    "p. , hindle d.": 1.0,
    ", hindle d. ,": 1.0,
    "hindle d. , ingria": 1.0,
    "d. , ingria r.": 1.0,
    ", ingria r. ,": 1.0,
    "ingria r. , jelinek": 1.0,
    "r. , jelinek f.": 1.0,
    ", jelinek f. ,": 1.0,
    "jelinek f. , klavans": 1.0,
    "f. , klavans j.": 1.0,
    ", klavans j. ,": 1.0,
    "klavans j. , liberman": 1.0,
    "j. , liberman m.": 1.0,
    ", liberman m. ,": 1.0,
    "liberman m. , marcus": 1.0,
    "m. , marcus m.": 1.0,
    ", marcus m. ,": 1.0,
    "marcus m. , reukos": 1.0,
    "m. , reukos s.": 1.0,
    ", reukos s. ,": 1.0,
    "reukos s. , santoni": 1.0,
    "s. , santoni b.": 1.0,
    ", santoni b. ,": 1.0,
    "santoni b. , strzalkowski": 1.0,
    "b. , strzalkowski t.": 1.0,
    ", strzalkowski t. 1991": 1.0,
    "strzalkowski t. 1991 a": 1.0,
    "t. 1991 a procedure": 1.0,
    "1991 a procedure for": 1.0,
    "a procedure for quantitatively": 1.0,
    "procedure for quantitatively comparing": 1.0,
    "for quantitatively comparing the": 1.0,
    "quantitatively comparing the syntactic": 1.0,
    "comparing the syntactic coverage": 1.0,
    "the syntactic coverage of": 1.0,
    "syntactic coverage of english": 1.0,
    "coverage of english grammars": 1.0,
    "of english grammars .": 1.0,
    "<s> darpa speech and": 1.0,
    "darpa speech and natural": 1.0,
    "speech and natural language": 1.0,
    "and natural language workshop": 0.2,
    "natural language workshop hirschman": 1.0,
    "language workshop hirschman l.": 1.0,
    "workshop hirschman l. 1998": 1.0,
    "hirschman l. 1998 language": 1.0,
    "l. 1998 language understanding": 1.0,
    "1998 language understanding evaluation": 1.0,
    "language understanding evaluation :": 1.0,
    "understanding evaluation : lessons": 1.0,
    "evaluation : lessons learned": 1.0,
    ": lessons learned from": 1.0,
    "lessons learned from muc": 1.0,
    "learned from muc and": 1.0,
    "from muc and atis": 1.0,
    "muc and atis .": 1.0,
    "<s> lrec granada pallet": 0.5,
    "lrec granada pallet d.s.": 1.0,
    "granada pallet d.s. 1998": 1.0,
    "pallet d.s. 1998 the": 1.0,
    "d.s. 1998 the nist": 1.0,
    "1998 the nist role": 1.0,
    "the nist role in": 1.0,
    "nist role in automatic": 1.0,
    "role in automatic speech": 1.0,
    "in automatic speech recognition": 1.0,
    "automatic speech recognition benchmark": 0.3333333333333333,
    "speech recognition benchmark tests": 1.0,
    "recognition benchmark tests .": 1.0,
    "<s> lrec granada different": 0.5,
    "lrec granada different types": 1.0,
    "granada different types of": 1.0,
    "different types of evaluation": 0.25,
    "types of evaluation depending": 1.0,
    "of evaluation depending on": 1.0,
    "evaluation depending on the": 1.0,
    "depending on the evaluation": 0.5,
    "on the evaluation procedures": 1.0,
    "the evaluation procedures ,": 1.0,
    "evaluation procedures , a": 1.0,
    "procedures , a number": 1.0,
    ", a number of": 1.0,
    "a number of distinctions": 0.045454545454545456,
    "number of distinctions are": 1.0,
    "of distinctions are traditionally": 1.0,
    "distinctions are traditionally made": 1.0,
    "are traditionally made in": 1.0,
    "traditionally made in nlp": 1.0,
    "made in nlp evaluation": 1.0,
    "in nlp evaluation .": 0.5,
    "<s> intrinsic vs. extrinsic": 1.0,
    "intrinsic vs. extrinsic evaluation": 1.0,
    "vs. extrinsic evaluation intrinsic": 1.0,
    "extrinsic evaluation intrinsic evaluation": 1.0,
    "evaluation intrinsic evaluation considers": 1.0,
    "intrinsic evaluation considers an": 1.0,
    "evaluation considers an isolated": 1.0,
    "considers an isolated nlp": 1.0,
    "an isolated nlp system": 1.0,
    "isolated nlp system and": 1.0,
    "nlp system and characterizes": 1.0,
    "system and characterizes its": 1.0,
    "and characterizes its performance": 1.0,
    "characterizes its performance mainly": 1.0,
    "its performance mainly with": 1.0,
    "performance mainly with respect": 1.0,
    "mainly with respect to": 1.0,
    "with respect to a": 0.2857142857142857,
    "respect to a gold": 0.5,
    "to a gold standard": 1.0,
    "a gold standard result": 0.5,
    "gold standard result ,": 1.0,
    "standard result , pre-defined": 1.0,
    "result , pre-defined by": 1.0,
    ", pre-defined by the": 1.0,
    "pre-defined by the evaluators": 1.0,
    "by the evaluators .": 1.0,
    "<s> extrinsic evaluation ,": 1.0,
    "extrinsic evaluation , also": 1.0,
    "evaluation , also called": 1.0,
    ", also called evaluation": 0.5,
    "also called evaluation in": 1.0,
    "called evaluation in use": 1.0,
    "evaluation in use considers": 1.0,
    "in use considers the": 1.0,
    "use considers the nlp": 1.0,
    "considers the nlp system": 1.0,
    "the nlp system in": 1.0,
    "nlp system in a": 1.0,
    "system in a more": 1.0,
    "in a more complex": 1.0,
    "a more complex setting": 0.5,
    "more complex setting ,": 1.0,
    "complex setting , either": 1.0,
    "setting , either as": 1.0,
    ", either as an": 1.0,
    "either as an embedded": 0.5,
    "as an embedded system": 1.0,
    "an embedded system or": 1.0,
    "embedded system or serving": 1.0,
    "system or serving a": 1.0,
    "or serving a precise": 1.0,
    "serving a precise function": 1.0,
    "a precise function for": 1.0,
    "precise function for a": 1.0,
    "function for a human": 1.0,
    "for a human user": 1.0,
    "a human user .": 1.0,
    "<s> the extrinsic performance": 1.0,
    "the extrinsic performance of": 1.0,
    "extrinsic performance of the": 1.0,
    "performance of the system": 1.0,
    "of the system is": 0.25,
    "the system is then": 0.25,
    "system is then characterized": 1.0,
    "is then characterized in": 1.0,
    "then characterized in terms": 1.0,
    "characterized in terms of": 1.0,
    "in terms of its": 0.14285714285714285,
    "terms of its utility": 1.0,
    "of its utility with": 1.0,
    "its utility with respect": 1.0,
    "utility with respect to": 1.0,
    "with respect to the": 0.14285714285714285,
    "respect to the overall": 1.0,
    "to the overall task": 1.0,
    "the overall task of": 1.0,
    "overall task of the": 1.0,
    "task of the complex": 0.5,
    "of the complex system": 1.0,
    "the complex system or": 1.0,
    "complex system or the": 1.0,
    "system or the human": 1.0,
    "or the human user": 1.0,
    "the human user .": 1.0,
    "for example , consider": 0.02127659574468085,
    "example , consider a": 1.0,
    ", consider a syntactic": 1.0,
    "consider a syntactic parser": 1.0,
    "a syntactic parser that": 1.0,
    "syntactic parser that is": 1.0,
    "parser that is based": 1.0,
    "that is based on": 1.0,
    "is based on the": 0.6666666666666666,
    "based on the output": 0.09090909090909091,
    "on the output of": 1.0,
    "the output of some": 0.5,
    "output of some new": 1.0,
    "of some new part": 1.0,
    "some new part of": 1.0,
    "new part of speech": 1.0,
    "part of speech -lrb-": 0.07142857142857142,
    "of speech -lrb- pos": 1.0,
    "speech -lrb- pos -rrb-": 1.0,
    "-lrb- pos -rrb- tagger": 1.0,
    "pos -rrb- tagger .": 1.0,
    "<s> an intrinsic evaluation": 1.0,
    "an intrinsic evaluation would": 0.5,
    "intrinsic evaluation would run": 1.0,
    "evaluation would run the": 1.0,
    "would run the pos": 0.5,
    "run the pos tagger": 1.0,
    "the pos tagger on": 0.5,
    "pos tagger on some": 1.0,
    "tagger on some labeled": 1.0,
    "on some labeled data": 1.0,
    "some labeled data ,": 1.0,
    "labeled data , and": 1.0,
    "data , and compare": 0.3333333333333333,
    ", and compare the": 1.0,
    "and compare the system": 0.5,
    "compare the system output": 1.0,
    "the system output of": 1.0,
    "system output of the": 1.0,
    "output of the pos": 0.5,
    "of the pos tagger": 1.0,
    "the pos tagger to": 0.5,
    "pos tagger to the": 1.0,
    "tagger to the gold": 1.0,
    "to the gold standard": 1.0,
    "the gold standard -lrb-": 0.6666666666666666,
    "gold standard -lrb- correct": 0.5,
    "standard -lrb- correct -rrb-": 1.0,
    "-lrb- correct -rrb- output": 1.0,
    "correct -rrb- output .": 1.0,
    "<s> an extrinsic evaluation": 1.0,
    "an extrinsic evaluation would": 0.5,
    "extrinsic evaluation would run": 1.0,
    "would run the parser": 0.5,
    "run the parser with": 1.0,
    "the parser with some": 1.0,
    "parser with some other": 1.0,
    "with some other pos": 1.0,
    "some other pos tagger": 1.0,
    "other pos tagger ,": 1.0,
    "pos tagger , and": 1.0,
    "tagger , and then": 0.5,
    ", and then with": 0.25,
    "and then with the": 1.0,
    "then with the new": 1.0,
    "with the new pos": 1.0,
    "the new pos tagger": 1.0,
    "new pos tagger ,": 1.0,
    "tagger , and compare": 0.5,
    "and compare the parsing": 0.5,
    "compare the parsing accuracy": 1.0,
    "the parsing accuracy .": 1.0,
    "<s> black-box vs. glass-box": 1.0,
    "black-box vs. glass-box evaluation": 1.0,
    "vs. glass-box evaluation black-box": 1.0,
    "glass-box evaluation black-box evaluation": 1.0,
    "evaluation black-box evaluation requires": 1.0,
    "black-box evaluation requires one": 1.0,
    "evaluation requires one to": 1.0,
    "requires one to run": 1.0,
    "one to run an": 1.0,
    "to run an nlp": 1.0,
    "run an nlp system": 1.0,
    "an nlp system on": 0.5,
    "nlp system on a": 1.0,
    "system on a given": 1.0,
    "on a given data": 1.0,
    "a given data set": 1.0,
    "given data set and": 1.0,
    "data set and to": 1.0,
    "set and to measure": 1.0,
    "and to measure a": 1.0,
    "to measure a number": 1.0,
    "measure a number of": 1.0,
    "a number of parameters": 0.045454545454545456,
    "number of parameters related": 1.0,
    "of parameters related to": 1.0,
    "parameters related to the": 1.0,
    "related to the quality": 0.5,
    "to the quality of": 1.0,
    "the quality of the": 0.5,
    "quality of the process": 0.5,
    "of the process -lrb-": 1.0,
    "the process -lrb- speed": 1.0,
    "process -lrb- speed ,": 1.0,
    "-lrb- speed , reliability": 1.0,
    "speed , reliability ,": 1.0,
    ", reliability , resource": 1.0,
    "reliability , resource consumption": 1.0,
    ", resource consumption -rrb-": 1.0,
    "resource consumption -rrb- and": 1.0,
    "consumption -rrb- and ,": 1.0,
    "-rrb- and , most": 1.0,
    "and , most importantly": 1.0,
    ", most importantly ,": 1.0,
    "most importantly , to": 1.0,
    "importantly , to the": 1.0,
    ", to the quality": 0.5,
    "quality of the result": 0.5,
    "of the result -lrb-": 1.0,
    "the result -lrb- e.g.": 1.0,
    "result -lrb- e.g. the": 1.0,
    "-lrb- e.g. the accuracy": 0.3333333333333333,
    "e.g. the accuracy of": 1.0,
    "the accuracy of data": 0.5,
    "accuracy of data annotation": 1.0,
    "of data annotation or": 1.0,
    "data annotation or the": 1.0,
    "annotation or the fidelity": 1.0,
    "or the fidelity of": 1.0,
    "the fidelity of a": 1.0,
    "fidelity of a translation": 1.0,
    "of a translation -rrb-": 1.0,
    "a translation -rrb- .": 1.0,
    "<s> glass-box evaluation looks": 1.0,
    "glass-box evaluation looks at": 1.0,
    "evaluation looks at the": 1.0,
    "looks at the design": 1.0,
    "at the design of": 1.0,
    "the design of the": 1.0,
    "design of the system": 1.0,
    "of the system ,": 0.5,
    "the system , the": 0.5,
    "system , the algorithms": 0.3333333333333333,
    ", the algorithms that": 1.0,
    "the algorithms that are": 1.0,
    "algorithms that are implemented": 1.0,
    "that are implemented ,": 1.0,
    "are implemented , the": 1.0,
    "implemented , the linguistic": 1.0,
    ", the linguistic resources": 1.0,
    "the linguistic resources it": 1.0,
    "linguistic resources it uses": 1.0,
    "resources it uses -lrb-": 1.0,
    "it uses -lrb- e.g.": 1.0,
    "uses -lrb- e.g. vocabulary": 1.0,
    "-lrb- e.g. vocabulary size": 1.0,
    "e.g. vocabulary size -rrb-": 1.0,
    "vocabulary size -rrb- ,": 1.0,
    "size -rrb- , etc.": 1.0,
    "-rrb- , etc. .": 1.0,
    "<s> given the complexity": 1.0,
    "given the complexity of": 1.0,
    "the complexity of nlp": 0.125,
    "complexity of nlp problems": 1.0,
    "of nlp problems ,": 1.0,
    "nlp problems , it": 0.5,
    "problems , it is": 1.0,
    ", it is often": 0.07692307692307693,
    "it is often difficult": 0.16666666666666666,
    "is often difficult to": 1.0,
    "often difficult to predict": 1.0,
    "difficult to predict performance": 1.0,
    "to predict performance only": 1.0,
    "predict performance only on": 1.0,
    "performance only on the": 1.0,
    "only on the basis": 1.0,
    "the basis of glass-box": 0.3333333333333333,
    "basis of glass-box evaluation": 1.0,
    "of glass-box evaluation ,": 1.0,
    "glass-box evaluation , but": 1.0,
    "evaluation , but this": 1.0,
    ", but this type": 0.3333333333333333,
    "but this type of": 1.0,
    "this type of evaluation": 0.5,
    "type of evaluation is": 1.0,
    "of evaluation is more": 1.0,
    "evaluation is more informative": 1.0,
    "is more informative with": 1.0,
    "more informative with respect": 1.0,
    "informative with respect to": 1.0,
    "with respect to error": 0.14285714285714285,
    "respect to error analysis": 1.0,
    "to error analysis or": 1.0,
    "error analysis or future": 1.0,
    "analysis or future developments": 1.0,
    "or future developments of": 1.0,
    "future developments of a": 1.0,
    "developments of a system": 1.0,
    "of a system .": 0.25,
    "<s> automatic vs. manual": 1.0,
    "automatic vs. manual evaluation": 1.0,
    "vs. manual evaluation in": 1.0,
    "manual evaluation in many": 1.0,
    "evaluation in many cases": 1.0,
    "in many cases ,": 1.0,
    "many cases , automatic": 1.0,
    "cases , automatic procedures": 1.0,
    ", automatic procedures can": 1.0,
    "automatic procedures can be": 1.0,
    "procedures can be defined": 1.0,
    "can be defined to": 1.0,
    "be defined to evaluate": 1.0,
    "defined to evaluate an": 1.0,
    "to evaluate an nlp": 1.0,
    "evaluate an nlp system": 1.0,
    "an nlp system by": 0.5,
    "nlp system by comparing": 1.0,
    "system by comparing its": 1.0,
    "by comparing its output": 1.0,
    "comparing its output with": 1.0,
    "its output with the": 1.0,
    "output with the gold": 1.0,
    "with the gold standard": 1.0,
    "gold standard -lrb- or": 0.5,
    "standard -lrb- or desired": 1.0,
    "-lrb- or desired -rrb-": 1.0,
    "or desired -rrb- one": 1.0,
    "desired -rrb- one .": 1.0,
    "<s> although the cost": 0.3333333333333333,
    "although the cost of": 1.0,
    "the cost of producing": 1.0,
    "cost of producing the": 1.0,
    "of producing the gold": 1.0,
    "producing the gold standard": 1.0,
    "the gold standard can": 0.3333333333333333,
    "gold standard can be": 1.0,
    "standard can be quite": 1.0,
    "can be quite high": 1.0,
    "be quite high ,": 1.0,
    "quite high , automatic": 1.0,
    "high , automatic evaluation": 1.0,
    ", automatic evaluation can": 1.0,
    "automatic evaluation can be": 1.0,
    "evaluation can be repeated": 0.5,
    "can be repeated as": 1.0,
    "be repeated as often": 1.0,
    "repeated as often as": 1.0,
    "as often as needed": 1.0,
    "often as needed without": 1.0,
    "as needed without much": 1.0,
    "needed without much additional": 1.0,
    "without much additional costs": 1.0,
    "much additional costs -lrb-": 1.0,
    "additional costs -lrb- on": 1.0,
    "costs -lrb- on the": 1.0,
    "-lrb- on the same": 1.0,
    "on the same input": 0.5,
    "the same input data": 1.0,
    "same input data -rrb-": 0.5,
    "input data -rrb- .": 1.0,
    "<s> however , for": 0.03125,
    "however , for many": 1.0,
    ", for many nlp": 1.0,
    "for many nlp problems": 1.0,
    "many nlp problems ,": 1.0,
    "nlp problems , the": 0.5,
    "problems , the definition": 1.0,
    ", the definition of": 1.0,
    "the definition of a": 0.3333333333333333,
    "definition of a gold": 1.0,
    "of a gold standard": 1.0,
    "a gold standard is": 0.5,
    "gold standard is a": 1.0,
    "standard is a complex": 1.0,
    "is a complex task": 1.0,
    "a complex task ,": 1.0,
    "complex task , and": 1.0,
    "task , and can": 0.5,
    ", and can prove": 0.2,
    "and can prove impossible": 1.0,
    "can prove impossible when": 1.0,
    "prove impossible when inter-annotator": 1.0,
    "impossible when inter-annotator agreement": 1.0,
    "when inter-annotator agreement is": 1.0,
    "inter-annotator agreement is insufficient": 1.0,
    "agreement is insufficient .": 1.0,
    "<s> manual evaluation is": 0.5,
    "manual evaluation is performed": 1.0,
    "evaluation is performed by": 1.0,
    "is performed by human": 1.0,
    "performed by human judges": 1.0,
    "by human judges ,": 1.0,
    "human judges , which": 1.0,
    "judges , which are": 1.0,
    ", which are instructed": 0.2,
    "which are instructed to": 1.0,
    "are instructed to estimate": 1.0,
    "instructed to estimate the": 1.0,
    "to estimate the quality": 0.5,
    "estimate the quality of": 1.0,
    "the quality of a": 0.5,
    "quality of a system": 0.3333333333333333,
    "of a system ,": 0.25,
    "a system , or": 0.5,
    "system , or most": 1.0,
    ", or most often": 1.0,
    "or most often of": 1.0,
    "most often of a": 1.0,
    "often of a sample": 1.0,
    "of a sample of": 1.0,
    "a sample of its": 1.0,
    "sample of its output": 1.0,
    "of its output ,": 1.0,
    "its output , based": 1.0,
    "output , based on": 1.0,
    ", based on a": 0.5,
    "based on a number": 0.25,
    "on a number of": 1.0,
    "a number of criteria": 0.045454545454545456,
    "number of criteria .": 1.0,
    "<s> although , thanks": 1.0,
    "although , thanks to": 1.0,
    ", thanks to their": 1.0,
    "thanks to their linguistic": 1.0,
    "to their linguistic competence": 1.0,
    "their linguistic competence ,": 1.0,
    "linguistic competence , human": 1.0,
    "competence , human judges": 1.0,
    ", human judges can": 1.0,
    "human judges can be": 1.0,
    "judges can be considered": 1.0,
    "can be considered as": 1.0,
    "be considered as the": 1.0,
    "considered as the reference": 1.0,
    "as the reference for": 1.0,
    "the reference for a": 1.0,
    "reference for a number": 1.0,
    "for a number of": 1.0,
    "a number of language": 0.045454545454545456,
    "number of language processing": 1.0,
    "of language processing tasks": 1.0,
    "language processing tasks ,": 1.0,
    "processing tasks , there": 1.0,
    "tasks , there is": 1.0,
    ", there is also": 0.16666666666666666,
    "there is also considerable": 0.5,
    "is also considerable variation": 1.0,
    "also considerable variation across": 1.0,
    "considerable variation across their": 1.0,
    "variation across their ratings": 1.0,
    "across their ratings .": 1.0,
    "<s> this is why": 0.07142857142857142,
    "this is why automatic": 1.0,
    "is why automatic evaluation": 1.0,
    "why automatic evaluation is": 1.0,
    "automatic evaluation is sometimes": 1.0,
    "evaluation is sometimes referred": 1.0,
    "referred to as objective": 0.25,
    "to as objective evaluation": 1.0,
    "as objective evaluation ,": 1.0,
    "objective evaluation , while": 1.0,
    "evaluation , while the": 1.0,
    ", while the human": 1.0,
    "while the human kind": 1.0,
    "the human kind appears": 1.0,
    "human kind appears to": 1.0,
    "kind appears to be": 1.0,
    "appears to be more": 1.0,
    "to be more subjective": 1.0,
    "be more subjective .": 1.0,
    "<s> shared tasks -lrb-": 1.0,
    "shared tasks -lrb- campaigns": 1.0,
    "tasks -lrb- campaigns -rrb-": 1.0,
    "-lrb- campaigns -rrb- biocreative": 1.0,
    "campaigns -rrb- biocreative message": 1.0,
    "-rrb- biocreative message understanding": 1.0,
    "biocreative message understanding conference": 1.0,
    "message understanding conference technolangue\\/easy": 1.0,
    "understanding conference technolangue\\/easy text": 1.0,
    "conference technolangue\\/easy text retrieval": 1.0,
    "technolangue\\/easy text retrieval conference": 1.0,
    "text retrieval conference evaluation": 1.0,
    "retrieval conference evaluation exercises": 1.0,
    "conference evaluation exercises on": 1.0,
    "evaluation exercises on semantic": 1.0,
    "exercises on semantic evaluation": 1.0,
    "on semantic evaluation -lrb-": 1.0,
    "semantic evaluation -lrb- semeval": 1.0,
    "evaluation -lrb- semeval -rrb-": 1.0,
    "-lrb- semeval -rrb- morphochallenge": 1.0,
    "semeval -rrb- morphochallenge semi-supervised": 1.0,
    "-rrb- morphochallenge semi-supervised and": 1.0,
    "morphochallenge semi-supervised and unsupervised": 1.0,
    "semi-supervised and unsupervised morpheme": 1.0,
    "and unsupervised morpheme analysis": 1.0,
    "unsupervised morpheme analysis standardization": 1.0,
    "morpheme analysis standardization in": 1.0,
    "analysis standardization in nlp": 1.0,
    "standardization in nlp an": 1.0,
    "in nlp an iso": 1.0,
    "nlp an iso sub-committee": 1.0,
    "an iso sub-committee is": 1.0,
    "iso sub-committee is working": 1.0,
    "sub-committee is working in": 1.0,
    "is working in order": 1.0,
    "working in order to": 1.0,
    "in order to ease": 0.125,
    "order to ease interoperability": 1.0,
    "to ease interoperability between": 1.0,
    "ease interoperability between lexical": 1.0,
    "interoperability between lexical resources": 1.0,
    "between lexical resources and": 1.0,
    "lexical resources and nlp": 1.0,
    "resources and nlp programs": 1.0,
    "and nlp programs .": 1.0,
    "<s> the sub-committee is": 1.0,
    "the sub-committee is part": 1.0,
    "sub-committee is part of": 1.0,
    "is part of iso\\/tc37": 1.0,
    "part of iso\\/tc37 and": 1.0,
    "of iso\\/tc37 and is": 1.0,
    "iso\\/tc37 and is called": 1.0,
    "and is called iso\\/tc37\\/sc4": 1.0,
    "is called iso\\/tc37\\/sc4 .": 1.0,
    "<s> some iso standards": 1.0,
    "some iso standards are": 1.0,
    "iso standards are already": 1.0,
    "standards are already published": 1.0,
    "are already published but": 1.0,
    "already published but most": 1.0,
    "published but most of": 1.0,
    "but most of them": 1.0,
    "most of them are": 1.0,
    "of them are under": 1.0,
    "them are under construction": 1.0,
    "are under construction ,": 1.0,
    "under construction , mainly": 1.0,
    "construction , mainly on": 1.0,
    ", mainly on lexicon": 1.0,
    "mainly on lexicon representation": 1.0,
    "on lexicon representation -lrb-": 1.0,
    "lexicon representation -lrb- see": 1.0,
    "representation -lrb- see lmf": 1.0,
    "-lrb- see lmf -rrb-": 1.0,
    "see lmf -rrb- ,": 1.0,
    "lmf -rrb- , annotation": 1.0,
    "-rrb- , annotation and": 1.0,
    ", annotation and data": 1.0,
    "annotation and data category": 1.0,
    "and data category registry": 1.0,
    "data category registry .": 1.0,
    "<s> automatic summarization is": 0.5,
    "automatic summarization is the": 1.0,
    "summarization is the creation": 0.5,
    "is the creation of": 1.0,
    "the creation of a": 1.0,
    "creation of a shortened": 1.0,
    "of a shortened version": 1.0,
    "a shortened version of": 1.0,
    "shortened version of a": 1.0,
    "version of a text": 1.0,
    "of a text by": 0.25,
    "a text by a": 1.0,
    "text by a computer": 1.0,
    "by a computer program": 1.0,
    "a computer program .": 0.6666666666666666,
    "<s> the product of": 0.5,
    "the product of this": 1.0,
    "product of this procedure": 1.0,
    "of this procedure still": 1.0,
    "this procedure still contains": 1.0,
    "procedure still contains the": 1.0,
    "still contains the most": 1.0,
    "contains the most important": 1.0,
    "the most important points": 1.0,
    "most important points of": 1.0,
    "important points of the": 1.0,
    "points of the original": 1.0,
    "of the original text": 1.0,
    "the original text .": 0.5,
    "<s> discourse analysis -lrb-": 0.3333333333333333,
    "discourse analysis -lrb- da": 1.0,
    "analysis -lrb- da -rrb-": 1.0,
    "-lrb- da -rrb- ,": 0.5,
    "da -rrb- , or": 1.0,
    "-rrb- , or discourse": 0.3333333333333333,
    ", or discourse studies": 1.0,
    "or discourse studies ,": 1.0,
    "discourse studies , is": 1.0,
    "studies , is a": 1.0,
    ", is a general": 0.25,
    "is a general term": 0.5,
    "a general term for": 1.0,
    "general term for a": 1.0,
    "term for a number": 1.0,
    "a number of approaches": 0.045454545454545456,
    "number of approaches to": 1.0,
    "of approaches to analyzing": 1.0,
    "approaches to analyzing written": 1.0,
    "to analyzing written ,": 1.0,
    "analyzing written , spoken": 1.0,
    "written , spoken ,": 1.0,
    ", spoken , signed": 1.0,
    "spoken , signed language": 1.0,
    ", signed language use": 1.0,
    "signed language use or": 1.0,
    "language use or any": 1.0,
    "use or any significant": 1.0,
    "or any significant semiotic": 1.0,
    "any significant semiotic event": 1.0,
    "significant semiotic event .": 1.0,
    "<s> machine translation ,": 0.3333333333333333,
    "machine translation , sometimes": 0.14285714285714285,
    "translation , sometimes referred": 1.0,
    ", sometimes referred to": 1.0,
    "sometimes referred to by": 0.3333333333333333,
    "referred to by the": 0.5,
    "to by the abbreviation": 1.0,
    "by the abbreviation mt": 1.0,
    "the abbreviation mt -lrb-": 1.0,
    "abbreviation mt -lrb- not": 1.0,
    "mt -lrb- not to": 1.0,
    "-lrb- not to be": 1.0,
    "not to be confused": 1.0,
    "to be confused with": 1.0,
    "be confused with computer-aided": 1.0,
    "confused with computer-aided translation": 1.0,
    "with computer-aided translation ,": 1.0,
    "computer-aided translation , machine-aided": 1.0,
    "translation , machine-aided human": 1.0,
    ", machine-aided human translation": 1.0,
    "machine-aided human translation maht": 1.0,
    "human translation maht and": 1.0,
    "translation maht and interactive": 1.0,
    "maht and interactive translation": 1.0,
    "and interactive translation -rrb-": 1.0,
    "interactive translation -rrb- is": 1.0,
    "translation -rrb- is a": 1.0,
    "-rrb- is a sub-field": 0.25,
    "is a sub-field of": 1.0,
    "a sub-field of computational": 1.0,
    "sub-field of computational linguistics": 1.0,
    "of computational linguistics that": 0.3333333333333333,
    "computational linguistics that investigates": 1.0,
    "linguistics that investigates the": 1.0,
    "that investigates the use": 1.0,
    "investigates the use of": 1.0,
    "the use of software": 0.06666666666666667,
    "use of software to": 1.0,
    "of software to translate": 1.0,
    "software to translate text": 1.0,
    "to translate text or": 1.0,
    "translate text or speech": 1.0,
    "text or speech from": 1.0,
    "or speech from one": 1.0,
    "speech from one natural": 1.0,
    "from one natural language": 1.0,
    "one natural language to": 0.5,
    "natural language to another": 1.0,
    "<s> on a basic": 1.0,
    "on a basic level": 1.0,
    "a basic level ,": 1.0,
    "basic level , mt": 1.0,
    "level , mt performs": 1.0,
    ", mt performs simple": 1.0,
    "mt performs simple substitution": 1.0,
    "performs simple substitution of": 1.0,
    "simple substitution of words": 1.0,
    "substitution of words in": 1.0,
    "of words in one": 0.25,
    "words in one natural": 1.0,
    "in one natural language": 1.0,
    "one natural language for": 0.5,
    "natural language for words": 1.0,
    "language for words in": 1.0,
    "for words in another": 1.0,
    "words in another ,": 1.0,
    "in another , but": 1.0,
    "another , but that": 1.0,
    ", but that alone": 0.5,
    "but that alone usually": 1.0,
    "that alone usually can": 1.0,
    "alone usually can not": 1.0,
    "usually can not produce": 1.0,
    "can not produce a": 1.0,
    "not produce a good": 1.0,
    "produce a good translation": 1.0,
    "a good translation of": 1.0,
    "good translation of a": 1.0,
    "translation of a text": 0.5,
    "of a text ,": 0.5,
    "a text , because": 0.25,
    "text , because recognition": 1.0,
    ", because recognition of": 1.0,
    "because recognition of whole": 1.0,
    "recognition of whole phrases": 1.0,
    "of whole phrases and": 1.0,
    "whole phrases and their": 1.0,
    "phrases and their closest": 1.0,
    "and their closest counterparts": 1.0,
    "their closest counterparts in": 1.0,
    "closest counterparts in the": 1.0,
    "counterparts in the target": 1.0,
    "in the target language": 1.0,
    "the target language is": 0.375,
    "target language is needed": 0.3333333333333333,
    "language is needed .": 1.0,
    "<s> solving this problem": 1.0,
    "solving this problem with": 1.0,
    "this problem with corpus": 1.0,
    "problem with corpus and": 1.0,
    "with corpus and statistical": 1.0,
    "corpus and statistical techniques": 1.0,
    "and statistical techniques is": 1.0,
    "statistical techniques is a": 1.0,
    "techniques is a rapidly": 1.0,
    "is a rapidly growing": 1.0,
    "a rapidly growing field": 1.0,
    "rapidly growing field that": 1.0,
    "growing field that is": 1.0,
    "field that is leading": 1.0,
    "that is leading to": 1.0,
    "is leading to better": 1.0,
    "leading to better translations": 1.0,
    "to better translations ,": 1.0,
    "better translations , handling": 1.0,
    "translations , handling differences": 1.0,
    ", handling differences in": 1.0,
    "handling differences in linguistic": 1.0,
    "differences in linguistic typology": 1.0,
    "in linguistic typology ,": 1.0,
    "linguistic typology , translation": 1.0,
    "typology , translation of": 1.0,
    ", translation of idioms": 1.0,
    "translation of idioms ,": 1.0,
    "of idioms , and": 1.0,
    "idioms , and the": 1.0,
    ", and the isolation": 0.1,
    "and the isolation of": 1.0,
    "the isolation of anomalies": 1.0,
    "isolation of anomalies .": 1.0,
    "<s> -lrb- citation needed": 1.0,
    "-lrb- citation needed -rrb-": 1.0,
    "citation needed -rrb- current": 0.07692307692307693,
    "needed -rrb- current machine": 1.0,
    "-rrb- current machine translation": 1.0,
    "current machine translation software": 1.0,
    "machine translation software often": 0.5,
    "translation software often allows": 1.0,
    "software often allows for": 1.0,
    "often allows for customisation": 1.0,
    "allows for customisation by": 1.0,
    "for customisation by domain": 1.0,
    "customisation by domain or": 1.0,
    "by domain or profession": 1.0,
    "domain or profession -lrb-": 1.0,
    "or profession -lrb- such": 1.0,
    "profession -lrb- such as": 1.0,
    "-lrb- such as weather": 0.125,
    "such as weather reports": 1.0,
    "as weather reports -rrb-": 1.0,
    "weather reports -rrb- ,": 0.5,
    "reports -rrb- , improving": 1.0,
    "-rrb- , improving output": 1.0,
    ", improving output by": 1.0,
    "improving output by limiting": 1.0,
    "output by limiting the": 1.0,
    "by limiting the scope": 1.0,
    "limiting the scope of": 1.0,
    "the scope of allowable": 0.5,
    "scope of allowable substitutions": 1.0,
    "of allowable substitutions .": 1.0,
    "<s> this technique is": 1.0,
    "this technique is particularly": 1.0,
    "technique is particularly effective": 1.0,
    "is particularly effective in": 1.0,
    "particularly effective in domains": 1.0,
    "effective in domains where": 1.0,
    "in domains where formal": 1.0,
    "domains where formal or": 1.0,
    "where formal or formulaic": 1.0,
    "formal or formulaic language": 1.0,
    "or formulaic language is": 1.0,
    "formulaic language is used": 1.0,
    "language is used .": 1.0,
    "<s> it follows that": 1.0,
    "it follows that machine": 1.0,
    "follows that machine translation": 1.0,
    "that machine translation of": 0.5,
    "machine translation of government": 0.5,
    "translation of government and": 1.0,
    "of government and legal": 1.0,
    "government and legal documents": 1.0,
    "and legal documents more": 1.0,
    "legal documents more readily": 1.0,
    "documents more readily produces": 1.0,
    "more readily produces usable": 1.0,
    "readily produces usable output": 1.0,
    "produces usable output than": 1.0,
    "usable output than conversation": 1.0,
    "output than conversation or": 1.0,
    "than conversation or less": 1.0,
    "conversation or less standardised": 1.0,
    "or less standardised text": 1.0,
    "less standardised text .": 1.0,
    "<s> improved output quality": 1.0,
    "improved output quality can": 1.0,
    "output quality can also": 1.0,
    "quality can also be": 1.0,
    "can also be achieved": 0.25,
    "also be achieved by": 1.0,
    "be achieved by human": 1.0,
    "achieved by human intervention": 1.0,
    "by human intervention :": 1.0,
    "human intervention : for": 1.0,
    "intervention : for example": 1.0,
    ": for example ,": 1.0,
    "for example , some": 0.02127659574468085,
    "example , some systems": 1.0,
    ", some systems are": 1.0,
    "some systems are able": 0.5,
    "systems are able to": 1.0,
    "are able to translate": 0.3333333333333333,
    "able to translate more": 1.0,
    "to translate more accurately": 1.0,
    "translate more accurately if": 1.0,
    "more accurately if the": 1.0,
    "accurately if the user": 1.0,
    "if the user has": 1.0,
    "the user has unambiguously": 1.0,
    "user has unambiguously identified": 1.0,
    "has unambiguously identified which": 1.0,
    "unambiguously identified which words": 1.0,
    "identified which words in": 1.0,
    "which words in the": 1.0,
    "words in the text": 0.25,
    "in the text are": 0.125,
    "the text are names": 1.0,
    "text are names .": 1.0,
    "<s> with the assistance": 0.5,
    "with the assistance of": 1.0,
    "the assistance of these": 1.0,
    "assistance of these techniques": 1.0,
    "of these techniques ,": 1.0,
    "these techniques , mt": 1.0,
    "techniques , mt has": 1.0,
    ", mt has proven": 1.0,
    "mt has proven useful": 1.0,
    "has proven useful as": 1.0,
    "proven useful as a": 1.0,
    "useful as a tool": 1.0,
    "as a tool to": 1.0,
    "a tool to assist": 1.0,
    "tool to assist human": 1.0,
    "to assist human translators": 1.0,
    "assist human translators and": 1.0,
    "human translators and ,": 1.0,
    "translators and , in": 1.0,
    "and , in a": 1.0,
    ", in a very": 0.3333333333333333,
    "in a very limited": 1.0,
    "a very limited number": 1.0,
    "very limited number of": 1.0,
    "limited number of cases": 0.5,
    "number of cases ,": 1.0,
    "of cases , can": 1.0,
    "cases , can even": 1.0,
    ", can even produce": 1.0,
    "can even produce output": 1.0,
    "even produce output that": 1.0,
    "produce output that can": 1.0,
    "output that can be": 1.0,
    "that can be used": 0.2,
    "can be used as": 0.2,
    "be used as is": 0.5,
    "used as is -lrb-": 1.0,
    "as is -lrb- e.g.": 1.0,
    "is -lrb- e.g. ,": 0.5,
    "-lrb- e.g. , weather": 0.05263157894736842,
    "e.g. , weather reports": 1.0,
    ", weather reports -rrb-": 1.0,
    "weather reports -rrb- .": 0.5,
    "<s> the progress and": 1.0,
    "the progress and potential": 1.0,
    "progress and potential of": 1.0,
    "and potential of machine": 1.0,
    "potential of machine translation": 1.0,
    "of machine translation has": 0.3333333333333333,
    "machine translation has been": 1.0,
    "translation has been debated": 1.0,
    "has been debated much": 1.0,
    "been debated much through": 1.0,
    "debated much through its": 1.0,
    "much through its history": 1.0,
    "through its history .": 1.0,
    "<s> since the 1950s": 1.0,
    "since the 1950s ,": 1.0,
    "the 1950s , a": 0.5,
    "1950s , a number": 1.0,
    "a number of scholars": 0.045454545454545456,
    "number of scholars have": 1.0,
    "of scholars have questioned": 1.0,
    "scholars have questioned the": 1.0,
    "have questioned the possibility": 1.0,
    "questioned the possibility of": 1.0,
    "the possibility of achieving": 0.3333333333333333,
    "possibility of achieving fully": 1.0,
    "of achieving fully automatic": 1.0,
    "achieving fully automatic machine": 1.0,
    "fully automatic machine translation": 1.0,
    "automatic machine translation of": 1.0,
    "machine translation of high": 0.5,
    "translation of high quality": 1.0,
    "of high quality .": 1.0,
    "<s> some critics claim": 1.0,
    "some critics claim that": 1.0,
    "critics claim that there": 1.0,
    "claim that there are": 1.0,
    "that there are in-principle": 0.5,
    "there are in-principle obstacles": 1.0,
    "are in-principle obstacles to": 1.0,
    "in-principle obstacles to automatizing": 1.0,
    "obstacles to automatizing the": 1.0,
    "to automatizing the translation": 1.0,
    "automatizing the translation process": 1.0,
    "the translation process .": 1.0,
    "<s> in 1629 ,": 1.0,
    "in 1629 , ren\u00e9": 1.0,
    "1629 , ren\u00e9 descartes": 1.0,
    ", ren\u00e9 descartes proposed": 1.0,
    "ren\u00e9 descartes proposed a": 1.0,
    "descartes proposed a universal": 1.0,
    "proposed a universal language": 1.0,
    "a universal language ,": 1.0,
    "universal language , with": 1.0,
    "language , with equivalent": 1.0,
    ", with equivalent ideas": 1.0,
    "with equivalent ideas in": 1.0,
    "equivalent ideas in different": 1.0,
    "ideas in different tongues": 1.0,
    "in different tongues sharing": 1.0,
    "different tongues sharing one": 1.0,
    "tongues sharing one symbol": 1.0,
    "sharing one symbol .": 1.0,
    "<s> in the 1950s": 0.08333333333333333,
    "in the 1950s ,": 0.5,
    "the 1950s , the": 0.5,
    "1950s , the georgetown": 1.0,
    ", the georgetown experiment": 1.0,
    "the georgetown experiment -lrb-": 0.3333333333333333,
    "georgetown experiment -lrb- 1954": 1.0,
    "experiment -lrb- 1954 -rrb-": 1.0,
    "-lrb- 1954 -rrb- involved": 1.0,
    "1954 -rrb- involved fully": 1.0,
    "-rrb- involved fully automatic": 1.0,
    "automatic translation of over": 0.5,
    "translation of over sixty": 1.0,
    "of over sixty russian": 1.0,
    "over sixty russian sentences": 1.0,
    "<s> the experiment was": 1.0,
    "the experiment was a": 1.0,
    "experiment was a great": 1.0,
    "was a great success": 1.0,
    "a great success and": 1.0,
    "great success and ushered": 1.0,
    "success and ushered in": 1.0,
    "and ushered in an": 1.0,
    "ushered in an era": 1.0,
    "in an era of": 1.0,
    "an era of substantial": 1.0,
    "era of substantial funding": 1.0,
    "of substantial funding for": 1.0,
    "substantial funding for machine-translation": 1.0,
    "funding for machine-translation research": 1.0,
    "for machine-translation research .": 1.0,
    "that within three to": 0.5,
    "within three to five": 1.0,
    "three to five years": 1.0,
    "to five years ,": 1.0,
    "<s> real progress was": 1.0,
    "much slower , however": 0.5,
    "slower , however ,": 1.0,
    ", however , and": 0.09090909090909091,
    "however , and after": 1.0,
    "the alpac report -lrb-": 0.5,
    "alpac report -lrb- 1966": 1.0,
    "report -lrb- 1966 -rrb-": 1.0,
    "-lrb- 1966 -rrb- ,": 1.0,
    "1966 -rrb- , which": 1.0,
    "-rrb- , which found": 0.3333333333333333,
    "which found that the": 0.5,
    "found that the ten-year-long": 1.0,
    "that the ten-year-long research": 1.0,
    "the ten-year-long research had": 1.0,
    "ten-year-long research had failed": 1.0,
    "failed to fulfill expectations": 0.5,
    "to fulfill expectations ,": 1.0,
    "fulfill expectations , funding": 1.0,
    "expectations , funding was": 0.5,
    ", funding was greatly": 1.0,
    "funding was greatly reduced": 1.0,
    "was greatly reduced .": 1.0,
    "<s> beginning in the": 1.0,
    "beginning in the late": 1.0,
    "late 1980s , as": 0.3333333333333333,
    "1980s , as computational": 1.0,
    ", as computational power": 1.0,
    "as computational power increased": 1.0,
    "computational power increased and": 1.0,
    "power increased and became": 1.0,
    "increased and became less": 1.0,
    "and became less expensive": 1.0,
    "became less expensive ,": 1.0,
    "less expensive , more": 1.0,
    "expensive , more interest": 1.0,
    ", more interest was": 1.0,
    "more interest was shown": 1.0,
    "interest was shown in": 1.0,
    "was shown in statistical": 1.0,
    "shown in statistical models": 1.0,
    "in statistical models for": 1.0,
    "statistical models for machine": 1.0,
    "models for machine translation": 1.0,
    "for machine translation .": 0.3333333333333333,
    "<s> the idea of": 1.0,
    "the idea of using": 0.5,
    "idea of using digital": 1.0,
    "of using digital computers": 1.0,
    "using digital computers for": 1.0,
    "digital computers for translation": 1.0,
    "computers for translation of": 1.0,
    "for translation of natural": 1.0,
    "translation of natural languages": 1.0,
    "of natural languages was": 0.2,
    "natural languages was proposed": 1.0,
    "languages was proposed as": 1.0,
    "was proposed as early": 1.0,
    "proposed as early as": 1.0,
    "as early as 1946": 1.0,
    "early as 1946 by": 1.0,
    "as 1946 by a.": 1.0,
    "1946 by a. d.": 1.0,
    "by a. d. booth": 1.0,
    "a. d. booth and": 1.0,
    "d. booth and possibly": 1.0,
    "booth and possibly others": 1.0,
    "and possibly others .": 1.0,
    "<s> warren weaver wrote": 1.0,
    "warren weaver wrote an": 1.0,
    "weaver wrote an important": 1.0,
    "wrote an important memorandum": 1.0,
    "an important memorandum ``": 1.0,
    "important memorandum `` translation": 1.0,
    "memorandum `` translation ''": 1.0,
    "`` translation '' in": 1.0,
    "translation '' in 1949": 1.0,
    "'' in 1949 .": 1.0,
    "the georgetown experiment was": 0.3333333333333333,
    "georgetown experiment was by": 1.0,
    "experiment was by no": 1.0,
    "was by no means": 1.0,
    "by no means the": 1.0,
    "no means the first": 1.0,
    "means the first such": 1.0,
    "the first such application": 1.0,
    "first such application ,": 1.0,
    "such application , and": 1.0,
    "application , and a": 1.0,
    ", and a demonstration": 0.3333333333333333,
    "and a demonstration was": 0.5,
    "a demonstration was made": 1.0,
    "demonstration was made in": 1.0,
    "was made in 1954": 1.0,
    "made in 1954 on": 1.0,
    "in 1954 on the": 1.0,
    "1954 on the apexc": 1.0,
    "on the apexc machine": 1.0,
    "the apexc machine at": 1.0,
    "apexc machine at birkbeck": 1.0,
    "machine at birkbeck college": 1.0,
    "at birkbeck college -lrb-": 0.5,
    "birkbeck college -lrb- university": 1.0,
    "college -lrb- university of": 1.0,
    "-lrb- university of london": 1.0,
    "university of london -rrb-": 1.0,
    "of london -rrb- of": 1.0,
    "london -rrb- of a": 1.0,
    "-rrb- of a rudimentary": 0.5,
    "of a rudimentary translation": 1.0,
    "a rudimentary translation of": 1.0,
    "rudimentary translation of english": 1.0,
    "translation of english into": 1.0,
    "of english into french": 1.0,
    "english into french .": 1.0,
    "<s> several papers on": 1.0,
    "several papers on the": 1.0,
    "papers on the topic": 1.0,
    "on the topic were": 1.0,
    "the topic were published": 1.0,
    "topic were published at": 1.0,
    "were published at the": 1.0,
    "published at the time": 1.0,
    "at the time ,": 1.0,
    "the time , and": 0.2,
    "time , and even": 0.5,
    ", and even articles": 0.16666666666666666,
    "and even articles in": 1.0,
    "even articles in popular": 1.0,
    "articles in popular journals": 1.0,
    "in popular journals -lrb-": 1.0,
    "popular journals -lrb- see": 1.0,
    "journals -lrb- see for": 1.0,
    "-lrb- see for example": 1.0,
    "see for example wireless": 1.0,
    "for example wireless world": 1.0,
    "example wireless world ,": 1.0,
    "wireless world , sept.": 1.0,
    "world , sept. 1955": 1.0,
    ", sept. 1955 ,": 1.0,
    "sept. 1955 , cleave": 1.0,
    "1955 , cleave and": 1.0,
    ", cleave and zacharov": 1.0,
    "cleave and zacharov -rrb-": 1.0,
    "and zacharov -rrb- .": 1.0,
    "<s> a similar application": 1.0,
    "a similar application ,": 1.0,
    "similar application , also": 1.0,
    "application , also pioneered": 1.0,
    ", also pioneered at": 1.0,
    "also pioneered at birkbeck": 1.0,
    "pioneered at birkbeck college": 1.0,
    "at birkbeck college at": 0.5,
    "birkbeck college at the": 1.0,
    "college at the time": 1.0,
    "the time , was": 0.2,
    "time , was reading": 1.0,
    ", was reading and": 1.0,
    "was reading and composing": 1.0,
    "reading and composing braille": 1.0,
    "and composing braille texts": 1.0,
    "composing braille texts by": 1.0,
    "braille texts by computer": 1.0,
    "texts by computer .": 1.0,
    "<s> translation process main": 1.0,
    "translation process main article": 1.0,
    "process main article :": 1.0,
    "main article : translation": 0.08333333333333333,
    "article : translation process": 1.0,
    ": translation process the": 1.0,
    "translation process the human": 1.0,
    "process the human translation": 1.0,
    "the human translation process": 1.0,
    "human translation process may": 1.0,
    "translation process may be": 1.0,
    "process may be described": 1.0,
    "may be described as": 1.0,
    "be described as :": 1.0,
    "described as : decoding": 1.0,
    "as : decoding the": 1.0,
    ": decoding the meaning": 1.0,
    "decoding the meaning of": 1.0,
    "the meaning of the": 0.3333333333333333,
    "meaning of the source": 1.0,
    "of the source text": 0.6,
    "the source text ;": 0.25,
    "source text ; and": 1.0,
    "text ; and re-encoding": 1.0,
    "; and re-encoding this": 1.0,
    "and re-encoding this meaning": 1.0,
    "re-encoding this meaning in": 1.0,
    "this meaning in the": 1.0,
    "meaning in the target": 1.0,
    "the target language .": 0.25,
    "<s> behind this ostensibly": 1.0,
    "behind this ostensibly simple": 1.0,
    "this ostensibly simple procedure": 1.0,
    "ostensibly simple procedure lies": 1.0,
    "simple procedure lies a": 1.0,
    "procedure lies a complex": 1.0,
    "lies a complex cognitive": 1.0,
    "a complex cognitive operation": 1.0,
    "complex cognitive operation .": 1.0,
    "<s> to decode the": 1.0,
    "to decode the meaning": 1.0,
    "decode the meaning of": 1.0,
    "the source text in": 0.25,
    "source text in its": 1.0,
    "text in its entirety": 1.0,
    "in its entirety ,": 1.0,
    "its entirety , the": 1.0,
    "entirety , the translator": 1.0,
    ", the translator must": 1.0,
    "the translator must interpret": 1.0,
    "translator must interpret and": 1.0,
    "must interpret and analyze": 1.0,
    "interpret and analyze all": 1.0,
    "and analyze all the": 1.0,
    "analyze all the features": 1.0,
    "all the features of": 1.0,
    "the features of the": 1.0,
    "features of the text": 1.0,
    "of the text ,": 0.375,
    "the text , a": 0.3333333333333333,
    "text , a process": 1.0,
    ", a process that": 1.0,
    "a process that requires": 0.5,
    "process that requires in-depth": 1.0,
    "that requires in-depth knowledge": 1.0,
    "requires in-depth knowledge of": 1.0,
    "in-depth knowledge of the": 1.0,
    "knowledge of the grammar": 0.4,
    "of the grammar ,": 0.3333333333333333,
    "the grammar , semantics": 1.0,
    ", semantics , syntax": 0.3333333333333333,
    "semantics , syntax ,": 1.0,
    ", syntax , idioms": 0.5,
    "syntax , idioms ,": 1.0,
    ", idioms , etc.": 1.0,
    "idioms , etc. ,": 1.0,
    ", etc. , of": 1.0,
    "etc. , of the": 1.0,
    ", of the source": 1.0,
    "of the source language": 0.2,
    "the source language ,": 0.6666666666666666,
    "source language , as": 0.5,
    "language , as well": 1.0,
    ", as well as": 1.0,
    "as well as the": 0.07692307692307693,
    "well as the culture": 1.0,
    "as the culture of": 1.0,
    "the culture of its": 1.0,
    "culture of its speakers": 1.0,
    "of its speakers .": 1.0,
    "<s> the translator needs": 1.0,
    "the translator needs the": 1.0,
    "translator needs the same": 1.0,
    "needs the same in-depth": 1.0,
    "the same in-depth knowledge": 1.0,
    "same in-depth knowledge to": 1.0,
    "in-depth knowledge to re-encode": 1.0,
    "knowledge to re-encode the": 1.0,
    "to re-encode the meaning": 1.0,
    "re-encode the meaning in": 1.0,
    "the meaning in the": 1.0,
    "<s> therein lies the": 1.0,
    "therein lies the challenge": 1.0,
    "lies the challenge in": 1.0,
    "the challenge in machine": 1.0,
    "challenge in machine translation": 1.0,
    "in machine translation :": 0.5,
    "machine translation : how": 0.5,
    "translation : how to": 1.0,
    ": how to program": 1.0,
    "how to program a": 1.0,
    "to program a computer": 1.0,
    "program a computer that": 1.0,
    "a computer that will": 1.0,
    "computer that will ``": 1.0,
    "that will `` understand": 0.5,
    "will `` understand ''": 1.0,
    "`` understand '' a": 1.0,
    "understand '' a text": 1.0,
    "'' a text as": 1.0,
    "a text as a": 1.0,
    "text as a person": 1.0,
    "as a person does": 1.0,
    "a person does ,": 1.0,
    "person does , and": 1.0,
    "does , and that": 1.0,
    ", and that will": 1.0,
    "and that will ``": 1.0,
    "that will `` create": 0.5,
    "will `` create ''": 1.0,
    "`` create '' a": 1.0,
    "create '' a new": 1.0,
    "'' a new text": 1.0,
    "a new text in": 1.0,
    "new text in the": 1.0,
    "text in the target": 0.6666666666666666,
    "the target language that": 0.125,
    "target language that ``": 1.0,
    "language that `` sounds": 1.0,
    "that `` sounds ''": 1.0,
    "`` sounds '' as": 1.0,
    "sounds '' as if": 1.0,
    "'' as if it": 1.0,
    "as if it has": 1.0,
    "if it has been": 1.0,
    "it has been written": 0.3333333333333333,
    "has been written by": 1.0,
    "been written by a": 1.0,
    "written by a person": 0.5,
    "by a person .": 1.0,
    "<s> this problem may": 0.25,
    "this problem may be": 1.0,
    "problem may be approached": 1.0,
    "may be approached in": 1.0,
    "be approached in a": 1.0,
    "approached in a number": 1.0,
    "in a number of": 1.0,
    "a number of ways": 0.09090909090909091,
    "number of ways .": 0.5,
    "<s> approaches bernard vauquois": 1.0,
    "approaches bernard vauquois '": 1.0,
    "bernard vauquois ' pyramid": 1.0,
    "vauquois ' pyramid showing": 1.0,
    "' pyramid showing comparative": 1.0,
    "pyramid showing comparative depths": 1.0,
    "showing comparative depths of": 1.0,
    "comparative depths of intermediary": 1.0,
    "depths of intermediary representation": 1.0,
    "of intermediary representation ,": 1.0,
    "intermediary representation , interlingual": 0.5,
    "representation , interlingual machine": 1.0,
    ", interlingual machine translation": 1.0,
    "interlingual machine translation at": 0.2,
    "machine translation at the": 1.0,
    "translation at the peak": 1.0,
    "at the peak ,": 1.0,
    "the peak , followed": 1.0,
    "peak , followed by": 1.0,
    ", followed by transfer-based": 1.0,
    "followed by transfer-based ,": 1.0,
    "by transfer-based , then": 1.0,
    "transfer-based , then direct": 1.0,
    ", then direct translation": 1.0,
    "then direct translation .": 1.0,
    "<s> machine translation can": 0.3333333333333333,
    "machine translation can use": 1.0,
    "translation can use a": 1.0,
    "can use a method": 1.0,
    "use a method based": 1.0,
    "a method based on": 1.0,
    "method based on linguistic": 0.5,
    "based on linguistic rules": 1.0,
    "on linguistic rules ,": 1.0,
    "linguistic rules , which": 1.0,
    "rules , which means": 0.5,
    ", which means that": 0.75,
    "which means that words": 0.3333333333333333,
    "means that words will": 1.0,
    "that words will be": 1.0,
    "words will be translated": 1.0,
    "will be translated in": 0.5,
    "be translated in a": 1.0,
    "translated in a linguistic": 1.0,
    "in a linguistic way": 1.0,
    "a linguistic way --": 1.0,
    "linguistic way -- the": 1.0,
    "way -- the most": 1.0,
    "-- the most suitable": 1.0,
    "the most suitable -lrb-": 1.0,
    "most suitable -lrb- orally": 1.0,
    "suitable -lrb- orally speaking": 1.0,
    "-lrb- orally speaking -rrb-": 1.0,
    "orally speaking -rrb- words": 1.0,
    "speaking -rrb- words of": 1.0,
    "-rrb- words of the": 1.0,
    "words of the target": 0.5,
    "of the target language": 1.0,
    "the target language will": 0.125,
    "target language will replace": 1.0,
    "language will replace the": 1.0,
    "will replace the ones": 1.0,
    "replace the ones in": 1.0,
    "the ones in the": 1.0,
    "ones in the source": 1.0,
    "in the source language": 0.5,
    "the source language .": 0.3333333333333333,
    "<s> it is often": 0.10526315789473684,
    "it is often argued": 0.16666666666666666,
    "is often argued that": 1.0,
    "often argued that the": 1.0,
    "argued that the success": 1.0,
    "that the success of": 1.0,
    "the success of machine": 0.3333333333333333,
    "success of machine translation": 1.0,
    "of machine translation requires": 0.3333333333333333,
    "machine translation requires the": 1.0,
    "translation requires the problem": 1.0,
    "requires the problem of": 1.0,
    "the problem of natural": 0.16666666666666666,
    "problem of natural language": 0.5,
    "of natural language understanding": 0.17647058823529413,
    "natural language understanding to": 0.08333333333333333,
    "language understanding to be": 1.0,
    "understanding to be solved": 1.0,
    "to be solved first": 1.0,
    "be solved first .": 1.0,
    "<s> generally , rule-based": 0.3333333333333333,
    "generally , rule-based methods": 1.0,
    ", rule-based methods parse": 1.0,
    "rule-based methods parse a": 1.0,
    "methods parse a text": 1.0,
    "parse a text ,": 1.0,
    "a text , usually": 0.25,
    "text , usually creating": 1.0,
    ", usually creating an": 1.0,
    "usually creating an intermediary": 1.0,
    "creating an intermediary ,": 1.0,
    "an intermediary , symbolic": 1.0,
    "intermediary , symbolic representation": 1.0,
    ", symbolic representation ,": 1.0,
    "symbolic representation , from": 1.0,
    "representation , from which": 1.0,
    ", from which the": 1.0,
    "from which the text": 1.0,
    "which the text in": 1.0,
    "the text in the": 0.6666666666666666,
    "target language is generated": 0.3333333333333333,
    "language is generated .": 1.0,
    "<s> according to the": 1.0,
    "according to the nature": 0.3333333333333333,
    "to the nature of": 1.0,
    "nature of the intermediary": 0.2,
    "of the intermediary representation": 1.0,
    "the intermediary representation ,": 1.0,
    "intermediary representation , an": 0.5,
    "representation , an approach": 1.0,
    ", an approach is": 1.0,
    "an approach is described": 0.5,
    "approach is described as": 1.0,
    "is described as interlingual": 1.0,
    "described as interlingual machine": 1.0,
    "as interlingual machine translation": 1.0,
    "interlingual machine translation or": 0.2,
    "machine translation or transfer-based": 1.0,
    "translation or transfer-based machine": 1.0,
    "or transfer-based machine translation": 1.0,
    "transfer-based machine translation .": 0.25,
    "<s> these methods require": 0.5,
    "these methods require extensive": 1.0,
    "methods require extensive lexicons": 1.0,
    "require extensive lexicons with": 1.0,
    "extensive lexicons with morphological": 1.0,
    "lexicons with morphological ,": 1.0,
    "with morphological , syntactic": 1.0,
    "morphological , syntactic ,": 1.0,
    ", syntactic , and": 1.0,
    "syntactic , and semantic": 1.0,
    ", and semantic information": 1.0,
    "and semantic information ,": 1.0,
    "semantic information , and": 1.0,
    "information , and large": 0.5,
    ", and large sets": 1.0,
    "and large sets of": 1.0,
    "<s> given enough data": 1.0,
    "given enough data ,": 1.0,
    "enough data , machine": 1.0,
    "data , machine translation": 1.0,
    ", machine translation programs": 0.3333333333333333,
    "machine translation programs often": 1.0,
    "translation programs often work": 1.0,
    "programs often work well": 1.0,
    "often work well enough": 1.0,
    "work well enough for": 1.0,
    "well enough for a": 1.0,
    "enough for a native": 1.0,
    "for a native speaker": 1.0,
    "a native speaker of": 1.0,
    "native speaker of one": 0.5,
    "speaker of one language": 1.0,
    "of one language to": 1.0,
    "one language to get": 1.0,
    "language to get the": 1.0,
    "to get the approximate": 1.0,
    "get the approximate meaning": 1.0,
    "the approximate meaning of": 1.0,
    "approximate meaning of what": 1.0,
    "meaning of what is": 1.0,
    "of what is written": 1.0,
    "what is written by": 1.0,
    "is written by the": 1.0,
    "written by the other": 1.0,
    "by the other native": 1.0,
    "the other native speaker": 1.0,
    "other native speaker .": 1.0,
    "<s> the difficulty is": 0.3333333333333333,
    "the difficulty is getting": 1.0,
    "difficulty is getting enough": 1.0,
    "is getting enough data": 1.0,
    "getting enough data of": 1.0,
    "enough data of the": 1.0,
    "data of the right": 1.0,
    "of the right kind": 1.0,
    "the right kind to": 1.0,
    "right kind to support": 1.0,
    "kind to support the": 1.0,
    "to support the particular": 1.0,
    "support the particular method": 1.0,
    "the particular method .": 1.0,
    "example , the large": 0.25,
    ", the large multilingual": 1.0,
    "the large multilingual corpus": 1.0,
    "large multilingual corpus of": 1.0,
    "multilingual corpus of data": 1.0,
    "corpus of data needed": 1.0,
    "of data needed for": 1.0,
    "data needed for statistical": 1.0,
    "needed for statistical methods": 1.0,
    "for statistical methods to": 1.0,
    "statistical methods to work": 0.3333333333333333,
    "methods to work is": 1.0,
    "to work is not": 1.0,
    "work is not necessary": 1.0,
    "is not necessary for": 1.0,
    "not necessary for the": 1.0,
    "necessary for the grammar-based": 1.0,
    "for the grammar-based methods": 1.0,
    "the grammar-based methods .": 1.0,
    "<s> but then ,": 1.0,
    "but then , the": 1.0,
    "then , the grammar": 0.3333333333333333,
    ", the grammar methods": 1.0,
    "the grammar methods need": 1.0,
    "grammar methods need a": 1.0,
    "methods need a skilled": 1.0,
    "need a skilled linguist": 1.0,
    "a skilled linguist to": 1.0,
    "skilled linguist to carefully": 1.0,
    "linguist to carefully design": 1.0,
    "to carefully design the": 1.0,
    "carefully design the grammar": 1.0,
    "design the grammar that": 1.0,
    "the grammar that they": 1.0,
    "grammar that they use": 1.0,
    "that they use .": 1.0,
    "<s> to translate between": 1.0,
    "to translate between closely": 1.0,
    "translate between closely related": 1.0,
    "between closely related languages": 1.0,
    "closely related languages ,": 1.0,
    "related languages , a": 1.0,
    "languages , a technique": 1.0,
    ", a technique referred": 1.0,
    "a technique referred to": 1.0,
    "technique referred to as": 1.0,
    "referred to as shallow-transfer": 0.25,
    "to as shallow-transfer machine": 1.0,
    "as shallow-transfer machine translation": 1.0,
    "shallow-transfer machine translation may": 1.0,
    "machine translation may be": 1.0,
    "translation may be used": 1.0,
    "may be used .": 1.0,
    "<s> rule-based the rule-based": 1.0,
    "rule-based the rule-based machine": 1.0,
    "the rule-based machine translation": 1.0,
    "rule-based machine translation paradigm": 0.5,
    "machine translation paradigm includes": 1.0,
    "translation paradigm includes transfer-based": 1.0,
    "paradigm includes transfer-based machine": 1.0,
    "includes transfer-based machine translation": 1.0,
    "transfer-based machine translation ,": 0.25,
    "machine translation , interlingual": 0.14285714285714285,
    "translation , interlingual machine": 1.0,
    "interlingual machine translation and": 0.2,
    "machine translation and dictionary-based": 0.5,
    "translation and dictionary-based machine": 1.0,
    "and dictionary-based machine translation": 1.0,
    "dictionary-based machine translation paradigms": 0.5,
    "machine translation paradigms .": 1.0,
    "<s> main article :": 1.0,
    "main article : rule-based": 0.08333333333333333,
    "article : rule-based machine": 1.0,
    ": rule-based machine translation": 1.0,
    "rule-based machine translation transfer-based": 0.5,
    "machine translation transfer-based machine": 1.0,
    "translation transfer-based machine translation": 1.0,
    "transfer-based machine translation main": 0.25,
    "machine translation main article": 1.0,
    "translation main article :": 1.0,
    "main article : transfer-based": 0.08333333333333333,
    "article : transfer-based machine": 1.0,
    ": transfer-based machine translation": 1.0,
    "transfer-based machine translation interlingual": 0.25,
    "machine translation interlingual main": 0.5,
    "translation interlingual main article": 1.0,
    "interlingual main article :": 1.0,
    "main article : interlingual": 0.08333333333333333,
    "article : interlingual machine": 1.0,
    ": interlingual machine translation": 1.0,
    "interlingual machine translation interlingual": 0.2,
    "machine translation interlingual machine": 0.5,
    "translation interlingual machine translation": 1.0,
    "interlingual machine translation is": 0.2,
    "machine translation is one": 1.0,
    "translation is one instance": 1.0,
    "is one instance of": 1.0,
    "one instance of rule-based": 1.0,
    "instance of rule-based machine-translation": 1.0,
    "of rule-based machine-translation approaches": 1.0,
    "rule-based machine-translation approaches .": 1.0,
    "<s> in this approach": 0.2,
    "in this approach ,": 1.0,
    "this approach , the": 1.0,
    "approach , the source": 1.0,
    ", the source language": 1.0,
    "source language , i.e.": 0.5,
    "language , i.e. the": 1.0,
    ", i.e. the text": 0.5,
    "i.e. the text to": 1.0,
    "the text to be": 0.5,
    "text to be translated": 1.0,
    "to be translated ,": 1.0,
    "be translated , is": 1.0,
    "translated , is transformed": 1.0,
    ", is transformed into": 1.0,
    "is transformed into an": 1.0,
    "transformed into an interlingual": 1.0,
    "into an interlingual ,": 1.0,
    "an interlingual , i.e.": 1.0,
    "interlingual , i.e. source": 1.0,
    ", i.e. source -": 1.0,
    "i.e. source - \\/": 1.0,
    "source - \\/ target-language-independent": 1.0,
    "- \\/ target-language-independent representation": 1.0,
    "\\/ target-language-independent representation .": 1.0,
    "<s> the target language": 1.0,
    "target language is then": 0.3333333333333333,
    "language is then generated": 1.0,
    "is then generated out": 1.0,
    "then generated out of": 1.0,
    "generated out of the": 1.0,
    "out of the interlingua": 1.0,
    "of the interlingua .": 1.0,
    "<s> dictionary-based main article": 1.0,
    "dictionary-based main article :": 1.0,
    "main article : dictionary-based": 0.08333333333333333,
    "article : dictionary-based machine": 1.0,
    ": dictionary-based machine translation": 1.0,
    "dictionary-based machine translation machine": 0.5,
    "machine translation machine translation": 1.0,
    "translation machine translation can": 1.0,
    "method based on dictionary": 0.5,
    "based on dictionary entries": 1.0,
    "on dictionary entries ,": 1.0,
    "dictionary entries , which": 1.0,
    "entries , which means": 1.0,
    "which means that the": 0.3333333333333333,
    "means that the words": 1.0,
    "that the words will": 1.0,
    "the words will be": 1.0,
    "will be translated as": 0.5,
    "be translated as they": 1.0,
    "translated as they are": 1.0,
    "as they are by": 0.5,
    "they are by a": 1.0,
    "are by a dictionary": 1.0,
    "by a dictionary .": 1.0,
    "<s> statistical main article": 1.0,
    "statistical main article :": 1.0,
    "article : statistical machine": 0.5,
    ": statistical machine translation": 1.0,
    "statistical machine translation statistical": 0.25,
    "machine translation statistical machine": 1.0,
    "translation statistical machine translation": 1.0,
    "statistical machine translation tries": 0.25,
    "machine translation tries to": 1.0,
    "translation tries to generate": 1.0,
    "tries to generate translations": 1.0,
    "to generate translations using": 1.0,
    "generate translations using statistical": 1.0,
    "translations using statistical methods": 1.0,
    "using statistical methods based": 1.0,
    "statistical methods based on": 1.0,
    "methods based on bilingual": 1.0,
    "based on bilingual text": 1.0,
    "on bilingual text corpora": 1.0,
    "bilingual text corpora ,": 1.0,
    "text corpora , such": 1.0,
    "corpora , such as": 1.0,
    ", such as the": 0.21212121212121213,
    "such as the canadian": 0.07142857142857142,
    "as the canadian hansard": 1.0,
    "the canadian hansard corpus": 1.0,
    "canadian hansard corpus ,": 1.0,
    "hansard corpus , the": 1.0,
    "corpus , the english-french": 1.0,
    ", the english-french record": 1.0,
    "the english-french record of": 1.0,
    "english-french record of the": 1.0,
    "record of the canadian": 0.5,
    "of the canadian parliament": 1.0,
    "the canadian parliament and": 1.0,
    "canadian parliament and europarl": 1.0,
    "parliament and europarl ,": 1.0,
    "and europarl , the": 1.0,
    "europarl , the record": 1.0,
    ", the record of": 1.0,
    "the record of the": 1.0,
    "record of the european": 0.5,
    "of the european parliament": 1.0,
    "the european parliament .": 1.0,
    "<s> where such corpora": 1.0,
    "where such corpora are": 1.0,
    "such corpora are available": 0.5,
    "corpora are available ,": 1.0,
    "are available , impressive": 1.0,
    "available , impressive results": 1.0,
    ", impressive results can": 1.0,
    "impressive results can be": 1.0,
    "results can be achieved": 1.0,
    "can be achieved translating": 0.25,
    "be achieved translating texts": 1.0,
    "achieved translating texts of": 1.0,
    "translating texts of a": 1.0,
    "texts of a similar": 0.5,
    "of a similar kind": 1.0,
    "a similar kind ,": 1.0,
    "similar kind , but": 1.0,
    "kind , but such": 1.0,
    ", but such corpora": 1.0,
    "but such corpora are": 1.0,
    "such corpora are still": 0.5,
    "corpora are still very": 1.0,
    "are still very rare": 1.0,
    "still very rare .": 1.0,
    "<s> the first statistical": 0.16666666666666666,
    "statistical machine translation software": 0.25,
    "machine translation software was": 0.5,
    "translation software was candide": 1.0,
    "software was candide from": 1.0,
    "was candide from ibm": 1.0,
    "candide from ibm .": 1.0,
    "<s> google used systran": 1.0,
    "google used systran for": 1.0,
    "used systran for several": 1.0,
    "systran for several years": 1.0,
    "for several years ,": 0.5,
    "several years , but": 1.0,
    "years , but switched": 1.0,
    ", but switched to": 1.0,
    "but switched to a": 1.0,
    "switched to a statistical": 1.0,
    "to a statistical translation": 1.0,
    "a statistical translation method": 1.0,
    "statistical translation method in": 1.0,
    "translation method in october": 1.0,
    "method in october 2007": 1.0,
    "in october 2007 .": 1.0,
    "<s> recently , they": 1.0,
    "recently , they improved": 1.0,
    ", they improved their": 1.0,
    "they improved their translation": 1.0,
    "improved their translation capabilities": 1.0,
    "their translation capabilities by": 1.0,
    "translation capabilities by inputting": 1.0,
    "capabilities by inputting approximately": 1.0,
    "by inputting approximately 200": 1.0,
    "inputting approximately 200 billion": 1.0,
    "approximately 200 billion words": 1.0,
    "200 billion words from": 1.0,
    "billion words from united": 1.0,
    "words from united nations": 1.0,
    "from united nations materials": 1.0,
    "united nations materials to": 1.0,
    "nations materials to train": 1.0,
    "materials to train their": 1.0,
    "to train their system": 1.0,
    "train their system .": 1.0,
    "<s> accuracy of the": 0.5,
    "accuracy of the translation": 1.0,
    "of the translation has": 1.0,
    "the translation has improved": 1.0,
    "translation has improved .": 1.0,
    "<s> example-based main article": 1.0,
    "example-based main article :": 1.0,
    "main article : example-based": 0.08333333333333333,
    "article : example-based machine": 1.0,
    ": example-based machine translation": 1.0,
    "example-based machine translation example-based": 0.5,
    "machine translation example-based machine": 1.0,
    "translation example-based machine translation": 1.0,
    "example-based machine translation -lrb-": 0.5,
    "machine translation -lrb- ebmt": 0.5,
    "translation -lrb- ebmt -rrb-": 1.0,
    "-lrb- ebmt -rrb- approach": 1.0,
    "ebmt -rrb- approach was": 1.0,
    "-rrb- approach was proposed": 1.0,
    "approach was proposed by": 1.0,
    "was proposed by makoto": 1.0,
    "proposed by makoto nagao": 1.0,
    "by makoto nagao in": 1.0,
    "makoto nagao in 1984": 1.0,
    "nagao in 1984 .": 1.0,
    "it is often characterised": 0.16666666666666666,
    "is often characterised by": 1.0,
    "often characterised by its": 1.0,
    "characterised by its use": 1.0,
    "by its use of": 1.0,
    "its use of a": 1.0,
    "use of a bilingual": 0.25,
    "of a bilingual corpus": 1.0,
    "a bilingual corpus as": 1.0,
    "bilingual corpus as its": 1.0,
    "corpus as its main": 1.0,
    "as its main knowledge": 1.0,
    "its main knowledge base": 1.0,
    "main knowledge base ,": 1.0,
    "knowledge base , at": 0.5,
    "base , at run-time": 1.0,
    ", at run-time .": 1.0,
    "<s> it is essentially": 0.05263157894736842,
    "it is essentially a": 1.0,
    "is essentially a translation": 0.5,
    "essentially a translation by": 1.0,
    "a translation by analogy": 1.0,
    "translation by analogy and": 1.0,
    "by analogy and can": 1.0,
    "analogy and can be": 1.0,
    "and can be viewed": 0.2,
    "can be viewed as": 1.0,
    "be viewed as an": 0.5,
    "viewed as an implementation": 0.5,
    "as an implementation of": 1.0,
    "an implementation of case-based": 1.0,
    "implementation of case-based reasoning": 1.0,
    "of case-based reasoning approach": 1.0,
    "case-based reasoning approach of": 1.0,
    "reasoning approach of machine": 1.0,
    "approach of machine learning": 1.0,
    "of machine learning .": 0.2,
    "<s> hybrid mt hybrid": 1.0,
    "hybrid mt hybrid machine": 1.0,
    "mt hybrid machine translation": 1.0,
    "hybrid machine translation -lrb-": 1.0,
    "machine translation -lrb- hmt": 0.5,
    "translation -lrb- hmt -rrb-": 1.0,
    "-lrb- hmt -rrb- leverages": 1.0,
    "hmt -rrb- leverages the": 1.0,
    "-rrb- leverages the strengths": 1.0,
    "leverages the strengths of": 1.0,
    "the strengths of statistical": 1.0,
    "strengths of statistical and": 1.0,
    "of statistical and rule-based": 1.0,
    "statistical and rule-based translation": 1.0,
    "and rule-based translation methodologies": 1.0,
    "rule-based translation methodologies .": 1.0,
    "<s> several mt companies": 1.0,
    "several mt companies -lrb-": 1.0,
    "mt companies -lrb- asia": 1.0,
    "companies -lrb- asia online": 1.0,
    "-lrb- asia online ,": 1.0,
    "asia online , linguasys": 1.0,
    "online , linguasys ,": 1.0,
    ", linguasys , systran": 1.0,
    "linguasys , systran ,": 1.0,
    ", systran , pangeamt": 1.0,
    "systran , pangeamt ,": 1.0,
    ", pangeamt , upv": 1.0,
    "pangeamt , upv -rrb-": 1.0,
    ", upv -rrb- are": 1.0,
    "upv -rrb- are claiming": 1.0,
    "-rrb- are claiming to": 1.0,
    "are claiming to have": 1.0,
    "claiming to have a": 1.0,
    "to have a hybrid": 0.25,
    "have a hybrid approach": 1.0,
    "a hybrid approach using": 1.0,
    "hybrid approach using both": 1.0,
    "approach using both rules": 1.0,
    "using both rules and": 1.0,
    "both rules and statistics": 1.0,
    "rules and statistics .": 1.0,
    "<s> the approaches differ": 1.0,
    "the approaches differ in": 1.0,
    "approaches differ in a": 1.0,
    "differ in a number": 1.0,
    "number of ways :": 0.5,
    "of ways : rules": 1.0,
    "ways : rules post-processed": 1.0,
    ": rules post-processed by": 1.0,
    "rules post-processed by statistics": 1.0,
    "post-processed by statistics :": 1.0,
    "by statistics : translations": 1.0,
    "statistics : translations are": 1.0,
    ": translations are performed": 1.0,
    "translations are performed using": 1.0,
    "are performed using a": 1.0,
    "performed using a rules": 1.0,
    "using a rules based": 1.0,
    "a rules based engine": 1.0,
    "rules based engine .": 1.0,
    "<s> statistics are then": 1.0,
    "statistics are then used": 1.0,
    "are then used in": 1.0,
    "then used in an": 1.0,
    "used in an attempt": 1.0,
    "in an attempt to": 1.0,
    "an attempt to adjust\\/correct": 0.3333333333333333,
    "attempt to adjust\\/correct the": 1.0,
    "to adjust\\/correct the output": 1.0,
    "adjust\\/correct the output from": 1.0,
    "the output from the": 1.0,
    "output from the rules": 1.0,
    "from the rules engine": 1.0,
    "the rules engine .": 1.0,
    "<s> statistics guided by": 1.0,
    "statistics guided by rules": 1.0,
    "guided by rules :": 1.0,
    "by rules : rules": 1.0,
    "rules : rules are": 1.0,
    ": rules are used": 1.0,
    "rules are used to": 1.0,
    "are used to pre-process": 0.5,
    "used to pre-process data": 1.0,
    "to pre-process data in": 1.0,
    "pre-process data in an": 1.0,
    "data in an attempt": 1.0,
    "an attempt to better": 0.3333333333333333,
    "attempt to better guide": 1.0,
    "to better guide the": 1.0,
    "better guide the statistical": 1.0,
    "guide the statistical engine": 1.0,
    "the statistical engine .": 1.0,
    "<s> rules are also": 1.0,
    "rules are also used": 1.0,
    "are also used to": 1.0,
    "also used to post-process": 1.0,
    "used to post-process the": 1.0,
    "to post-process the statistical": 1.0,
    "post-process the statistical output": 1.0,
    "the statistical output to": 1.0,
    "statistical output to perform": 1.0,
    "output to perform functions": 1.0,
    "to perform functions such": 1.0,
    "perform functions such as": 1.0,
    "functions such as normalization": 1.0,
    "such as normalization .": 1.0,
    "<s> this approach has": 0.5,
    "this approach has a": 1.0,
    "approach has a lot": 1.0,
    "has a lot more": 1.0,
    "a lot more power": 1.0,
    "lot more power ,": 1.0,
    "more power , flexibility": 1.0,
    "power , flexibility and": 1.0,
    ", flexibility and control": 1.0,
    "flexibility and control when": 1.0,
    "and control when translating": 1.0,
    "control when translating .": 1.0,
    "<s> major issues disambiguation": 1.0,
    "major issues disambiguation main": 1.0,
    "issues disambiguation main article": 1.0,
    "disambiguation main article :": 1.0,
    "main article : word": 0.08333333333333333,
    "article : word sense": 1.0,
    ": word sense disambiguation": 1.0,
    "word sense disambiguation word-sense": 0.5,
    "sense disambiguation word-sense disambiguation": 1.0,
    "disambiguation word-sense disambiguation concerns": 1.0,
    "word-sense disambiguation concerns finding": 1.0,
    "disambiguation concerns finding a": 1.0,
    "concerns finding a suitable": 1.0,
    "finding a suitable translation": 1.0,
    "a suitable translation when": 1.0,
    "suitable translation when a": 1.0,
    "translation when a word": 1.0,
    "when a word can": 1.0,
    "a word can have": 0.5,
    "word can have more": 1.0,
    "can have more than": 1.0,
    "than one meaning .": 0.5,
    "<s> the problem was": 0.3333333333333333,
    "the problem was first": 1.0,
    "problem was first raised": 1.0,
    "was first raised in": 1.0,
    "first raised in the": 1.0,
    "raised in the 1950s": 1.0,
    "in the 1950s by": 0.5,
    "the 1950s by yehoshua": 1.0,
    "1950s by yehoshua bar-hillel": 1.0,
    "by yehoshua bar-hillel .": 1.0,
    "<s> he pointed out": 1.0,
    "he pointed out that": 1.0,
    "pointed out that without": 1.0,
    "out that without a": 1.0,
    "that without a ``": 1.0,
    "without a `` universal": 1.0,
    "a `` universal encyclopedia": 0.5,
    "`` universal encyclopedia ''": 1.0,
    "universal encyclopedia '' ,": 1.0,
    "encyclopedia '' , a": 1.0,
    "'' , a machine": 1.0,
    ", a machine would": 1.0,
    "a machine would never": 0.5,
    "machine would never be": 1.0,
    "would never be able": 1.0,
    "never be able to": 1.0,
    "be able to distinguish": 0.2,
    "able to distinguish between": 1.0,
    "to distinguish between the": 0.5,
    "distinguish between the two": 1.0,
    "between the two meanings": 0.3333333333333333,
    "the two meanings of": 1.0,
    "two meanings of a": 1.0,
    "meanings of a word": 1.0,
    "of a word .": 0.3333333333333333,
    "<s> today there are": 1.0,
    "today there are numerous": 1.0,
    "there are numerous approaches": 1.0,
    "are numerous approaches designed": 1.0,
    "numerous approaches designed to": 1.0,
    "approaches designed to overcome": 1.0,
    "designed to overcome this": 1.0,
    "to overcome this problem": 1.0,
    "overcome this problem .": 1.0,
    "<s> they can be": 1.0,
    "they can be approximately": 0.25,
    "can be approximately divided": 1.0,
    "be approximately divided into": 1.0,
    "approximately divided into ``": 1.0,
    "divided into `` shallow": 1.0,
    "into `` shallow ''": 1.0,
    "`` shallow '' approaches": 1.0,
    "shallow '' approaches and": 1.0,
    "'' approaches and ``": 1.0,
    "approaches and `` deep": 1.0,
    "and `` deep ''": 1.0,
    "`` deep '' approaches": 1.0,
    "deep '' approaches .": 1.0,
    "<s> shallow approaches assume": 1.0,
    "shallow approaches assume no": 1.0,
    "approaches assume no knowledge": 1.0,
    "assume no knowledge of": 1.0,
    "no knowledge of the": 1.0,
    "knowledge of the text": 0.2,
    "of the text .": 0.5,
    "<s> they simply apply": 1.0,
    "they simply apply statistical": 1.0,
    "simply apply statistical methods": 1.0,
    "apply statistical methods to": 1.0,
    "statistical methods to the": 0.3333333333333333,
    "methods to the words": 1.0,
    "to the words surrounding": 1.0,
    "the words surrounding the": 1.0,
    "words surrounding the ambiguous": 1.0,
    "surrounding the ambiguous word": 1.0,
    "the ambiguous word .": 1.0,
    "<s> deep approaches presume": 1.0,
    "deep approaches presume a": 1.0,
    "approaches presume a comprehensive": 1.0,
    "presume a comprehensive knowledge": 1.0,
    "a comprehensive knowledge of": 1.0,
    "comprehensive knowledge of the": 1.0,
    "knowledge of the word": 0.2,
    "of the word .": 0.25,
    "<s> so far ,": 1.0,
    "so far , shallow": 1.0,
    "far , shallow approaches": 1.0,
    ", shallow approaches have": 1.0,
    "shallow approaches have been": 1.0,
    "approaches have been more": 0.5,
    "have been more successful": 1.0,
    "been more successful .": 1.0,
    "citation needed -rrb- the": 0.07692307692307693,
    "needed -rrb- the late": 1.0,
    "-rrb- the late claude": 1.0,
    "the late claude piron": 1.0,
    "late claude piron ,": 1.0,
    "claude piron , a": 1.0,
    "piron , a long-time": 1.0,
    ", a long-time translator": 1.0,
    "a long-time translator for": 1.0,
    "long-time translator for the": 1.0,
    "translator for the united": 1.0,
    "for the united nations": 1.0,
    "the united nations and": 1.0,
    "united nations and the": 1.0,
    "nations and the world": 1.0,
    "and the world health": 1.0,
    "the world health organization": 1.0,
    "world health organization ,": 1.0,
    "health organization , wrote": 1.0,
    "organization , wrote that": 1.0,
    ", wrote that machine": 1.0,
    "wrote that machine translation": 1.0,
    "that machine translation ,": 0.5,
    "machine translation , at": 0.14285714285714285,
    "translation , at its": 1.0,
    ", at its best": 1.0,
    "at its best ,": 1.0,
    "its best , automates": 1.0,
    "best , automates the": 1.0,
    ", automates the easier": 1.0,
    "automates the easier part": 1.0,
    "the easier part of": 1.0,
    "easier part of a": 1.0,
    "part of a translator": 0.3333333333333333,
    "of a translator 's": 1.0,
    "a translator 's job": 1.0,
    "translator 's job ;": 0.5,
    "'s job ; the": 1.0,
    "job ; the harder": 1.0,
    "; the harder and": 1.0,
    "the harder and more": 1.0,
    "harder and more time-consuming": 1.0,
    "and more time-consuming part": 1.0,
    "more time-consuming part usually": 1.0,
    "time-consuming part usually involves": 1.0,
    "part usually involves doing": 1.0,
    "usually involves doing extensive": 1.0,
    "involves doing extensive research": 1.0,
    "doing extensive research to": 1.0,
    "extensive research to resolve": 1.0,
    "research to resolve ambiguities": 1.0,
    "to resolve ambiguities in": 1.0,
    "resolve ambiguities in the": 1.0,
    "ambiguities in the source": 1.0,
    "in the source text": 0.5,
    "the source text ,": 0.5,
    "source text , which": 0.5,
    "text , which the": 0.5,
    ", which the grammatical": 1.0,
    "which the grammatical and": 1.0,
    "the grammatical and lexical": 1.0,
    "grammatical and lexical exigencies": 1.0,
    "and lexical exigencies of": 1.0,
    "lexical exigencies of the": 1.0,
    "exigencies of the target": 1.0,
    "the target language require": 0.125,
    "target language require to": 1.0,
    "language require to be": 1.0,
    "require to be resolved": 1.0,
    "to be resolved :": 1.0,
    "be resolved : why": 1.0,
    "resolved : why does": 1.0,
    ": why does a": 1.0,
    "why does a translator": 0.5,
    "does a translator need": 1.0,
    "a translator need a": 1.0,
    "translator need a whole": 1.0,
    "need a whole workday": 1.0,
    "a whole workday to": 1.0,
    "whole workday to translate": 1.0,
    "workday to translate five": 1.0,
    "to translate five pages": 1.0,
    "translate five pages ,": 1.0,
    "five pages , and": 1.0,
    "pages , and not": 0.5,
    ", and not an": 0.3333333333333333,
    "and not an hour": 1.0,
    "not an hour or": 1.0,
    "an hour or two": 1.0,
    "hour or two ?": 1.0,
    "<s> ... about 90": 1.0,
    "... about 90 %": 1.0,
    "about 90 % of": 1.0,
    "90 % of an": 0.5,
    "% of an average": 1.0,
    "of an average text": 1.0,
    "an average text corresponds": 1.0,
    "average text corresponds to": 1.0,
    "text corresponds to these": 1.0,
    "corresponds to these simple": 1.0,
    "to these simple conditions": 1.0,
    "these simple conditions .": 1.0,
    "<s> but unfortunately ,": 1.0,
    "but unfortunately , there": 1.0,
    "unfortunately , there 's": 1.0,
    ", there 's the": 1.0,
    "there 's the other": 1.0,
    "'s the other 10": 1.0,
    "the other 10 %": 1.0,
    "other 10 % .": 1.0,
    "<s> it 's that": 0.5,
    "it 's that part": 1.0,
    "'s that part that": 1.0,
    "that part that requires": 1.0,
    "part that requires six": 1.0,
    "that requires six -lrb-": 1.0,
    "requires six -lrb- more": 1.0,
    "six -lrb- more -rrb-": 1.0,
    "-lrb- more -rrb- hours": 1.0,
    "more -rrb- hours of": 1.0,
    "-rrb- hours of work": 1.0,
    "hours of work .": 1.0,
    "<s> there are ambiguities": 0.2,
    "there are ambiguities one": 1.0,
    "are ambiguities one has": 1.0,
    "ambiguities one has to": 1.0,
    "one has to resolve": 1.0,
    "has to resolve .": 1.0,
    "<s> for instance ,": 1.0,
    "for instance , the": 0.2222222222222222,
    "instance , the author": 0.5,
    ", the author of": 1.0,
    "the author of the": 1.0,
    "author of the source": 1.0,
    "source text , an": 0.5,
    "text , an australian": 1.0,
    ", an australian physician": 1.0,
    "an australian physician ,": 1.0,
    "australian physician , cited": 1.0,
    "physician , cited the": 1.0,
    ", cited the example": 1.0,
    "cited the example of": 1.0,
    "the example of an": 1.0,
    "example of an epidemic": 0.5,
    "of an epidemic which": 1.0,
    "an epidemic which was": 1.0,
    "epidemic which was declared": 1.0,
    "which was declared during": 1.0,
    "was declared during world": 1.0,
    "declared during world war": 1.0,
    "during world war ii": 1.0,
    "world war ii in": 1.0,
    "war ii in a": 1.0,
    "ii in a ``": 1.0,
    "in a `` japanese": 1.0,
    "a `` japanese prisoner": 1.0,
    "`` japanese prisoner of": 1.0,
    "japanese prisoner of war": 1.0,
    "prisoner of war camp": 1.0,
    "of war camp ''": 1.0,
    "war camp '' .": 1.0,
    "<s> was he talking": 1.0,
    "was he talking about": 1.0,
    "he talking about an": 1.0,
    "talking about an american": 1.0,
    "about an american camp": 1.0,
    "an american camp with": 1.0,
    "american camp with japanese": 1.0,
    "camp with japanese prisoners": 1.0,
    "with japanese prisoners or": 1.0,
    "japanese prisoners or a": 1.0,
    "prisoners or a japanese": 1.0,
    "or a japanese camp": 1.0,
    "a japanese camp with": 1.0,
    "japanese camp with american": 1.0,
    "camp with american prisoners": 1.0,
    "with american prisoners ?": 1.0,
    "<s> the english has": 1.0,
    "the english has two": 1.0,
    "english has two senses": 1.0,
    "has two senses .": 1.0,
    "<s> it 's necessary": 0.5,
    "it 's necessary therefore": 1.0,
    "'s necessary therefore to": 1.0,
    "necessary therefore to do": 1.0,
    "therefore to do research": 1.0,
    "to do research ,": 1.0,
    "do research , maybe": 1.0,
    "research , maybe to": 1.0,
    ", maybe to the": 1.0,
    "maybe to the extent": 1.0,
    "to the extent of": 1.0,
    "the extent of a": 1.0,
    "extent of a phone": 1.0,
    "of a phone call": 1.0,
    "a phone call to": 1.0,
    "phone call to australia": 1.0,
    "call to australia .": 1.0,
    "<s> the ideal deep": 1.0,
    "the ideal deep approach": 1.0,
    "ideal deep approach would": 1.0,
    "deep approach would require": 1.0,
    "approach would require the": 1.0,
    "would require the translation": 1.0,
    "require the translation software": 1.0,
    "the translation software to": 1.0,
    "translation software to do": 1.0,
    "software to do all": 1.0,
    "to do all the": 1.0,
    "do all the research": 1.0,
    "all the research necessary": 1.0,
    "the research necessary for": 1.0,
    "research necessary for this": 1.0,
    "necessary for this kind": 1.0,
    "for this kind of": 1.0,
    "this kind of disambiguation": 1.0,
    "kind of disambiguation on": 1.0,
    "of disambiguation on its": 1.0,
    "disambiguation on its own": 1.0,
    "on its own ;": 0.5,
    "its own ; but": 1.0,
    "own ; but this": 1.0,
    "; but this would": 1.0,
    "but this would require": 1.0,
    "this would require a": 1.0,
    "would require a higher": 0.5,
    "require a higher degree": 1.0,
    "a higher degree of": 1.0,
    "higher degree of ai": 1.0,
    "degree of ai than": 1.0,
    "of ai than has": 1.0,
    "ai than has yet": 1.0,
    "than has yet been": 1.0,
    "has yet been attained": 1.0,
    "yet been attained .": 1.0,
    "<s> a shallow approach": 1.0,
    "a shallow approach which": 0.5,
    "shallow approach which simply": 1.0,
    "approach which simply guessed": 1.0,
    "which simply guessed at": 1.0,
    "simply guessed at the": 1.0,
    "guessed at the sense": 1.0,
    "at the sense of": 1.0,
    "the sense of the": 1.0,
    "sense of the ambiguous": 1.0,
    "of the ambiguous english": 1.0,
    "the ambiguous english phrase": 1.0,
    "ambiguous english phrase that": 1.0,
    "english phrase that piron": 1.0,
    "phrase that piron mentions": 1.0,
    "that piron mentions -lrb-": 1.0,
    "piron mentions -lrb- based": 1.0,
    "mentions -lrb- based ,": 1.0,
    "-lrb- based , perhaps": 1.0,
    "based , perhaps ,": 1.0,
    ", perhaps , on": 1.0,
    "perhaps , on which": 1.0,
    ", on which kind": 1.0,
    "on which kind of": 1.0,
    "which kind of prisoner-of-war": 1.0,
    "kind of prisoner-of-war camp": 1.0,
    "of prisoner-of-war camp is": 1.0,
    "prisoner-of-war camp is more": 1.0,
    "camp is more often": 1.0,
    "is more often mentioned": 1.0,
    "more often mentioned in": 1.0,
    "often mentioned in a": 1.0,
    "mentioned in a given": 1.0,
    "in a given corpus": 0.5,
    "a given corpus -rrb-": 1.0,
    "given corpus -rrb- would": 1.0,
    "corpus -rrb- would have": 1.0,
    "-rrb- would have a": 1.0,
    "would have a reasonable": 1.0,
    "have a reasonable chance": 1.0,
    "a reasonable chance of": 1.0,
    "reasonable chance of guessing": 1.0,
    "chance of guessing wrong": 1.0,
    "of guessing wrong fairly": 1.0,
    "guessing wrong fairly often": 1.0,
    "wrong fairly often .": 1.0,
    "a shallow approach that": 0.5,
    "shallow approach that involves": 1.0,
    "approach that involves ``": 1.0,
    "that involves `` ask": 1.0,
    "involves `` ask the": 1.0,
    "`` ask the user": 1.0,
    "ask the user about": 1.0,
    "the user about each": 1.0,
    "user about each ambiguity": 1.0,
    "about each ambiguity ''": 1.0,
    "each ambiguity '' would": 1.0,
    "ambiguity '' would ,": 1.0,
    "'' would , by": 1.0,
    "would , by piron": 1.0,
    ", by piron 's": 1.0,
    "by piron 's estimate": 1.0,
    "piron 's estimate ,": 1.0,
    "'s estimate , only": 1.0,
    "estimate , only automate": 1.0,
    ", only automate about": 1.0,
    "only automate about 25": 1.0,
    "automate about 25 %": 1.0,
    "about 25 % of": 1.0,
    "25 % of a": 1.0,
    "% of a professional": 1.0,
    "of a professional translator": 1.0,
    "a professional translator 's": 1.0,
    "professional translator 's job": 1.0,
    "translator 's job ,": 0.5,
    "'s job , leaving": 1.0,
    "job , leaving the": 1.0,
    ", leaving the harder": 1.0,
    "leaving the harder 75": 1.0,
    "the harder 75 %": 1.0,
    "harder 75 % still": 1.0,
    "75 % still to": 1.0,
    "% still to be": 1.0,
    "still to be done": 1.0,
    "to be done by": 0.3333333333333333,
    "be done by a": 1.0,
    "done by a human": 1.0,
    "by a human .": 0.3333333333333333,
    "<s> the objects of": 1.0,
    "the objects of discourse": 1.0,
    "objects of discourse analysis": 1.0,
    "of discourse analysis --": 0.25,
    "discourse analysis -- discourse": 1.0,
    "analysis -- discourse ,": 1.0,
    "-- discourse , writing": 1.0,
    "discourse , writing ,": 1.0,
    ", writing , conversation": 1.0,
    "writing , conversation ,": 1.0,
    ", conversation , communicative": 1.0,
    "conversation , communicative event": 1.0,
    ", communicative event ,": 1.0,
    "communicative event , etc.": 1.0,
    "event , etc. --": 1.0,
    ", etc. -- are": 1.0,
    "etc. -- are variously": 1.0,
    "-- are variously defined": 1.0,
    "are variously defined in": 1.0,
    "variously defined in terms": 1.0,
    "defined in terms of": 1.0,
    "in terms of coherent": 0.14285714285714285,
    "terms of coherent sequences": 1.0,
    "of coherent sequences of": 1.0,
    "coherent sequences of sentences": 1.0,
    "sequences of sentences ,": 1.0,
    "of sentences , propositions": 0.5,
    "sentences , propositions ,": 1.0,
    ", propositions , speech": 0.5,
    "propositions , speech acts": 1.0,
    ", speech acts or": 0.5,
    "speech acts or turns-at-talk": 1.0,
    "acts or turns-at-talk .": 1.0,
    "<s> contrary to much": 0.5,
    "contrary to much of": 1.0,
    "to much of traditional": 1.0,
    "much of traditional linguistics": 1.0,
    "of traditional linguistics ,": 1.0,
    "traditional linguistics , discourse": 1.0,
    "linguistics , discourse analysts": 1.0,
    ", discourse analysts not": 1.0,
    "discourse analysts not only": 1.0,
    "analysts not only study": 1.0,
    "not only study language": 1.0,
    "only study language use": 1.0,
    "study language use `": 1.0,
    "language use ` beyond": 1.0,
    "use ` beyond the": 1.0,
    "` beyond the sentence": 1.0,
    "beyond the sentence boundary": 1.0,
    "the sentence boundary '": 1.0,
    "sentence boundary ' ,": 1.0,
    "boundary ' , but": 1.0,
    "' , but also": 1.0,
    ", but also prefer": 0.3333333333333333,
    "but also prefer to": 1.0,
    "also prefer to analyze": 1.0,
    "prefer to analyze `": 1.0,
    "to analyze ` naturally": 1.0,
    "analyze ` naturally occurring": 1.0,
    "` naturally occurring '": 1.0,
    "naturally occurring ' language": 1.0,
    "occurring ' language use": 1.0,
    "' language use ,": 1.0,
    "language use , and": 0.5,
    "use , and not": 0.3333333333333333,
    ", and not invented": 0.3333333333333333,
    "and not invented examples": 1.0,
    "not invented examples .": 1.0,
    "<s> text linguistics is": 1.0,
    "text linguistics is related": 0.5,
    "linguistics is related .": 1.0,
    "<s> the essential difference": 1.0,
    "the essential difference between": 1.0,
    "essential difference between discourse": 1.0,
    "difference between discourse analysis": 1.0,
    "between discourse analysis and": 1.0,
    "discourse analysis and text": 1.0,
    "analysis and text linguistics": 1.0,
    "and text linguistics is": 1.0,
    "text linguistics is that": 0.5,
    "linguistics is that it": 1.0,
    "is that it aims": 1.0,
    "that it aims at": 1.0,
    "it aims at revealing": 1.0,
    "aims at revealing socio-psychological": 1.0,
    "at revealing socio-psychological characteristics": 1.0,
    "revealing socio-psychological characteristics of": 1.0,
    "socio-psychological characteristics of a": 1.0,
    "characteristics of a person\\/persons": 1.0,
    "of a person\\/persons rather": 1.0,
    "a person\\/persons rather than": 1.0,
    "person\\/persons rather than text": 1.0,
    "rather than text structure": 1.0,
    "than text structure .": 1.0,
    "<s> discourse analysis has": 0.3333333333333333,
    "discourse analysis has been": 1.0,
    "analysis has been taken": 1.0,
    "has been taken up": 1.0,
    "been taken up in": 1.0,
    "taken up in a": 1.0,
    "up in a variety": 1.0,
    "in a variety of": 1.0,
    "a variety of social": 0.14285714285714285,
    "variety of social science": 1.0,
    "of social science disciplines": 1.0,
    "social science disciplines ,": 1.0,
    "science disciplines , including": 1.0,
    "disciplines , including linguistics": 1.0,
    "including linguistics , sociology": 0.5,
    "linguistics , sociology ,": 1.0,
    ", sociology , anthropology": 1.0,
    "sociology , anthropology ,": 1.0,
    ", anthropology , social": 1.0,
    "anthropology , social work": 1.0,
    ", social work ,": 1.0,
    "social work , cognitive": 1.0,
    "work , cognitive psychology": 1.0,
    ", cognitive psychology ,": 1.0,
    "cognitive psychology , social": 0.5,
    "psychology , social psychology": 1.0,
    ", social psychology ,": 1.0,
    "social psychology , international": 1.0,
    "psychology , international relations": 1.0,
    ", international relations ,": 1.0,
    "international relations , human": 1.0,
    "relations , human geography": 1.0,
    ", human geography ,": 1.0,
    "human geography , communication": 1.0,
    "geography , communication studies": 1.0,
    ", communication studies and": 1.0,
    "communication studies and translation": 1.0,
    "studies and translation studies": 1.0,
    "and translation studies ,": 1.0,
    "translation studies , each": 1.0,
    "studies , each of": 1.0,
    "of which is subject": 0.3333333333333333,
    "which is subject to": 1.0,
    "is subject to its": 1.0,
    "subject to its own": 1.0,
    "to its own assumptions": 1.0,
    "its own assumptions ,": 1.0,
    "own assumptions , dimensions": 1.0,
    "assumptions , dimensions of": 1.0,
    ", dimensions of analysis": 1.0,
    "dimensions of analysis ,": 1.0,
    "of analysis , and": 1.0,
    "analysis , and methodologies": 0.5,
    ", and methodologies .": 1.0,
    "<s> the examples and": 1.0,
    "the examples and perspective": 0.5,
    "examples and perspective in": 1.0,
    "and perspective in this": 1.0,
    "perspective in this article": 1.0,
    "in this article deal": 0.5,
    "this article deal primarily": 1.0,
    "article deal primarily with": 1.0,
    "deal primarily with the": 1.0,
    "primarily with the united": 1.0,
    "with the united states": 1.0,
    "the united states and": 0.14285714285714285,
    "united states and do": 1.0,
    "states and do not": 1.0,
    "and do not represent": 1.0,
    "do not represent a": 1.0,
    "not represent a worldwide": 1.0,
    "represent a worldwide view": 1.0,
    "a worldwide view of": 1.0,
    "worldwide view of the": 1.0,
    "view of the subject": 1.0,
    "of the subject .": 0.5,
    "<s> please improve this": 1.0,
    "please improve this article": 1.0,
    "improve this article and": 0.5,
    "this article and discuss": 1.0,
    "article and discuss the": 1.0,
    "and discuss the issue": 1.0,
    "discuss the issue on": 1.0,
    "the issue on the": 1.0,
    "issue on the talk": 1.0,
    "on the talk page": 1.0,
    "the talk page .": 1.0,
    "<s> -lrb- december 2010": 1.0,
    "-lrb- december 2010 -rrb-": 1.0,
    "december 2010 -rrb- some": 1.0,
    "2010 -rrb- some scholars": 1.0,
    "-rrb- some scholars -lrb-": 1.0,
    "some scholars -lrb- which": 1.0,
    "scholars -lrb- which ?": 1.0,
    "-lrb- which ? -rrb-": 1.0,
    "<s> consider the austrian": 0.3333333333333333,
    "consider the austrian emigre": 1.0,
    "the austrian emigre leo": 1.0,
    "austrian emigre leo spitzer": 1.0,
    "emigre leo spitzer 's": 1.0,
    "leo spitzer 's stilstudien": 1.0,
    "spitzer 's stilstudien -lrb-": 1.0,
    "'s stilstudien -lrb- style": 1.0,
    "stilstudien -lrb- style studies": 1.0,
    "-lrb- style studies -rrb-": 1.0,
    "style studies -rrb- of": 1.0,
    "studies -rrb- of 1928": 1.0,
    "-rrb- of 1928 the": 1.0,
    "of 1928 the earliest": 1.0,
    "1928 the earliest example": 1.0,
    "the earliest example of": 1.0,
    "earliest example of discourse": 1.0,
    "example of discourse analysis": 1.0,
    "of discourse analysis -lrb-": 0.25,
    "-lrb- da -rrb- ;": 0.5,
    "da -rrb- ; michel": 1.0,
    "-rrb- ; michel foucault": 1.0,
    "; michel foucault himself": 1.0,
    "michel foucault himself translated": 1.0,
    "foucault himself translated it": 1.0,
    "himself translated it into": 1.0,
    "translated it into french": 1.0,
    "it into french .": 1.0,
    "<s> but the term": 1.0,
    "but the term first": 1.0,
    "the term first came": 1.0,
    "term first came into": 1.0,
    "first came into general": 1.0,
    "came into general use": 1.0,
    "into general use following": 1.0,
    "general use following the": 1.0,
    "use following the publication": 1.0,
    "following the publication of": 1.0,
    "the publication of a": 0.5,
    "publication of a series": 1.0,
    "of a series of": 1.0,
    "a series of papers": 0.14285714285714285,
    "series of papers by": 1.0,
    "of papers by zellig": 1.0,
    "papers by zellig harris": 1.0,
    "by zellig harris beginning": 1.0,
    "zellig harris beginning in": 1.0,
    "harris beginning in 1952": 1.0,
    "beginning in 1952 and": 1.0,
    "in 1952 and reporting": 1.0,
    "1952 and reporting on": 1.0,
    "and reporting on work": 1.0,
    "reporting on work from": 1.0,
    "on work from which": 1.0,
    "work from which he": 1.0,
    "from which he developed": 1.0,
    "which he developed transformational": 1.0,
    "he developed transformational grammar": 1.0,
    "developed transformational grammar in": 1.0,
    "transformational grammar in the": 1.0,
    "grammar in the late": 1.0,
    "in the late 1930s": 0.2,
    "the late 1930s .": 1.0,
    "<s> formal equivalence relations": 1.0,
    "formal equivalence relations among": 1.0,
    "equivalence relations among the": 1.0,
    "relations among the sentences": 1.0,
    "among the sentences of": 1.0,
    "the sentences of a": 1.0,
    "sentences of a coherent": 1.0,
    "of a coherent discourse": 1.0,
    "a coherent discourse are": 1.0,
    "coherent discourse are made": 1.0,
    "discourse are made explicit": 1.0,
    "are made explicit by": 1.0,
    "made explicit by using": 1.0,
    "explicit by using sentence": 1.0,
    "by using sentence transformations": 1.0,
    "using sentence transformations to": 1.0,
    "sentence transformations to put": 1.0,
    "transformations to put the": 1.0,
    "to put the text": 1.0,
    "put the text in": 1.0,
    "the text in a": 0.3333333333333333,
    "text in a canonical": 1.0,
    "in a canonical form": 1.0,
    "a canonical form .": 1.0,
    "<s> words and sentences": 1.0,
    "words and sentences with": 1.0,
    "and sentences with equivalent": 1.0,
    "sentences with equivalent information": 1.0,
    "with equivalent information then": 1.0,
    "equivalent information then appear": 1.0,
    "information then appear in": 1.0,
    "then appear in the": 1.0,
    "appear in the same": 0.6666666666666666,
    "in the same column": 0.25,
    "the same column of": 1.0,
    "same column of an": 1.0,
    "column of an array": 1.0,
    "of an array .": 1.0,
    "<s> this work progressed": 0.5,
    "this work progressed over": 1.0,
    "work progressed over the": 1.0,
    "progressed over the next": 1.0,
    "over the next four": 1.0,
    "the next four decades": 1.0,
    "next four decades -lrb-": 1.0,
    "four decades -lrb- see": 1.0,
    "decades -lrb- see references": 1.0,
    "-lrb- see references -rrb-": 1.0,
    "see references -rrb- into": 1.0,
    "references -rrb- into a": 1.0,
    "-rrb- into a science": 1.0,
    "into a science of": 1.0,
    "a science of sublanguage": 1.0,
    "science of sublanguage analysis": 1.0,
    "of sublanguage analysis -lrb-": 1.0,
    "sublanguage analysis -lrb- kittredge": 1.0,
    "analysis -lrb- kittredge &": 1.0,
    "-lrb- kittredge & lehrberger": 1.0,
    "kittredge & lehrberger 1982": 1.0,
    "& lehrberger 1982 -rrb-": 1.0,
    "lehrberger 1982 -rrb- ,": 1.0,
    "1982 -rrb- , culminating": 1.0,
    "-rrb- , culminating in": 1.0,
    ", culminating in a": 1.0,
    "culminating in a demonstration": 1.0,
    "in a demonstration of": 1.0,
    "a demonstration of the": 1.0,
    "demonstration of the informational": 1.0,
    "of the informational structures": 1.0,
    "the informational structures in": 1.0,
    "informational structures in texts": 1.0,
    "structures in texts of": 1.0,
    "in texts of a": 1.0,
    "texts of a sublanguage": 0.5,
    "of a sublanguage of": 1.0,
    "a sublanguage of science": 1.0,
    "sublanguage of science ,": 1.0,
    "of science , that": 1.0,
    "science , that of": 1.0,
    ", that of immunology": 1.0,
    "that of immunology ,": 1.0,
    "of immunology , -lrb-": 1.0,
    "immunology , -lrb- harris": 1.0,
    ", -lrb- harris et": 1.0,
    "-lrb- harris et al.": 1.0,
    "harris et al. 1989": 1.0,
    "et al. 1989 -rrb-": 1.0,
    "al. 1989 -rrb- and": 1.0,
    "1989 -rrb- and a": 1.0,
    "-rrb- and a fully": 1.0,
    "and a fully articulated": 1.0,
    "a fully articulated theory": 1.0,
    "fully articulated theory of": 1.0,
    "articulated theory of linguistic": 1.0,
    "theory of linguistic informational": 1.0,
    "of linguistic informational content": 1.0,
    "linguistic informational content -lrb-": 1.0,
    "informational content -lrb- harris": 1.0,
    "content -lrb- harris 1991": 1.0,
    "-lrb- harris 1991 -rrb-": 1.0,
    "harris 1991 -rrb- .": 1.0,
    "this time , however": 0.5,
    "time , however ,": 1.0,
    ", however , most": 0.09090909090909091,
    "however , most linguists": 0.5,
    ", most linguists decided": 1.0,
    "most linguists decided a": 1.0,
    "linguists decided a succession": 1.0,
    "decided a succession of": 1.0,
    "a succession of elaborate": 1.0,
    "succession of elaborate theories": 1.0,
    "of elaborate theories of": 1.0,
    "elaborate theories of sentence-level": 1.0,
    "theories of sentence-level syntax": 1.0,
    "of sentence-level syntax and": 1.0,
    "sentence-level syntax and semantics": 1.0,
    "syntax and semantics .": 1.0,
    "<s> although harris had": 1.0,
    "although harris had mentioned": 1.0,
    "harris had mentioned the": 1.0,
    "had mentioned the analysis": 1.0,
    "mentioned the analysis of": 1.0,
    "the analysis of whole": 0.25,
    "analysis of whole discourses": 1.0,
    "of whole discourses ,": 1.0,
    "whole discourses , he": 1.0,
    "discourses , he had": 1.0,
    ", he had not": 1.0,
    "he had not worked": 1.0,
    "had not worked out": 1.0,
    "not worked out a": 1.0,
    "worked out a comprehensive": 1.0,
    "out a comprehensive model": 1.0,
    "a comprehensive model ,": 1.0,
    "comprehensive model , as": 1.0,
    "model , as of": 1.0,
    ", as of january": 1.0,
    "as of january ,": 1.0,
    "of january , 1952": 1.0,
    "january , 1952 .": 1.0,
    "<s> a linguist working": 1.0,
    "a linguist working for": 1.0,
    "linguist working for the": 1.0,
    "working for the american": 1.0,
    "for the american bible": 1.0,
    "the american bible society": 1.0,
    "american bible society ,": 1.0,
    "bible society , james": 1.0,
    "society , james a.": 1.0,
    ", james a. lauriault\\/loriot": 1.0,
    "james a. lauriault\\/loriot ,": 1.0,
    "a. lauriault\\/loriot , needed": 0.5,
    "lauriault\\/loriot , needed to": 1.0,
    ", needed to find": 1.0,
    "needed to find answers": 1.0,
    "to find answers to": 1.0,
    "find answers to some": 1.0,
    "answers to some fundamental": 1.0,
    "to some fundamental errors": 1.0,
    "some fundamental errors in": 1.0,
    "fundamental errors in translating": 1.0,
    "errors in translating quechua": 1.0,
    "in translating quechua ,": 1.0,
    "translating quechua , in": 1.0,
    "quechua , in the": 1.0,
    ", in the cuzco": 0.125,
    "in the cuzco area": 1.0,
    "the cuzco area of": 1.0,
    "cuzco area of peru": 1.0,
    "area of peru .": 1.0,
    "<s> he took harris": 1.0,
    "he took harris 's": 1.0,
    "took harris 's idea": 1.0,
    "harris 's idea ,": 1.0,
    "'s idea , recorded": 1.0,
    "idea , recorded all": 1.0,
    ", recorded all of": 1.0,
    "recorded all of the": 1.0,
    "all of the legends": 0.3333333333333333,
    "of the legends and": 1.0,
    "the legends and ,": 1.0,
    "legends and , after": 1.0,
    "and , after going": 1.0,
    ", after going over": 1.0,
    "after going over the": 1.0,
    "going over the meaning": 1.0,
    "over the meaning and": 1.0,
    "the meaning and placement": 1.0,
    "meaning and placement of": 1.0,
    "and placement of each": 1.0,
    "placement of each word": 1.0,
    "of each word with": 0.5,
    "each word with a": 1.0,
    "word with a native": 1.0,
    "with a native speaker": 1.0,
    "native speaker of quechua": 0.5,
    "speaker of quechua ,": 1.0,
    "of quechua , was": 1.0,
    "quechua , was able": 1.0,
    ", was able to": 1.0,
    "was able to form": 0.25,
    "able to form logical": 1.0,
    "to form logical ,": 1.0,
    "form logical , mathematical": 1.0,
    "logical , mathematical rules": 1.0,
    ", mathematical rules that": 1.0,
    "mathematical rules that transcended": 1.0,
    "rules that transcended the": 1.0,
    "that transcended the simple": 1.0,
    "transcended the simple sentence": 1.0,
    "the simple sentence structure": 1.0,
    "simple sentence structure .": 1.0,
    "<s> he then applied": 1.0,
    "he then applied the": 1.0,
    "then applied the process": 1.0,
    "applied the process to": 1.0,
    "the process to another": 0.5,
    "process to another language": 1.0,
    "to another language of": 1.0,
    "another language of eastern": 1.0,
    "language of eastern peru": 1.0,
    "of eastern peru ,": 1.0,
    "eastern peru , shipibo": 1.0,
    "peru , shipibo .": 1.0,
    "<s> he taught the": 1.0,
    "he taught the theory": 1.0,
    "taught the theory in": 0.5,
    "the theory in norman": 1.0,
    "theory in norman ,": 1.0,
    "in norman , oklahoma": 1.0,
    "norman , oklahoma ,": 1.0,
    ", oklahoma , in": 1.0,
    "oklahoma , in the": 1.0,
    ", in the summers": 0.125,
    "in the summers of": 1.0,
    "the summers of 1956": 1.0,
    "summers of 1956 and": 1.0,
    "of 1956 and 1957": 1.0,
    "1956 and 1957 and": 1.0,
    "and 1957 and entered": 1.0,
    "1957 and entered the": 1.0,
    "and entered the university": 1.0,
    "entered the university of": 1.0,
    "the university of pennsylvania": 1.0,
    "university of pennsylvania in": 1.0,
    "of pennsylvania in the": 1.0,
    "pennsylvania in the interim": 1.0,
    "in the interim year": 1.0,
    "the interim year .": 1.0,
    "<s> he tried to": 1.0,
    "he tried to publish": 1.0,
    "tried to publish a": 1.0,
    "to publish a paper": 1.0,
    "publish a paper shipibo": 1.0,
    "a paper shipibo paragraph": 1.0,
    "paper shipibo paragraph structure": 1.0,
    "shipibo paragraph structure ,": 1.0,
    "paragraph structure , but": 1.0,
    "structure , but it": 1.0,
    ", but it was": 0.3333333333333333,
    "but it was delayed": 1.0,
    "it was delayed until": 1.0,
    "was delayed until 1970": 1.0,
    "delayed until 1970 -lrb-": 1.0,
    "until 1970 -lrb- loriot": 1.0,
    "1970 -lrb- loriot &": 1.0,
    "-lrb- loriot & hollenbach": 1.0,
    "loriot & hollenbach 1970": 1.0,
    "& hollenbach 1970 -rrb-": 1.0,
    "hollenbach 1970 -rrb- .": 1.0,
    "<s> in the meantime": 0.08333333333333333,
    "in the meantime ,": 1.0,
    "the meantime , dr.": 1.0,
    "meantime , dr. kenneth": 1.0,
    ", dr. kenneth lee": 1.0,
    "dr. kenneth lee pike": 1.0,
    "kenneth lee pike ,": 1.0,
    "lee pike , a": 1.0,
    "pike , a professor": 1.0,
    ", a professor at": 1.0,
    "a professor at university": 1.0,
    "professor at university of": 1.0,
    "at university of michigan": 1.0,
    "university of michigan ,": 1.0,
    "of michigan , ann": 1.0,
    "michigan , ann arbor": 1.0,
    ", ann arbor ,": 1.0,
    "ann arbor , taught": 1.0,
    "arbor , taught the": 1.0,
    ", taught the theory": 1.0,
    "taught the theory ,": 0.5,
    "the theory , and": 1.0,
    "theory , and one": 0.5,
    ", and one of": 1.0,
    "and one of his": 1.0,
    "one of his students": 1.0,
    "of his students ,": 1.0,
    "his students , robert": 1.0,
    "students , robert e.": 1.0,
    ", robert e. longacre": 1.0,
    "robert e. longacre ,": 1.0,
    "e. longacre , was": 0.5,
    "longacre , was able": 1.0,
    "was able to disseminate": 0.25,
    "able to disseminate it": 1.0,
    "to disseminate it in": 1.0,
    "disseminate it in a": 1.0,
    "it in a dissertation": 1.0,
    "in a dissertation .": 1.0,
    "<s> harris 's methodology": 1.0,
    "harris 's methodology was": 1.0,
    "'s methodology was developed": 1.0,
    "methodology was developed into": 1.0,
    "was developed into a": 1.0,
    "developed into a system": 1.0,
    "into a system for": 1.0,
    "a system for the": 1.0,
    "system for the computer-aided": 1.0,
    "for the computer-aided analysis": 1.0,
    "the computer-aided analysis of": 1.0,
    "computer-aided analysis of natural": 1.0,
    "of natural language by": 0.058823529411764705,
    "natural language by a": 1.0,
    "language by a team": 1.0,
    "by a team led": 1.0,
    "a team led by": 1.0,
    "team led by naomi": 1.0,
    "led by naomi sager": 1.0,
    "by naomi sager at": 1.0,
    "naomi sager at nyu": 1.0,
    "sager at nyu ,": 1.0,
    "at nyu , which": 1.0,
    "nyu , which has": 1.0,
    ", which has been": 1.0,
    "which has been applied": 0.3333333333333333,
    "has been applied to": 1.0,
    "been applied to a": 0.2,
    "applied to a number": 0.5,
    "to a number of": 1.0,
    "a number of sublanguage": 0.045454545454545456,
    "number of sublanguage domains": 1.0,
    "of sublanguage domains ,": 1.0,
    "sublanguage domains , most": 1.0,
    "domains , most notably": 1.0,
    ", most notably to": 1.0,
    "most notably to medical": 1.0,
    "notably to medical informatics": 1.0,
    "to medical informatics .": 1.0,
    "<s> the software for": 1.0,
    "the software for the": 1.0,
    "software for the medical": 1.0,
    "for the medical language": 1.0,
    "the medical language processor": 1.0,
    "medical language processor is": 1.0,
    "language processor is publicly": 1.0,
    "processor is publicly available": 1.0,
    "is publicly available on": 1.0,
    "publicly available on sourceforge": 1.0,
    "available on sourceforge .": 1.0,
    "<s> in the late": 0.08333333333333333,
    "in the late 1960s": 0.2,
    "the late 1960s and": 1.0,
    "late 1960s and 1970s": 1.0,
    "1960s and 1970s ,": 1.0,
    "and 1970s , and": 1.0,
    "1970s , and without": 1.0,
    ", and without reference": 0.5,
    "and without reference to": 1.0,
    "without reference to this": 1.0,
    "reference to this prior": 1.0,
    "to this prior work": 1.0,
    "this prior work ,": 1.0,
    "prior work , a": 1.0,
    "work , a variety": 1.0,
    ", a variety of": 1.0,
    "a variety of other": 0.14285714285714285,
    "variety of other approaches": 1.0,
    "of other approaches to": 1.0,
    "other approaches to a": 1.0,
    "approaches to a new": 1.0,
    "to a new cross-discipline": 1.0,
    "a new cross-discipline of": 1.0,
    "new cross-discipline of da": 1.0,
    "cross-discipline of da began": 1.0,
    "of da began to": 1.0,
    "da began to develop": 1.0,
    "began to develop in": 0.5,
    "to develop in most": 1.0,
    "develop in most of": 1.0,
    "in most of the": 1.0,
    "most of the humanities": 0.3333333333333333,
    "of the humanities and": 1.0,
    "the humanities and social": 1.0,
    "humanities and social sciences": 1.0,
    "and social sciences concurrently": 1.0,
    "social sciences concurrently with": 1.0,
    "sciences concurrently with ,": 1.0,
    "concurrently with , and": 1.0,
    "with , and related": 1.0,
    ", and related to": 1.0,
    "and related to ,": 1.0,
    "related to , other": 1.0,
    "to , other disciplines": 1.0,
    ", other disciplines ,": 1.0,
    "other disciplines , such": 1.0,
    "disciplines , such as": 1.0,
    ", such as semiotics": 0.030303030303030304,
    "such as semiotics ,": 1.0,
    "as semiotics , psycholinguistics": 1.0,
    "semiotics , psycholinguistics ,": 1.0,
    ", psycholinguistics , sociolinguistics": 1.0,
    "psycholinguistics , sociolinguistics ,": 1.0,
    ", sociolinguistics , and": 1.0,
    "sociolinguistics , and pragmatics": 1.0,
    ", and pragmatics .": 1.0,
    "<s> many of these": 0.5,
    "many of these approaches": 1.0,
    "of these approaches ,": 1.0,
    "these approaches , especially": 1.0,
    "approaches , especially those": 1.0,
    ", especially those influenced": 0.5,
    "especially those influenced by": 1.0,
    "those influenced by the": 1.0,
    "influenced by the social": 0.3333333333333333,
    "by the social sciences": 1.0,
    "the social sciences ,": 1.0,
    "social sciences , favor": 1.0,
    "sciences , favor a": 1.0,
    ", favor a more": 1.0,
    "favor a more dynamic": 1.0,
    "a more dynamic study": 1.0,
    "more dynamic study of": 1.0,
    "dynamic study of oral": 1.0,
    "study of oral talk-in-interaction": 1.0,
    "of oral talk-in-interaction .": 1.0,
    "<s> mention must also": 1.0,
    "mention must also be": 1.0,
    "must also be made": 1.0,
    "also be made of": 1.0,
    "be made of the": 1.0,
    "made of the term": 1.0,
    "of the term ``": 1.0,
    "the term `` conversational": 1.0,
    "term `` conversational analysis": 1.0,
    "`` conversational analysis ''": 1.0,
    "conversational analysis '' ,": 1.0,
    "analysis '' , which": 1.0,
    "'' , which was": 0.5,
    ", which was influenced": 0.25,
    "which was influenced by": 1.0,
    "was influenced by the": 1.0,
    "influenced by the sociologist": 0.3333333333333333,
    "by the sociologist harold": 1.0,
    "the sociologist harold garfinkel": 1.0,
    "sociologist harold garfinkel who": 1.0,
    "harold garfinkel who is": 1.0,
    "garfinkel who is the": 1.0,
    "who is the founder": 0.3333333333333333,
    "is the founder of": 1.0,
    "the founder of ethnomethodology": 1.0,
    "founder of ethnomethodology .": 1.0,
    "<s> in europe ,": 1.0,
    "in europe , michel": 0.5,
    "europe , michel foucault": 1.0,
    ", michel foucault became": 0.5,
    "michel foucault became one": 1.0,
    "foucault became one of": 1.0,
    "became one of the": 1.0,
    "one of the key": 0.08333333333333333,
    "of the key theorists": 1.0,
    "the key theorists of": 1.0,
    "key theorists of the": 1.0,
    "theorists of the subject": 1.0,
    "of the subject ,": 0.5,
    "the subject , especially": 1.0,
    "subject , especially of": 1.0,
    ", especially of discourse": 1.0,
    "especially of discourse ,": 1.0,
    "of discourse , and": 0.5,
    "discourse , and wrote": 1.0,
    ", and wrote the": 1.0,
    "and wrote the archaeology": 1.0,
    "wrote the archaeology of": 1.0,
    "the archaeology of knowledge": 1.0,
    "archaeology of knowledge on": 1.0,
    "of knowledge on the": 1.0,
    "knowledge on the subject": 0.5,
    "on the subject .": 1.0,
    "<s> topics of interest": 1.0,
    "topics of interest topics": 1.0,
    "of interest topics of": 1.0,
    "interest topics of discourse": 1.0,
    "topics of discourse analysis": 1.0,
    "of discourse analysis include": 0.25,
    "discourse analysis include :": 1.0,
    "analysis include : the": 1.0,
    "include : the various": 1.0,
    ": the various levels": 1.0,
    "the various levels or": 1.0,
    "various levels or dimensions": 1.0,
    "levels or dimensions of": 1.0,
    "or dimensions of discourse": 1.0,
    "dimensions of discourse ,": 1.0,
    "of discourse , such": 0.5,
    "discourse , such as": 1.0,
    ", such as sounds": 0.030303030303030304,
    "such as sounds -lrb-": 1.0,
    "as sounds -lrb- intonation": 1.0,
    "sounds -lrb- intonation ,": 1.0,
    "-lrb- intonation , etc.": 1.0,
    "intonation , etc. -rrb-": 1.0,
    ", etc. -rrb- ,": 0.3333333333333333,
    "etc. -rrb- , gestures": 0.3333333333333333,
    "-rrb- , gestures ,": 1.0,
    ", gestures , syntax": 1.0,
    "gestures , syntax ,": 1.0,
    ", syntax , the": 0.5,
    "syntax , the lexicon": 1.0,
    ", the lexicon ,": 1.0,
    "the lexicon , style": 1.0,
    "lexicon , style ,": 1.0,
    ", style , rhetoric": 1.0,
    "style , rhetoric ,": 1.0,
    ", rhetoric , meanings": 1.0,
    "rhetoric , meanings ,": 1.0,
    ", meanings , speech": 1.0,
    "meanings , speech acts": 1.0,
    ", speech acts ,": 0.5,
    "speech acts , moves": 1.0,
    "acts , moves ,": 1.0,
    ", moves , strategies": 1.0,
    "moves , strategies ,": 1.0,
    ", strategies , turns": 1.0,
    "strategies , turns and": 1.0,
    ", turns and other": 1.0,
    "turns and other aspects": 1.0,
    "and other aspects of": 1.0,
    "other aspects of interaction": 1.0,
    "aspects of interaction genres": 1.0,
    "of interaction genres of": 1.0,
    "interaction genres of discourse": 1.0,
    "genres of discourse -lrb-": 1.0,
    "of discourse -lrb- various": 0.5,
    "discourse -lrb- various types": 1.0,
    "-lrb- various types of": 1.0,
    "various types of discourse": 0.5,
    "types of discourse in": 0.5,
    "of discourse in politics": 1.0,
    "discourse in politics ,": 1.0,
    "in politics , the": 1.0,
    "politics , the media": 1.0,
    ", the media ,": 1.0,
    "the media , education": 1.0,
    "media , education ,": 1.0,
    ", education , science": 1.0,
    "education , science ,": 1.0,
    ", science , business": 1.0,
    "science , business ,": 1.0,
    ", business , etc.": 1.0,
    "business , etc. -rrb-": 1.0,
    ", etc. -rrb- the": 0.1111111111111111,
    "etc. -rrb- the relations": 1.0,
    "-rrb- the relations between": 1.0,
    "the relations between discourse": 0.8,
    "relations between discourse and": 1.0,
    "between discourse and the": 0.25,
    "discourse and the emergence": 1.0,
    "and the emergence of": 1.0,
    "the emergence of syntactic": 1.0,
    "emergence of syntactic structure": 1.0,
    "of syntactic structure the": 1.0,
    "syntactic structure the relations": 1.0,
    "structure the relations between": 1.0,
    "the relations between text": 0.2,
    "relations between text -lrb-": 1.0,
    "between text -lrb- discourse": 1.0,
    "text -lrb- discourse -rrb-": 1.0,
    "-lrb- discourse -rrb- and": 1.0,
    "discourse -rrb- and context": 1.0,
    "-rrb- and context the": 1.0,
    "and context the relations": 0.5,
    "context the relations between": 1.0,
    "between discourse and power": 0.25,
    "discourse and power the": 1.0,
    "and power the relations": 1.0,
    "power the relations between": 1.0,
    "between discourse and interaction": 0.25,
    "discourse and interaction the": 1.0,
    "and interaction the relations": 1.0,
    "interaction the relations between": 1.0,
    "between discourse and cognition": 0.25,
    "discourse and cognition and": 1.0,
    "and cognition and memory": 1.0,
    "cognition and memory political": 1.0,
    "and memory political discourse": 1.0,
    "memory political discourse political": 1.0,
    "political discourse political discourse": 1.0,
    "discourse political discourse analysis": 1.0,
    "political discourse analysis is": 1.0,
    "discourse analysis is a": 1.0,
    "analysis is a field": 1.0,
    "a field of discourse": 0.3333333333333333,
    "field of discourse analysis": 1.0,
    "of discourse analysis which": 0.25,
    "discourse analysis which focuses": 1.0,
    "analysis which focuses on": 1.0,
    "which focuses on discourse": 1.0,
    "focuses on discourse in": 1.0,
    "on discourse in political": 1.0,
    "discourse in political forums": 1.0,
    "in political forums -lrb-": 1.0,
    "political forums -lrb- such": 1.0,
    "forums -lrb- such as": 1.0,
    "-lrb- such as debates": 0.125,
    "such as debates ,": 1.0,
    "as debates , speeches": 1.0,
    "debates , speeches ,": 1.0,
    ", speeches , and": 1.0,
    "speeches , and hearings": 1.0,
    ", and hearings -rrb-": 1.0,
    "and hearings -rrb- as": 1.0,
    "hearings -rrb- as the": 1.0,
    "-rrb- as the phenomenon": 1.0,
    "as the phenomenon of": 1.0,
    "the phenomenon of interest": 0.3333333333333333,
    "phenomenon of interest .": 1.0,
    "<s> political discourse is": 1.0,
    "political discourse is the": 0.5,
    "discourse is the informal": 1.0,
    "is the informal exchange": 1.0,
    "the informal exchange of": 1.0,
    "informal exchange of reasoned": 1.0,
    "exchange of reasoned views": 1.0,
    "of reasoned views as": 1.0,
    "reasoned views as to": 1.0,
    "views as to which": 1.0,
    "as to which of": 0.5,
    "to which of several": 1.0,
    "which of several alternative": 1.0,
    "of several alternative courses": 1.0,
    "several alternative courses of": 1.0,
    "alternative courses of action": 1.0,
    "courses of action should": 1.0,
    "of action should be": 1.0,
    "action should be taken": 1.0,
    "should be taken to": 1.0,
    "be taken to solve": 1.0,
    "taken to solve a": 1.0,
    "to solve a societal": 1.0,
    "solve a societal problem": 1.0,
    "a societal problem .": 1.0,
    "it is a science": 0.16666666666666666,
    "is a science that": 1.0,
    "a science that has": 1.0,
    "science that has been": 1.0,
    "that has been used": 0.25,
    "has been used through": 0.5,
    "been used through the": 1.0,
    "used through the history": 1.0,
    "through the history of": 1.0,
    "the history of the": 1.0,
    "history of the united": 1.0,
    "of the united states": 1.0,
    "the united states .": 0.2857142857142857,
    "<s> it is the": 0.05263157894736842,
    "it is the essence": 0.3333333333333333,
    "is the essence of": 1.0,
    "the essence of democracy": 0.5,
    "essence of democracy .": 1.0,
    "<s> full of problems": 1.0,
    "full of problems and": 1.0,
    "of problems and persuasion": 1.0,
    "problems and persuasion ,": 1.0,
    "and persuasion , political": 1.0,
    "persuasion , political discourse": 1.0,
    ", political discourse is": 1.0,
    "political discourse is used": 0.5,
    "discourse is used in": 1.0,
    "is used in many": 0.5,
    "used in many debates": 0.3333333333333333,
    "in many debates ,": 1.0,
    "many debates , candidacies": 1.0,
    "debates , candidacies and": 1.0,
    ", candidacies and in": 1.0,
    "candidacies and in our": 1.0,
    "and in our everyday": 1.0,
    "in our everyday life": 1.0,
    "our everyday life .": 1.0,
    "<s> perspectives the following": 1.0,
    "perspectives the following are": 1.0,
    "the following are some": 1.0,
    "following are some of": 1.0,
    "are some of the": 1.0,
    "some of the specific": 0.1,
    "of the specific theoretical": 0.5,
    "the specific theoretical perspectives": 1.0,
    "specific theoretical perspectives and": 1.0,
    "theoretical perspectives and analytical": 1.0,
    "perspectives and analytical approaches": 1.0,
    "and analytical approaches used": 1.0,
    "analytical approaches used in": 1.0,
    "approaches used in linguistic": 1.0,
    "used in linguistic discourse": 1.0,
    "in linguistic discourse analysis": 1.0,
    "linguistic discourse analysis :": 1.0,
    "discourse analysis : emergent": 0.5,
    "analysis : emergent grammar": 1.0,
    ": emergent grammar text": 1.0,
    "emergent grammar text grammar": 1.0,
    "grammar text grammar -lrb-": 1.0,
    "text grammar -lrb- or": 1.0,
    "grammar -lrb- or `": 1.0,
    "-lrb- or ` discourse": 1.0,
    "or ` discourse grammar": 1.0,
    "` discourse grammar '": 1.0,
    "discourse grammar ' -rrb-": 1.0,
    "grammar ' -rrb- cohesion": 1.0,
    "' -rrb- cohesion and": 1.0,
    "-rrb- cohesion and relevance": 1.0,
    "cohesion and relevance theory": 1.0,
    "and relevance theory functional": 1.0,
    "relevance theory functional grammar": 1.0,
    "theory functional grammar rhetoric": 1.0,
    "functional grammar rhetoric stylistics": 1.0,
    "grammar rhetoric stylistics -lrb-": 1.0,
    "rhetoric stylistics -lrb- linguistics": 1.0,
    "stylistics -lrb- linguistics -rrb-": 1.0,
    "-lrb- linguistics -rrb- interactional": 0.5,
    "linguistics -rrb- interactional sociolinguistics": 1.0,
    "-rrb- interactional sociolinguistics ethnography": 1.0,
    "interactional sociolinguistics ethnography of": 1.0,
    "sociolinguistics ethnography of communication": 1.0,
    "ethnography of communication pragmatics": 1.0,
    "of communication pragmatics ,": 1.0,
    "communication pragmatics , particularly": 1.0,
    "pragmatics , particularly speech": 1.0,
    ", particularly speech act": 1.0,
    "particularly speech act theory": 1.0,
    "speech act theory conversation": 1.0,
    "act theory conversation analysis": 1.0,
    "theory conversation analysis variation": 1.0,
    "conversation analysis variation analysis": 1.0,
    "analysis variation analysis applied": 1.0,
    "variation analysis applied linguistics": 1.0,
    "analysis applied linguistics cognitive": 1.0,
    "applied linguistics cognitive psychology": 1.0,
    "linguistics cognitive psychology ,": 1.0,
    "cognitive psychology , often": 0.5,
    "psychology , often under": 1.0,
    ", often under the": 1.0,
    "often under the label": 1.0,
    "under the label discourse": 1.0,
    "the label discourse processing": 1.0,
    "label discourse processing ,": 1.0,
    "discourse processing , studying": 1.0,
    "processing , studying the": 1.0,
    ", studying the production": 1.0,
    "studying the production and": 1.0,
    "the production and comprehension": 1.0,
    "production and comprehension of": 1.0,
    "and comprehension of discourse": 1.0,
    "comprehension of discourse .": 1.0,
    "<s> discursive psychology response": 1.0,
    "discursive psychology response based": 1.0,
    "psychology response based therapy": 1.0,
    "response based therapy -lrb-": 1.0,
    "based therapy -lrb- counselling": 1.0,
    "therapy -lrb- counselling -rrb-": 1.0,
    "-lrb- counselling -rrb- critical": 1.0,
    "counselling -rrb- critical discourse": 1.0,
    "-rrb- critical discourse analysis": 1.0,
    "critical discourse analysis sublanguage": 1.0,
    "discourse analysis sublanguage analysis": 1.0,
    "analysis sublanguage analysis genre": 1.0,
    "sublanguage analysis genre analysis": 1.0,
    "analysis genre analysis &": 1.0,
    "genre analysis & critical": 1.0,
    "analysis & critical genre": 1.0,
    "& critical genre analysis": 1.0,
    "critical genre analysis although": 1.0,
    "genre analysis although these": 1.0,
    "analysis although these approaches": 1.0,
    "although these approaches emphasize": 1.0,
    "these approaches emphasize different": 1.0,
    "approaches emphasize different aspects": 1.0,
    "emphasize different aspects of": 1.0,
    "different aspects of language": 1.0,
    "aspects of language use": 1.0,
    "of language use ,": 1.0,
    "language use , they": 0.5,
    "use , they all": 1.0,
    ", they all view": 0.5,
    "they all view language": 1.0,
    "all view language as": 1.0,
    "view language as social": 1.0,
    "language as social interaction": 1.0,
    "as social interaction ,": 1.0,
    "social interaction , and": 1.0,
    "interaction , and are": 1.0,
    ", and are concerned": 1.0,
    "and are concerned with": 1.0,
    "are concerned with the": 1.0,
    "concerned with the social": 0.5,
    "with the social contexts": 1.0,
    "the social contexts in": 1.0,
    "social contexts in which": 1.0,
    "contexts in which discourse": 1.0,
    "in which discourse is": 1.0,
    "which discourse is embedded": 1.0,
    "discourse is embedded .": 1.0,
    "<s> often a distinction": 1.0,
    "often a distinction is": 1.0,
    "a distinction is made": 1.0,
    "distinction is made between": 1.0,
    "is made between `": 1.0,
    "made between ` local": 1.0,
    "between ` local '": 1.0,
    "` local ' structures": 1.0,
    "local ' structures of": 1.0,
    "' structures of discourse": 1.0,
    "structures of discourse -lrb-": 1.0,
    "of discourse -lrb- such": 0.5,
    "discourse -lrb- such as": 1.0,
    "-lrb- such as relations": 0.125,
    "such as relations among": 1.0,
    "as relations among sentences": 1.0,
    "relations among sentences ,": 1.0,
    "among sentences , propositions": 1.0,
    ", propositions , and": 0.5,
    "propositions , and turns": 1.0,
    ", and turns -rrb-": 1.0,
    "and turns -rrb- and": 1.0,
    "turns -rrb- and `": 1.0,
    "-rrb- and ` global": 1.0,
    "and ` global '": 1.0,
    "` global ' structures": 1.0,
    "global ' structures ,": 1.0,
    "' structures , such": 1.0,
    "structures , such as": 1.0,
    ", such as overall": 0.030303030303030304,
    "such as overall topics": 1.0,
    "as overall topics and": 1.0,
    "overall topics and the": 1.0,
    "topics and the schematic": 1.0,
    "and the schematic organization": 1.0,
    "the schematic organization of": 1.0,
    "schematic organization of discourses": 1.0,
    "organization of discourses and": 1.0,
    "of discourses and conversations": 1.0,
    "discourses and conversations .": 1.0,
    "for instance , many": 0.1111111111111111,
    "instance , many types": 1.0,
    ", many types of": 1.0,
    "many types of discourse": 1.0,
    "types of discourse begin": 0.5,
    "of discourse begin with": 1.0,
    "discourse begin with some": 1.0,
    "begin with some kind": 1.0,
    "with some kind of": 1.0,
    "some kind of global": 0.25,
    "kind of global `": 1.0,
    "of global ` summary": 1.0,
    "global ` summary '": 1.0,
    "` summary ' ,": 1.0,
    "summary ' , in": 1.0,
    "' , in titles": 1.0,
    ", in titles ,": 1.0,
    "in titles , headlines": 1.0,
    "titles , headlines ,": 1.0,
    ", headlines , leads": 1.0,
    "headlines , leads ,": 1.0,
    ", leads , abstracts": 1.0,
    "leads , abstracts ,": 1.0,
    ", abstracts , and": 1.0,
    "abstracts , and so": 1.0,
    ", and so on": 0.8333333333333334,
    "and so on .": 0.8,
    "<s> a problem for": 1.0,
    "a problem for the": 1.0,
    "problem for the discourse": 1.0,
    "for the discourse analyst": 1.0,
    "the discourse analyst is": 1.0,
    "discourse analyst is to": 1.0,
    "analyst is to decide": 1.0,
    "is to decide when": 1.0,
    "to decide when a": 1.0,
    "decide when a particular": 1.0,
    "when a particular feature": 1.0,
    "a particular feature is": 1.0,
    "particular feature is relevant": 1.0,
    "feature is relevant to": 1.0,
    "is relevant to the": 1.0,
    "relevant to the specification": 1.0,
    "to the specification is": 1.0,
    "the specification is required": 1.0,
    "specification is required .": 1.0,
    "<s> are there general": 1.0,
    "are there general principles": 1.0,
    "there general principles which": 1.0,
    "general principles which will": 1.0,
    "principles which will determine": 1.0,
    "which will determine the": 1.0,
    "will determine the relevance": 1.0,
    "determine the relevance or": 1.0,
    "the relevance or nature": 1.0,
    "relevance or nature of": 1.0,
    "or nature of the": 1.0,
    "nature of the specification": 0.2,
    "of the specification .": 1.0,
    "<s> prominent discourse analysts": 1.0,
    "prominent discourse analysts this": 1.0,
    "discourse analysts this article": 1.0,
    "analysts this article contains": 1.0,
    "this article contains embedded": 1.0,
    "article contains embedded lists": 1.0,
    "contains embedded lists that": 1.0,
    "embedded lists that may": 1.0,
    "lists that may be": 1.0,
    "that may be poorly": 1.0,
    "may be poorly defined": 1.0,
    "be poorly defined ,": 1.0,
    "poorly defined , unverified": 1.0,
    "defined , unverified or": 1.0,
    ", unverified or indiscriminate": 1.0,
    "unverified or indiscriminate .": 1.0,
    "<s> please help to": 0.5,
    "please help to clean": 1.0,
    "help to clean it": 1.0,
    "to clean it up": 1.0,
    "clean it up to": 1.0,
    "it up to meet": 1.0,
    "up to meet wikipedia": 1.0,
    "to meet wikipedia 's": 1.0,
    "meet wikipedia 's quality": 1.0,
    "wikipedia 's quality standards": 1.0,
    "'s quality standards .": 1.0,
    "<s> -lrb- may 2012": 0.5,
    "-lrb- may 2012 -rrb-": 1.0,
    "may 2012 -rrb- marc": 1.0,
    "2012 -rrb- marc angenot": 1.0,
    "-rrb- marc angenot ,": 1.0,
    "marc angenot , robert": 1.0,
    "angenot , robert de": 1.0,
    ", robert de beaugrande": 1.0,
    "robert de beaugrande ,": 1.0,
    "de beaugrande , jan": 1.0,
    "beaugrande , jan blommaert": 1.0,
    ", jan blommaert ,": 1.0,
    "jan blommaert , adriana": 1.0,
    "blommaert , adriana bolivar": 1.0,
    ", adriana bolivar ,": 1.0,
    "adriana bolivar , carmen": 1.0,
    "bolivar , carmen rosa": 1.0,
    ", carmen rosa caldas-coulthard": 1.0,
    "carmen rosa caldas-coulthard ,": 1.0,
    "rosa caldas-coulthard , robyn": 1.0,
    "caldas-coulthard , robyn carston": 1.0,
    ", robyn carston ,": 1.0,
    "robyn carston , wallace": 1.0,
    "carston , wallace chafe": 1.0,
    ", wallace chafe ,": 1.0,
    "wallace chafe , paul": 1.0,
    "chafe , paul chilton": 1.0,
    ", paul chilton ,": 1.0,
    "paul chilton , guy": 1.0,
    "chilton , guy cook": 1.0,
    ", guy cook ,": 1.0,
    "guy cook , malcolm": 1.0,
    "cook , malcolm coulthard": 1.0,
    ", malcolm coulthard ,": 1.0,
    "malcolm coulthard , james": 1.0,
    "coulthard , james deese": 1.0,
    ", james deese ,": 1.0,
    "james deese , paul": 1.0,
    "deese , paul drew": 1.0,
    ", paul drew ,": 1.0,
    "paul drew , john": 1.0,
    "drew , john du": 1.0,
    ", john du bois": 1.0,
    "john du bois ,": 1.0,
    "du bois , alessandro": 1.0,
    "bois , alessandro duranti": 1.0,
    ", alessandro duranti ,": 1.0,
    "alessandro duranti , brenton": 1.0,
    "duranti , brenton d.": 1.0,
    ", brenton d. faber": 1.0,
    "brenton d. faber ,": 1.0,
    "d. faber , norman": 1.0,
    "faber , norman fairclough": 1.0,
    ", norman fairclough ,": 1.0,
    "norman fairclough , michel": 1.0,
    "fairclough , michel foucault": 1.0,
    ", michel foucault ,": 0.5,
    "michel foucault , roger": 1.0,
    "foucault , roger fowler": 1.0,
    ", roger fowler ,": 1.0,
    "roger fowler , james": 1.0,
    "fowler , james paul": 1.0,
    ", james paul gee": 1.0,
    "james paul gee ,": 1.0,
    "paul gee , talmy": 1.0,
    "gee , talmy giv\u00f3n": 1.0,
    ", talmy giv\u00f3n ,": 1.0,
    "talmy giv\u00f3n , charles": 1.0,
    "giv\u00f3n , charles goodwin": 1.0,
    ", charles goodwin ,": 1.0,
    "charles goodwin , art": 1.0,
    "goodwin , art graesser": 1.0,
    ", art graesser ,": 1.0,
    "art graesser , michael": 1.0,
    "graesser , michael halliday": 1.0,
    ", michael halliday ,": 1.0,
    "michael halliday , zellig": 1.0,
    "halliday , zellig harris": 1.0,
    ", zellig harris ,": 0.5,
    "zellig harris , john": 1.0,
    "harris , john heritage": 1.0,
    ", john heritage ,": 1.0,
    "john heritage , janet": 1.0,
    "heritage , janet holmes": 1.0,
    ", janet holmes ,": 1.0,
    "janet holmes , david": 1.0,
    "holmes , david r.": 1.0,
    ", david r. howarth": 1.0,
    "david r. howarth ,": 1.0,
    "r. howarth , paul": 1.0,
    "howarth , paul hopper": 1.0,
    ", paul hopper ,": 1.0,
    "paul hopper , gail": 1.0,
    "hopper , gail jefferson": 1.0,
    ", gail jefferson ,": 1.0,
    "gail jefferson , barbara": 1.0,
    "jefferson , barbara johnstone": 1.0,
    ", barbara johnstone ,": 1.0,
    "barbara johnstone , walter": 1.0,
    "johnstone , walter kintsch": 1.0,
    ", walter kintsch ,": 1.0,
    "walter kintsch , richard": 1.0,
    "kintsch , richard kittredge": 1.0,
    ", richard kittredge ,": 1.0,
    "richard kittredge , adam": 1.0,
    "kittredge , adam jaworski": 1.0,
    ", adam jaworski ,": 1.0,
    "adam jaworski , william": 1.0,
    "jaworski , william labov": 1.0,
    ", william labov ,": 1.0,
    "william labov , george": 1.0,
    "labov , george lakoff": 1.0,
    ", george lakoff ,": 1.0,
    "george lakoff , jay": 1.0,
    "lakoff , jay lemke": 1.0,
    ", jay lemke ,": 1.0,
    "jay lemke , stephen": 1.0,
    "lemke , stephen h.": 1.0,
    ", stephen h. levinsohn": 1.0,
    "stephen h. levinsohn ,": 1.0,
    "h. levinsohn , james": 1.0,
    "levinsohn , james a.": 1.0,
    "a. lauriault\\/loriot , robert": 0.5,
    "lauriault\\/loriot , robert e.": 1.0,
    "e. longacre , jim": 0.5,
    "longacre , jim martin": 1.0,
    ", jim martin ,": 1.0,
    "jim martin , aletta": 1.0,
    "martin , aletta norval": 1.0,
    ", aletta norval ,": 1.0,
    "aletta norval , david": 1.0,
    "norval , david nunan": 1.0,
    ", david nunan ,": 1.0,
    "david nunan , elinor": 1.0,
    "nunan , elinor ochs": 1.0,
    ", elinor ochs ,": 1.0,
    "elinor ochs , gina": 1.0,
    "ochs , gina poncini": 1.0,
    ", gina poncini ,": 1.0,
    "gina poncini , jonathan": 1.0,
    "poncini , jonathan potter": 1.0,
    ", jonathan potter ,": 1.0,
    "jonathan potter , edward": 1.0,
    "potter , edward robinson": 1.0,
    ", edward robinson ,": 1.0,
    "edward robinson , nikolas": 1.0,
    "robinson , nikolas rose": 1.0,
    ", nikolas rose ,": 1.0,
    "nikolas rose , harvey": 1.0,
    "rose , harvey sacks": 1.0,
    ", harvey sacks ,": 1.0,
    "harvey sacks , svenka": 1.0,
    "sacks , svenka savic": 1.0,
    ", svenka savic naomi": 1.0,
    "svenka savic naomi sager": 1.0,
    "savic naomi sager ,": 1.0,
    "naomi sager , emanuel": 1.0,
    "sager , emanuel schegloff": 1.0,
    ", emanuel schegloff ,": 1.0,
    "emanuel schegloff , deborah": 1.0,
    "schegloff , deborah schiffrin": 1.0,
    ", deborah schiffrin ,": 1.0,
    "deborah schiffrin , michael": 1.0,
    "schiffrin , michael schober": 1.0,
    ", michael schober ,": 1.0,
    "michael schober , stef": 1.0,
    "schober , stef slembrouck": 1.0,
    ", stef slembrouck ,": 1.0,
    "stef slembrouck , michael": 1.0,
    "slembrouck , michael stubbs": 1.0,
    ", michael stubbs ,": 1.0,
    "michael stubbs , john": 1.0,
    "stubbs , john swales": 1.0,
    ", john swales ,": 1.0,
    "john swales , deborah": 0.5,
    "swales , deborah tannen": 1.0,
    ", deborah tannen ,": 1.0,
    "deborah tannen , sandra": 1.0,
    "tannen , sandra thompson": 1.0,
    ", sandra thompson ,": 1.0,
    "sandra thompson , teun": 1.0,
    "thompson , teun a.": 1.0,
    ", teun a. van": 1.0,
    "teun a. van dijk": 1.0,
    "a. van dijk ,": 1.0,
    "van dijk , theo": 1.0,
    "dijk , theo van": 1.0,
    ", theo van leeuwen": 1.0,
    "theo van leeuwen ,": 1.0,
    "van leeuwen , jef": 1.0,
    "leeuwen , jef verschueren": 1.0,
    ", jef verschueren ,": 1.0,
    "jef verschueren , henry": 1.0,
    "verschueren , henry widdowson": 1.0,
    ", henry widdowson ,": 1.0,
    "henry widdowson , carla": 1.0,
    "widdowson , carla willig": 1.0,
    ", carla willig ,": 1.0,
    "carla willig , deirdre": 1.0,
    "willig , deirdre wilson": 1.0,
    ", deirdre wilson ,": 1.0,
    "deirdre wilson , ruth": 1.0,
    "wilson , ruth wodak": 1.0,
    ", ruth wodak ,": 1.0,
    "ruth wodak , margaret": 1.0,
    "wodak , margaret wetherell": 1.0,
    ", margaret wetherell ,": 1.0,
    "margaret wetherell , ernesto": 1.0,
    "wetherell , ernesto laclau": 1.0,
    ", ernesto laclau ,": 1.0,
    "ernesto laclau , chantal": 1.0,
    "laclau , chantal mouffe": 1.0,
    ", chantal mouffe ,": 1.0,
    "chantal mouffe , judith": 1.0,
    "mouffe , judith m.": 1.0,
    ", judith m. de": 1.0,
    "judith m. de guzman": 1.0,
    "m. de guzman ,": 1.0,
    "de guzman , cynthia": 1.0,
    "guzman , cynthia hardy": 1.0,
    ", cynthia hardy ,": 1.0,
    "cynthia hardy , louise": 1.0,
    "hardy , louise j.": 1.0,
    ", louise j. phillips": 1.0,
    "louise j. phillips .": 1.0,
    "citation needed -rrb- bhatia": 0.07692307692307693,
    "needed -rrb- bhatia ,": 1.0,
    "-rrb- bhatia , v.j.": 1.0,
    "bhatia , v.j. ,": 1.0,
    ", v.j. , john": 1.0,
    "v.j. , john swales": 1.0,
    "john swales , zellig": 0.5,
    "swales , zellig harris": 1.0,
    ", zellig harris the": 0.5,
    "zellig harris the phenomenon": 1.0,
    "harris the phenomenon of": 1.0,
    "the phenomenon of information": 0.3333333333333333,
    "phenomenon of information overload": 1.0,
    "of information overload has": 1.0,
    "information overload has meant": 1.0,
    "overload has meant that": 1.0,
    "has meant that access": 1.0,
    "meant that access to": 1.0,
    "that access to coherent": 1.0,
    "access to coherent and": 1.0,
    "to coherent and correctly-developed": 1.0,
    "coherent and correctly-developed summaries": 1.0,
    "and correctly-developed summaries is": 1.0,
    "correctly-developed summaries is vital": 1.0,
    "summaries is vital .": 1.0,
    "<s> as access to": 1.0,
    "as access to data": 1.0,
    "access to data has": 1.0,
    "to data has increased": 1.0,
    "data has increased so": 1.0,
    "has increased so has": 1.0,
    "increased so has interest": 1.0,
    "so has interest in": 1.0,
    "has interest in automatic": 1.0,
    "interest in automatic summarization": 1.0,
    "in automatic summarization .": 1.0,
    "<s> an example of": 0.5,
    "an example of the": 0.3333333333333333,
    "example of the use": 1.0,
    "of the use of": 1.0,
    "the use of summarization": 0.06666666666666667,
    "use of summarization technology": 1.0,
    "of summarization technology is": 1.0,
    "summarization technology is search": 1.0,
    "technology is search engines": 1.0,
    "is search engines such": 1.0,
    "search engines such as": 1.0,
    "engines such as google": 1.0,
    "such as google .": 1.0,
    "<s> technologies that can": 1.0,
    "technologies that can make": 1.0,
    "that can make a": 0.5,
    "can make a coherent": 1.0,
    "make a coherent summary": 1.0,
    "a coherent summary ,": 1.0,
    "coherent summary , of": 1.0,
    "summary , of any": 1.0,
    ", of any kind": 1.0,
    "of any kind of": 1.0,
    "any kind of text": 1.0,
    "kind of text ,": 1.0,
    "of text , need": 0.1,
    "text , need to": 1.0,
    ", need to take": 1.0,
    "need to take into": 1.0,
    "to take into account": 0.5,
    "take into account several": 0.5,
    "into account several variables": 1.0,
    "account several variables such": 1.0,
    "several variables such as": 1.0,
    "variables such as length": 1.0,
    "such as length ,": 1.0,
    "as length , writing": 1.0,
    "length , writing style": 1.0,
    ", writing style and": 1.0,
    "writing style and syntax": 1.0,
    "style and syntax to": 1.0,
    "and syntax to make": 1.0,
    "syntax to make a": 1.0,
    "to make a useful": 0.5,
    "make a useful summary": 1.0,
    "a useful summary .": 1.0,
    "<s> extractive methods work": 1.0,
    "extractive methods work by": 1.0,
    "methods work by selecting": 1.0,
    "work by selecting a": 1.0,
    "by selecting a subset": 1.0,
    "selecting a subset of": 1.0,
    "a subset of existing": 0.3333333333333333,
    "subset of existing words": 1.0,
    "of existing words ,": 1.0,
    "existing words , phrases": 1.0,
    "words , phrases ,": 1.0,
    ", phrases , or": 0.5,
    "phrases , or sentences": 1.0,
    ", or sentences in": 1.0,
    "or sentences in the": 1.0,
    "sentences in the original": 0.5,
    "in the original text": 0.75,
    "the original text to": 0.16666666666666666,
    "original text to form": 1.0,
    "text to form the": 1.0,
    "to form the summary": 1.0,
    "form the summary .": 1.0,
    "<s> in contrast ,": 0.8,
    "in contrast , abstractive": 0.2,
    "contrast , abstractive methods": 1.0,
    ", abstractive methods build": 1.0,
    "abstractive methods build an": 1.0,
    "methods build an internal": 1.0,
    "build an internal semantic": 1.0,
    "an internal semantic representation": 1.0,
    "internal semantic representation and": 1.0,
    "semantic representation and then": 1.0,
    "representation and then use": 1.0,
    "and then use natural": 1.0,
    "then use natural language": 1.0,
    "use natural language generation": 1.0,
    "natural language generation techniques": 0.2,
    "language generation techniques to": 1.0,
    "generation techniques to create": 1.0,
    "techniques to create a": 1.0,
    "to create a summary": 0.2,
    "create a summary that": 1.0,
    "a summary that is": 1.0,
    "summary that is closer": 0.5,
    "that is closer to": 1.0,
    "is closer to what": 1.0,
    "closer to what a": 1.0,
    "to what a human": 1.0,
    "what a human might": 0.5,
    "a human might generate": 1.0,
    "human might generate .": 1.0,
    "<s> such a summary": 1.0,
    "such a summary might": 1.0,
    "a summary might contain": 1.0,
    "summary might contain words": 1.0,
    "might contain words not": 1.0,
    "contain words not explicitly": 1.0,
    "words not explicitly present": 1.0,
    "not explicitly present in": 1.0,
    "explicitly present in the": 1.0,
    "present in the original": 0.5,
    "in the original .": 0.25,
    "<s> the state-of-the-art abstractive": 1.0,
    "the state-of-the-art abstractive methods": 1.0,
    "state-of-the-art abstractive methods are": 1.0,
    "abstractive methods are still": 1.0,
    "methods are still quite": 1.0,
    "are still quite weak": 1.0,
    "still quite weak ,": 1.0,
    "quite weak , so": 1.0,
    "weak , so most": 1.0,
    ", so most research": 1.0,
    "so most research has": 1.0,
    "most research has focused": 1.0,
    "has focused on extractive": 0.25,
    "focused on extractive methods": 1.0,
    "on extractive methods ,": 1.0,
    "extractive methods , and": 1.0,
    "methods , and this": 1.0,
    ", and this is": 1.0,
    "and this is what": 1.0,
    "this is what we": 1.0,
    "is what we will": 1.0,
    "what we will cover": 1.0,
    "we will cover .": 1.0,
    "<s> two particular types": 1.0,
    "two particular types of": 1.0,
    "particular types of summarization": 1.0,
    "types of summarization often": 1.0,
    "of summarization often addressed": 1.0,
    "summarization often addressed in": 1.0,
    "often addressed in the": 1.0,
    "addressed in the literature": 1.0,
    "in the literature are": 1.0,
    "the literature are keyphrase": 1.0,
    "literature are keyphrase extraction": 1.0,
    "are keyphrase extraction ,": 1.0,
    "keyphrase extraction , where": 0.25,
    "extraction , where the": 1.0,
    ", where the goal": 0.4,
    "where the goal is": 1.0,
    "the goal is to": 1.0,
    "goal is to select": 0.6666666666666666,
    "is to select individual": 0.5,
    "to select individual words": 1.0,
    "select individual words or": 1.0,
    "individual words or phrases": 1.0,
    "words or phrases to": 0.5,
    "or phrases to ``": 1.0,
    "phrases to `` tag": 1.0,
    "to `` tag ''": 1.0,
    "`` tag '' a": 1.0,
    "tag '' a document": 1.0,
    "'' a document ,": 1.0,
    "a document , and": 0.5,
    "document , and document": 1.0,
    ", and document summarization": 1.0,
    "and document summarization ,": 1.0,
    "document summarization , where": 0.5,
    "summarization , where the": 1.0,
    "is to select whole": 0.5,
    "to select whole sentences": 1.0,
    "select whole sentences to": 1.0,
    "whole sentences to create": 1.0,
    "sentences to create a": 1.0,
    "to create a short": 0.2,
    "create a short paragraph": 1.0,
    "a short paragraph summary": 1.0,
    "short paragraph summary .": 1.0,
    "<s> extraction and abstraction": 1.0,
    "extraction and abstraction broadly": 0.5,
    "and abstraction broadly ,": 1.0,
    "abstraction broadly , one": 1.0,
    "broadly , one distinguishes": 1.0,
    ", one distinguishes two": 1.0,
    "one distinguishes two approaches": 1.0,
    "distinguishes two approaches :": 1.0,
    "two approaches : extraction": 1.0,
    "approaches : extraction and": 1.0,
    ": extraction and abstraction": 1.0,
    "extraction and abstraction .": 0.5,
    "<s> extraction techniques merely": 1.0,
    "extraction techniques merely copy": 1.0,
    "techniques merely copy the": 1.0,
    "merely copy the information": 1.0,
    "copy the information deemed": 1.0,
    "the information deemed most": 1.0,
    "information deemed most important": 1.0,
    "deemed most important by": 1.0,
    "most important by the": 1.0,
    "important by the system": 1.0,
    "by the system to": 1.0,
    "the system to the": 0.5,
    "system to the summary": 1.0,
    "to the summary -lrb-": 1.0,
    "the summary -lrb- for": 1.0,
    "summary -lrb- for example": 1.0,
    "for example , key": 0.02127659574468085,
    "example , key clauses": 1.0,
    ", key clauses ,": 1.0,
    "key clauses , sentences": 1.0,
    "clauses , sentences or": 1.0,
    ", sentences or paragraphs": 1.0,
    "sentences or paragraphs -rrb-": 1.0,
    "or paragraphs -rrb- ,": 1.0,
    "paragraphs -rrb- , while": 1.0,
    "-rrb- , while abstraction": 0.5,
    ", while abstraction involves": 1.0,
    "while abstraction involves paraphrasing": 1.0,
    "abstraction involves paraphrasing sections": 1.0,
    "involves paraphrasing sections of": 1.0,
    "paraphrasing sections of the": 1.0,
    "sections of the source": 1.0,
    "of the source document": 0.2,
    "the source document .": 1.0,
    "<s> in general ,": 1.0,
    "in general , abstraction": 0.16666666666666666,
    "general , abstraction can": 1.0,
    ", abstraction can condense": 1.0,
    "abstraction can condense a": 1.0,
    "can condense a text": 1.0,
    "condense a text more": 1.0,
    "a text more strongly": 1.0,
    "text more strongly than": 1.0,
    "more strongly than extraction": 1.0,
    "strongly than extraction ,": 1.0,
    "than extraction , but": 1.0,
    "extraction , but the": 1.0,
    ", but the programs": 0.5,
    "but the programs that": 1.0,
    "the programs that can": 1.0,
    "programs that can do": 1.0,
    "that can do this": 1.0,
    "can do this are": 1.0,
    "do this are harder": 1.0,
    "this are harder to": 1.0,
    "are harder to develop": 1.0,
    "harder to develop as": 1.0,
    "to develop as they": 1.0,
    "develop as they require": 1.0,
    "as they require the": 1.0,
    "they require the use": 1.0,
    "require the use of": 1.0,
    "the use of natural": 0.06666666666666667,
    "use of natural language": 1.0,
    "of natural language generation": 0.058823529411764705,
    "natural language generation technology": 0.2,
    "language generation technology ,": 1.0,
    "generation technology , which": 1.0,
    "technology , which itself": 1.0,
    ", which itself is": 1.0,
    "which itself is a": 1.0,
    "itself is a growing": 1.0,
    "is a growing field": 1.0,
    "a growing field .": 1.0,
    "<s> types of summaries": 0.5,
    "types of summaries there": 0.5,
    "of summaries there are": 1.0,
    "summaries there are different": 1.0,
    "there are different types": 1.0,
    "are different types of": 1.0,
    "different types of summaries": 0.25,
    "types of summaries depending": 0.5,
    "of summaries depending what": 1.0,
    "summaries depending what the": 1.0,
    "depending what the summarization": 1.0,
    "what the summarization program": 1.0,
    "the summarization program focuses": 1.0,
    "summarization program focuses on": 1.0,
    "program focuses on to": 1.0,
    "focuses on to make": 1.0,
    "on to make the": 1.0,
    "to make the summary": 1.0,
    "make the summary of": 1.0,
    "the summary of the": 1.0,
    "summary of the text": 1.0,
    "the text , for": 0.3333333333333333,
    "text , for example": 1.0,
    ", for example generic": 0.1,
    "for example generic summaries": 1.0,
    "example generic summaries or": 1.0,
    "generic summaries or query": 1.0,
    "summaries or query relevant": 1.0,
    "or query relevant summaries": 1.0,
    "query relevant summaries -lrb-": 1.0,
    "relevant summaries -lrb- sometimes": 1.0,
    "summaries -lrb- sometimes called": 1.0,
    "-lrb- sometimes called query-biased": 1.0,
    "sometimes called query-biased summaries": 1.0,
    "called query-biased summaries -rrb-": 1.0,
    "query-biased summaries -rrb- .": 1.0,
    "<s> summarization systems are": 1.0,
    "summarization systems are able": 0.3333333333333333,
    "are able to create": 0.3333333333333333,
    "able to create both": 1.0,
    "to create both query": 1.0,
    "create both query relevant": 1.0,
    "both query relevant text": 1.0,
    "query relevant text summaries": 1.0,
    "relevant text summaries and": 1.0,
    "text summaries and generic": 1.0,
    "summaries and generic machine-generated": 1.0,
    "and generic machine-generated summaries": 1.0,
    "generic machine-generated summaries depending": 1.0,
    "machine-generated summaries depending on": 1.0,
    "summaries depending on what": 1.0,
    "depending on what the": 1.0,
    "on what the user": 1.0,
    "what the user needs": 1.0,
    "the user needs .": 1.0,
    "<s> summarization of multimedia": 1.0,
    "summarization of multimedia documents": 1.0,
    "of multimedia documents ,": 1.0,
    "multimedia documents , e.g.": 1.0,
    "documents , e.g. pictures": 1.0,
    ", e.g. pictures or": 1.0,
    "e.g. pictures or movies": 1.0,
    "pictures or movies ,": 1.0,
    "or movies , is": 1.0,
    "movies , is also": 1.0,
    ", is also possible": 1.0,
    "is also possible .": 1.0,
    "<s> some systems will": 0.5,
    "some systems will generate": 1.0,
    "systems will generate a": 1.0,
    "will generate a summary": 0.3333333333333333,
    "generate a summary based": 1.0,
    "a summary based on": 1.0,
    "summary based on a": 1.0,
    "based on a single": 0.25,
    "on a single source": 0.5,
    "a single source document": 1.0,
    "single source document ,": 1.0,
    "source document , while": 1.0,
    "document , while others": 1.0,
    ", while others can": 0.3333333333333333,
    "while others can use": 1.0,
    "others can use multiple": 1.0,
    "can use multiple source": 1.0,
    "use multiple source documents": 1.0,
    "multiple source documents -lrb-": 1.0,
    "source documents -lrb- for": 1.0,
    "documents -lrb- for example": 1.0,
    "for example , a": 0.10638297872340426,
    "example , a cluster": 0.2,
    ", a cluster of": 1.0,
    "a cluster of news": 1.0,
    "cluster of news stories": 0.5,
    "of news stories on": 1.0,
    "news stories on the": 1.0,
    "stories on the same": 1.0,
    "on the same topic": 0.5,
    "the same topic -rrb-": 1.0,
    "same topic -rrb- .": 1.0,
    "<s> these systems are": 0.25,
    "these systems are known": 1.0,
    "systems are known as": 1.0,
    "are known as multi-document": 1.0,
    "known as multi-document summarization": 1.0,
    "as multi-document summarization systems": 1.0,
    "multi-document summarization systems .": 1.0,
    "<s> keyphrase extraction task": 0.5,
    "keyphrase extraction task description": 1.0,
    "extraction task description and": 1.0,
    "task description and example": 1.0,
    "description and example the": 1.0,
    "and example the task": 1.0,
    "example the task is": 1.0,
    "the task is the": 0.5,
    "task is the following": 1.0,
    "is the following .": 1.0,
    "<s> you are given": 1.0,
    "you are given a": 1.0,
    "are given a piece": 1.0,
    "given a piece of": 1.0,
    "a piece of text": 0.5,
    "piece of text ,": 1.0,
    "of text , such": 0.1,
    "text , such as": 1.0,
    ", such as a": 0.030303030303030304,
    "such as a journal": 0.3333333333333333,
    "as a journal article": 1.0,
    "a journal article ,": 1.0,
    "journal article , and": 1.0,
    "article , and you": 1.0,
    ", and you must": 0.3333333333333333,
    "and you must produce": 1.0,
    "you must produce a": 1.0,
    "must produce a list": 1.0,
    "produce a list of": 1.0,
    "a list of keywords": 0.16666666666666666,
    "list of keywords or": 1.0,
    "of keywords or keyphrases": 1.0,
    "keywords or keyphrases that": 1.0,
    "or keyphrases that capture": 1.0,
    "keyphrases that capture the": 1.0,
    "that capture the primary": 1.0,
    "capture the primary topics": 1.0,
    "the primary topics discussed": 1.0,
    "primary topics discussed in": 1.0,
    "topics discussed in the": 1.0,
    "discussed in the text": 1.0,
    "in the text .": 0.375,
    "<s> in the case": 0.25,
    "in the case of": 1.0,
    "the case of research": 0.2,
    "case of research articles": 1.0,
    "of research articles ,": 1.0,
    "research articles , many": 1.0,
    "articles , many authors": 1.0,
    ", many authors provide": 1.0,
    "many authors provide manually": 1.0,
    "authors provide manually assigned": 1.0,
    "provide manually assigned keywords": 1.0,
    "manually assigned keywords ,": 1.0,
    "assigned keywords , but": 1.0,
    "keywords , but most": 1.0,
    ", but most text": 1.0,
    "but most text lacks": 1.0,
    "most text lacks pre-existing": 1.0,
    "text lacks pre-existing keyphrases": 1.0,
    "lacks pre-existing keyphrases .": 1.0,
    "for example , news": 0.02127659574468085,
    "example , news articles": 1.0,
    ", news articles rarely": 1.0,
    "news articles rarely have": 1.0,
    "articles rarely have keyphrases": 1.0,
    "rarely have keyphrases attached": 1.0,
    "have keyphrases attached ,": 1.0,
    "keyphrases attached , but": 1.0,
    "attached , but it": 1.0,
    ", but it would": 0.3333333333333333,
    "but it would be": 1.0,
    "it would be useful": 0.5,
    "would be useful to": 1.0,
    "be useful to be": 0.5,
    "useful to be able": 1.0,
    "to be able to": 1.0,
    "be able to automatically": 0.2,
    "able to automatically do": 1.0,
    "to automatically do so": 1.0,
    "automatically do so for": 1.0,
    "do so for a": 1.0,
    "so for a number": 1.0,
    "a number of applications": 0.045454545454545456,
    "number of applications discussed": 1.0,
    "of applications discussed below": 1.0,
    "applications discussed below .": 1.0,
    "<s> consider the example": 0.3333333333333333,
    "consider the example text": 1.0,
    "the example text from": 1.0,
    "example text from a": 1.0,
    "text from a recent": 1.0,
    "from a recent news": 1.0,
    "a recent news article": 1.0,
    "recent news article :": 1.0,
    "news article : ``": 1.0,
    "article : `` the": 1.0,
    ": `` the army": 1.0,
    "`` the army corps": 1.0,
    "the army corps of": 1.0,
    "army corps of engineers": 1.0,
    "corps of engineers ,": 0.5,
    "of engineers , rushing": 1.0,
    "engineers , rushing to": 1.0,
    ", rushing to meet": 1.0,
    "rushing to meet president": 1.0,
    "to meet president bush": 1.0,
    "meet president bush 's": 1.0,
    "president bush 's promise": 1.0,
    "bush 's promise to": 1.0,
    "'s promise to protect": 1.0,
    "promise to protect new": 1.0,
    "to protect new orleans": 1.0,
    "protect new orleans by": 1.0,
    "new orleans by the": 1.0,
    "orleans by the start": 1.0,
    "by the start of": 1.0,
    "the start of the": 0.5,
    "start of the 2006": 1.0,
    "of the 2006 hurricane": 1.0,
    "the 2006 hurricane season": 1.0,
    "2006 hurricane season ,": 1.0,
    "hurricane season , installed": 1.0,
    "season , installed defective": 1.0,
    ", installed defective flood-control": 1.0,
    "installed defective flood-control pumps": 1.0,
    "defective flood-control pumps last": 0.5,
    "flood-control pumps last year": 1.0,
    "pumps last year despite": 1.0,
    "last year despite warnings": 1.0,
    "year despite warnings from": 1.0,
    "despite warnings from its": 1.0,
    "warnings from its own": 1.0,
    "from its own expert": 1.0,
    "its own expert that": 1.0,
    "own expert that the": 1.0,
    "expert that the equipment": 1.0,
    "that the equipment would": 1.0,
    "the equipment would fail": 1.0,
    "equipment would fail during": 1.0,
    "would fail during a": 1.0,
    "fail during a storm": 1.0,
    "during a storm ,": 1.0,
    "a storm , according": 1.0,
    "storm , according to": 1.0,
    ", according to documents": 1.0,
    "according to documents obtained": 1.0,
    "to documents obtained by": 1.0,
    "documents obtained by the": 1.0,
    "obtained by the associated": 1.0,
    "by the associated press": 1.0,
    "the associated press ''": 1.0,
    "associated press '' .": 1.0,
    "<s> an extractive keyphrase": 1.0,
    "an extractive keyphrase extractor": 1.0,
    "extractive keyphrase extractor might": 1.0,
    "keyphrase extractor might select": 1.0,
    "extractor might select ``": 1.0,
    "might select `` army": 1.0,
    "select `` army corps": 1.0,
    "`` army corps of": 1.0,
    "corps of engineers ''": 0.5,
    "of engineers '' ,": 1.0,
    "engineers '' , ``": 1.0,
    "'' , `` president": 0.09090909090909091,
    ", `` president bush": 1.0,
    "`` president bush ''": 1.0,
    "president bush '' ,": 1.0,
    "bush '' , ``": 1.0,
    "'' , `` new": 0.09090909090909091,
    ", `` new orleans": 1.0,
    "`` new orleans ''": 1.0,
    "new orleans '' ,": 1.0,
    "orleans '' , and": 1.0,
    "'' , and ``": 1.0,
    ", and `` defective": 0.2,
    "and `` defective flood-control": 1.0,
    "`` defective flood-control pumps": 1.0,
    "defective flood-control pumps ''": 0.5,
    "flood-control pumps '' as": 1.0,
    "pumps '' as keyphrases": 1.0,
    "'' as keyphrases .": 1.0,
    "<s> these are pulled": 0.5,
    "these are pulled directly": 1.0,
    "are pulled directly from": 1.0,
    "pulled directly from the": 1.0,
    "directly from the text": 1.0,
    "from the text .": 1.0,
    "in contrast , an": 0.2,
    "contrast , an abstractive": 1.0,
    ", an abstractive keyphrase": 1.0,
    "an abstractive keyphrase system": 1.0,
    "abstractive keyphrase system would": 1.0,
    "keyphrase system would somehow": 1.0,
    "system would somehow internalize": 1.0,
    "would somehow internalize the": 1.0,
    "somehow internalize the content": 1.0,
    "internalize the content and": 1.0,
    "the content and generate": 1.0,
    "content and generate keyphrases": 1.0,
    "and generate keyphrases that": 1.0,
    "generate keyphrases that might": 1.0,
    "keyphrases that might be": 1.0,
    "that might be more": 1.0,
    "might be more descriptive": 1.0,
    "be more descriptive and": 1.0,
    "more descriptive and more": 1.0,
    "descriptive and more like": 1.0,
    "and more like what": 1.0,
    "more like what a": 1.0,
    "like what a human": 1.0,
    "what a human would": 0.5,
    "a human would produce": 1.0,
    "human would produce ,": 1.0,
    "would produce , such": 1.0,
    "produce , such as": 1.0,
    ", such as ``": 0.030303030303030304,
    "such as `` political": 0.125,
    "as `` political negligence": 1.0,
    "`` political negligence ''": 1.0,
    "political negligence '' or": 1.0,
    "negligence '' or ``": 1.0,
    "'' or `` inadequate": 0.25,
    "or `` inadequate protection": 1.0,
    "`` inadequate protection from": 1.0,
    "inadequate protection from floods": 1.0,
    "protection from floods ''": 1.0,
    "from floods '' .": 1.0,
    "<s> note that these": 0.14285714285714285,
    "note that these terms": 1.0,
    "that these terms do": 1.0,
    "these terms do not": 1.0,
    "terms do not appear": 1.0,
    "do not appear in": 1.0,
    "not appear in the": 1.0,
    "appear in the text": 0.3333333333333333,
    "in the text and": 0.125,
    "the text and require": 1.0,
    "text and require a": 1.0,
    "and require a deep": 1.0,
    "require a deep understanding": 1.0,
    "a deep understanding ,": 1.0,
    "deep understanding , which": 0.5,
    "understanding , which makes": 1.0,
    ", which makes it": 1.0,
    "which makes it difficult": 0.5,
    "makes it difficult for": 1.0,
    "it difficult for a": 1.0,
    "difficult for a computer": 1.0,
    "for a computer to": 0.5,
    "a computer to produce": 0.5,
    "computer to produce such": 1.0,
    "to produce such keyphrases": 1.0,
    "produce such keyphrases .": 1.0,
    "<s> keyphrases have many": 1.0,
    "keyphrases have many applications": 1.0,
    "have many applications ,": 1.0,
    "many applications , such": 1.0,
    "applications , such as": 1.0,
    ", such as to": 0.030303030303030304,
    "such as to improve": 1.0,
    "as to improve document": 1.0,
    "to improve document browsing": 1.0,
    "improve document browsing by": 1.0,
    "document browsing by providing": 1.0,
    "browsing by providing a": 1.0,
    "by providing a short": 1.0,
    "providing a short summary": 1.0,
    "a short summary .": 1.0,
    "<s> also , keyphrases": 0.3333333333333333,
    "also , keyphrases can": 1.0,
    ", keyphrases can improve": 1.0,
    "keyphrases can improve information": 1.0,
    "can improve information retrieval": 1.0,
    "improve information retrieval --": 1.0,
    "information retrieval -- if": 1.0,
    "retrieval -- if documents": 1.0,
    "-- if documents have": 1.0,
    "if documents have keyphrases": 1.0,
    "documents have keyphrases assigned": 1.0,
    "have keyphrases assigned ,": 1.0,
    "keyphrases assigned , a": 1.0,
    "assigned , a user": 1.0,
    ", a user could": 1.0,
    "a user could search": 1.0,
    "user could search by": 1.0,
    "could search by keyphrase": 1.0,
    "search by keyphrase to": 1.0,
    "by keyphrase to produce": 1.0,
    "keyphrase to produce more": 1.0,
    "to produce more reliable": 1.0,
    "produce more reliable hits": 0.5,
    "more reliable hits than": 1.0,
    "reliable hits than a": 1.0,
    "hits than a full-text": 1.0,
    "than a full-text search": 1.0,
    "a full-text search .": 1.0,
    "<s> also , automatic": 0.3333333333333333,
    "also , automatic keyphrase": 1.0,
    ", automatic keyphrase extraction": 1.0,
    "automatic keyphrase extraction can": 1.0,
    "keyphrase extraction can be": 1.0,
    "extraction can be useful": 1.0,
    "can be useful in": 0.5,
    "be useful in generating": 1.0,
    "useful in generating index": 1.0,
    "in generating index entries": 1.0,
    "generating index entries for": 1.0,
    "index entries for a": 1.0,
    "entries for a large": 1.0,
    "for a large text": 1.0,
    "a large text corpus": 1.0,
    "large text corpus .": 1.0,
    "<s> keyphrase extraction as": 0.5,
    "keyphrase extraction as supervised": 0.5,
    "extraction as supervised learning": 1.0,
    "as supervised learning beginning": 1.0,
    "supervised learning beginning with": 1.0,
    "learning beginning with the": 1.0,
    "beginning with the turney": 1.0,
    "with the turney paper": 1.0,
    "the turney paper ,": 0.5,
    "turney paper , many": 1.0,
    "paper , many researchers": 1.0,
    ", many researchers have": 1.0,
    "many researchers have approached": 1.0,
    "researchers have approached keyphrase": 1.0,
    "have approached keyphrase extraction": 1.0,
    "approached keyphrase extraction as": 1.0,
    "keyphrase extraction as a": 0.5,
    "extraction as a supervised": 1.0,
    "as a supervised machine": 1.0,
    "a supervised machine learning": 1.0,
    "supervised machine learning problem": 1.0,
    "machine learning problem .": 1.0,
    "<s> given a document": 1.0,
    "given a document ,": 1.0,
    "a document , we": 0.5,
    "document , we construct": 1.0,
    ", we construct an": 1.0,
    "we construct an example": 1.0,
    "construct an example for": 1.0,
    "an example for each": 0.5,
    "example for each unigram": 1.0,
    "for each unigram ,": 1.0,
    "each unigram , bigram": 1.0,
    "unigram , bigram ,": 1.0,
    ", bigram , and": 0.3333333333333333,
    "bigram , and trigram": 1.0,
    ", and trigram found": 1.0,
    "and trigram found in": 1.0,
    "trigram found in the": 1.0,
    "found in the text": 1.0,
    "in the text -lrb-": 0.125,
    "the text -lrb- though": 1.0,
    "text -lrb- though other": 1.0,
    "-lrb- though other text": 1.0,
    "though other text units": 1.0,
    "other text units are": 1.0,
    "text units are also": 1.0,
    "units are also possible": 1.0,
    "are also possible ,": 1.0,
    "also possible , as": 1.0,
    "possible , as discussed": 0.5,
    ", as discussed below": 1.0,
    "as discussed below -rrb-": 1.0,
    "discussed below -rrb- .": 1.0,
    "<s> we then compute": 1.0,
    "we then compute various": 1.0,
    "then compute various features": 1.0,
    "compute various features describing": 1.0,
    "various features describing each": 1.0,
    "features describing each example": 1.0,
    "describing each example -lrb-": 1.0,
    "each example -lrb- e.g.": 1.0,
    "example -lrb- e.g. ,": 1.0,
    "-lrb- e.g. , does": 0.05263157894736842,
    "e.g. , does the": 1.0,
    ", does the phrase": 1.0,
    "does the phrase begin": 1.0,
    "the phrase begin with": 1.0,
    "phrase begin with an": 1.0,
    "begin with an upper-case": 1.0,
    "with an upper-case letter": 1.0,
    "an upper-case letter ?": 1.0,
    "upper-case letter ? -rrb-": 1.0,
    "letter ? -rrb- .": 1.0,
    "<s> we assume there": 1.0,
    "we assume there are": 1.0,
    "assume there are known": 1.0,
    "there are known keyphrases": 1.0,
    "are known keyphrases available": 1.0,
    "known keyphrases available for": 1.0,
    "keyphrases available for a": 1.0,
    "available for a set": 1.0,
    "for a set of": 1.0,
    "a set of training": 0.07142857142857142,
    "set of training documents": 1.0,
    "of training documents .": 1.0,
    "<s> using the known": 1.0,
    "using the known keyphrases": 1.0,
    "the known keyphrases ,": 0.5,
    "known keyphrases , we": 1.0,
    "keyphrases , we can": 1.0,
    ", we can assign": 0.5,
    "we can assign positive": 1.0,
    "can assign positive or": 1.0,
    "assign positive or negative": 1.0,
    "positive or negative labels": 0.5,
    "or negative labels to": 1.0,
    "negative labels to the": 1.0,
    "labels to the examples": 1.0,
    "to the examples .": 1.0,
    "<s> then we learn": 1.0,
    "then we learn a": 1.0,
    "we learn a classifier": 1.0,
    "learn a classifier that": 1.0,
    "a classifier that can": 1.0,
    "classifier that can discriminate": 1.0,
    "that can discriminate between": 1.0,
    "can discriminate between positive": 1.0,
    "discriminate between positive and": 1.0,
    "between positive and negative": 1.0,
    "positive and negative examples": 0.5,
    "and negative examples as": 1.0,
    "negative examples as a": 1.0,
    "examples as a function": 1.0,
    "as a function of": 1.0,
    "a function of the": 1.0,
    "function of the features": 1.0,
    "of the features .": 1.0,
    "<s> some classifiers make": 1.0,
    "some classifiers make a": 1.0,
    "classifiers make a binary": 1.0,
    "make a binary classification": 1.0,
    "a binary classification for": 1.0,
    "binary classification for a": 1.0,
    "classification for a test": 1.0,
    "for a test example": 0.5,
    "a test example ,": 1.0,
    "test example , while": 1.0,
    "example , while others": 1.0,
    ", while others assign": 0.3333333333333333,
    "while others assign a": 1.0,
    "others assign a probability": 1.0,
    "assign a probability of": 1.0,
    "a probability of being": 1.0,
    "probability of being a": 1.0,
    "of being a keyphrase": 1.0,
    "being a keyphrase .": 1.0,
    "for instance , in": 0.2222222222222222,
    "instance , in the": 1.0,
    ", in the above": 0.125,
    "in the above text": 1.0,
    "the above text ,": 1.0,
    "above text , we": 1.0,
    "text , we might": 1.0,
    ", we might learn": 1.0,
    "we might learn a": 1.0,
    "might learn a rule": 1.0,
    "learn a rule that": 1.0,
    "a rule that says": 1.0,
    "rule that says phrases": 1.0,
    "that says phrases with": 1.0,
    "says phrases with initial": 1.0,
    "phrases with initial capital": 1.0,
    "with initial capital letters": 1.0,
    "initial capital letters are": 1.0,
    "capital letters are likely": 1.0,
    "letters are likely to": 1.0,
    "are likely to be": 0.6666666666666666,
    "likely to be keyphrases": 0.25,
    "to be keyphrases .": 1.0,
    "<s> after training a": 1.0,
    "after training a learner": 1.0,
    "training a learner ,": 1.0,
    "a learner , we": 1.0,
    "learner , we can": 1.0,
    ", we can select": 0.5,
    "we can select keyphrases": 1.0,
    "can select keyphrases for": 1.0,
    "select keyphrases for test": 1.0,
    "keyphrases for test documents": 1.0,
    "for test documents in": 1.0,
    "test documents in the": 1.0,
    "documents in the following": 1.0,
    "in the following manner": 0.3333333333333333,
    "the following manner .": 1.0,
    "<s> we apply the": 1.0,
    "we apply the same": 1.0,
    "apply the same example-generation": 1.0,
    "the same example-generation strategy": 1.0,
    "same example-generation strategy to": 1.0,
    "example-generation strategy to the": 1.0,
    "strategy to the test": 1.0,
    "to the test documents": 0.5,
    "the test documents ,": 1.0,
    "test documents , then": 1.0,
    "documents , then run": 1.0,
    ", then run each": 1.0,
    "then run each example": 1.0,
    "run each example through": 1.0,
    "each example through the": 1.0,
    "example through the learner": 1.0,
    "through the learner .": 1.0,
    "<s> we can determine": 0.5,
    "we can determine the": 1.0,
    "can determine the keyphrases": 1.0,
    "determine the keyphrases by": 1.0,
    "the keyphrases by looking": 1.0,
    "keyphrases by looking at": 1.0,
    "by looking at binary": 1.0,
    "looking at binary classification": 1.0,
    "at binary classification decisions": 1.0,
    "binary classification decisions or": 1.0,
    "classification decisions or probabilities": 1.0,
    "decisions or probabilities returned": 1.0,
    "or probabilities returned from": 1.0,
    "probabilities returned from our": 1.0,
    "returned from our learned": 1.0,
    "from our learned model": 1.0,
    "our learned model .": 1.0,
    "<s> if probabilities are": 1.0,
    "if probabilities are given": 1.0,
    "probabilities are given ,": 1.0,
    "are given , a": 1.0,
    "given , a threshold": 1.0,
    ", a threshold is": 1.0,
    "a threshold is used": 1.0,
    "threshold is used to": 1.0,
    "is used to select": 0.14285714285714285,
    "used to select the": 1.0,
    "to select the keyphrases": 0.5,
    "select the keyphrases .": 1.0,
    "<s> keyphrase extractors are": 1.0,
    "keyphrase extractors are generally": 1.0,
    "extractors are generally evaluated": 1.0,
    "are generally evaluated using": 1.0,
    "generally evaluated using precision": 1.0,
    "evaluated using precision and": 1.0,
    "using precision and recall": 1.0,
    "precision and recall .": 1.0,
    "<s> precision measures how": 1.0,
    "precision measures how many": 1.0,
    "measures how many of": 1.0,
    "how many of the": 1.0,
    "many of the proposed": 0.3333333333333333,
    "of the proposed keyphrases": 1.0,
    "the proposed keyphrases are": 0.5,
    "proposed keyphrases are actually": 1.0,
    "keyphrases are actually correct": 1.0,
    "are actually correct .": 1.0,
    "<s> recall measures how": 1.0,
    "recall measures how many": 1.0,
    "many of the true": 0.3333333333333333,
    "of the true keyphrases": 1.0,
    "the true keyphrases your": 1.0,
    "true keyphrases your system": 1.0,
    "keyphrases your system proposed": 1.0,
    "your system proposed .": 1.0,
    "<s> the two measures": 0.5,
    "the two measures can": 1.0,
    "two measures can be": 1.0,
    "measures can be combined": 0.5,
    "can be combined in": 1.0,
    "be combined in an": 1.0,
    "combined in an f-score": 1.0,
    "in an f-score ,": 1.0,
    "an f-score , which": 1.0,
    "f-score , which is": 1.0,
    ", which is the": 0.42857142857142855,
    "which is the harmonic": 0.3333333333333333,
    "is the harmonic mean": 1.0,
    "the harmonic mean of": 1.0,
    "harmonic mean of the": 1.0,
    "mean of the two": 1.0,
    "of the two -lrb-": 1.0,
    "the two -lrb- f": 1.0,
    "two -lrb- f =": 1.0,
    "-lrb- f = 2pr": 1.0,
    "f = 2pr \\/": 1.0,
    "= 2pr \\/ -lrb-": 1.0,
    "2pr \\/ -lrb- p": 1.0,
    "\\/ -lrb- p +": 1.0,
    "-lrb- p + r": 1.0,
    "p + r -rrb-": 1.0,
    "+ r -rrb- -rrb-": 1.0,
    "r -rrb- -rrb- .": 1.0,
    "<s> matches between the": 1.0,
    "matches between the proposed": 1.0,
    "between the proposed keyphrases": 1.0,
    "the proposed keyphrases and": 0.5,
    "proposed keyphrases and the": 1.0,
    "keyphrases and the known": 1.0,
    "and the known keyphrases": 1.0,
    "the known keyphrases can": 0.5,
    "known keyphrases can be": 1.0,
    "keyphrases can be checked": 1.0,
    "can be checked after": 1.0,
    "be checked after stemming": 1.0,
    "checked after stemming or": 1.0,
    "after stemming or applying": 1.0,
    "stemming or applying some": 1.0,
    "or applying some other": 1.0,
    "applying some other text": 1.0,
    "some other text normalization": 1.0,
    "other text normalization .": 1.0,
    "<s> design choices designing": 0.3333333333333333,
    "design choices designing a": 1.0,
    "choices designing a supervised": 1.0,
    "designing a supervised keyphrase": 1.0,
    "a supervised keyphrase extraction": 1.0,
    "supervised keyphrase extraction system": 0.5,
    "keyphrase extraction system involves": 1.0,
    "extraction system involves deciding": 1.0,
    "system involves deciding on": 1.0,
    "involves deciding on several": 1.0,
    "deciding on several choices": 1.0,
    "on several choices -lrb-": 1.0,
    "several choices -lrb- some": 1.0,
    "choices -lrb- some of": 1.0,
    "-lrb- some of these": 1.0,
    "some of these apply": 0.5,
    "of these apply to": 1.0,
    "these apply to unsupervised": 1.0,
    "apply to unsupervised ,": 1.0,
    "to unsupervised , too": 1.0,
    "unsupervised , too -rrb-": 1.0,
    ", too -rrb- :": 1.0,
    "too -rrb- : what": 1.0,
    "-rrb- : what are": 1.0,
    ": what are the": 1.0,
    "what are the examples": 0.25,
    "are the examples ?": 1.0,
    "<s> the first choice": 0.16666666666666666,
    "the first choice is": 1.0,
    "first choice is exactly": 1.0,
    "choice is exactly how": 1.0,
    "is exactly how to": 1.0,
    "exactly how to generate": 1.0,
    "how to generate examples": 1.0,
    "to generate examples .": 1.0,
    "<s> turney and others": 1.0,
    "turney and others have": 1.0,
    "and others have used": 1.0,
    "others have used all": 1.0,
    "have used all possible": 1.0,
    "used all possible unigrams": 1.0,
    "all possible unigrams ,": 1.0,
    "possible unigrams , bigrams": 1.0,
    "unigrams , bigrams ,": 1.0,
    ", bigrams , and": 1.0,
    "bigrams , and trigrams": 1.0,
    ", and trigrams without": 0.5,
    "and trigrams without intervening": 1.0,
    "trigrams without intervening punctuation": 1.0,
    "without intervening punctuation and": 1.0,
    "intervening punctuation and after": 1.0,
    "punctuation and after removing": 1.0,
    "and after removing stopwords": 1.0,
    "after removing stopwords .": 1.0,
    "<s> hulth showed that": 1.0,
    "hulth showed that you": 1.0,
    "showed that you can": 1.0,
    "that you can get": 1.0,
    "you can get some": 1.0,
    "can get some improvement": 1.0,
    "get some improvement by": 1.0,
    "some improvement by selecting": 1.0,
    "improvement by selecting examples": 1.0,
    "by selecting examples to": 1.0,
    "selecting examples to be": 1.0,
    "examples to be sequences": 1.0,
    "to be sequences of": 1.0,
    "be sequences of tokens": 1.0,
    "sequences of tokens that": 1.0,
    "of tokens that match": 1.0,
    "tokens that match certain": 1.0,
    "that match certain patterns": 1.0,
    "match certain patterns of": 1.0,
    "certain patterns of part-of-speech": 1.0,
    "patterns of part-of-speech tags": 1.0,
    "of part-of-speech tags .": 1.0,
    "<s> ideally , the": 0.5,
    "ideally , the mechanism": 1.0,
    ", the mechanism for": 1.0,
    "the mechanism for generating": 1.0,
    "mechanism for generating examples": 1.0,
    "for generating examples produces": 1.0,
    "generating examples produces all": 1.0,
    "examples produces all the": 1.0,
    "produces all the known": 1.0,
    "all the known labeled": 1.0,
    "the known labeled keyphrases": 1.0,
    "known labeled keyphrases as": 1.0,
    "labeled keyphrases as candidates": 1.0,
    "keyphrases as candidates ,": 1.0,
    "as candidates , though": 1.0,
    "candidates , though this": 1.0,
    ", though this is": 1.0,
    "though this is often": 1.0,
    "this is often not": 1.0,
    "is often not the": 0.5,
    "often not the case": 1.0,
    "not the case .": 1.0,
    "for example , if": 0.1276595744680851,
    "example , if we": 0.3333333333333333,
    ", if we use": 0.5,
    "if we use only": 1.0,
    "we use only unigrams": 1.0,
    "use only unigrams ,": 1.0,
    "only unigrams , bigrams": 1.0,
    ", and trigrams ,": 0.5,
    "and trigrams , then": 1.0,
    "trigrams , then we": 1.0,
    ", then we will": 0.5,
    "then we will never": 1.0,
    "we will never be": 1.0,
    "will never be able": 1.0,
    "be able to extract": 0.2,
    "able to extract a": 1.0,
    "to extract a known": 1.0,
    "extract a known keyphrase": 1.0,
    "a known keyphrase containing": 1.0,
    "known keyphrase containing four": 1.0,
    "keyphrase containing four words": 1.0,
    "containing four words .": 1.0,
    "<s> thus , recall": 0.09090909090909091,
    "thus , recall may": 1.0,
    ", recall may suffer": 1.0,
    "recall may suffer .": 1.0,
    "<s> however , generating": 0.03125,
    "however , generating too": 1.0,
    ", generating too many": 1.0,
    "generating too many examples": 1.0,
    "too many examples can": 1.0,
    "many examples can also": 1.0,
    "examples can also lead": 1.0,
    "can also lead to": 1.0,
    "also lead to low": 1.0,
    "lead to low precision": 1.0,
    "to low precision .": 1.0,
    "<s> what are the": 1.0,
    "what are the features": 0.25,
    "are the features ?": 1.0,
    "<s> we also need": 1.0,
    "we also need to": 1.0,
    "also need to create": 1.0,
    "need to create features": 1.0,
    "to create features that": 1.0,
    "create features that describe": 1.0,
    "features that describe the": 1.0,
    "that describe the examples": 1.0,
    "describe the examples and": 1.0,
    "the examples and are": 0.5,
    "examples and are informative": 1.0,
    "and are informative enough": 1.0,
    "are informative enough to": 1.0,
    "informative enough to allow": 1.0,
    "enough to allow a": 1.0,
    "to allow a learning": 1.0,
    "allow a learning algorithm": 1.0,
    "a learning algorithm to": 1.0,
    "learning algorithm to discriminate": 1.0,
    "algorithm to discriminate keyphrases": 1.0,
    "to discriminate keyphrases from": 1.0,
    "discriminate keyphrases from non": 1.0,
    "keyphrases from non -": 1.0,
    "from non - keyphrases": 1.0,
    "non - keyphrases .": 1.0,
    "<s> typically features involve": 1.0,
    "typically features involve various": 1.0,
    "features involve various term": 1.0,
    "involve various term frequencies": 1.0,
    "various term frequencies -lrb-": 1.0,
    "term frequencies -lrb- how": 1.0,
    "frequencies -lrb- how many": 1.0,
    "-lrb- how many times": 1.0,
    "how many times a": 1.0,
    "many times a phrase": 1.0,
    "times a phrase appears": 1.0,
    "a phrase appears in": 1.0,
    "phrase appears in the": 1.0,
    "appears in the current": 1.0,
    "in the current text": 1.0,
    "the current text or": 1.0,
    "current text or in": 1.0,
    "text or in a": 1.0,
    "or in a larger": 1.0,
    "in a larger corpus": 1.0,
    "a larger corpus -rrb-": 1.0,
    "larger corpus -rrb- ,": 0.5,
    "corpus -rrb- , the": 0.3333333333333333,
    "-rrb- , the length": 0.2,
    ", the length of": 1.0,
    "the length of the": 1.0,
    "length of the example": 0.5,
    "of the example ,": 1.0,
    "the example , relative": 1.0,
    "example , relative position": 1.0,
    ", relative position of": 1.0,
    "relative position of the": 1.0,
    "position of the first": 1.0,
    "of the first occurrence": 0.25,
    "the first occurrence ,": 1.0,
    "first occurrence , various": 1.0,
    "occurrence , various boolean": 1.0,
    ", various boolean syntactic": 1.0,
    "various boolean syntactic features": 1.0,
    "boolean syntactic features -lrb-": 1.0,
    "syntactic features -lrb- e.g.": 1.0,
    "features -lrb- e.g. ,": 1.0,
    "-lrb- e.g. , contains": 0.05263157894736842,
    "e.g. , contains all": 1.0,
    ", contains all caps": 1.0,
    "contains all caps -rrb-": 1.0,
    "all caps -rrb- ,": 1.0,
    "caps -rrb- , etc.": 1.0,
    "<s> the turney paper": 1.0,
    "the turney paper used": 0.5,
    "turney paper used about": 1.0,
    "paper used about 12": 1.0,
    "used about 12 such": 1.0,
    "about 12 such features": 1.0,
    "12 such features .": 1.0,
    "<s> hulth uses a": 1.0,
    "hulth uses a reduced": 1.0,
    "uses a reduced set": 1.0,
    "a reduced set of": 1.0,
    "reduced set of features": 1.0,
    "set of features ,": 1.0,
    "of features , which": 1.0,
    "features , which were": 1.0,
    ", which were found": 1.0,
    "which were found most": 1.0,
    "were found most successful": 1.0,
    "found most successful in": 1.0,
    "most successful in the": 1.0,
    "successful in the kea": 1.0,
    "in the kea -lrb-": 1.0,
    "the kea -lrb- keyphrase": 1.0,
    "kea -lrb- keyphrase extraction": 1.0,
    "-lrb- keyphrase extraction algorithm": 1.0,
    "keyphrase extraction algorithm -rrb-": 0.5,
    "extraction algorithm -rrb- work": 1.0,
    "algorithm -rrb- work derived": 1.0,
    "-rrb- work derived from": 1.0,
    "work derived from turney": 1.0,
    "derived from turney 's": 1.0,
    "from turney 's seminal": 1.0,
    "turney 's seminal paper": 1.0,
    "'s seminal paper .": 1.0,
    "<s> how many keyphrases": 1.0,
    "how many keyphrases to": 1.0,
    "many keyphrases to return": 1.0,
    "keyphrases to return ?": 1.0,
    "<s> in the end": 0.08333333333333333,
    "in the end ,": 1.0,
    "the end , the": 1.0,
    "end , the system": 1.0,
    ", the system will": 0.25,
    "the system will need": 1.0,
    "system will need to": 1.0,
    "will need to return": 1.0,
    "need to return a": 1.0,
    "to return a list": 1.0,
    "return a list of": 1.0,
    "a list of keyphrases": 0.16666666666666666,
    "list of keyphrases for": 1.0,
    "of keyphrases for a": 1.0,
    "keyphrases for a test": 1.0,
    "for a test document": 0.5,
    "a test document ,": 1.0,
    "test document , so": 1.0,
    "document , so we": 1.0,
    ", so we need": 1.0,
    "so we need to": 1.0,
    "we need to have": 0.6666666666666666,
    "need to have a": 0.5,
    "to have a way": 0.25,
    "have a way to": 1.0,
    "a way to limit": 0.3333333333333333,
    "way to limit the": 1.0,
    "to limit the number": 0.5,
    "limit the number .": 1.0,
    "<s> ensemble methods -lrb-": 1.0,
    "ensemble methods -lrb- i.e.": 1.0,
    "methods -lrb- i.e. ,": 1.0,
    "-lrb- i.e. , using": 0.14285714285714285,
    "i.e. , using votes": 1.0,
    ", using votes from": 1.0,
    "using votes from several": 1.0,
    "votes from several classifiers": 1.0,
    "from several classifiers -rrb-": 1.0,
    "several classifiers -rrb- have": 1.0,
    "classifiers -rrb- have been": 1.0,
    "-rrb- have been used": 1.0,
    "have been used to": 0.3333333333333333,
    "been used to produce": 1.0,
    "used to produce numeric": 1.0,
    "to produce numeric scores": 1.0,
    "produce numeric scores that": 1.0,
    "numeric scores that can": 1.0,
    "scores that can be": 1.0,
    "that can be thresholded": 0.2,
    "can be thresholded to": 1.0,
    "be thresholded to provide": 1.0,
    "thresholded to provide a": 1.0,
    "to provide a user-provided": 1.0,
    "provide a user-provided number": 1.0,
    "a user-provided number of": 1.0,
    "user-provided number of keyphrases": 1.0,
    "number of keyphrases .": 1.0,
    "this is the technique": 0.3333333333333333,
    "is the technique used": 1.0,
    "the technique used by": 1.0,
    "technique used by turney": 1.0,
    "used by turney with": 1.0,
    "by turney with c4": 1.0,
    "turney with c4 .5": 1.0,
    "with c4 .5 decision": 1.0,
    "c4 .5 decision trees": 1.0,
    ".5 decision trees .": 1.0,
    "<s> hulth used a": 1.0,
    "hulth used a single": 1.0,
    "used a single binary": 1.0,
    "a single binary classifier": 1.0,
    "single binary classifier so": 1.0,
    "binary classifier so the": 1.0,
    "classifier so the learning": 1.0,
    "so the learning algorithm": 1.0,
    "the learning algorithm implicitly": 1.0,
    "learning algorithm implicitly determines": 1.0,
    "algorithm implicitly determines the": 1.0,
    "implicitly determines the appropriate": 1.0,
    "determines the appropriate number": 1.0,
    "the appropriate number .": 1.0,
    "<s> what learning algorithm": 1.0,
    "what learning algorithm ?": 1.0,
    "<s> once examples and": 1.0,
    "once examples and features": 1.0,
    "examples and features are": 1.0,
    "and features are created": 1.0,
    "features are created ,": 1.0,
    "are created , we": 0.5,
    "created , we need": 1.0,
    ", we need a": 1.0,
    "we need a way": 1.0,
    "need a way to": 1.0,
    "a way to learn": 0.3333333333333333,
    "way to learn to": 1.0,
    "to learn to predict": 1.0,
    "learn to predict keyphrases": 1.0,
    "to predict keyphrases .": 1.0,
    "<s> virtually any supervised": 1.0,
    "virtually any supervised learning": 1.0,
    "any supervised learning algorithm": 1.0,
    "supervised learning algorithm could": 1.0,
    "learning algorithm could be": 1.0,
    "algorithm could be used": 1.0,
    "could be used ,": 0.3333333333333333,
    "be used , such": 0.5,
    "used , such as": 1.0,
    "decision trees , naive": 0.3333333333333333,
    "trees , naive bayes": 1.0,
    ", naive bayes ,": 1.0,
    "naive bayes , and": 1.0,
    "bayes , and rule": 1.0,
    ", and rule induction": 1.0,
    "and rule induction .": 1.0,
    "the case of turney": 0.2,
    "case of turney 's": 1.0,
    "of turney 's genex": 0.5,
    "turney 's genex algorithm": 1.0,
    "'s genex algorithm ,": 1.0,
    "genex algorithm , a": 1.0,
    "algorithm , a genetic": 1.0,
    ", a genetic algorithm": 1.0,
    "a genetic algorithm is": 1.0,
    "genetic algorithm is used": 1.0,
    "algorithm is used to": 1.0,
    "is used to learn": 0.14285714285714285,
    "used to learn parameters": 1.0,
    "to learn parameters for": 1.0,
    "learn parameters for a": 1.0,
    "parameters for a domain-specific": 1.0,
    "for a domain-specific keyphrase": 1.0,
    "a domain-specific keyphrase extraction": 1.0,
    "domain-specific keyphrase extraction algorithm": 1.0,
    "keyphrase extraction algorithm .": 0.5,
    "<s> the extractor follows": 1.0,
    "the extractor follows a": 1.0,
    "extractor follows a series": 1.0,
    "follows a series of": 1.0,
    "a series of heuristics": 0.14285714285714285,
    "series of heuristics to": 1.0,
    "of heuristics to identify": 1.0,
    "heuristics to identify keyphrases": 1.0,
    "to identify keyphrases .": 1.0,
    "<s> the genetic algorithm": 1.0,
    "the genetic algorithm optimizes": 1.0,
    "genetic algorithm optimizes parameters": 1.0,
    "algorithm optimizes parameters for": 1.0,
    "optimizes parameters for these": 1.0,
    "parameters for these heuristics": 1.0,
    "for these heuristics with": 1.0,
    "these heuristics with respect": 1.0,
    "heuristics with respect to": 1.0,
    "with respect to performance": 0.14285714285714285,
    "respect to performance on": 1.0,
    "to performance on training": 1.0,
    "performance on training documents": 1.0,
    "on training documents with": 1.0,
    "training documents with known": 1.0,
    "documents with known key": 0.5,
    "with known key phrases": 1.0,
    "known key phrases .": 1.0,
    "<s> unsupervised keyphrase extraction": 1.0,
    "unsupervised keyphrase extraction :": 0.3333333333333333,
    "keyphrase extraction : textrank": 1.0,
    "extraction : textrank while": 1.0,
    ": textrank while supervised": 1.0,
    "textrank while supervised methods": 1.0,
    "while supervised methods have": 1.0,
    "supervised methods have some": 1.0,
    "methods have some nice": 1.0,
    "have some nice properties": 1.0,
    "some nice properties ,": 1.0,
    "nice properties , like": 1.0,
    "properties , like being": 1.0,
    ", like being able": 1.0,
    "like being able to": 1.0,
    "being able to produce": 1.0,
    "able to produce interpretable": 0.5,
    "to produce interpretable rules": 1.0,
    "produce interpretable rules for": 1.0,
    "interpretable rules for what": 1.0,
    "rules for what features": 1.0,
    "for what features characterize": 1.0,
    "what features characterize a": 1.0,
    "features characterize a keyphrase": 1.0,
    "characterize a keyphrase ,": 1.0,
    "a keyphrase , they": 1.0,
    "keyphrase , they also": 1.0,
    ", they also require": 1.0,
    "they also require a": 1.0,
    "also require a large": 1.0,
    "require a large amount": 1.0,
    "a large amount of": 1.0,
    "large amount of training": 1.0,
    "amount of training data": 1.0,
    "of training data .": 0.3333333333333333,
    "<s> many documents with": 1.0,
    "many documents with known": 1.0,
    "documents with known keyphrases": 0.5,
    "with known keyphrases are": 1.0,
    "known keyphrases are needed": 1.0,
    "keyphrases are needed .": 1.0,
    "<s> furthermore , training": 0.16666666666666666,
    "furthermore , training on": 1.0,
    ", training on a": 1.0,
    "training on a specific": 1.0,
    "on a specific domain": 1.0,
    "a specific domain tends": 0.5,
    "specific domain tends to": 1.0,
    "domain tends to customize": 1.0,
    "tends to customize the": 1.0,
    "to customize the extraction": 1.0,
    "customize the extraction process": 1.0,
    "the extraction process to": 1.0,
    "extraction process to that": 1.0,
    "process to that domain": 1.0,
    "to that domain ,": 1.0,
    "that domain , so": 1.0,
    "domain , so the": 1.0,
    ", so the resulting": 0.25,
    "so the resulting classifier": 1.0,
    "the resulting classifier is": 1.0,
    "resulting classifier is not": 1.0,
    "classifier is not necessarily": 1.0,
    "is not necessarily portable": 1.0,
    "not necessarily portable ,": 1.0,
    "necessarily portable , as": 1.0,
    "portable , as some": 1.0,
    ", as some of": 1.0,
    "as some of turney": 1.0,
    "some of turney 's": 1.0,
    "of turney 's results": 0.5,
    "turney 's results demonstrate": 1.0,
    "'s results demonstrate .": 1.0,
    "unsupervised keyphrase extraction removes": 0.3333333333333333,
    "keyphrase extraction removes the": 1.0,
    "extraction removes the need": 1.0,
    "removes the need for": 1.0,
    "the need for training": 0.5,
    "need for training data": 1.0,
    "for training data .": 1.0,
    "<s> it approaches the": 1.0,
    "it approaches the problem": 1.0,
    "approaches the problem from": 1.0,
    "the problem from a": 1.0,
    "problem from a different": 1.0,
    "from a different angle": 1.0,
    "a different angle .": 1.0,
    "<s> instead of trying": 0.5,
    "instead of trying to": 1.0,
    "of trying to learn": 1.0,
    "trying to learn explicit": 1.0,
    "to learn explicit features": 1.0,
    "learn explicit features that": 1.0,
    "explicit features that characterize": 1.0,
    "features that characterize keyphrases": 1.0,
    "that characterize keyphrases ,": 1.0,
    "characterize keyphrases , the": 1.0,
    "keyphrases , the textrank": 1.0,
    ", the textrank algorithm": 1.0,
    "the textrank algorithm exploits": 1.0,
    "textrank algorithm exploits the": 1.0,
    "algorithm exploits the structure": 1.0,
    "exploits the structure of": 1.0,
    "the structure of the": 0.3333333333333333,
    "structure of the text": 1.0,
    "of the text itself": 0.125,
    "the text itself to": 1.0,
    "text itself to determine": 1.0,
    "itself to determine keyphrases": 1.0,
    "to determine keyphrases that": 1.0,
    "determine keyphrases that appear": 1.0,
    "keyphrases that appear ``": 1.0,
    "that appear `` central": 1.0,
    "appear `` central ''": 1.0,
    "`` central '' to": 0.5,
    "central '' to the": 1.0,
    "'' to the text": 1.0,
    "to the text in": 1.0,
    "text in the same": 0.3333333333333333,
    "in the same way": 0.25,
    "the same way that": 1.0,
    "same way that pagerank": 1.0,
    "way that pagerank selects": 1.0,
    "that pagerank selects important": 1.0,
    "pagerank selects important web": 1.0,
    "selects important web pages": 1.0,
    "important web pages .": 1.0,
    "<s> recall this is": 1.0,
    "recall this is based": 1.0,
    "this is based on": 1.0,
    "based on the notion": 0.09090909090909091,
    "on the notion of": 1.0,
    "the notion of ``": 0.6666666666666666,
    "notion of `` prestige": 0.5,
    "of `` prestige ''": 1.0,
    "`` prestige '' or": 1.0,
    "prestige '' or ``": 1.0,
    "'' or `` recommendation": 0.25,
    "or `` recommendation ''": 1.0,
    "`` recommendation '' from": 0.5,
    "recommendation '' from social": 1.0,
    "'' from social networks": 1.0,
    "from social networks .": 1.0,
    "<s> in this way": 0.2,
    "in this way ,": 1.0,
    "this way , textrank": 1.0,
    "way , textrank does": 1.0,
    ", textrank does not": 1.0,
    "textrank does not rely": 1.0,
    "does not rely on": 1.0,
    "not rely on any": 0.5,
    "rely on any previous": 1.0,
    "on any previous training": 1.0,
    "any previous training data": 1.0,
    "previous training data at": 1.0,
    "training data at all": 1.0,
    "data at all ,": 1.0,
    "at all , but": 0.5,
    "all , but rather": 1.0,
    ", but rather can": 0.5,
    "but rather can be": 1.0,
    "rather can be run": 1.0,
    "can be run on": 1.0,
    "be run on any": 1.0,
    "run on any arbitrary": 1.0,
    "on any arbitrary piece": 1.0,
    "any arbitrary piece of": 1.0,
    "arbitrary piece of text": 1.0,
    "text , and it": 0.3333333333333333,
    ", and it can": 0.25,
    "and it can produce": 1.0,
    "it can produce output": 1.0,
    "can produce output simply": 1.0,
    "produce output simply based": 1.0,
    "output simply based on": 1.0,
    "simply based on the": 1.0,
    "based on the text": 0.09090909090909091,
    "on the text 's": 1.0,
    "the text 's intrinsic": 1.0,
    "text 's intrinsic properties": 1.0,
    "'s intrinsic properties .": 1.0,
    "<s> thus the algorithm": 1.0,
    "thus the algorithm is": 1.0,
    "the algorithm is easily": 0.5,
    "algorithm is easily portable": 1.0,
    "is easily portable to": 1.0,
    "easily portable to new": 1.0,
    "portable to new domains": 1.0,
    "to new domains and": 1.0,
    "new domains and languages": 1.0,
    "domains and languages .": 1.0,
    "<s> textrank is a": 1.0,
    "textrank is a general": 1.0,
    "is a general purpose": 0.5,
    "a general purpose graph-based": 1.0,
    "general purpose graph-based ranking": 1.0,
    "purpose graph-based ranking algorithm": 1.0,
    "graph-based ranking algorithm for": 0.5,
    "ranking algorithm for nlp": 1.0,
    "algorithm for nlp .": 1.0,
    "<s> essentially , it": 1.0,
    "essentially , it runs": 1.0,
    ", it runs pagerank": 1.0,
    "it runs pagerank on": 1.0,
    "runs pagerank on a": 1.0,
    "pagerank on a graph": 1.0,
    "on a graph specially": 1.0,
    "a graph specially designed": 1.0,
    "graph specially designed for": 1.0,
    "specially designed for a": 1.0,
    "designed for a particular": 1.0,
    "for a particular nlp": 1.0,
    "a particular nlp task": 1.0,
    "particular nlp task .": 1.0,
    "<s> for keyphrase extraction": 1.0,
    "for keyphrase extraction ,": 0.5,
    "keyphrase extraction , it": 0.25,
    "extraction , it builds": 1.0,
    ", it builds a": 1.0,
    "it builds a graph": 1.0,
    "builds a graph using": 1.0,
    "a graph using some": 1.0,
    "graph using some set": 1.0,
    "using some set of": 1.0,
    "some set of text": 1.0,
    "set of text units": 1.0,
    "of text units as": 1.0,
    "text units as vertices": 1.0,
    "units as vertices .": 1.0,
    "<s> edges are based": 0.5,
    "edges are based on": 1.0,
    "are based on some": 0.6,
    "based on some measure": 0.25,
    "on some measure of": 1.0,
    "some measure of semantic": 1.0,
    "measure of semantic or": 1.0,
    "of semantic or lexical": 1.0,
    "semantic or lexical similarity": 1.0,
    "or lexical similarity between": 1.0,
    "lexical similarity between the": 1.0,
    "similarity between the text": 1.0,
    "between the text unit": 1.0,
    "the text unit vertices": 1.0,
    "text unit vertices .": 1.0,
    "<s> unlike pagerank ,": 1.0,
    "unlike pagerank , the": 1.0,
    "pagerank , the edges": 1.0,
    ", the edges are": 1.0,
    "the edges are typically": 1.0,
    "edges are typically undirected": 1.0,
    "are typically undirected and": 1.0,
    "typically undirected and can": 1.0,
    "undirected and can be": 1.0,
    "and can be weighted": 0.2,
    "can be weighted to": 1.0,
    "be weighted to reflect": 1.0,
    "weighted to reflect a": 1.0,
    "to reflect a degree": 1.0,
    "reflect a degree of": 1.0,
    "a degree of similarity": 1.0,
    "degree of similarity .": 1.0,
    "<s> once the graph": 1.0,
    "once the graph is": 1.0,
    "the graph is constructed": 0.5,
    "graph is constructed ,": 0.5,
    "is constructed , it": 1.0,
    "constructed , it is": 1.0,
    ", it is used": 0.07692307692307693,
    "it is used to": 1.0,
    "is used to form": 0.14285714285714285,
    "used to form a": 1.0,
    "to form a stochastic": 1.0,
    "form a stochastic matrix": 1.0,
    "a stochastic matrix ,": 1.0,
    "stochastic matrix , combined": 1.0,
    "matrix , combined with": 1.0,
    ", combined with a": 1.0,
    "combined with a damping": 1.0,
    "with a damping factor": 1.0,
    "a damping factor -lrb-": 1.0,
    "damping factor -lrb- as": 1.0,
    "factor -lrb- as in": 1.0,
    "-lrb- as in the": 0.75,
    "as in the ``": 0.25,
    "in the `` random": 1.0,
    "the `` random surfer": 1.0,
    "`` random surfer model": 1.0,
    "random surfer model ''": 1.0,
    "surfer model '' -rrb-": 1.0,
    "model '' -rrb- ,": 1.0,
    "'' -rrb- , and": 0.5,
    "-rrb- , and the": 0.09090909090909091,
    ", and the ranking": 0.1,
    "and the ranking over": 1.0,
    "the ranking over vertices": 1.0,
    "ranking over vertices is": 1.0,
    "over vertices is obtained": 1.0,
    "vertices is obtained by": 1.0,
    "is obtained by finding": 1.0,
    "obtained by finding the": 1.0,
    "by finding the eigenvector": 1.0,
    "finding the eigenvector corresponding": 1.0,
    "the eigenvector corresponding to": 1.0,
    "eigenvector corresponding to eigenvalue": 1.0,
    "corresponding to eigenvalue 1": 1.0,
    "to eigenvalue 1 -lrb-": 1.0,
    "eigenvalue 1 -lrb- i.e.": 1.0,
    "1 -lrb- i.e. ,": 1.0,
    "-lrb- i.e. , the": 0.42857142857142855,
    "i.e. , the stationary": 0.3333333333333333,
    ", the stationary distribution": 1.0,
    "the stationary distribution of": 1.0,
    "stationary distribution of the": 1.0,
    "distribution of the random": 1.0,
    "of the random walk": 1.0,
    "the random walk on": 1.0,
    "random walk on the": 0.5,
    "walk on the graph": 1.0,
    "on the graph -rrb-": 0.5,
    "the graph -rrb- .": 1.0,
    "<s> design choices what": 0.6666666666666666,
    "design choices what should": 0.5,
    "choices what should vertices": 1.0,
    "what should vertices be": 1.0,
    "should vertices be ?": 1.0,
    "<s> the vertices should": 1.0,
    "the vertices should correspond": 1.0,
    "vertices should correspond to": 1.0,
    "should correspond to what": 1.0,
    "correspond to what we": 1.0,
    "to what we want": 1.0,
    "what we want to": 1.0,
    "we want to rank": 0.5,
    "want to rank .": 1.0,
    "<s> potentially , we": 1.0,
    "potentially , we could": 1.0,
    ", we could do": 1.0,
    "we could do something": 1.0,
    "could do something similar": 1.0,
    "do something similar to": 1.0,
    "something similar to the": 1.0,
    "similar to the supervised": 0.2,
    "to the supervised methods": 1.0,
    "the supervised methods and": 1.0,
    "supervised methods and create": 1.0,
    "methods and create a": 1.0,
    "and create a vertex": 0.5,
    "create a vertex for": 1.0,
    "a vertex for each": 1.0,
    "vertex for each unigram": 0.5,
    ", bigram , trigram": 0.6666666666666666,
    "bigram , trigram ,": 1.0,
    ", trigram , etc.": 0.5,
    "trigram , etc. .": 1.0,
    "<s> however , to": 0.03125,
    "however , to keep": 1.0,
    ", to keep the": 1.0,
    "to keep the graph": 1.0,
    "keep the graph small": 1.0,
    "the graph small ,": 1.0,
    "graph small , the": 1.0,
    "small , the authors": 1.0,
    ", the authors decide": 1.0,
    "the authors decide to": 1.0,
    "authors decide to rank": 1.0,
    "decide to rank individual": 1.0,
    "to rank individual unigrams": 1.0,
    "rank individual unigrams in": 1.0,
    "individual unigrams in a": 1.0,
    "unigrams in a first": 1.0,
    "in a first step": 1.0,
    "a first step ,": 1.0,
    "first step , and": 1.0,
    "step , and then": 1.0,
    ", and then include": 0.25,
    "and then include a": 1.0,
    "then include a second": 1.0,
    "include a second step": 1.0,
    "a second step that": 1.0,
    "second step that merges": 1.0,
    "step that merges highly": 1.0,
    "that merges highly ranked": 1.0,
    "merges highly ranked adjacent": 1.0,
    "highly ranked adjacent unigrams": 1.0,
    "ranked adjacent unigrams to": 1.0,
    "adjacent unigrams to form": 1.0,
    "unigrams to form multi-word": 1.0,
    "to form multi-word phrases": 1.0,
    "form multi-word phrases .": 1.0,
    "<s> this has a": 1.0,
    "this has a nice": 1.0,
    "has a nice side": 1.0,
    "a nice side effect": 1.0,
    "nice side effect of": 1.0,
    "side effect of allowing": 1.0,
    "effect of allowing us": 1.0,
    "of allowing us to": 1.0,
    "allowing us to produce": 1.0,
    "us to produce keyphrases": 1.0,
    "to produce keyphrases of": 1.0,
    "produce keyphrases of arbitrary": 1.0,
    "keyphrases of arbitrary length": 1.0,
    "of arbitrary length .": 1.0,
    ", if we rank": 0.5,
    "if we rank unigrams": 1.0,
    "we rank unigrams and": 1.0,
    "rank unigrams and find": 1.0,
    "unigrams and find that": 1.0,
    "and find that ``": 1.0,
    "find that `` advanced": 1.0,
    "that `` advanced ''": 1.0,
    "`` advanced '' ,": 1.0,
    "advanced '' , ``": 1.0,
    "'' , `` natural": 0.09090909090909091,
    ", `` natural ''": 1.0,
    "`` natural '' ,": 0.3333333333333333,
    "natural '' , ``": 1.0,
    "'' , `` language": 0.09090909090909091,
    ", `` language ''": 1.0,
    "`` language '' ,": 0.5,
    "language '' , and": 1.0,
    ", and `` processing": 0.2,
    "and `` processing ''": 1.0,
    "`` processing '' all": 0.5,
    "processing '' all get": 1.0,
    "'' all get high": 1.0,
    "all get high ranks": 1.0,
    "get high ranks ,": 1.0,
    "high ranks , then": 1.0,
    "ranks , then we": 1.0,
    ", then we would": 0.5,
    "then we would look": 1.0,
    "we would look at": 1.0,
    "would look at the": 0.5,
    "look at the original": 1.0,
    "at the original text": 1.0,
    "the original text and": 0.16666666666666666,
    "original text and see": 1.0,
    "text and see that": 1.0,
    "and see that these": 1.0,
    "see that these words": 1.0,
    "that these words appear": 1.0,
    "these words appear consecutively": 1.0,
    "words appear consecutively and": 1.0,
    "appear consecutively and create": 1.0,
    "consecutively and create a": 1.0,
    "and create a final": 0.5,
    "create a final keyphrase": 1.0,
    "a final keyphrase using": 1.0,
    "final keyphrase using all": 1.0,
    "keyphrase using all four": 1.0,
    "using all four together": 1.0,
    "all four together .": 1.0,
    "<s> note that the": 0.14285714285714285,
    "note that the unigrams": 1.0,
    "that the unigrams placed": 1.0,
    "the unigrams placed in": 1.0,
    "unigrams placed in the": 1.0,
    "placed in the graph": 0.5,
    "in the graph can": 0.5,
    "the graph can be": 1.0,
    "graph can be filtered": 1.0,
    "can be filtered by": 0.3333333333333333,
    "be filtered by part": 1.0,
    "filtered by part of": 1.0,
    "by part of speech": 1.0,
    "part of speech .": 0.07142857142857142,
    "<s> the authors found": 0.3333333333333333,
    "the authors found that": 1.0,
    "authors found that adjectives": 1.0,
    "found that adjectives and": 1.0,
    "that adjectives and nouns": 1.0,
    "adjectives and nouns were": 1.0,
    "and nouns were the": 1.0,
    "nouns were the best": 1.0,
    "were the best to": 1.0,
    "the best to include": 1.0,
    "best to include .": 1.0,
    "<s> thus , some": 0.09090909090909091,
    "thus , some linguistic": 1.0,
    ", some linguistic knowledge": 1.0,
    "some linguistic knowledge comes": 1.0,
    "linguistic knowledge comes into": 1.0,
    "knowledge comes into play": 1.0,
    "comes into play in": 1.0,
    "into play in this": 1.0,
    "play in this step": 1.0,
    "in this step .": 1.0,
    "<s> how should we": 1.0,
    "how should we create": 1.0,
    "should we create edges": 1.0,
    "we create edges ?": 1.0,
    "<s> edges are created": 0.5,
    "edges are created based": 1.0,
    "are created based on": 1.0,
    "created based on word": 1.0,
    "based on word co-occurrence": 1.0,
    "on word co-occurrence in": 1.0,
    "word co-occurrence in this": 1.0,
    "co-occurrence in this application": 1.0,
    "in this application of": 1.0,
    "this application of textrank": 1.0,
    "application of textrank .": 1.0,
    "<s> two vertices are": 1.0,
    "two vertices are connected": 1.0,
    "vertices are connected by": 1.0,
    "are connected by an": 1.0,
    "connected by an edge": 1.0,
    "by an edge if": 1.0,
    "an edge if the": 1.0,
    "edge if the unigrams": 1.0,
    "if the unigrams appear": 1.0,
    "the unigrams appear within": 1.0,
    "unigrams appear within a": 1.0,
    "appear within a window": 1.0,
    "within a window of": 1.0,
    "a window of size": 1.0,
    "window of size n": 1.0,
    "of size n in": 1.0,
    "size n in the": 1.0,
    "n in the original": 1.0,
    "<s> n is typically": 1.0,
    "n is typically around": 1.0,
    "is typically around 2": 1.0,
    "typically around 2 --": 1.0,
    "around 2 -- 10": 1.0,
    "2 -- 10 .": 1.0,
    "<s> thus , ``": 0.09090909090909091,
    "thus , `` natural": 1.0,
    "`` natural '' and": 0.6666666666666666,
    "natural '' and ``": 1.0,
    "'' and `` language": 0.1111111111111111,
    "and `` language ''": 1.0,
    "`` language '' might": 0.5,
    "language '' might be": 1.0,
    "'' might be linked": 1.0,
    "might be linked in": 1.0,
    "be linked in a": 1.0,
    "linked in a text": 1.0,
    "in a text about": 0.5,
    "a text about nlp": 0.5,
    "text about nlp .": 1.0,
    "<s> `` natural ''": 1.0,
    "'' and `` processing": 0.1111111111111111,
    "`` processing '' would": 0.5,
    "processing '' would also": 1.0,
    "'' would also be": 1.0,
    "would also be linked": 1.0,
    "also be linked because": 1.0,
    "be linked because they": 1.0,
    "linked because they would": 1.0,
    "because they would both": 1.0,
    "they would both appear": 1.0,
    "would both appear in": 1.0,
    "both appear in the": 1.0,
    "in the same string": 0.25,
    "the same string of": 1.0,
    "same string of n": 1.0,
    "string of n words": 1.0,
    "of n words .": 1.0,
    "<s> these edges build": 1.0,
    "these edges build on": 1.0,
    "edges build on the": 1.0,
    "build on the notion": 1.0,
    "notion of `` text": 0.5,
    "of `` text cohesion": 1.0,
    "`` text cohesion ''": 1.0,
    "text cohesion '' and": 1.0,
    "cohesion '' and the": 1.0,
    "'' and the idea": 1.0,
    "and the idea that": 1.0,
    "the idea that words": 0.5,
    "idea that words that": 1.0,
    "that words that appear": 1.0,
    "words that appear near": 1.0,
    "that appear near each": 1.0,
    "appear near each other": 1.0,
    "near each other are": 1.0,
    "each other are likely": 1.0,
    "other are likely related": 1.0,
    "are likely related in": 1.0,
    "likely related in a": 1.0,
    "related in a meaningful": 1.0,
    "in a meaningful way": 1.0,
    "a meaningful way and": 1.0,
    "meaningful way and ``": 1.0,
    "way and `` recommend": 1.0,
    "and `` recommend ''": 1.0,
    "`` recommend '' each": 0.5,
    "recommend '' each other": 1.0,
    "'' each other to": 1.0,
    "each other to the": 1.0,
    "other to the reader": 1.0,
    "to the reader .": 1.0,
    "<s> how are the": 0.5,
    "how are the final": 1.0,
    "are the final keyphrases": 1.0,
    "the final keyphrases formed": 1.0,
    "final keyphrases formed ?": 1.0,
    "<s> since this method": 1.0,
    "since this method simply": 1.0,
    "this method simply ranks": 1.0,
    "method simply ranks the": 1.0,
    "simply ranks the individual": 1.0,
    "ranks the individual vertices": 1.0,
    "the individual vertices ,": 1.0,
    "individual vertices , we": 1.0,
    "vertices , we need": 1.0,
    "a way to threshold": 0.3333333333333333,
    "way to threshold or": 1.0,
    "to threshold or produce": 1.0,
    "threshold or produce a": 1.0,
    "or produce a limited": 1.0,
    "produce a limited number": 1.0,
    "a limited number of": 1.0,
    "limited number of keyphrases": 0.5,
    "<s> the technique chosen": 1.0,
    "the technique chosen is": 1.0,
    "technique chosen is to": 1.0,
    "chosen is to set": 1.0,
    "is to set a": 1.0,
    "to set a count": 0.5,
    "set a count t": 1.0,
    "a count t to": 1.0,
    "count t to be": 1.0,
    "t to be a": 1.0,
    "to be a user-specified": 0.2,
    "be a user-specified fraction": 1.0,
    "a user-specified fraction of": 1.0,
    "user-specified fraction of the": 1.0,
    "fraction of the total": 1.0,
    "of the total number": 1.0,
    "the total number of": 1.0,
    "total number of vertices": 1.0,
    "number of vertices in": 1.0,
    "of vertices in the": 1.0,
    "vertices in the graph": 1.0,
    "in the graph .": 0.5,
    "<s> then the top": 0.5,
    "then the top t": 1.0,
    "the top t vertices\\/unigrams": 0.5,
    "top t vertices\\/unigrams are": 1.0,
    "t vertices\\/unigrams are selected": 1.0,
    "vertices\\/unigrams are selected based": 1.0,
    "are selected based on": 1.0,
    "selected based on their": 1.0,
    "based on their stationary": 1.0,
    "on their stationary probabilities": 1.0,
    "their stationary probabilities .": 1.0,
    "<s> a post -": 1.0,
    "a post - processing": 1.0,
    "post - processing step": 1.0,
    "- processing step is": 1.0,
    "processing step is then": 1.0,
    "step is then applied": 1.0,
    "is then applied to": 1.0,
    "then applied to merge": 1.0,
    "applied to merge adjacent": 1.0,
    "to merge adjacent instances": 1.0,
    "merge adjacent instances of": 1.0,
    "adjacent instances of these": 1.0,
    "instances of these t": 1.0,
    "of these t unigrams": 1.0,
    "these t unigrams .": 1.0,
    "a result , potentially": 0.5,
    "result , potentially more": 1.0,
    ", potentially more or": 1.0,
    "potentially more or less": 1.0,
    "more or less than": 0.3333333333333333,
    "or less than t": 1.0,
    "less than t final": 1.0,
    "than t final keyphrases": 1.0,
    "t final keyphrases will": 1.0,
    "final keyphrases will be": 1.0,
    "keyphrases will be produced": 1.0,
    "will be produced ,": 1.0,
    "be produced , but": 1.0,
    "produced , but the": 1.0,
    ", but the number": 0.5,
    "but the number should": 1.0,
    "the number should be": 1.0,
    "number should be roughly": 1.0,
    "should be roughly proportional": 1.0,
    "be roughly proportional to": 1.0,
    "roughly proportional to the": 1.0,
    "proportional to the length": 1.0,
    "to the length of": 1.0,
    "length of the original": 0.5,
    "<s> why it works": 1.0,
    "why it works it": 1.0,
    "it works it is": 1.0,
    "works it is not": 1.0,
    "it is not initially": 1.0,
    "is not initially clear": 1.0,
    "not initially clear why": 1.0,
    "initially clear why applying": 1.0,
    "clear why applying pagerank": 1.0,
    "why applying pagerank to": 1.0,
    "applying pagerank to a": 0.5,
    "pagerank to a co-occurrence": 1.0,
    "to a co-occurrence graph": 1.0,
    "a co-occurrence graph would": 1.0,
    "co-occurrence graph would produce": 1.0,
    "graph would produce useful": 1.0,
    "would produce useful keyphrases": 1.0,
    "produce useful keyphrases .": 1.0,
    "<s> one way to": 1.0,
    "one way to think": 0.5,
    "way to think about": 1.0,
    "to think about it": 1.0,
    "think about it is": 1.0,
    "about it is the": 1.0,
    "it is the following": 0.3333333333333333,
    "<s> a word that": 1.0,
    "a word that appears": 1.0,
    "word that appears multiple": 1.0,
    "that appears multiple times": 1.0,
    "appears multiple times throughout": 1.0,
    "multiple times throughout a": 1.0,
    "times throughout a text": 1.0,
    "throughout a text may": 1.0,
    "a text may have": 1.0,
    "text may have many": 1.0,
    "may have many different": 1.0,
    "have many different co-occurring": 1.0,
    "many different co-occurring neighbors": 1.0,
    "different co-occurring neighbors .": 1.0,
    ", in a text": 0.3333333333333333,
    "a text about machine": 0.5,
    "text about machine learning": 1.0,
    "about machine learning ,": 1.0,
    "machine learning , the": 0.3333333333333333,
    "learning , the unigram": 1.0,
    ", the unigram ``": 1.0,
    "the unigram `` learning": 1.0,
    "unigram `` learning ''": 1.0,
    "`` learning '' might": 0.25,
    "learning '' might co-occur": 1.0,
    "'' might co-occur with": 1.0,
    "might co-occur with ``": 1.0,
    "co-occur with `` machine": 1.0,
    "with `` machine ''": 1.0,
    "`` machine '' ,": 1.0,
    "machine '' , supervised": 1.0,
    "'' , supervised ''": 1.0,
    ", supervised '' ,": 1.0,
    "supervised '' , ``": 1.0,
    "'' , `` un-supervised": 0.09090909090909091,
    ", `` un-supervised ''": 1.0,
    "`` un-supervised '' ,": 1.0,
    "un-supervised '' , and": 1.0,
    ", and `` semi-supervised": 0.2,
    "and `` semi-supervised ''": 1.0,
    "`` semi-supervised '' in": 1.0,
    "semi-supervised '' in four": 1.0,
    "'' in four different": 1.0,
    "in four different sentences": 0.5,
    "four different sentences .": 1.0,
    "<s> thus , the": 0.09090909090909091,
    "thus , the ``": 1.0,
    ", the `` learning": 1.0,
    "the `` learning ''": 1.0,
    "`` learning '' vertex": 0.25,
    "learning '' vertex would": 1.0,
    "'' vertex would be": 1.0,
    "vertex would be a": 1.0,
    "would be a central": 0.3333333333333333,
    "be a central ``": 1.0,
    "a central `` hub": 1.0,
    "central `` hub ''": 1.0,
    "`` hub '' that": 1.0,
    "hub '' that connects": 1.0,
    "'' that connects to": 1.0,
    "that connects to these": 1.0,
    "connects to these other": 1.0,
    "to these other modifying": 1.0,
    "these other modifying words": 1.0,
    "other modifying words .": 1.0,
    "<s> running pagerank\\/textrank on": 1.0,
    "running pagerank\\/textrank on the": 1.0,
    "pagerank\\/textrank on the graph": 1.0,
    "on the graph is": 0.5,
    "the graph is likely": 0.5,
    "graph is likely to": 1.0,
    "is likely to rank": 0.3333333333333333,
    "likely to rank ``": 1.0,
    "to rank `` learning": 1.0,
    "rank `` learning ''": 1.0,
    "`` learning '' highly": 0.25,
    "learning '' highly .": 1.0,
    "<s> similarly , if": 1.0,
    "similarly , if the": 1.0,
    ", if the text": 0.5,
    "if the text contains": 1.0,
    "the text contains the": 1.0,
    "text contains the phrase": 1.0,
    "contains the phrase ``": 1.0,
    "the phrase `` supervised": 1.0,
    "phrase `` supervised classification": 1.0,
    "`` supervised classification ''": 1.0,
    "supervised classification '' ,": 0.5,
    "classification '' , then": 1.0,
    "'' , then there": 1.0,
    ", then there would": 1.0,
    "then there would be": 1.0,
    "there would be an": 1.0,
    "would be an edge": 1.0,
    "be an edge between": 1.0,
    "an edge between ``": 1.0,
    "edge between `` supervised": 1.0,
    "between `` supervised ''": 1.0,
    "`` supervised '' and": 0.5,
    "supervised '' and ``": 1.0,
    "'' and `` classification": 0.1111111111111111,
    "and `` classification ''": 1.0,
    "`` classification '' .": 0.6666666666666666,
    "<s> if `` classification": 1.0,
    "if `` classification ''": 1.0,
    "`` classification '' appears": 0.3333333333333333,
    "classification '' appears several": 1.0,
    "'' appears several other": 1.0,
    "appears several other places": 1.0,
    "several other places and": 1.0,
    "other places and thus": 1.0,
    "places and thus has": 1.0,
    "and thus has many": 1.0,
    "thus has many neighbors": 1.0,
    "has many neighbors ,": 1.0,
    "many neighbors , it": 1.0,
    "neighbors , it is": 1.0,
    ", it is importance": 0.07692307692307693,
    "it is importance would": 1.0,
    "is importance would contribute": 1.0,
    "importance would contribute to": 1.0,
    "would contribute to the": 1.0,
    "contribute to the importance": 1.0,
    "to the importance of": 1.0,
    "the importance of ``": 0.3333333333333333,
    "importance of `` supervised": 1.0,
    "of `` supervised ''": 1.0,
    "`` supervised '' .": 0.5,
    "<s> if it ends": 1.0,
    "if it ends up": 1.0,
    "it ends up with": 1.0,
    "ends up with a": 1.0,
    "up with a high": 1.0,
    "with a high rank": 0.5,
    "a high rank ,": 1.0,
    "high rank , it": 1.0,
    "rank , it will": 1.0,
    ", it will be": 0.5,
    "it will be selected": 1.0,
    "will be selected as": 1.0,
    "be selected as one": 1.0,
    "selected as one of": 1.0,
    "as one of the": 1.0,
    "one of the top": 0.08333333333333333,
    "of the top t": 1.0,
    "the top t unigrams": 0.5,
    "top t unigrams ,": 1.0,
    "t unigrams , along": 1.0,
    "unigrams , along with": 1.0,
    ", along with ``": 1.0,
    "along with `` learning": 1.0,
    "with `` learning ''": 1.0,
    "`` learning '' and": 0.25,
    "learning '' and probably": 0.5,
    "'' and probably ``": 1.0,
    "and probably `` classification": 1.0,
    "probably `` classification ''": 1.0,
    "<s> in the final": 0.08333333333333333,
    "in the final post-processing": 1.0,
    "the final post-processing step": 1.0,
    "final post-processing step ,": 1.0,
    "post-processing step , we": 1.0,
    "step , we would": 1.0,
    ", we would then": 0.5,
    "we would then end": 1.0,
    "would then end up": 1.0,
    "then end up with": 1.0,
    "end up with keyphrases": 1.0,
    "up with keyphrases ``": 1.0,
    "with keyphrases `` supervised": 1.0,
    "keyphrases `` supervised learning": 1.0,
    "`` supervised learning ''": 1.0,
    "supervised learning '' and": 1.0,
    "learning '' and ``": 0.5,
    "'' and `` supervised": 0.1111111111111111,
    "and `` supervised classification": 1.0,
    "supervised classification '' .": 0.5,
    "<s> in short ,": 1.0,
    "in short , the": 1.0,
    "short , the co-occurrence": 1.0,
    ", the co-occurrence graph": 1.0,
    "the co-occurrence graph will": 1.0,
    "co-occurrence graph will contain": 1.0,
    "graph will contain densely": 1.0,
    "will contain densely connected": 1.0,
    "contain densely connected regions": 1.0,
    "densely connected regions for": 1.0,
    "connected regions for terms": 1.0,
    "regions for terms that": 1.0,
    "for terms that appear": 1.0,
    "terms that appear often": 1.0,
    "that appear often and": 1.0,
    "appear often and in": 1.0,
    "often and in different": 1.0,
    "and in different contexts": 1.0,
    "in different contexts .": 1.0,
    "<s> a random walk": 1.0,
    "a random walk on": 1.0,
    "random walk on this": 0.5,
    "walk on this graph": 1.0,
    "on this graph will": 1.0,
    "this graph will have": 1.0,
    "graph will have a": 1.0,
    "will have a stationary": 0.5,
    "have a stationary distribution": 1.0,
    "a stationary distribution that": 1.0,
    "stationary distribution that assigns": 1.0,
    "distribution that assigns large": 1.0,
    "that assigns large probabilities": 1.0,
    "assigns large probabilities to": 1.0,
    "large probabilities to the": 1.0,
    "probabilities to the terms": 1.0,
    "to the terms in": 1.0,
    "the terms in the": 1.0,
    "terms in the centers": 1.0,
    "in the centers of": 1.0,
    "the centers of the": 1.0,
    "centers of the clusters": 1.0,
    "of the clusters .": 1.0,
    "<s> this is similar": 0.07142857142857142,
    "this is similar to": 1.0,
    "is similar to densely": 0.5,
    "similar to densely connected": 1.0,
    "to densely connected web": 1.0,
    "densely connected web pages": 1.0,
    "connected web pages getting": 1.0,
    "web pages getting ranked": 1.0,
    "pages getting ranked highly": 1.0,
    "getting ranked highly by": 1.0,
    "ranked highly by pagerank": 1.0,
    "highly by pagerank .": 1.0,
    "<s> document summarization like": 1.0,
    "document summarization like keyphrase": 1.0,
    "summarization like keyphrase extraction": 1.0,
    "like keyphrase extraction ,": 1.0,
    "keyphrase extraction , document": 0.25,
    "extraction , document summarization": 1.0,
    ", document summarization hopes": 1.0,
    "document summarization hopes to": 1.0,
    "summarization hopes to identify": 1.0,
    "hopes to identify the": 1.0,
    "to identify the essence": 0.5,
    "identify the essence of": 1.0,
    "the essence of a": 0.5,
    "essence of a text": 1.0,
    "of a text .": 0.25,
    "<s> the only real": 0.5,
    "the only real difference": 1.0,
    "only real difference is": 1.0,
    "real difference is that": 1.0,
    "difference is that now": 1.0,
    "is that now we": 1.0,
    "that now we are": 1.0,
    "now we are dealing": 1.0,
    "we are dealing with": 1.0,
    "are dealing with larger": 1.0,
    "dealing with larger text": 1.0,
    "with larger text units": 1.0,
    "larger text units --": 1.0,
    "text units -- whole": 1.0,
    "units -- whole sentences": 1.0,
    "-- whole sentences instead": 1.0,
    "whole sentences instead of": 1.0,
    "sentences instead of words": 1.0,
    "instead of words and": 1.0,
    "of words and phrases": 0.6666666666666666,
    "words and phrases .": 0.5,
    "<s> while some work": 1.0,
    "while some work has": 1.0,
    "some work has been": 1.0,
    "work has been done": 1.0,
    "has been done in": 1.0,
    "been done in abstractive": 0.5,
    "done in abstractive summarization": 1.0,
    "in abstractive summarization -lrb-": 1.0,
    "abstractive summarization -lrb- creating": 1.0,
    "summarization -lrb- creating an": 1.0,
    "-lrb- creating an abstract": 1.0,
    "creating an abstract synopsis": 1.0,
    "an abstract synopsis like": 1.0,
    "abstract synopsis like that": 1.0,
    "synopsis like that of": 1.0,
    "like that of a": 1.0,
    "that of a human": 0.5,
    "of a human -rrb-": 1.0,
    "a human -rrb- ,": 0.5,
    "human -rrb- , the": 1.0,
    "-rrb- , the majority": 0.2,
    ", the majority of": 1.0,
    "the majority of summarization": 1.0,
    "majority of summarization systems": 1.0,
    "of summarization systems are": 1.0,
    "summarization systems are extractive": 0.3333333333333333,
    "systems are extractive -lrb-": 1.0,
    "are extractive -lrb- selecting": 1.0,
    "extractive -lrb- selecting a": 1.0,
    "-lrb- selecting a subset": 1.0,
    "a subset of sentences": 0.3333333333333333,
    "subset of sentences to": 1.0,
    "of sentences to place": 0.5,
    "sentences to place in": 1.0,
    "to place in a": 0.5,
    "place in a summary": 1.0,
    "in a summary -rrb-": 0.5,
    "a summary -rrb- .": 1.0,
    "<s> before getting into": 1.0,
    "before getting into the": 1.0,
    "getting into the details": 1.0,
    "into the details of": 1.0,
    "the details of some": 1.0,
    "details of some summarization": 1.0,
    "of some summarization methods": 1.0,
    "some summarization methods ,": 1.0,
    "summarization methods , we": 1.0,
    "methods , we will": 1.0,
    ", we will mention": 1.0,
    "we will mention how": 1.0,
    "will mention how summarization": 1.0,
    "mention how summarization systems": 1.0,
    "how summarization systems are": 1.0,
    "summarization systems are typically": 0.3333333333333333,
    "systems are typically evaluated": 1.0,
    "are typically evaluated .": 1.0,
    "<s> the most common": 0.3333333333333333,
    "the most common way": 0.3333333333333333,
    "most common way is": 0.5,
    "common way is using": 1.0,
    "way is using the": 1.0,
    "is using the so-called": 1.0,
    "using the so-called rouge": 1.0,
    "the so-called rouge -lrb-": 1.0,
    "so-called rouge -lrb- recall-oriented": 1.0,
    "rouge -lrb- recall-oriented understudy": 1.0,
    "-lrb- recall-oriented understudy for": 1.0,
    "recall-oriented understudy for gisting": 1.0,
    "understudy for gisting evaluation": 1.0,
    "for gisting evaluation -rrb-": 1.0,
    "gisting evaluation -rrb- measure": 0.5,
    "evaluation -rrb- measure -lrb-": 1.0,
    "-rrb- measure -lrb- http:\\/\\/haydn.isi.edu\\/rouge\\/": 1.0,
    "measure -lrb- http:\\/\\/haydn.isi.edu\\/rouge\\/ -rrb-": 1.0,
    "-lrb- http:\\/\\/haydn.isi.edu\\/rouge\\/ -rrb- .": 1.0,
    "<s> this is a": 0.14285714285714285,
    "this is a recall-based": 0.5,
    "is a recall-based measure": 1.0,
    "a recall-based measure that": 1.0,
    "recall-based measure that determines": 1.0,
    "measure that determines how": 1.0,
    "that determines how well": 1.0,
    "determines how well a": 1.0,
    "how well a system-generated": 1.0,
    "well a system-generated summary": 1.0,
    "a system-generated summary covers": 1.0,
    "system-generated summary covers the": 1.0,
    "summary covers the content": 1.0,
    "covers the content present": 1.0,
    "the content present in": 1.0,
    "content present in one": 1.0,
    "present in one or": 1.0,
    "in one or more": 1.0,
    "one or more human-generated": 0.5,
    "or more human-generated model": 1.0,
    "more human-generated model summaries": 1.0,
    "human-generated model summaries known": 1.0,
    "model summaries known as": 1.0,
    "summaries known as references": 1.0,
    "known as references .": 1.0,
    "<s> it is recall-based": 0.05263157894736842,
    "it is recall-based to": 1.0,
    "is recall-based to encourage": 1.0,
    "recall-based to encourage systems": 1.0,
    "to encourage systems to": 1.0,
    "encourage systems to include": 1.0,
    "systems to include all": 1.0,
    "to include all the": 1.0,
    "include all the important": 1.0,
    "all the important topics": 1.0,
    "the important topics in": 1.0,
    "important topics in the": 1.0,
    "topics in the text": 1.0,
    "<s> recall can be": 1.0,
    "recall can be computed": 1.0,
    "can be computed with": 1.0,
    "be computed with respect": 1.0,
    "computed with respect to": 1.0,
    "with respect to unigram": 0.14285714285714285,
    "respect to unigram ,": 1.0,
    "to unigram , bigram": 1.0,
    ", trigram , or": 0.5,
    "trigram , or 4-gram": 1.0,
    ", or 4-gram matching": 1.0,
    "or 4-gram matching ,": 1.0,
    "4-gram matching , though": 1.0,
    "matching , though rouge-1": 1.0,
    ", though rouge-1 -lrb-": 1.0,
    "though rouge-1 -lrb- unigram": 1.0,
    "rouge-1 -lrb- unigram matching": 1.0,
    "-lrb- unigram matching -rrb-": 1.0,
    "unigram matching -rrb- has": 1.0,
    "matching -rrb- has been": 1.0,
    "-rrb- has been shown": 1.0,
    "has been shown to": 1.0,
    "been shown to correlate": 1.0,
    "shown to correlate best": 1.0,
    "to correlate best with": 1.0,
    "correlate best with human": 1.0,
    "best with human assessments": 1.0,
    "with human assessments of": 1.0,
    "human assessments of system-generated": 1.0,
    "assessments of system-generated summaries": 1.0,
    "of system-generated summaries -lrb-": 1.0,
    "system-generated summaries -lrb- i.e.": 1.0,
    "summaries -lrb- i.e. ,": 1.0,
    "i.e. , the summaries": 0.3333333333333333,
    ", the summaries with": 1.0,
    "the summaries with highest": 1.0,
    "summaries with highest rouge-1": 1.0,
    "with highest rouge-1 values": 1.0,
    "highest rouge-1 values correlate": 1.0,
    "rouge-1 values correlate with": 1.0,
    "values correlate with the": 1.0,
    "correlate with the summaries": 1.0,
    "with the summaries humans": 1.0,
    "the summaries humans deemed": 1.0,
    "summaries humans deemed the": 1.0,
    "humans deemed the best": 1.0,
    "deemed the best -rrb-": 1.0,
    "the best -rrb- .": 1.0,
    "<s> rouge-1 is computed": 1.0,
    "rouge-1 is computed as": 1.0,
    "is computed as division": 1.0,
    "computed as division of": 1.0,
    "as division of count": 1.0,
    "division of count of": 1.0,
    "of count of unigrams": 1.0,
    "count of unigrams in": 1.0,
    "of unigrams in reference": 1.0,
    "unigrams in reference that": 0.5,
    "in reference that appear": 1.0,
    "reference that appear in": 1.0,
    "that appear in system": 1.0,
    "appear in system and": 1.0,
    "in system and count": 1.0,
    "system and count of": 1.0,
    "and count of unigrams": 1.0,
    "unigrams in reference summary": 0.5,
    "in reference summary .": 1.0,
    "<s> if there are": 1.0,
    "if there are multiple": 0.5,
    "there are multiple references": 1.0,
    "are multiple references ,": 1.0,
    "multiple references , the": 1.0,
    "references , the rouge-1": 1.0,
    ", the rouge-1 scores": 1.0,
    "the rouge-1 scores are": 1.0,
    "rouge-1 scores are averaged": 1.0,
    "scores are averaged .": 1.0,
    "<s> because rouge is": 1.0,
    "because rouge is based": 1.0,
    "rouge is based only": 1.0,
    "is based only on": 1.0,
    "based only on content": 1.0,
    "only on content overlap": 1.0,
    "on content overlap ,": 1.0,
    "content overlap , it": 1.0,
    "overlap , it can": 1.0,
    ", it can determine": 1.0,
    "it can determine if": 1.0,
    "can determine if the": 1.0,
    "determine if the same": 0.3333333333333333,
    "if the same general": 1.0,
    "the same general concepts": 1.0,
    "same general concepts are": 1.0,
    "general concepts are discussed": 1.0,
    "concepts are discussed between": 1.0,
    "are discussed between an": 1.0,
    "discussed between an automatic": 1.0,
    "between an automatic summary": 1.0,
    "an automatic summary and": 1.0,
    "automatic summary and a": 0.5,
    "summary and a reference": 1.0,
    "and a reference summary": 1.0,
    "a reference summary ,": 1.0,
    "reference summary , but": 0.5,
    "summary , but it": 1.0,
    ", but it can": 0.3333333333333333,
    "but it can not": 1.0,
    "it can not determine": 1.0,
    "can not determine if": 1.0,
    "not determine if the": 1.0,
    "determine if the result": 0.3333333333333333,
    "if the result is": 1.0,
    "the result is coherent": 0.5,
    "result is coherent or": 1.0,
    "is coherent or the": 1.0,
    "coherent or the sentences": 1.0,
    "or the sentences flow": 1.0,
    "the sentences flow together": 1.0,
    "sentences flow together in": 1.0,
    "flow together in a": 1.0,
    "together in a sensible": 1.0,
    "in a sensible manner": 1.0,
    "a sensible manner .": 1.0,
    "<s> high-order n-gram rouge": 1.0,
    "high-order n-gram rouge measures": 1.0,
    "n-gram rouge measures try": 1.0,
    "rouge measures try to": 1.0,
    "measures try to judge": 1.0,
    "try to judge fluency": 1.0,
    "to judge fluency to": 1.0,
    "judge fluency to some": 1.0,
    "fluency to some degree": 1.0,
    "to some degree .": 0.5,
    "<s> note that rouge": 0.14285714285714285,
    "note that rouge is": 1.0,
    "that rouge is similar": 1.0,
    "rouge is similar to": 1.0,
    "is similar to the": 0.5,
    "similar to the bleu": 0.2,
    "to the bleu measure": 1.0,
    "the bleu measure for": 1.0,
    "bleu measure for machine": 1.0,
    "measure for machine translation": 1.0,
    "for machine translation ,": 0.3333333333333333,
    "machine translation , but": 0.14285714285714285,
    "translation , but bleu": 1.0,
    ", but bleu is": 1.0,
    "but bleu is precision": 1.0,
    "bleu is precision -": 1.0,
    "is precision - based": 1.0,
    "precision - based ,": 1.0,
    "- based , because": 1.0,
    "based , because translation": 1.0,
    ", because translation systems": 1.0,
    "because translation systems favor": 1.0,
    "translation systems favor accuracy": 1.0,
    "systems favor accuracy .": 1.0,
    "<s> a promising line": 1.0,
    "a promising line in": 1.0,
    "promising line in document": 1.0,
    "line in document summarization": 1.0,
    "in document summarization is": 1.0,
    "document summarization is adaptive": 1.0,
    "summarization is adaptive document\\/text": 1.0,
    "is adaptive document\\/text summarization": 1.0,
    "adaptive document\\/text summarization .": 1.0,
    "the idea of adaptive": 0.5,
    "idea of adaptive summarization": 1.0,
    "of adaptive summarization involves": 1.0,
    "adaptive summarization involves preliminary": 1.0,
    "summarization involves preliminary recognition": 1.0,
    "involves preliminary recognition of": 1.0,
    "preliminary recognition of document\\/text": 1.0,
    "recognition of document\\/text genre": 1.0,
    "of document\\/text genre and": 1.0,
    "document\\/text genre and subsequent": 1.0,
    "genre and subsequent application": 1.0,
    "and subsequent application of": 1.0,
    "subsequent application of summarization": 1.0,
    "application of summarization algorithms": 1.0,
    "of summarization algorithms optimized": 1.0,
    "summarization algorithms optimized for": 1.0,
    "algorithms optimized for this": 1.0,
    "optimized for this genre": 1.0,
    "for this genre .": 1.0,
    "<s> first summarizes that": 1.0,
    "first summarizes that perform": 1.0,
    "summarizes that perform adaptive": 1.0,
    "that perform adaptive summarization": 1.0,
    "perform adaptive summarization have": 1.0,
    "adaptive summarization have been": 1.0,
    "summarization have been created": 1.0,
    "have been created .": 0.5,
    "<s> overview of supervised": 0.5,
    "overview of supervised learning": 1.0,
    "of supervised learning approaches": 1.0,
    "supervised learning approaches supervised": 1.0,
    "learning approaches supervised text": 1.0,
    "approaches supervised text summarization": 1.0,
    "supervised text summarization is": 1.0,
    "text summarization is very": 1.0,
    "summarization is very much": 1.0,
    "is very much like": 1.0,
    "very much like supervised": 1.0,
    "much like supervised keyphrase": 1.0,
    "like supervised keyphrase extraction": 1.0,
    "supervised keyphrase extraction ,": 0.5,
    "keyphrase extraction , and": 0.25,
    "extraction , and we": 1.0,
    ", and we will": 1.0,
    "and we will not": 1.0,
    "we will not spend": 1.0,
    "will not spend much": 1.0,
    "not spend much time": 1.0,
    "spend much time on": 1.0,
    "much time on it": 1.0,
    "time on it .": 1.0,
    "<s> basically , if": 1.0,
    "basically , if you": 1.0,
    ", if you have": 0.5,
    "if you have a": 1.0,
    "you have a collection": 0.5,
    "have a collection of": 1.0,
    "a collection of documents": 0.5,
    "collection of documents and": 1.0,
    "of documents and human-generated": 1.0,
    "documents and human-generated summaries": 1.0,
    "and human-generated summaries for": 1.0,
    "human-generated summaries for them": 1.0,
    "summaries for them ,": 1.0,
    "for them , you": 1.0,
    "them , you can": 1.0,
    ", you can learn": 1.0,
    "you can learn features": 1.0,
    "can learn features of": 1.0,
    "learn features of sentences": 1.0,
    "features of sentences that": 1.0,
    "of sentences that make": 1.0,
    "sentences that make them": 1.0,
    "that make them good": 1.0,
    "make them good candidates": 1.0,
    "them good candidates for": 1.0,
    "good candidates for inclusion": 1.0,
    "candidates for inclusion in": 1.0,
    "for inclusion in the": 1.0,
    "inclusion in the summary": 1.0,
    "in the summary .": 0.75,
    "<s> features might include": 1.0,
    "features might include the": 1.0,
    "might include the position": 1.0,
    "include the position in": 1.0,
    "the position in the": 1.0,
    "position in the document": 0.5,
    "in the document -lrb-": 0.25,
    "the document -lrb- i.e.": 1.0,
    "document -lrb- i.e. ,": 1.0,
    "i.e. , the first": 0.3333333333333333,
    ", the first few": 0.3333333333333333,
    "the first few sentences": 1.0,
    "first few sentences are": 1.0,
    "few sentences are probably": 1.0,
    "sentences are probably important": 1.0,
    "are probably important -rrb-": 1.0,
    "probably important -rrb- ,": 1.0,
    "important -rrb- , the": 1.0,
    "-rrb- , the number": 0.2,
    ", the number of": 1.0,
    "the number of words": 0.4,
    "number of words in": 0.5,
    "words in the sentence": 0.25,
    "in the sentence ,": 1.0,
    "the sentence , etc.": 1.0,
    "sentence , etc. .": 1.0,
    "<s> the main difficulty": 1.0,
    "the main difficulty in": 1.0,
    "main difficulty in supervised": 0.5,
    "difficulty in supervised extractive": 1.0,
    "in supervised extractive summarization": 1.0,
    "supervised extractive summarization is": 1.0,
    "extractive summarization is that": 1.0,
    "summarization is that the": 1.0,
    "is that the known": 0.3333333333333333,
    "that the known summaries": 1.0,
    "the known summaries must": 1.0,
    "known summaries must be": 1.0,
    "summaries must be manually": 1.0,
    "must be manually created": 1.0,
    "be manually created by": 1.0,
    "manually created by extracting": 1.0,
    "created by extracting sentences": 1.0,
    "by extracting sentences so": 1.0,
    "extracting sentences so the": 1.0,
    "sentences so the sentences": 1.0,
    "so the sentences in": 1.0,
    "the sentences in an": 0.3333333333333333,
    "sentences in an original": 1.0,
    "in an original training": 1.0,
    "an original training document": 1.0,
    "original training document can": 1.0,
    "training document can be": 1.0,
    "document can be labeled": 1.0,
    "can be labeled as": 1.0,
    "be labeled as ``": 1.0,
    "labeled as `` in": 1.0,
    "as `` in summary": 1.0,
    "`` in summary ''": 1.0,
    "in summary '' or": 0.5,
    "summary '' or ``": 1.0,
    "'' or `` not": 0.25,
    "or `` not in": 1.0,
    "`` not in summary": 1.0,
    "not in summary ''": 1.0,
    "in summary '' .": 0.5,
    "<s> this is not": 0.14285714285714285,
    "this is not typically": 0.5,
    "is not typically how": 1.0,
    "not typically how people": 1.0,
    "typically how people create": 1.0,
    "how people create summaries": 1.0,
    "people create summaries ,": 1.0,
    "create summaries , so": 1.0,
    "summaries , so simply": 1.0,
    ", so simply using": 1.0,
    "so simply using journal": 1.0,
    "simply using journal abstracts": 1.0,
    "using journal abstracts or": 1.0,
    "journal abstracts or existing": 1.0,
    "abstracts or existing summaries": 1.0,
    "or existing summaries is": 1.0,
    "existing summaries is usually": 1.0,
    "summaries is usually not": 1.0,
    "is usually not sufficient": 1.0,
    "usually not sufficient .": 1.0,
    "<s> the sentences in": 1.0,
    "the sentences in these": 0.3333333333333333,
    "sentences in these summaries": 1.0,
    "in these summaries do": 1.0,
    "these summaries do not": 1.0,
    "summaries do not necessarily": 1.0,
    "do not necessarily match": 1.0,
    "not necessarily match up": 1.0,
    "necessarily match up with": 1.0,
    "match up with sentences": 1.0,
    "up with sentences in": 1.0,
    "with sentences in the": 1.0,
    "the original text ,": 0.16666666666666666,
    "original text , so": 1.0,
    "text , so it": 1.0,
    ", so it would": 1.0,
    "so it would difficult": 1.0,
    "it would difficult to": 1.0,
    "would difficult to assign": 1.0,
    "difficult to assign labels": 1.0,
    "to assign labels to": 1.0,
    "assign labels to examples": 1.0,
    "labels to examples for": 1.0,
    "to examples for training": 1.0,
    "examples for training .": 1.0,
    "<s> note , however": 1.0,
    "note , however ,": 1.0,
    ", however , that": 0.09090909090909091,
    "however , that these": 1.0,
    ", that these natural": 1.0,
    "that these natural summaries": 1.0,
    "these natural summaries can": 1.0,
    "natural summaries can still": 1.0,
    "summaries can still be": 1.0,
    "can still be used": 1.0,
    "still be used for": 1.0,
    "be used for evaluation": 0.3333333333333333,
    "used for evaluation purposes": 1.0,
    "for evaluation purposes ,": 1.0,
    "evaluation purposes , since": 1.0,
    "purposes , since rouge-1": 1.0,
    ", since rouge-1 only": 1.0,
    "since rouge-1 only cares": 1.0,
    "rouge-1 only cares about": 1.0,
    "only cares about unigrams": 1.0,
    "cares about unigrams .": 1.0,
    "<s> unsupervised approaches :": 1.0,
    "unsupervised approaches : textrank": 1.0,
    "approaches : textrank and": 1.0,
    ": textrank and lexrank": 1.0,
    "textrank and lexrank the": 0.5,
    "and lexrank the unsupervised": 1.0,
    "lexrank the unsupervised approach": 1.0,
    "the unsupervised approach to": 1.0,
    "unsupervised approach to summarization": 1.0,
    "approach to summarization is": 1.0,
    "to summarization is also": 1.0,
    "summarization is also quite": 1.0,
    "is also quite similar": 1.0,
    "also quite similar in": 1.0,
    "quite similar in spirit": 1.0,
    "similar in spirit to": 1.0,
    "in spirit to unsupervised": 1.0,
    "spirit to unsupervised keyphrase": 1.0,
    "to unsupervised keyphrase extraction": 1.0,
    "unsupervised keyphrase extraction and": 0.3333333333333333,
    "keyphrase extraction and gets": 1.0,
    "extraction and gets around": 1.0,
    "and gets around the": 1.0,
    "gets around the issue": 1.0,
    "around the issue of": 1.0,
    "the issue of costly": 1.0,
    "issue of costly training": 1.0,
    "of costly training data": 1.0,
    "costly training data .": 1.0,
    "<s> some unsupervised summarization": 1.0,
    "some unsupervised summarization approaches": 1.0,
    "unsupervised summarization approaches are": 1.0,
    "summarization approaches are based": 1.0,
    "approaches are based on": 1.0,
    "are based on finding": 0.2,
    "based on finding a": 1.0,
    "on finding a ``": 1.0,
    "finding a `` centroid": 1.0,
    "a `` centroid ''": 1.0,
    "`` centroid '' sentence": 1.0,
    "centroid '' sentence ,": 1.0,
    "'' sentence , which": 1.0,
    "sentence , which is": 1.0,
    "which is the mean": 0.3333333333333333,
    "is the mean word": 1.0,
    "the mean word vector": 1.0,
    "mean word vector of": 1.0,
    "word vector of all": 1.0,
    "vector of all the": 1.0,
    "of all the sentences": 0.5,
    "all the sentences in": 1.0,
    "the sentences in the": 0.3333333333333333,
    "sentences in the document": 0.25,
    "in the document .": 0.5,
    "<s> then the sentences": 0.5,
    "then the sentences can": 1.0,
    "the sentences can be": 1.0,
    "sentences can be ranked": 1.0,
    "can be ranked with": 1.0,
    "be ranked with regard": 1.0,
    "ranked with regard to": 1.0,
    "with regard to their": 0.25,
    "regard to their similarity": 1.0,
    "to their similarity to": 1.0,
    "their similarity to this": 1.0,
    "similarity to this centroid": 1.0,
    "to this centroid sentence": 1.0,
    "this centroid sentence .": 1.0,
    "<s> a more principled": 1.0,
    "a more principled way": 1.0,
    "more principled way to": 1.0,
    "principled way to estimate": 1.0,
    "way to estimate sentence": 1.0,
    "to estimate sentence importance": 1.0,
    "estimate sentence importance is": 1.0,
    "sentence importance is using": 1.0,
    "importance is using random": 1.0,
    "is using random walks": 1.0,
    "using random walks and": 1.0,
    "random walks and eigenvector": 1.0,
    "walks and eigenvector centrality": 1.0,
    "and eigenvector centrality .": 1.0,
    "<s> lexrank is an": 1.0,
    "lexrank is an algorithm": 1.0,
    "is an algorithm essentially": 0.5,
    "an algorithm essentially identical": 1.0,
    "algorithm essentially identical to": 1.0,
    "essentially identical to textrank": 1.0,
    "identical to textrank ,": 1.0,
    "to textrank , and": 1.0,
    "textrank , and both": 1.0,
    ", and both use": 1.0,
    "and both use this": 1.0,
    "both use this approach": 1.0,
    "use this approach for": 1.0,
    "this approach for document": 1.0,
    "approach for document summarization": 1.0,
    "for document summarization .": 1.0,
    "<s> the two methods": 0.5,
    "the two methods were": 1.0,
    "two methods were developed": 1.0,
    "methods were developed by": 1.0,
    "were developed by different": 1.0,
    "developed by different groups": 1.0,
    "by different groups at": 1.0,
    "different groups at the": 1.0,
    "groups at the same": 1.0,
    "at the same time": 1.0,
    "the same time ,": 1.0,
    "same time , and": 0.3333333333333333,
    "time , and lexrank": 0.5,
    ", and lexrank simply": 1.0,
    "and lexrank simply focused": 1.0,
    "lexrank simply focused on": 1.0,
    "simply focused on summarization": 1.0,
    "focused on summarization ,": 1.0,
    "on summarization , but": 1.0,
    "summarization , but could": 1.0,
    ", but could just": 1.0,
    "but could just as": 1.0,
    "could just as easily": 1.0,
    "just as easily be": 0.5,
    "as easily be used": 1.0,
    "easily be used for": 1.0,
    "be used for keyphrase": 0.3333333333333333,
    "used for keyphrase extraction": 1.0,
    "for keyphrase extraction or": 0.5,
    "keyphrase extraction or any": 1.0,
    "extraction or any other": 1.0,
    "or any other nlp": 1.0,
    "any other nlp ranking": 1.0,
    "other nlp ranking task": 1.0,
    "nlp ranking task .": 1.0,
    "design choices what are": 0.5,
    "choices what are the": 1.0,
    "what are the vertices": 0.25,
    "are the vertices ?": 1.0,
    "<s> in both lexrank": 0.5,
    "in both lexrank and": 1.0,
    "both lexrank and textrank": 1.0,
    "lexrank and textrank ,": 1.0,
    "and textrank , a": 1.0,
    "textrank , a graph": 1.0,
    ", a graph is": 1.0,
    "a graph is constructed": 1.0,
    "graph is constructed by": 0.5,
    "is constructed by creating": 1.0,
    "constructed by creating a": 1.0,
    "by creating a vertex": 1.0,
    "creating a vertex for": 1.0,
    "vertex for each sentence": 0.5,
    "for each sentence in": 1.0,
    "each sentence in the": 1.0,
    "sentence in the document": 1.0,
    "what are the edges": 0.25,
    "are the edges ?": 1.0,
    "<s> the edges between": 1.0,
    "the edges between sentences": 1.0,
    "edges between sentences are": 1.0,
    "between sentences are based": 1.0,
    "sentences are based on": 1.0,
    "based on some form": 0.5,
    "on some form of": 1.0,
    "some form of semantic": 0.25,
    "form of semantic similarity": 1.0,
    "of semantic similarity or": 1.0,
    "semantic similarity or content": 1.0,
    "similarity or content overlap": 1.0,
    "or content overlap .": 1.0,
    "<s> while lexrank uses": 1.0,
    "while lexrank uses cosine": 1.0,
    "lexrank uses cosine similarity": 1.0,
    "uses cosine similarity of": 1.0,
    "cosine similarity of tf-idf": 1.0,
    "similarity of tf-idf vectors": 1.0,
    "of tf-idf vectors ,": 1.0,
    "tf-idf vectors , textrank": 1.0,
    "vectors , textrank uses": 1.0,
    ", textrank uses a": 1.0,
    "textrank uses a very": 1.0,
    "uses a very similar": 1.0,
    "a very similar measure": 1.0,
    "very similar measure based": 1.0,
    "similar measure based on": 1.0,
    "measure based on the": 1.0,
    "based on the number": 0.09090909090909091,
    "on the number of": 1.0,
    "number of words two": 0.5,
    "of words two sentences": 1.0,
    "words two sentences have": 1.0,
    "two sentences have in": 1.0,
    "sentences have in common": 1.0,
    "have in common -lrb-": 1.0,
    "in common -lrb- normalized": 1.0,
    "common -lrb- normalized by": 1.0,
    "-lrb- normalized by the": 1.0,
    "normalized by the sentences": 1.0,
    "by the sentences '": 1.0,
    "the sentences ' lengths": 1.0,
    "sentences ' lengths -rrb-": 1.0,
    "' lengths -rrb- .": 1.0,
    "<s> the lexrank paper": 1.0,
    "the lexrank paper explored": 1.0,
    "lexrank paper explored using": 1.0,
    "paper explored using unweighted": 1.0,
    "explored using unweighted edges": 1.0,
    "using unweighted edges after": 1.0,
    "unweighted edges after applying": 1.0,
    "edges after applying a": 1.0,
    "after applying a threshold": 1.0,
    "applying a threshold to": 1.0,
    "a threshold to the": 1.0,
    "threshold to the cosine": 1.0,
    "to the cosine values": 1.0,
    "the cosine values ,": 1.0,
    "cosine values , but": 1.0,
    "values , but also": 1.0,
    ", but also experimented": 0.3333333333333333,
    "but also experimented with": 1.0,
    "also experimented with using": 1.0,
    "experimented with using edges": 1.0,
    "with using edges with": 1.0,
    "using edges with weights": 1.0,
    "edges with weights equal": 1.0,
    "with weights equal to": 1.0,
    "weights equal to the": 1.0,
    "equal to the similarity": 1.0,
    "to the similarity score": 1.0,
    "the similarity score .": 1.0,
    "<s> textrank uses continuous": 1.0,
    "textrank uses continuous similarity": 1.0,
    "uses continuous similarity scores": 1.0,
    "continuous similarity scores as": 1.0,
    "similarity scores as weights": 1.0,
    "scores as weights .": 1.0,
    "<s> how are summaries": 0.5,
    "how are summaries formed": 1.0,
    "are summaries formed ?": 1.0,
    "<s> in both algorithms": 0.5,
    "in both algorithms ,": 1.0,
    "both algorithms , the": 1.0,
    "algorithms , the sentences": 0.5,
    ", the sentences are": 1.0,
    "the sentences are ranked": 1.0,
    "sentences are ranked by": 1.0,
    "are ranked by applying": 1.0,
    "ranked by applying pagerank": 1.0,
    "by applying pagerank to": 1.0,
    "applying pagerank to the": 0.5,
    "pagerank to the resulting": 1.0,
    "to the resulting graph": 1.0,
    "the resulting graph .": 1.0,
    "<s> a summary is": 1.0,
    "a summary is formed": 1.0,
    "summary is formed by": 1.0,
    "is formed by combining": 1.0,
    "formed by combining the": 1.0,
    "by combining the top": 1.0,
    "combining the top ranking": 1.0,
    "the top ranking sentences": 1.0,
    "top ranking sentences ,": 1.0,
    "ranking sentences , using": 1.0,
    "sentences , using a": 1.0,
    ", using a threshold": 1.0,
    "using a threshold or": 1.0,
    "a threshold or length": 1.0,
    "threshold or length cutoff": 1.0,
    "or length cutoff to": 1.0,
    "length cutoff to limit": 1.0,
    "cutoff to limit the": 1.0,
    "to limit the size": 0.5,
    "limit the size of": 1.0,
    "the size of the": 1.0,
    "size of the summary": 1.0,
    "of the summary .": 1.0,
    "<s> textrank and lexrank": 1.0,
    "textrank and lexrank differences": 0.5,
    "and lexrank differences it": 1.0,
    "lexrank differences it is": 1.0,
    "differences it is worth": 1.0,
    "it is worth noting": 0.5,
    "is worth noting that": 1.0,
    "worth noting that textrank": 1.0,
    "noting that textrank was": 1.0,
    "that textrank was applied": 0.5,
    "textrank was applied to": 1.0,
    "was applied to summarization": 1.0,
    "applied to summarization exactly": 1.0,
    "to summarization exactly as": 1.0,
    "summarization exactly as described": 1.0,
    "exactly as described here": 1.0,
    "as described here ,": 1.0,
    "described here , while": 1.0,
    "here , while lexrank": 1.0,
    ", while lexrank was": 0.5,
    "while lexrank was used": 1.0,
    "lexrank was used as": 1.0,
    "was used as part": 1.0,
    "used as part of": 1.0,
    "as part of a": 1.0,
    "part of a larger": 0.3333333333333333,
    "of a larger summarization": 0.5,
    "a larger summarization system": 1.0,
    "larger summarization system -lrb-": 1.0,
    "summarization system -lrb- mead": 1.0,
    "system -lrb- mead -rrb-": 1.0,
    "-lrb- mead -rrb- that": 1.0,
    "mead -rrb- that combines": 1.0,
    "-rrb- that combines the": 1.0,
    "that combines the lexrank": 1.0,
    "combines the lexrank score": 1.0,
    "the lexrank score -lrb-": 1.0,
    "lexrank score -lrb- stationary": 1.0,
    "score -lrb- stationary probability": 1.0,
    "-lrb- stationary probability -rrb-": 1.0,
    "stationary probability -rrb- with": 1.0,
    "probability -rrb- with other": 1.0,
    "-rrb- with other features": 1.0,
    "with other features like": 1.0,
    "other features like sentence": 1.0,
    "features like sentence position": 1.0,
    "like sentence position and": 1.0,
    "sentence position and length": 1.0,
    "position and length using": 1.0,
    "and length using a": 1.0,
    "length using a linear": 1.0,
    "using a linear combination": 1.0,
    "a linear combination with": 1.0,
    "linear combination with either": 1.0,
    "combination with either user-specified": 1.0,
    "with either user-specified or": 1.0,
    "either user-specified or automatically": 1.0,
    "user-specified or automatically tuned": 1.0,
    "or automatically tuned weights": 1.0,
    "automatically tuned weights .": 1.0,
    "<s> in this case": 0.2,
    "in this case ,": 1.0,
    "this case , some": 1.0,
    "case , some training": 1.0,
    ", some training documents": 1.0,
    "some training documents might": 1.0,
    "training documents might be": 1.0,
    "documents might be needed": 1.0,
    "might be needed ,": 1.0,
    "be needed , though": 1.0,
    "needed , though the": 1.0,
    ", though the textrank": 1.0,
    "though the textrank results": 1.0,
    "the textrank results show": 1.0,
    "textrank results show the": 1.0,
    "results show the additional": 1.0,
    "show the additional features": 1.0,
    "the additional features are": 1.0,
    "additional features are not": 1.0,
    "features are not absolutely": 1.0,
    "are not absolutely necessary": 1.0,
    "not absolutely necessary .": 1.0,
    "<s> another important distinction": 1.0,
    "another important distinction is": 1.0,
    "important distinction is that": 1.0,
    "distinction is that textrank": 1.0,
    "is that textrank was": 1.0,
    "that textrank was used": 0.5,
    "textrank was used for": 1.0,
    "was used for single": 1.0,
    "used for single document": 1.0,
    "for single document summarization": 1.0,
    "single document summarization ,": 1.0,
    "document summarization , while": 0.5,
    "summarization , while lexrank": 1.0,
    ", while lexrank has": 0.5,
    "while lexrank has been": 1.0,
    "lexrank has been applied": 1.0,
    "been applied to multi-document": 0.2,
    "applied to multi-document summarization": 1.0,
    "to multi-document summarization .": 1.0,
    "<s> the task remains": 0.5,
    "the task remains the": 1.0,
    "task remains the same": 1.0,
    "remains the same in": 1.0,
    "the same in both": 1.0,
    "same in both cases": 1.0,
    "in both cases --": 1.0,
    "both cases -- only": 1.0,
    "cases -- only the": 1.0,
    "-- only the number": 1.0,
    "only the number of": 1.0,
    "the number of sentences": 0.2,
    "number of sentences to": 0.5,
    "of sentences to choose": 0.5,
    "sentences to choose from": 1.0,
    "to choose from has": 1.0,
    "choose from has grown": 1.0,
    "from has grown .": 1.0,
    "<s> however , when": 0.03125,
    "however , when summarizing": 1.0,
    ", when summarizing multiple": 1.0,
    "when summarizing multiple documents": 1.0,
    "summarizing multiple documents ,": 1.0,
    "multiple documents , there": 1.0,
    "documents , there is": 1.0,
    "there is a greater": 0.25,
    "is a greater risk": 1.0,
    "a greater risk of": 1.0,
    "greater risk of selecting": 1.0,
    "risk of selecting duplicate": 1.0,
    "of selecting duplicate or": 1.0,
    "selecting duplicate or highly": 1.0,
    "duplicate or highly redundant": 1.0,
    "or highly redundant sentences": 1.0,
    "highly redundant sentences to": 1.0,
    "redundant sentences to place": 1.0,
    "to place in the": 0.5,
    "place in the same": 1.0,
    "in the same summary": 0.25,
    "the same summary .": 1.0,
    "<s> imagine you have": 1.0,
    "imagine you have a": 1.0,
    "you have a cluster": 0.5,
    "have a cluster of": 1.0,
    "cluster of news articles": 0.5,
    "of news articles on": 1.0,
    "news articles on a": 1.0,
    "articles on a particular": 1.0,
    "on a particular event": 1.0,
    "a particular event ,": 1.0,
    "particular event , and": 1.0,
    "event , and you": 1.0,
    ", and you want": 0.3333333333333333,
    "and you want to": 1.0,
    "you want to produce": 1.0,
    "want to produce one": 1.0,
    "to produce one summary": 1.0,
    "produce one summary .": 1.0,
    "<s> each article is": 1.0,
    "each article is likely": 1.0,
    "article is likely to": 1.0,
    "is likely to have": 0.3333333333333333,
    "likely to have many": 1.0,
    "to have many similar": 1.0,
    "have many similar sentences": 1.0,
    "many similar sentences ,": 1.0,
    "similar sentences , and": 1.0,
    "sentences , and you": 0.5,
    ", and you would": 0.3333333333333333,
    "and you would only": 1.0,
    "you would only want": 1.0,
    "would only want to": 1.0,
    "only want to include": 1.0,
    "want to include distinct": 1.0,
    "to include distinct ideas": 1.0,
    "include distinct ideas in": 1.0,
    "distinct ideas in the": 1.0,
    "ideas in the summary": 1.0,
    "<s> to address this": 1.0,
    "to address this issue": 1.0,
    "address this issue ,": 1.0,
    "this issue , lexrank": 1.0,
    "issue , lexrank applies": 1.0,
    ", lexrank applies a": 1.0,
    "lexrank applies a heuristic": 1.0,
    "applies a heuristic post-processing": 1.0,
    "a heuristic post-processing step": 1.0,
    "heuristic post-processing step that": 1.0,
    "post-processing step that builds": 1.0,
    "step that builds up": 1.0,
    "that builds up a": 1.0,
    "builds up a summary": 1.0,
    "up a summary by": 1.0,
    "a summary by adding": 1.0,
    "summary by adding sentences": 1.0,
    "by adding sentences in": 1.0,
    "adding sentences in rank": 1.0,
    "sentences in rank order": 1.0,
    "in rank order ,": 1.0,
    "rank order , but": 1.0,
    "order , but discards": 1.0,
    ", but discards any": 1.0,
    "but discards any sentences": 1.0,
    "discards any sentences that": 1.0,
    "any sentences that are": 1.0,
    "sentences that are too": 0.3333333333333333,
    "that are too similar": 1.0,
    "are too similar to": 1.0,
    "too similar to ones": 1.0,
    "similar to ones already": 1.0,
    "to ones already placed": 1.0,
    "ones already placed in": 1.0,
    "already placed in the": 1.0,
    "placed in the summary": 0.5,
    "<s> the method used": 1.0,
    "the method used is": 1.0,
    "method used is called": 1.0,
    "used is called cross-sentence": 1.0,
    "is called cross-sentence information": 1.0,
    "called cross-sentence information subsumption": 1.0,
    "cross-sentence information subsumption -lrb-": 1.0,
    "information subsumption -lrb- csis": 1.0,
    "subsumption -lrb- csis -rrb-": 1.0,
    "-lrb- csis -rrb- .": 1.0,
    "<s> why unsupervised summarization": 1.0,
    "why unsupervised summarization works": 1.0,
    "unsupervised summarization works these": 1.0,
    "summarization works these methods": 1.0,
    "works these methods work": 1.0,
    "these methods work based": 1.0,
    "methods work based on": 1.0,
    "work based on the": 1.0,
    "based on the idea": 0.09090909090909091,
    "on the idea that": 1.0,
    "the idea that sentences": 0.5,
    "idea that sentences ``": 1.0,
    "that sentences `` recommend": 1.0,
    "sentences `` recommend ''": 1.0,
    "`` recommend '' other": 0.5,
    "recommend '' other similar": 1.0,
    "'' other similar sentences": 1.0,
    "other similar sentences to": 1.0,
    "similar sentences to the": 0.5,
    "sentences to the reader": 1.0,
    "<s> thus , if": 0.09090909090909091,
    "thus , if one": 1.0,
    ", if one sentence": 1.0,
    "if one sentence is": 1.0,
    "one sentence is very": 1.0,
    "sentence is very similar": 1.0,
    "is very similar to": 1.0,
    "very similar to many": 0.3333333333333333,
    "similar to many others": 0.3333333333333333,
    "to many others ,": 1.0,
    "many others , it": 1.0,
    "others , it will": 1.0,
    ", it will likely": 0.5,
    "it will likely be": 1.0,
    "will likely be a": 1.0,
    "likely be a sentence": 1.0,
    "be a sentence of": 1.0,
    "a sentence of great": 1.0,
    "sentence of great importance": 1.0,
    "of great importance .": 1.0,
    "<s> the importance of": 1.0,
    "the importance of this": 0.3333333333333333,
    "importance of this sentence": 1.0,
    "of this sentence also": 1.0,
    "this sentence also stems": 1.0,
    "sentence also stems from": 1.0,
    "also stems from the": 1.0,
    "stems from the importance": 1.0,
    "from the importance of": 1.0,
    "the importance of the": 0.3333333333333333,
    "importance of the sentences": 1.0,
    "of the sentences ``": 1.0,
    "the sentences `` recommending": 1.0,
    "sentences `` recommending ''": 1.0,
    "`` recommending '' it": 1.0,
    "recommending '' it .": 1.0,
    "<s> thus , to": 0.09090909090909091,
    "thus , to get": 1.0,
    ", to get ranked": 1.0,
    "to get ranked highly": 1.0,
    "get ranked highly and": 1.0,
    "ranked highly and placed": 1.0,
    "highly and placed in": 1.0,
    "and placed in a": 1.0,
    "placed in a summary": 1.0,
    "in a summary ,": 0.5,
    "a summary , a": 1.0,
    "summary , a sentence": 1.0,
    ", a sentence must": 1.0,
    "a sentence must be": 1.0,
    "sentence must be similar": 1.0,
    "must be similar to": 1.0,
    "be similar to many": 1.0,
    "similar to many sentences": 0.3333333333333333,
    "to many sentences that": 1.0,
    "many sentences that are": 1.0,
    "sentences that are in": 0.3333333333333333,
    "that are in turn": 1.0,
    "are in turn also": 1.0,
    "in turn also similar": 1.0,
    "turn also similar to": 1.0,
    "also similar to many": 1.0,
    "similar to many other": 0.3333333333333333,
    "to many other sentences": 1.0,
    "many other sentences .": 1.0,
    "<s> this makes intuitive": 1.0,
    "this makes intuitive sense": 1.0,
    "makes intuitive sense and": 1.0,
    "intuitive sense and allows": 1.0,
    "sense and allows the": 1.0,
    "and allows the algorithms": 1.0,
    "allows the algorithms to": 1.0,
    "the algorithms to be": 1.0,
    "algorithms to be applied": 1.0,
    "to be applied to": 1.0,
    "be applied to any": 0.5,
    "applied to any arbitrary": 1.0,
    "to any arbitrary new": 1.0,
    "any arbitrary new text": 1.0,
    "arbitrary new text .": 1.0,
    "<s> the methods are": 1.0,
    "the methods are domain-independent": 1.0,
    "methods are domain-independent and": 1.0,
    "are domain-independent and easily": 1.0,
    "domain-independent and easily portable": 1.0,
    "and easily portable .": 1.0,
    "<s> one could imagine": 1.0,
    "one could imagine the": 1.0,
    "could imagine the features": 1.0,
    "imagine the features indicating": 1.0,
    "the features indicating important": 1.0,
    "features indicating important sentences": 1.0,
    "indicating important sentences in": 1.0,
    "important sentences in the": 1.0,
    "sentences in the news": 0.25,
    "in the news domain": 1.0,
    "the news domain might": 0.5,
    "news domain might vary": 1.0,
    "domain might vary considerably": 1.0,
    "might vary considerably from": 1.0,
    "vary considerably from the": 1.0,
    "considerably from the biomedical": 1.0,
    "from the biomedical domain": 1.0,
    "the biomedical domain .": 1.0,
    "<s> however , the": 0.0625,
    "however , the unsupervised": 0.5,
    ", the unsupervised ``": 1.0,
    "the unsupervised `` recommendation": 1.0,
    "unsupervised `` recommendation ''": 1.0,
    "`` recommendation '' -": 0.5,
    "recommendation '' - based": 1.0,
    "'' - based approach": 1.0,
    "- based approach applies": 1.0,
    "based approach applies to": 1.0,
    "approach applies to any": 1.0,
    "applies to any domain": 1.0,
    "to any domain .": 1.0,
    "<s> incorporating diversity :": 1.0,
    "incorporating diversity : grasshopper": 1.0,
    "diversity : grasshopper algorithm": 1.0,
    ": grasshopper algorithm as": 1.0,
    "grasshopper algorithm as mentioned": 1.0,
    "algorithm as mentioned above": 1.0,
    "as mentioned above ,": 1.0,
    "mentioned above , multi-document": 1.0,
    "above , multi-document extractive": 1.0,
    ", multi-document extractive summarization": 1.0,
    "multi-document extractive summarization faces": 1.0,
    "extractive summarization faces a": 1.0,
    "summarization faces a problem": 1.0,
    "faces a problem of": 1.0,
    "a problem of potential": 1.0,
    "problem of potential redundancy": 1.0,
    "of potential redundancy .": 1.0,
    "<s> ideally , we": 0.5,
    "ideally , we would": 1.0,
    ", we would like": 0.5,
    "we would like to": 1.0,
    "would like to extract": 0.5,
    "like to extract sentences": 1.0,
    "to extract sentences that": 1.0,
    "extract sentences that are": 1.0,
    "sentences that are both": 0.3333333333333333,
    "that are both ``": 0.5,
    "are both `` central": 1.0,
    "both `` central ''": 1.0,
    "`` central '' -lrb-": 0.5,
    "central '' -lrb- i.e.": 1.0,
    "'' -lrb- i.e. ,": 1.0,
    "-lrb- i.e. , contain": 0.14285714285714285,
    "i.e. , contain the": 1.0,
    ", contain the main": 1.0,
    "contain the main ideas": 1.0,
    "the main ideas -rrb-": 1.0,
    "main ideas -rrb- and": 1.0,
    "ideas -rrb- and ``": 1.0,
    "-rrb- and `` diverse": 1.0,
    "and `` diverse ''": 1.0,
    "`` diverse '' -lrb-": 1.0,
    "diverse '' -lrb- i.e.": 1.0,
    "-lrb- i.e. , they": 0.14285714285714285,
    "i.e. , they differ": 1.0,
    ", they differ from": 1.0,
    "they differ from one": 1.0,
    "differ from one another": 1.0,
    "from one another -rrb-": 1.0,
    "one another -rrb- .": 1.0,
    "<s> lexrank deals with": 1.0,
    "lexrank deals with diversity": 1.0,
    "deals with diversity as": 1.0,
    "with diversity as a": 1.0,
    "diversity as a heuristic": 1.0,
    "as a heuristic final": 1.0,
    "a heuristic final stage": 1.0,
    "heuristic final stage using": 1.0,
    "final stage using csis": 1.0,
    "stage using csis ,": 1.0,
    "using csis , and": 1.0,
    "csis , and other": 1.0,
    ", and other systems": 0.3333333333333333,
    "and other systems have": 1.0,
    "other systems have used": 1.0,
    "systems have used similar": 1.0,
    "have used similar methods": 1.0,
    "used similar methods ,": 1.0,
    "similar methods , such": 1.0,
    "methods , such as": 1.0,
    ", such as maximal": 0.030303030303030304,
    "such as maximal marginal": 1.0,
    "as maximal marginal relevance": 1.0,
    "maximal marginal relevance -lrb-": 1.0,
    "marginal relevance -lrb- mmr": 1.0,
    "relevance -lrb- mmr -rrb-": 1.0,
    "-lrb- mmr -rrb- ,": 1.0,
    "mmr -rrb- , in": 1.0,
    "-rrb- , in trying": 1.0,
    ", in trying to": 1.0,
    "in trying to eliminate": 1.0,
    "trying to eliminate redundancy": 1.0,
    "to eliminate redundancy in": 1.0,
    "eliminate redundancy in information": 1.0,
    "redundancy in information retrieval": 1.0,
    "in information retrieval results": 0.5,
    "information retrieval results .": 1.0,
    "<s> we have developed": 1.0,
    "we have developed a": 1.0,
    "have developed a general": 1.0,
    "developed a general purpose": 1.0,
    "graph-based ranking algorithm like": 0.5,
    "ranking algorithm like page\\/lex\\/textrank": 1.0,
    "algorithm like page\\/lex\\/textrank that": 1.0,
    "like page\\/lex\\/textrank that handles": 1.0,
    "page\\/lex\\/textrank that handles both": 1.0,
    "that handles both ``": 1.0,
    "handles both `` centrality": 1.0,
    "both `` centrality ''": 1.0,
    "`` centrality '' and": 1.0,
    "centrality '' and ``": 1.0,
    "'' and `` diversity": 0.1111111111111111,
    "and `` diversity ''": 1.0,
    "`` diversity '' in": 1.0,
    "diversity '' in a": 1.0,
    "'' in a unified": 1.0,
    "in a unified mathematical": 1.0,
    "a unified mathematical framework": 1.0,
    "unified mathematical framework based": 1.0,
    "mathematical framework based on": 1.0,
    "framework based on absorbing": 1.0,
    "based on absorbing markov": 1.0,
    "on absorbing markov chain": 1.0,
    "absorbing markov chain random": 1.0,
    "markov chain random walks": 1.0,
    "chain random walks .": 1.0,
    "<s> -lrb- an absorbing": 0.5,
    "-lrb- an absorbing random": 1.0,
    "an absorbing random walk": 1.0,
    "absorbing random walk is": 1.0,
    "random walk is like": 1.0,
    "walk is like a": 1.0,
    "is like a standard": 0.5,
    "like a standard random": 1.0,
    "a standard random walk": 1.0,
    "standard random walk ,": 1.0,
    "random walk , except": 1.0,
    "walk , except some": 1.0,
    ", except some states": 1.0,
    "except some states are": 1.0,
    "some states are now": 1.0,
    "states are now absorbing": 1.0,
    "are now absorbing states": 1.0,
    "now absorbing states that": 1.0,
    "absorbing states that act": 1.0,
    "states that act as": 1.0,
    "that act as ``": 1.0,
    "act as `` black": 1.0,
    "as `` black holes": 1.0,
    "`` black holes ''": 1.0,
    "black holes '' that": 1.0,
    "holes '' that cause": 1.0,
    "'' that cause the": 1.0,
    "that cause the walk": 1.0,
    "cause the walk to": 1.0,
    "the walk to end": 1.0,
    "walk to end abruptly": 1.0,
    "to end abruptly at": 1.0,
    "end abruptly at that": 1.0,
    "abruptly at that state": 1.0,
    "at that state .": 1.0,
    "that state . -rrb-": 1.0,
    "<s> the algorithm is": 1.0,
    "the algorithm is called": 0.5,
    "algorithm is called grasshopper": 1.0,
    "is called grasshopper for": 1.0,
    "called grasshopper for reasons": 1.0,
    "grasshopper for reasons that": 1.0,
    "for reasons that should": 1.0,
    "reasons that should soon": 1.0,
    "that should soon become": 1.0,
    "should soon become clear": 1.0,
    "soon become clear .": 1.0,
    "<s> in addition to": 0.3333333333333333,
    "in addition to explicitly": 0.3333333333333333,
    "addition to explicitly promoting": 1.0,
    "to explicitly promoting diversity": 1.0,
    "explicitly promoting diversity during": 1.0,
    "promoting diversity during the": 1.0,
    "diversity during the ranking": 1.0,
    "during the ranking process": 1.0,
    "the ranking process ,": 1.0,
    "ranking process , grasshopper": 1.0,
    "process , grasshopper incorporates": 1.0,
    ", grasshopper incorporates a": 1.0,
    "grasshopper incorporates a prior": 1.0,
    "incorporates a prior ranking": 1.0,
    "a prior ranking -lrb-": 1.0,
    "prior ranking -lrb- based": 1.0,
    "ranking -lrb- based on": 1.0,
    "-lrb- based on sentence": 1.0,
    "based on sentence position": 1.0,
    "on sentence position in": 1.0,
    "sentence position in the": 1.0,
    "position in the case": 0.5,
    "the case of summarization": 0.2,
    "case of summarization -rrb-": 1.0,
    "of summarization -rrb- .": 1.0,
    "<s> maximum entropy-based summarization": 1.0,
    "maximum entropy-based summarization it": 1.0,
    "entropy-based summarization it is": 1.0,
    "summarization it is an": 1.0,
    "it is an abstractive": 1.0,
    "is an abstractive method": 1.0,
    "an abstractive method .": 1.0,
    "<s> even though automating": 1.0,
    "even though automating abstractive": 1.0,
    "though automating abstractive summarization": 1.0,
    "automating abstractive summarization is": 1.0,
    "abstractive summarization is the": 1.0,
    "summarization is the goal": 0.5,
    "is the goal of": 1.0,
    "the goal of summarization": 0.5,
    "goal of summarization research": 1.0,
    "of summarization research ,": 1.0,
    "summarization research , most": 1.0,
    "research , most practical": 1.0,
    ", most practical systems": 1.0,
    "most practical systems are": 1.0,
    "practical systems are based": 1.0,
    "systems are based on": 1.0,
    "some form of extractive": 0.25,
    "form of extractive summarization": 1.0,
    "of extractive summarization .": 1.0,
    "<s> extracted sentences can": 1.0,
    "extracted sentences can form": 1.0,
    "sentences can form a": 1.0,
    "can form a valid": 1.0,
    "form a valid summary": 1.0,
    "a valid summary in": 1.0,
    "valid summary in itself": 1.0,
    "summary in itself or": 1.0,
    "in itself or form": 1.0,
    "itself or form a": 1.0,
    "or form a basis": 1.0,
    "form a basis for": 1.0,
    "a basis for further": 1.0,
    "basis for further condensation": 1.0,
    "for further condensation operations": 1.0,
    "further condensation operations .": 1.0,
    "<s> furthermore , evaluation": 0.16666666666666666,
    "furthermore , evaluation of": 1.0,
    ", evaluation of extracted": 1.0,
    "evaluation of extracted summaries": 1.0,
    "of extracted summaries can": 1.0,
    "extracted summaries can be": 1.0,
    "summaries can be automated": 1.0,
    "can be automated ,": 1.0,
    "be automated , since": 1.0,
    "automated , since it": 1.0,
    ", since it is": 1.0,
    "since it is essentially": 1.0,
    "is essentially a classification": 0.5,
    "essentially a classification task": 1.0,
    "a classification task .": 1.0,
    "<s> during the duc": 0.5,
    "during the duc 2001": 1.0,
    "the duc 2001 and": 1.0,
    "duc 2001 and 2002": 1.0,
    "2001 and 2002 evaluation": 1.0,
    "and 2002 evaluation workshops": 1.0,
    "2002 evaluation workshops ,": 1.0,
    "evaluation workshops , tno": 1.0,
    "workshops , tno developed": 1.0,
    ", tno developed a": 1.0,
    "tno developed a sentence": 1.0,
    "developed a sentence extraction": 1.0,
    "a sentence extraction system": 1.0,
    "sentence extraction system for": 1.0,
    "extraction system for multi-document": 1.0,
    "system for multi-document summarization": 1.0,
    "for multi-document summarization in": 1.0,
    "multi-document summarization in the": 1.0,
    "summarization in the news": 0.5,
    "the news domain .": 0.5,
    "<s> the system was": 0.16666666666666666,
    "the system was based": 1.0,
    "system was based on": 1.0,
    "was based on a": 1.0,
    "based on a hybrid": 0.25,
    "on a hybrid system": 1.0,
    "a hybrid system using": 1.0,
    "hybrid system using a": 1.0,
    "system using a naive": 1.0,
    "using a naive bayes": 1.0,
    "a naive bayes classifier": 1.0,
    "naive bayes classifier and": 1.0,
    "bayes classifier and statistical": 1.0,
    "classifier and statistical language": 1.0,
    "and statistical language models": 1.0,
    "statistical language models for": 1.0,
    "language models for modeling": 1.0,
    "models for modeling salience": 1.0,
    "for modeling salience .": 1.0,
    "<s> although the system": 0.3333333333333333,
    "although the system exhibited": 1.0,
    "the system exhibited good": 1.0,
    "system exhibited good results": 1.0,
    "exhibited good results ,": 1.0,
    "good results , we": 1.0,
    "results , we wanted": 1.0,
    ", we wanted to": 1.0,
    "we wanted to explore": 1.0,
    "wanted to explore the": 1.0,
    "to explore the effectiveness": 1.0,
    "explore the effectiveness of": 1.0,
    "the effectiveness of a": 1.0,
    "effectiveness of a maximum": 1.0,
    "of a maximum entropy": 1.0,
    "a maximum entropy -lrb-": 0.5,
    "maximum entropy -lrb- me": 1.0,
    "entropy -lrb- me -rrb-": 1.0,
    "-lrb- me -rrb- classifier": 1.0,
    "me -rrb- classifier for": 1.0,
    "-rrb- classifier for the": 1.0,
    "classifier for the meeting": 1.0,
    "for the meeting summarization": 1.0,
    "the meeting summarization task": 1.0,
    "meeting summarization task ,": 1.0,
    "summarization task , as": 1.0,
    "task , as me": 1.0,
    ", as me is": 1.0,
    "as me is known": 1.0,
    "me is known to": 1.0,
    "is known to be": 1.0,
    "known to be robust": 0.5,
    "to be robust against": 1.0,
    "be robust against feature": 1.0,
    "robust against feature dependencies": 1.0,
    "against feature dependencies .": 1.0,
    "<s> maximum entropy has": 1.0,
    "maximum entropy has also": 1.0,
    "entropy has also been": 1.0,
    "has also been applied": 0.3333333333333333,
    "also been applied successfully": 0.5,
    "been applied successfully for": 1.0,
    "applied successfully for summarization": 1.0,
    "successfully for summarization in": 1.0,
    "for summarization in the": 1.0,
    "summarization in the broadcast": 0.5,
    "in the broadcast news": 1.0,
    "the broadcast news domain": 1.0,
    "broadcast news domain .": 1.0,
    "<s> aided summarization machine": 1.0,
    "aided summarization machine learning": 1.0,
    "summarization machine learning techniques": 1.0,
    "machine learning techniques from": 1.0,
    "learning techniques from closely": 1.0,
    "techniques from closely related": 1.0,
    "from closely related fields": 1.0,
    "closely related fields such": 1.0,
    "related fields such as": 1.0,
    "fields such as information": 1.0,
    "such as information retrieval": 1.0,
    "as information retrieval or": 1.0,
    "information retrieval or text": 1.0,
    "retrieval or text mining": 1.0,
    "or text mining have": 1.0,
    "text mining have been": 1.0,
    "mining have been successfully": 1.0,
    "have been successfully adapted": 1.0,
    "been successfully adapted to": 1.0,
    "successfully adapted to help": 1.0,
    "adapted to help automatic": 1.0,
    "to help automatic summarization": 1.0,
    "help automatic summarization .": 1.0,
    "<s> apart from fully": 1.0,
    "apart from fully automated": 1.0,
    "from fully automated summarizers": 1.0,
    "fully automated summarizers -lrb-": 1.0,
    "automated summarizers -lrb- fas": 1.0,
    "summarizers -lrb- fas -rrb-": 1.0,
    "-lrb- fas -rrb- ,": 1.0,
    "fas -rrb- , there": 1.0,
    "-rrb- , there are": 1.0,
    ", there are systems": 0.3333333333333333,
    "there are systems that": 1.0,
    "are systems that aid": 0.3333333333333333,
    "systems that aid users": 1.0,
    "that aid users with": 1.0,
    "aid users with the": 1.0,
    "users with the task": 1.0,
    "with the task of": 1.0,
    "the task of summarization": 0.16666666666666666,
    "task of summarization -lrb-": 1.0,
    "of summarization -lrb- mahs": 1.0,
    "summarization -lrb- mahs =": 1.0,
    "-lrb- mahs = machine": 1.0,
    "mahs = machine aided": 1.0,
    "= machine aided human": 1.0,
    "machine aided human summarization": 1.0,
    "aided human summarization -rrb-": 1.0,
    "human summarization -rrb- ,": 1.0,
    "summarization -rrb- , for": 1.0,
    "-rrb- , for example": 1.0,
    ", for example by": 0.2,
    "for example by highlighting": 0.5,
    "example by highlighting candidate": 1.0,
    "by highlighting candidate passages": 1.0,
    "highlighting candidate passages to": 1.0,
    "candidate passages to be": 1.0,
    "passages to be included": 1.0,
    "to be included in": 1.0,
    "be included in the": 1.0,
    "included in the summary": 1.0,
    "in the summary ,": 0.25,
    "the summary , and": 1.0,
    "summary , and there": 0.5,
    ", and there are": 0.6666666666666666,
    "and there are systems": 0.5,
    "are systems that depend": 0.3333333333333333,
    "systems that depend on": 1.0,
    "that depend on post-processing": 1.0,
    "depend on post-processing by": 1.0,
    "on post-processing by a": 1.0,
    "post-processing by a human": 1.0,
    "by a human -lrb-": 0.3333333333333333,
    "a human -lrb- hams": 1.0,
    "human -lrb- hams =": 1.0,
    "-lrb- hams = human": 1.0,
    "hams = human aided": 1.0,
    "= human aided machine": 1.0,
    "human aided machine summarization": 1.0,
    "aided machine summarization -rrb-": 1.0,
    "machine summarization -rrb- .": 1.0,
    "<s> evaluation an ongoing": 1.0,
    "evaluation an ongoing issue": 1.0,
    "an ongoing issue in": 1.0,
    "ongoing issue in this": 1.0,
    "issue in this field": 1.0,
    "in this field is": 0.5,
    "this field is that": 1.0,
    "field is that of": 1.0,
    "is that of evaluation": 1.0,
    "that of evaluation .": 1.0,
    "<s> evaluation techniques fall": 1.0,
    "evaluation techniques fall into": 1.0,
    "techniques fall into intrinsic": 1.0,
    "fall into intrinsic and": 1.0,
    "into intrinsic and extrinsic": 1.0,
    "intrinsic and extrinsic ,": 1.0,
    "and extrinsic , inter-texual": 1.0,
    "extrinsic , inter-texual and": 1.0,
    ", inter-texual and intra-texual": 1.0,
    "inter-texual and intra-texual .": 1.0,
    "an intrinsic evaluation tests": 0.5,
    "intrinsic evaluation tests the": 1.0,
    "evaluation tests the summarization": 1.0,
    "tests the summarization system": 0.5,
    "the summarization system in": 1.0,
    "summarization system in of": 1.0,
    "system in of itself": 1.0,
    "in of itself while": 1.0,
    "of itself while an": 1.0,
    "itself while an extrinsic": 1.0,
    "while an extrinsic evaluation": 1.0,
    "an extrinsic evaluation tests": 0.5,
    "extrinsic evaluation tests the": 1.0,
    "tests the summarization based": 0.5,
    "the summarization based on": 1.0,
    "summarization based on how": 1.0,
    "based on how it": 1.0,
    "on how it affects": 0.5,
    "how it affects the": 1.0,
    "it affects the completion": 1.0,
    "affects the completion of": 1.0,
    "the completion of some": 1.0,
    "completion of some other": 1.0,
    "of some other task": 0.5,
    "some other task .": 1.0,
    "<s> intrinsic evaluations have": 1.0,
    "intrinsic evaluations have assessed": 1.0,
    "evaluations have assessed mainly": 1.0,
    "have assessed mainly the": 1.0,
    "assessed mainly the coherence": 1.0,
    "mainly the coherence and": 1.0,
    "the coherence and informativeness": 1.0,
    "coherence and informativeness of": 1.0,
    "and informativeness of summaries": 1.0,
    "informativeness of summaries .": 1.0,
    "<s> extrinsic evaluations ,": 1.0,
    "extrinsic evaluations , on": 1.0,
    "evaluations , on the": 1.0,
    ", on the other": 0.5,
    "other hand , have": 0.2,
    "hand , have tested": 1.0,
    ", have tested the": 1.0,
    "have tested the impact": 1.0,
    "tested the impact of": 1.0,
    "the impact of summarization": 1.0,
    "impact of summarization on": 1.0,
    "of summarization on tasks": 1.0,
    "summarization on tasks like": 1.0,
    "on tasks like relevance": 0.5,
    "tasks like relevance assessment": 1.0,
    "like relevance assessment ,": 1.0,
    "relevance assessment , reading": 1.0,
    "assessment , reading comprehension": 1.0,
    ", reading comprehension ,": 1.0,
    "reading comprehension , etc.": 1.0,
    "comprehension , etc. .": 1.0,
    "<s> intra-texual methods assess": 1.0,
    "intra-texual methods assess the": 1.0,
    "methods assess the output": 1.0,
    "assess the output of": 1.0,
    "the output of a": 0.5,
    "output of a specific": 1.0,
    "of a specific summarization": 1.0,
    "a specific summarization system": 1.0,
    "specific summarization system ,": 1.0,
    "summarization system , and": 1.0,
    "system , and the": 1.0,
    ", and the inter-texual": 0.1,
    "and the inter-texual ones": 1.0,
    "the inter-texual ones focus": 1.0,
    "inter-texual ones focus on": 1.0,
    "ones focus on contrastive": 1.0,
    "focus on contrastive analysis": 1.0,
    "on contrastive analysis of": 1.0,
    "contrastive analysis of outputs": 1.0,
    "analysis of outputs of": 1.0,
    "of outputs of several": 1.0,
    "outputs of several summarization": 1.0,
    "of several summarization systems": 1.0,
    "several summarization systems .": 1.0,
    "<s> human judgement often": 1.0,
    "human judgement often has": 1.0,
    "judgement often has wide": 1.0,
    "often has wide variance": 1.0,
    "has wide variance on": 1.0,
    "wide variance on what": 1.0,
    "variance on what is": 1.0,
    "on what is considered": 1.0,
    "what is considered a": 1.0,
    "is considered a ``": 1.0,
    "considered a `` good": 1.0,
    "a `` good ''": 1.0,
    "`` good '' summary": 1.0,
    "good '' summary ,": 1.0,
    "'' summary , which": 1.0,
    "summary , which means": 1.0,
    "which means that making": 0.3333333333333333,
    "means that making the": 1.0,
    "that making the evaluation": 1.0,
    "making the evaluation process": 1.0,
    "the evaluation process automatic": 1.0,
    "evaluation process automatic is": 1.0,
    "process automatic is particularly": 1.0,
    "automatic is particularly difficult": 1.0,
    "is particularly difficult .": 1.0,
    "<s> manual evaluation can": 0.5,
    "manual evaluation can be": 1.0,
    "evaluation can be used": 0.5,
    "can be used ,": 0.2,
    "be used , but": 0.5,
    "used , but this": 1.0,
    ", but this is": 0.3333333333333333,
    "but this is both": 1.0,
    "this is both time": 1.0,
    "is both time and": 1.0,
    "both time and labor": 1.0,
    "time and labor intensive": 1.0,
    "and labor intensive as": 1.0,
    "labor intensive as it": 1.0,
    "intensive as it requires": 1.0,
    "as it requires humans": 1.0,
    "it requires humans to": 1.0,
    "requires humans to read": 1.0,
    "humans to read not": 1.0,
    "to read not only": 1.0,
    "read not only the": 1.0,
    "not only the summaries": 0.5,
    "only the summaries but": 1.0,
    "the summaries but also": 1.0,
    "summaries but also the": 1.0,
    "but also the source": 0.5,
    "also the source documents": 1.0,
    "the source documents .": 1.0,
    "<s> other issues are": 1.0,
    "other issues are those": 1.0,
    "issues are those concerning": 1.0,
    "are those concerning coherence": 1.0,
    "those concerning coherence and": 1.0,
    "concerning coherence and coverage": 1.0,
    "coherence and coverage .": 1.0,
    "<s> one of the": 1.0,
    "one of the metrics": 0.08333333333333333,
    "of the metrics used": 1.0,
    "the metrics used in": 1.0,
    "metrics used in nist": 1.0,
    "used in nist 's": 1.0,
    "in nist 's annual": 1.0,
    "nist 's annual document": 1.0,
    "'s annual document understanding": 1.0,
    "annual document understanding conferences": 1.0,
    "document understanding conferences ,": 1.0,
    "understanding conferences , in": 1.0,
    "conferences , in which": 1.0,
    ", in which research": 1.0,
    "in which research groups": 1.0,
    "which research groups submit": 1.0,
    "research groups submit their": 1.0,
    "groups submit their systems": 1.0,
    "submit their systems for": 1.0,
    "their systems for both": 1.0,
    "systems for both summarization": 1.0,
    "for both summarization and": 1.0,
    "both summarization and translation": 1.0,
    "summarization and translation tasks": 1.0,
    "and translation tasks ,": 1.0,
    "translation tasks , is": 1.0,
    "tasks , is the": 1.0,
    ", is the rouge": 0.16666666666666666,
    "is the rouge metric": 1.0,
    "the rouge metric -lrb-": 1.0,
    "rouge metric -lrb- recall-oriented": 1.0,
    "metric -lrb- recall-oriented understudy": 1.0,
    "gisting evaluation -rrb- .": 0.5,
    "<s> it essentially calculates": 1.0,
    "it essentially calculates n-gram": 1.0,
    "essentially calculates n-gram overlaps": 1.0,
    "calculates n-gram overlaps between": 1.0,
    "n-gram overlaps between automatically": 1.0,
    "overlaps between automatically generated": 1.0,
    "between automatically generated summaries": 1.0,
    "automatically generated summaries and": 1.0,
    "generated summaries and previously-written": 1.0,
    "summaries and previously-written human": 1.0,
    "and previously-written human summaries": 1.0,
    "previously-written human summaries .": 1.0,
    "<s> a high level": 1.0,
    "a high level of": 1.0,
    "high level of overlap": 0.3333333333333333,
    "level of overlap should": 1.0,
    "of overlap should indicate": 1.0,
    "overlap should indicate a": 1.0,
    "should indicate a high": 1.0,
    "indicate a high level": 1.0,
    "high level of shared": 0.3333333333333333,
    "level of shared concepts": 1.0,
    "of shared concepts between": 1.0,
    "shared concepts between the": 1.0,
    "concepts between the two": 1.0,
    "between the two summaries": 0.3333333333333333,
    "the two summaries .": 1.0,
    "<s> note that overlap": 0.14285714285714285,
    "note that overlap metrics": 1.0,
    "that overlap metrics like": 1.0,
    "overlap metrics like this": 1.0,
    "metrics like this are": 1.0,
    "like this are unable": 1.0,
    "this are unable to": 1.0,
    "are unable to provide": 1.0,
    "unable to provide any": 1.0,
    "to provide any feedback": 1.0,
    "provide any feedback on": 1.0,
    "any feedback on a": 1.0,
    "feedback on a summary": 1.0,
    "on a summary 's": 1.0,
    "a summary 's coherence": 1.0,
    "summary 's coherence .": 1.0,
    "<s> anaphor resolution remains": 1.0,
    "anaphor resolution remains another": 1.0,
    "resolution remains another problem": 1.0,
    "remains another problem yet": 1.0,
    "another problem yet to": 1.0,
    "problem yet to be": 1.0,
    "yet to be fully": 1.0,
    "to be fully solved": 1.0,
    "be fully solved .": 1.0,
    "<s> evaluating summaries ,": 0.5,
    "evaluating summaries , either": 1.0,
    "summaries , either manually": 1.0,
    ", either manually or": 1.0,
    "either manually or automatically": 1.0,
    "manually or automatically ,": 1.0,
    "or automatically , is": 1.0,
    "automatically , is a": 1.0,
    ", is a hard": 0.25,
    "is a hard task": 0.5,
    "a hard task .": 1.0,
    "main difficulty in evaluation": 0.5,
    "difficulty in evaluation comes": 1.0,
    "in evaluation comes from": 1.0,
    "evaluation comes from the": 1.0,
    "comes from the impossibility": 1.0,
    "from the impossibility of": 1.0,
    "the impossibility of building": 1.0,
    "impossibility of building a": 1.0,
    "of building a fair": 1.0,
    "building a fair gold-standard": 1.0,
    "a fair gold-standard against": 1.0,
    "fair gold-standard against which": 1.0,
    "gold-standard against which the": 1.0,
    "against which the results": 1.0,
    "which the results of": 1.0,
    "the results of the": 1.0,
    "results of the systems": 1.0,
    "of the systems can": 1.0,
    "the systems can be": 1.0,
    "systems can be compared": 0.5,
    "can be compared .": 1.0,
    "<s> furthermore , it": 0.16666666666666666,
    "furthermore , it is": 1.0,
    ", it is also": 0.07692307692307693,
    "it is also very": 0.5,
    "is also very hard": 0.5,
    "also very hard to": 1.0,
    "very hard to determine": 1.0,
    "hard to determine what": 1.0,
    "to determine what a": 1.0,
    "determine what a correct": 1.0,
    "what a correct summary": 1.0,
    "a correct summary is": 1.0,
    "correct summary is ,": 1.0,
    "summary is , because": 1.0,
    "is , because there": 1.0,
    ", because there is": 0.5,
    "because there is always": 1.0,
    "there is always the": 1.0,
    "is always the possibility": 1.0,
    "always the possibility of": 1.0,
    "the possibility of a": 0.3333333333333333,
    "possibility of a system": 1.0,
    "of a system to": 0.25,
    "a system to generate": 1.0,
    "system to generate a": 1.0,
    "to generate a good": 1.0,
    "generate a good summary": 1.0,
    "a good summary that": 1.0,
    "good summary that is": 1.0,
    "summary that is quite": 0.5,
    "that is quite different": 1.0,
    "is quite different from": 1.0,
    "quite different from any": 0.5,
    "different from any human": 1.0,
    "from any human summary": 1.0,
    "any human summary used": 1.0,
    "human summary used as": 1.0,
    "summary used as an": 1.0,
    "used as an approximation": 1.0,
    "as an approximation to": 1.0,
    "an approximation to the": 1.0,
    "approximation to the correct": 0.5,
    "to the correct output": 1.0,
    "the correct output .": 1.0,
    "<s> current difficulties in": 1.0,
    "current difficulties in evaluating": 1.0,
    "difficulties in evaluating summaries": 1.0,
    "in evaluating summaries automatically": 1.0,
    "evaluating summaries automatically the": 1.0,
    "summaries automatically the most": 1.0,
    "automatically the most common": 1.0,
    "most common way to": 0.5,
    "common way to evaluate": 1.0,
    "way to evaluate the": 0.5,
    "to evaluate the informativeness": 0.5,
    "evaluate the informativeness of": 1.0,
    "the informativeness of automatic": 1.0,
    "informativeness of automatic summaries": 1.0,
    "of automatic summaries is": 0.5,
    "automatic summaries is to": 1.0,
    "summaries is to compare": 1.0,
    "is to compare them": 1.0,
    "to compare them with": 1.0,
    "compare them with human-made": 1.0,
    "them with human-made model": 1.0,
    "with human-made model summaries": 1.0,
    "human-made model summaries .": 1.0,
    "<s> however , as": 0.03125,
    "however , as content": 1.0,
    ", as content selection": 1.0,
    "as content selection is": 1.0,
    "content selection is not": 1.0,
    "selection is not a": 1.0,
    "is not a deterministic": 1.0,
    "not a deterministic problem": 1.0,
    "a deterministic problem ,": 1.0,
    "deterministic problem , different": 1.0,
    "problem , different people": 1.0,
    ", different people would": 1.0,
    "different people would choose": 1.0,
    "people would choose different": 1.0,
    "would choose different sentences": 1.0,
    "choose different sentences ,": 1.0,
    "different sentences , and": 1.0,
    "sentences , and even": 0.5,
    ", and even ,": 0.16666666666666666,
    "and even , the": 1.0,
    "even , the same": 1.0,
    ", the same person": 1.0,
    "the same person may": 1.0,
    "same person may chose": 1.0,
    "person may chose different": 1.0,
    "may chose different sentences": 1.0,
    "chose different sentences at": 1.0,
    "different sentences at different": 1.0,
    "sentences at different times": 1.0,
    "at different times ,": 1.0,
    "different times , showing": 1.0,
    "times , showing evidence": 1.0,
    ", showing evidence of": 1.0,
    "showing evidence of low": 1.0,
    "evidence of low agreement": 1.0,
    "of low agreement among": 1.0,
    "low agreement among humans": 1.0,
    "agreement among humans as": 1.0,
    "among humans as to": 1.0,
    "humans as to which": 1.0,
    "as to which sentences": 0.5,
    "to which sentences are": 1.0,
    "which sentences are good": 1.0,
    "sentences are good summary": 1.0,
    "are good summary sentences": 1.0,
    "good summary sentences .": 1.0,
    "<s> besides the human": 1.0,
    "besides the human variability": 1.0,
    "the human variability ,": 1.0,
    "human variability , the": 1.0,
    "variability , the semantic": 1.0,
    ", the semantic equivalence": 1.0,
    "the semantic equivalence is": 1.0,
    "semantic equivalence is another": 1.0,
    "equivalence is another problem": 1.0,
    "is another problem ,": 1.0,
    "another problem , because": 1.0,
    "problem , because two": 1.0,
    ", because two distinct": 1.0,
    "because two distinct sentences": 1.0,
    "two distinct sentences can": 1.0,
    "distinct sentences can express": 1.0,
    "sentences can express the": 1.0,
    "can express the same": 0.5,
    "express the same meaning": 1.0,
    "the same meaning but": 1.0,
    "same meaning but not": 1.0,
    "meaning but not using": 1.0,
    "but not using the": 1.0,
    "not using the same": 1.0,
    "using the same words": 1.0,
    "the same words .": 1.0,
    "<s> this phenomenon is": 0.5,
    "this phenomenon is known": 1.0,
    "phenomenon is known as": 1.0,
    "is known as paraphrase": 1.0,
    "known as paraphrase .": 1.0,
    "<s> we can find": 0.5,
    "we can find an": 1.0,
    "can find an approach": 1.0,
    "find an approach to": 1.0,
    "an approach to automatically": 1.0,
    "approach to automatically evaluating": 1.0,
    "to automatically evaluating summaries": 1.0,
    "automatically evaluating summaries using": 1.0,
    "evaluating summaries using paraphrases": 1.0,
    "summaries using paraphrases -lrb-": 1.0,
    "using paraphrases -lrb- paraeval": 1.0,
    "paraphrases -lrb- paraeval -rrb-": 1.0,
    "-lrb- paraeval -rrb- .": 1.0,
    "<s> moreover , most": 0.25,
    "moreover , most summarization": 1.0,
    ", most summarization systems": 1.0,
    "most summarization systems perform": 1.0,
    "summarization systems perform an": 1.0,
    "systems perform an extractive": 1.0,
    "perform an extractive approach": 1.0,
    "an extractive approach ,": 1.0,
    "extractive approach , selecting": 1.0,
    "approach , selecting and": 1.0,
    ", selecting and copying": 1.0,
    "selecting and copying important": 1.0,
    "and copying important sentences": 1.0,
    "copying important sentences from": 1.0,
    "important sentences from the": 1.0,
    "sentences from the source": 1.0,
    "from the source documents": 1.0,
    "<s> although humans can": 1.0,
    "although humans can also": 1.0,
    "humans can also cut": 1.0,
    "can also cut and": 1.0,
    "also cut and paste": 1.0,
    "cut and paste relevant": 1.0,
    "and paste relevant information": 1.0,
    "paste relevant information of": 1.0,
    "relevant information of a": 1.0,
    "information of a text": 1.0,
    "a text , most": 0.25,
    "text , most of": 1.0,
    ", most of the": 1.0,
    "most of the times": 0.3333333333333333,
    "of the times they": 1.0,
    "the times they rephrase": 1.0,
    "times they rephrase sentences": 1.0,
    "they rephrase sentences when": 1.0,
    "rephrase sentences when necessary": 1.0,
    "sentences when necessary ,": 1.0,
    "when necessary , or": 1.0,
    "necessary , or they": 1.0,
    ", or they join": 1.0,
    "or they join different": 1.0,
    "they join different related": 1.0,
    "join different related information": 1.0,
    "different related information into": 1.0,
    "related information into one": 1.0,
    "information into one sentence": 1.0,
    "into one sentence .": 1.0,
    "<s> evaluating summaries qualitatively": 0.5,
    "evaluating summaries qualitatively the": 1.0,
    "summaries qualitatively the main": 1.0,
    "qualitatively the main drawback": 1.0,
    "the main drawback of": 1.0,
    "main drawback of the": 1.0,
    "drawback of the evaluation": 1.0,
    "of the evaluation systems": 1.0,
    "the evaluation systems existing": 1.0,
    "evaluation systems existing so": 1.0,
    "systems existing so far": 1.0,
    "existing so far is": 1.0,
    "so far is that": 1.0,
    "far is that we": 1.0,
    "is that we need": 1.0,
    "that we need at": 1.0,
    "we need at least": 1.0,
    "need at least one": 1.0,
    "at least one reference": 1.0,
    "least one reference summary": 1.0,
    "one reference summary ,": 1.0,
    "reference summary , and": 0.5,
    "summary , and for": 0.5,
    ", and for some": 1.0,
    "and for some methods": 1.0,
    "for some methods more": 0.5,
    "some methods more than": 1.0,
    "methods more than one": 1.0,
    "more than one ,": 0.3333333333333333,
    "than one , to": 1.0,
    "one , to be": 1.0,
    ", to be able": 1.0,
    "be able to compare": 0.2,
    "able to compare automatic": 1.0,
    "to compare automatic summaries": 1.0,
    "compare automatic summaries with": 1.0,
    "automatic summaries with models": 1.0,
    "summaries with models .": 1.0,
    "this is a hard": 0.5,
    "is a hard and": 0.5,
    "a hard and expensive": 1.0,
    "hard and expensive task": 1.0,
    "and expensive task .": 1.0,
    "<s> much effort has": 1.0,
    "much effort has to": 1.0,
    "effort has to be": 1.0,
    "has to be done": 0.25,
    "to be done in": 0.3333333333333333,
    "be done in order": 0.5,
    "done in order to": 1.0,
    "in order to have": 0.125,
    "order to have corpus": 1.0,
    "to have corpus of": 1.0,
    "have corpus of texts": 1.0,
    "corpus of texts and": 1.0,
    "of texts and their": 1.0,
    "texts and their corresponding": 1.0,
    "and their corresponding summaries": 1.0,
    "their corresponding summaries .": 1.0,
    "<s> furthermore , for": 0.16666666666666666,
    "furthermore , for some": 1.0,
    ", for some methods": 1.0,
    "for some methods presented": 0.5,
    "some methods presented in": 1.0,
    "methods presented in the": 1.0,
    "presented in the previous": 1.0,
    "in the previous section": 1.0,
    "the previous section ,": 1.0,
    "previous section , not": 1.0,
    "section , not only": 1.0,
    ", not only do": 0.5,
    "not only do we": 1.0,
    "only do we need": 1.0,
    "do we need to": 1.0,
    "need to have human-made": 0.5,
    "to have human-made summaries": 1.0,
    "have human-made summaries available": 1.0,
    "human-made summaries available for": 1.0,
    "summaries available for comparison": 1.0,
    "available for comparison ,": 1.0,
    "for comparison , but": 1.0,
    "comparison , but also": 1.0,
    ", but also manual": 0.3333333333333333,
    "but also manual annotation": 1.0,
    "also manual annotation has": 1.0,
    "manual annotation has to": 1.0,
    "annotation has to be": 1.0,
    "has to be performed": 0.25,
    "to be performed in": 1.0,
    "be performed in some": 1.0,
    "performed in some of": 1.0,
    "in some of them": 1.0,
    "some of them -lrb-": 1.0,
    "of them -lrb- e.g.": 1.0,
    "them -lrb- e.g. scu": 1.0,
    "-lrb- e.g. scu in": 1.0,
    "e.g. scu in the": 1.0,
    "scu in the pyramid": 1.0,
    "in the pyramid method": 1.0,
    "the pyramid method -rrb-": 1.0,
    "pyramid method -rrb- .": 1.0,
    "<s> in any case": 1.0,
    "in any case ,": 0.6666666666666666,
    "any case , what": 0.5,
    "case , what the": 1.0,
    ", what the evaluation": 1.0,
    "what the evaluation methods": 1.0,
    "the evaluation methods need": 1.0,
    "evaluation methods need as": 1.0,
    "methods need as an": 1.0,
    "need as an input": 1.0,
    "as an input ,": 1.0,
    "an input , is": 1.0,
    "input , is a": 1.0,
    ", is a set": 0.25,
    "a set of summaries": 0.07142857142857142,
    "set of summaries to": 1.0,
    "of summaries to serve": 1.0,
    "summaries to serve as": 1.0,
    "to serve as gold": 1.0,
    "serve as gold standards": 1.0,
    "as gold standards and": 1.0,
    "gold standards and a": 1.0,
    "standards and a set": 1.0,
    "and a set of": 1.0,
    "a set of automatic": 0.07142857142857142,
    "set of automatic summaries": 1.0,
    "of automatic summaries .": 0.5,
    "<s> moreover , they": 0.25,
    "moreover , they all": 1.0,
    ", they all perform": 0.5,
    "they all perform a": 1.0,
    "all perform a quantitative": 1.0,
    "perform a quantitative evaluation": 1.0,
    "a quantitative evaluation with": 1.0,
    "quantitative evaluation with regard": 1.0,
    "evaluation with regard to": 1.0,
    "with regard to different": 0.25,
    "regard to different similarity": 1.0,
    "to different similarity metrics": 1.0,
    "different similarity metrics .": 1.0,
    "<s> to overcome these": 1.0,
    "to overcome these problems": 1.0,
    "overcome these problems ,": 1.0,
    "these problems , we": 1.0,
    "problems , we think": 1.0,
    ", we think that": 1.0,
    "we think that the": 1.0,
    "think that the quantitative": 1.0,
    "that the quantitative evaluation": 1.0,
    "the quantitative evaluation might": 1.0,
    "quantitative evaluation might not": 1.0,
    "evaluation might not be": 1.0,
    "might not be the": 1.0,
    "not be the only": 1.0,
    "be the only way": 1.0,
    "the only way to": 1.0,
    "only way to evaluate": 1.0,
    "way to evaluate summaries": 0.5,
    "to evaluate summaries ,": 1.0,
    "evaluate summaries , and": 1.0,
    "summaries , and a": 1.0,
    ", and a qualitative": 0.16666666666666666,
    "and a qualitative automatic": 1.0,
    "a qualitative automatic evaluation": 1.0,
    "qualitative automatic evaluation would": 1.0,
    "automatic evaluation would be": 1.0,
    "evaluation would be also": 1.0,
    "would be also important": 1.0,
    "be also important .": 1.0,
    "<s> therefore , the": 0.5,
    "therefore , the second": 1.0,
    ", the second aim": 1.0,
    "the second aim of": 1.0,
    "second aim of this": 1.0,
    "aim of this paper": 1.0,
    "of this paper is": 1.0,
    "this paper is to": 1.0,
    "paper is to suggest": 1.0,
    "is to suggest a": 1.0,
    "to suggest a novel": 1.0,
    "suggest a novel proposal": 1.0,
    "a novel proposal for": 1.0,
    "novel proposal for evaluating": 1.0,
    "proposal for evaluating automatically": 1.0,
    "for evaluating automatically the": 1.0,
    "evaluating automatically the quality": 1.0,
    "automatically the quality of": 1.0,
    "quality of a summary": 0.3333333333333333,
    "of a summary in": 1.0,
    "a summary in a": 1.0,
    "summary in a qualitative": 1.0,
    "in a qualitative manner": 1.0,
    "a qualitative manner rather": 1.0,
    "qualitative manner rather than": 1.0,
    "manner rather than in": 1.0,
    "rather than in a": 1.0,
    "than in a quantitative": 1.0,
    "in a quantitative one": 1.0,
    "a quantitative one .": 1.0,
    "<s> our evaluation approach": 1.0,
    "our evaluation approach is": 1.0,
    "evaluation approach is a": 1.0,
    "approach is a preliminary": 1.0,
    "is a preliminary approach": 1.0,
    "a preliminary approach which": 1.0,
    "preliminary approach which has": 1.0,
    "approach which has to": 1.0,
    "which has to be": 1.0,
    "has to be studied": 0.25,
    "to be studied more": 1.0,
    "be studied more deeply": 1.0,
    "studied more deeply ,": 1.0,
    "more deeply , and": 1.0,
    "deeply , and developed": 1.0,
    ", and developed in": 1.0,
    "and developed in the": 1.0,
    "developed in the future": 0.16666666666666666,
    "in the future .": 1.0,
    "<s> its main underlying": 1.0,
    "its main underlying idea": 1.0,
    "main underlying idea is": 1.0,
    "underlying idea is to": 1.0,
    "idea is to define": 1.0,
    "is to define several": 1.0,
    "to define several quality": 1.0,
    "define several quality criteria": 1.0,
    "several quality criteria and": 1.0,
    "quality criteria and check": 1.0,
    "criteria and check how": 1.0,
    "and check how a": 1.0,
    "check how a generated": 1.0,
    "how a generated summary": 1.0,
    "a generated summary tackles": 1.0,
    "generated summary tackles each": 1.0,
    "summary tackles each of": 1.0,
    "tackles each of these": 1.0,
    "each of these ,": 1.0,
    "of these , in": 1.0,
    "these , in such": 1.0,
    ", in such a": 1.0,
    "in such a way": 0.5,
    "such a way that": 1.0,
    "a way that a": 1.0,
    "way that a reference": 1.0,
    "that a reference model": 1.0,
    "a reference model would": 1.0,
    "reference model would not": 1.0,
    "model would not be": 1.0,
    "would not be necessary": 1.0,
    "not be necessary anymore": 1.0,
    "be necessary anymore ,": 1.0,
    "necessary anymore , taking": 1.0,
    "anymore , taking only": 1.0,
    ", taking only into": 1.0,
    "taking only into consideration": 1.0,
    "only into consideration the": 1.0,
    "into consideration the automatic": 1.0,
    "consideration the automatic summary": 1.0,
    "the automatic summary and": 1.0,
    "automatic summary and the": 0.5,
    "summary and the original": 1.0,
    "and the original source": 1.0,
    "the original source .": 1.0,
    "<s> once performed ,": 0.5,
    "once performed , it": 1.0,
    "performed , it could": 1.0,
    ", it could be": 1.0,
    "it could be used": 1.0,
    "could be used together": 0.3333333333333333,
    "be used together with": 1.0,
    "used together with any": 1.0,
    "together with any other": 1.0,
    "with any other automatic": 1.0,
    "any other automatic methodology": 1.0,
    "other automatic methodology to": 1.0,
    "automatic methodology to measure": 1.0,
    "methodology to measure summary": 1.0,
    "to measure summary 's": 1.0,
    "measure summary 's informativeness": 1.0,
    "summary 's informativeness .": 1.0,
    "natural language generation -lrb-": 0.2,
    "language generation -lrb- nlg": 1.0,
    "generation -lrb- nlg -rrb-": 1.0,
    "-lrb- nlg -rrb- is": 1.0,
    "nlg -rrb- is the": 1.0,
    "-rrb- is the natural": 0.3333333333333333,
    "is the natural language": 1.0,
    "the natural language processing": 1.0,
    "natural language processing task": 0.03571428571428571,
    "language processing task of": 1.0,
    "processing task of generating": 1.0,
    "task of generating natural": 1.0,
    "of generating natural language": 1.0,
    "generating natural language from": 1.0,
    "natural language from a": 1.0,
    "language from a machine": 1.0,
    "from a machine representation": 1.0,
    "a machine representation system": 1.0,
    "machine representation system such": 1.0,
    "representation system such as": 1.0,
    "system such as a": 1.0,
    "such as a knowledge": 0.3333333333333333,
    "as a knowledge base": 1.0,
    "a knowledge base or": 1.0,
    "knowledge base or a": 1.0,
    "base or a logical": 1.0,
    "or a logical form": 1.0,
    "a logical form .": 1.0,
    "<s> psycholinguists prefer the": 1.0,
    "psycholinguists prefer the term": 1.0,
    "prefer the term language": 1.0,
    "the term language production": 1.0,
    "term language production when": 1.0,
    "language production when such": 1.0,
    "production when such formal": 1.0,
    "when such formal representations": 1.0,
    "such formal representations are": 1.0,
    "formal representations are interpreted": 1.0,
    "representations are interpreted as": 1.0,
    "are interpreted as models": 1.0,
    "interpreted as models for": 1.0,
    "as models for mental": 1.0,
    "models for mental representations": 1.0,
    "for mental representations .": 1.0,
    "<s> in a sense": 0.5,
    "in a sense ,": 1.0,
    "a sense , one": 1.0,
    "sense , one can": 1.0,
    ", one can say": 1.0,
    "one can say that": 1.0,
    "can say that an": 1.0,
    "say that an nlg": 1.0,
    "that an nlg system": 1.0,
    "an nlg system is": 1.0,
    "nlg system is like": 1.0,
    "system is like a": 1.0,
    "is like a translator": 0.5,
    "like a translator that": 1.0,
    "a translator that converts": 1.0,
    "translator that converts a": 1.0,
    "that converts a computer": 1.0,
    "converts a computer based": 1.0,
    "a computer based representation": 1.0,
    "computer based representation into": 1.0,
    "based representation into a": 1.0,
    "representation into a natural": 1.0,
    "into a natural language": 1.0,
    "a natural language representation": 0.25,
    "natural language representation .": 1.0,
    "however , the methods": 0.5,
    ", the methods to": 1.0,
    "the methods to produce": 1.0,
    "methods to produce the": 1.0,
    "to produce the final": 0.5,
    "produce the final language": 1.0,
    "the final language are": 1.0,
    "final language are very": 1.0,
    "language are very different": 1.0,
    "are very different from": 1.0,
    "very different from those": 1.0,
    "different from those of": 1.0,
    "from those of a": 1.0,
    "those of a compiler": 1.0,
    "of a compiler due": 0.5,
    "a compiler due to": 1.0,
    "compiler due to the": 1.0,
    "due to the inherent": 0.5,
    "to the inherent expressivity": 1.0,
    "the inherent expressivity of": 1.0,
    "inherent expressivity of natural": 1.0,
    "expressivity of natural languages": 1.0,
    "of natural languages .": 0.2,
    "<s> nlg may be": 1.0,
    "nlg may be viewed": 1.0,
    "may be viewed as": 1.0,
    "be viewed as the": 0.25,
    "viewed as the opposite": 1.0,
    "as the opposite of": 1.0,
    "the opposite of natural": 0.5,
    "opposite of natural language": 1.0,
    "natural language understanding .": 0.16666666666666666,
    "<s> the difference can": 1.0,
    "the difference can be": 1.0,
    "difference can be put": 1.0,
    "can be put this": 1.0,
    "be put this way": 1.0,
    "put this way :": 1.0,
    "this way : whereas": 1.0,
    "way : whereas in": 1.0,
    ": whereas in natural": 1.0,
    "whereas in natural language": 1.0,
    "in natural language understanding": 0.3333333333333333,
    "natural language understanding the": 0.08333333333333333,
    "language understanding the system": 1.0,
    "understanding the system needs": 1.0,
    "the system needs to": 0.6666666666666666,
    "system needs to disambiguate": 0.3333333333333333,
    "needs to disambiguate the": 1.0,
    "to disambiguate the input": 1.0,
    "disambiguate the input sentence": 1.0,
    "the input sentence to": 1.0,
    "input sentence to produce": 1.0,
    "sentence to produce the": 1.0,
    "to produce the machine": 0.5,
    "produce the machine representation": 1.0,
    "the machine representation language": 1.0,
    "machine representation language ,": 1.0,
    "representation language , in": 1.0,
    "language , in nlg": 1.0,
    ", in nlg the": 1.0,
    "in nlg the system": 1.0,
    "nlg the system needs": 1.0,
    "system needs to make": 0.3333333333333333,
    "needs to make decisions": 1.0,
    "to make decisions about": 1.0,
    "make decisions about how": 1.0,
    "decisions about how to": 1.0,
    "about how to put": 1.0,
    "how to put a": 1.0,
    "to put a concept": 1.0,
    "put a concept into": 1.0,
    "a concept into words": 1.0,
    "concept into words .": 1.0,
    "<s> the simplest -lrb-": 1.0,
    "the simplest -lrb- and": 1.0,
    "simplest -lrb- and perhaps": 1.0,
    "-lrb- and perhaps trivial": 1.0,
    "and perhaps trivial -rrb-": 1.0,
    "perhaps trivial -rrb- examples": 1.0,
    "trivial -rrb- examples are": 1.0,
    "-rrb- examples are systems": 1.0,
    "examples are systems that": 1.0,
    "are systems that generate": 0.3333333333333333,
    "systems that generate form": 1.0,
    "that generate form letters": 1.0,
    "generate form letters .": 1.0,
    "<s> such systems do": 1.0,
    "such systems do not": 1.0,
    "systems do not typically": 1.0,
    "do not typically involve": 1.0,
    "not typically involve grammar": 1.0,
    "typically involve grammar rules": 1.0,
    "involve grammar rules ,": 1.0,
    "grammar rules , but": 1.0,
    "rules , but may": 1.0,
    ", but may generate": 1.0,
    "but may generate a": 1.0,
    "may generate a letter": 1.0,
    "generate a letter to": 1.0,
    "a letter to a": 1.0,
    "letter to a consumer": 1.0,
    "to a consumer ,": 1.0,
    "a consumer , e.g.": 1.0,
    "consumer , e.g. stating": 1.0,
    ", e.g. stating that": 1.0,
    "e.g. stating that a": 1.0,
    "stating that a credit": 1.0,
    "that a credit card": 1.0,
    "a credit card spending": 0.5,
    "credit card spending limit": 1.0,
    "card spending limit is": 1.0,
    "spending limit is about": 1.0,
    "limit is about to": 1.0,
    "is about to be": 1.0,
    "about to be reached": 1.0,
    "to be reached .": 1.0,
    "<s> more complex nlg": 1.0,
    "more complex nlg systems": 1.0,
    "complex nlg systems dynamically": 1.0,
    "nlg systems dynamically create": 1.0,
    "systems dynamically create texts": 1.0,
    "dynamically create texts to": 1.0,
    "create texts to meet": 1.0,
    "texts to meet a": 1.0,
    "to meet a communicative": 1.0,
    "meet a communicative goal": 1.0,
    "a communicative goal .": 1.0,
    "<s> as in other": 0.3333333333333333,
    "as in other areas": 0.6666666666666666,
    "in other areas of": 1.0,
    "other areas of natural": 0.5,
    "areas of natural language": 1.0,
    "natural language processing ,": 0.17857142857142858,
    "language processing , this": 0.16666666666666666,
    "processing , this can": 1.0,
    ", this can be": 1.0,
    "this can be done": 1.0,
    "can be done using": 0.5,
    "be done using either": 1.0,
    "done using either explicit": 1.0,
    "using either explicit models": 1.0,
    "either explicit models of": 1.0,
    "explicit models of language": 1.0,
    "models of language -lrb-": 1.0,
    "of language -lrb- e.g.": 1.0,
    "language -lrb- e.g. ,": 1.0,
    "-lrb- e.g. , grammars": 0.05263157894736842,
    "e.g. , grammars -rrb-": 1.0,
    ", grammars -rrb- and": 1.0,
    "grammars -rrb- and the": 1.0,
    "-rrb- and the domain": 0.2,
    "and the domain ,": 1.0,
    "the domain , or": 1.0,
    "domain , or using": 1.0,
    ", or using statistical": 0.5,
    "or using statistical models": 1.0,
    "using statistical models derived": 1.0,
    "statistical models derived by": 1.0,
    "models derived by analyzing": 1.0,
    "derived by analyzing human-written": 0.5,
    "by analyzing human-written texts": 1.0,
    "analyzing human-written texts .": 1.0,
    "<s> nlg is a": 1.0,
    "nlg is a fast-evolving": 1.0,
    "is a fast-evolving field": 1.0,
    "a fast-evolving field .": 1.0,
    "<s> the best single": 1.0,
    "the best single source": 1.0,
    "best single source for": 1.0,
    "single source for up-to-date": 1.0,
    "source for up-to-date research": 1.0,
    "for up-to-date research in": 1.0,
    "up-to-date research in the": 1.0,
    "research in the area": 0.5,
    "in the area is": 1.0,
    "the area is the": 1.0,
    "area is the siggen": 1.0,
    "is the siggen portion": 1.0,
    "the siggen portion of": 1.0,
    "siggen portion of the": 1.0,
    "portion of the acl": 0.5,
    "of the acl anthology": 1.0,
    "the acl anthology .": 1.0,
    "<s> perhaps the closest": 1.0,
    "perhaps the closest the": 1.0,
    "the closest the field": 1.0,
    "closest the field comes": 1.0,
    "the field comes to": 1.0,
    "field comes to a": 1.0,
    "comes to a specialist": 1.0,
    "to a specialist textbook": 1.0,
    "a specialist textbook is": 1.0,
    "specialist textbook is reiter": 1.0,
    "textbook is reiter and": 1.0,
    "is reiter and dale": 1.0,
    "reiter and dale -lrb-": 1.0,
    "and dale -lrb- 2000": 1.0,
    "dale -lrb- 2000 -rrb-": 1.0,
    "-lrb- 2000 -rrb- ,": 1.0,
    "2000 -rrb- , but": 1.0,
    "-rrb- , but this": 0.3333333333333333,
    ", but this book": 0.3333333333333333,
    "but this book does": 1.0,
    "this book does not": 1.0,
    "book does not describe": 1.0,
    "does not describe developments": 1.0,
    "not describe developments in": 1.0,
    "describe developments in the": 1.0,
    "developments in the field": 1.0,
    "in the field since": 0.08333333333333333,
    "the field since 2000": 1.0,
    "field since 2000 .": 1.0,
    "<s> this system takes": 1.0,
    "this system takes as": 1.0,
    "system takes as input": 1.0,
    "takes as input six": 1.0,
    "as input six numbers": 1.0,
    "input six numbers ,": 1.0,
    "six numbers , which": 1.0,
    "numbers , which give": 1.0,
    ", which give predicted": 1.0,
    "which give predicted pollen": 1.0,
    "give predicted pollen levels": 1.0,
    "predicted pollen levels in": 1.0,
    "pollen levels in different": 1.0,
    "levels in different parts": 1.0,
    "in different parts of": 1.0,
    "different parts of scotland": 0.5,
    "parts of scotland .": 1.0,
    "<s> from these numbers": 1.0,
    "from these numbers ,": 1.0,
    "these numbers , the": 1.0,
    "numbers , the system": 1.0,
    ", the system generates": 0.25,
    "the system generates a": 1.0,
    "system generates a short": 1.0,
    "generates a short textual": 1.0,
    "a short textual summary": 1.0,
    "short textual summary of": 1.0,
    "textual summary of pollen": 1.0,
    "summary of pollen levels": 1.0,
    "of pollen levels as": 1.0,
    "pollen levels as its": 1.0,
    "levels as its output": 1.0,
    "as its output .": 1.0,
    "for example , using": 0.0425531914893617,
    "example , using the": 0.5,
    ", using the historical": 1.0,
    "using the historical data": 1.0,
    "the historical data for": 1.0,
    "historical data for 1-july-2005": 1.0,
    "data for 1-july-2005 ,": 1.0,
    "for 1-july-2005 , the": 1.0,
    "1-july-2005 , the software": 1.0,
    ", the software produces": 1.0,
    "the software produces grass": 1.0,
    "software produces grass pollen": 1.0,
    "produces grass pollen levels": 1.0,
    "grass pollen levels for": 0.75,
    "pollen levels for friday": 1.0,
    "levels for friday have": 1.0,
    "for friday have increased": 1.0,
    "friday have increased from": 1.0,
    "have increased from the": 1.0,
    "increased from the moderate": 1.0,
    "from the moderate to": 1.0,
    "the moderate to high": 1.0,
    "moderate to high levels": 1.0,
    "to high levels of": 1.0,
    "high levels of yesterday": 1.0,
    "levels of yesterday with": 0.6666666666666666,
    "of yesterday with values": 1.0,
    "yesterday with values of": 1.0,
    "with values of around": 0.6666666666666666,
    "values of around 6": 1.0,
    "of around 6 to": 1.0,
    "around 6 to 7": 1.0,
    "6 to 7 across": 1.0,
    "to 7 across most": 1.0,
    "7 across most parts": 1.0,
    "across most parts of": 1.0,
    "most parts of the": 1.0,
    "parts of the country": 1.0,
    "of the country .": 0.6666666666666666,
    "<s> however , in": 0.09375,
    "however , in northern": 0.25,
    ", in northern areas": 1.0,
    "in northern areas ,": 1.0,
    "northern areas , pollen": 1.0,
    "areas , pollen levels": 1.0,
    ", pollen levels will": 1.0,
    "pollen levels will be": 1.0,
    "levels will be moderate": 0.5,
    "will be moderate with": 1.0,
    "be moderate with values": 1.0,
    "moderate with values of": 1.0,
    "with values of 4": 0.3333333333333333,
    "values of 4 .": 1.0,
    "in contrast , the": 0.2,
    "contrast , the actual": 1.0,
    ", the actual forecast": 1.0,
    "the actual forecast -lrb-": 1.0,
    "actual forecast -lrb- written": 1.0,
    "forecast -lrb- written by": 1.0,
    "-lrb- written by a": 1.0,
    "written by a human": 0.5,
    "by a human meteorologist": 0.3333333333333333,
    "a human meteorologist -rrb-": 1.0,
    "human meteorologist -rrb- from": 1.0,
    "meteorologist -rrb- from this": 1.0,
    "-rrb- from this data": 1.0,
    "from this data was": 1.0,
    "this data was pollen": 1.0,
    "data was pollen counts": 1.0,
    "was pollen counts are": 1.0,
    "pollen counts are expected": 1.0,
    "counts are expected to": 1.0,
    "are expected to remain": 1.0,
    "expected to remain high": 1.0,
    "to remain high at": 1.0,
    "remain high at level": 1.0,
    "high at level 6": 1.0,
    "at level 6 over": 1.0,
    "level 6 over most": 1.0,
    "6 over most of": 1.0,
    "over most of scotland": 1.0,
    "most of scotland ,": 1.0,
    "of scotland , and": 1.0,
    "scotland , and even": 1.0,
    ", and even level": 0.16666666666666666,
    "and even level 7": 1.0,
    "even level 7 in": 1.0,
    "level 7 in the": 1.0,
    "7 in the south": 1.0,
    "in the south east": 1.0,
    "the south east .": 1.0,
    "<s> the only relief": 0.5,
    "the only relief is": 1.0,
    "only relief is in": 1.0,
    "relief is in the": 1.0,
    "is in the northern": 1.0,
    "in the northern isles": 1.0,
    "the northern isles and": 1.0,
    "northern isles and far": 1.0,
    "isles and far northeast": 1.0,
    "and far northeast of": 1.0,
    "far northeast of mainland": 1.0,
    "northeast of mainland scotland": 1.0,
    "of mainland scotland with": 0.5,
    "mainland scotland with medium": 1.0,
    "scotland with medium levels": 1.0,
    "with medium levels of": 1.0,
    "medium levels of pollen": 1.0,
    "levels of pollen count": 1.0,
    "of pollen count .": 1.0,
    "<s> comparing these two": 1.0,
    "comparing these two illustrates": 1.0,
    "these two illustrates some": 1.0,
    "two illustrates some of": 1.0,
    "illustrates some of the": 1.0,
    "some of the choices": 0.1,
    "of the choices that": 1.0,
    "the choices that nlg": 1.0,
    "choices that nlg systems": 1.0,
    "that nlg systems must": 1.0,
    "nlg systems must make": 1.0,
    "systems must make ;": 1.0,
    "must make ; these": 1.0,
    "make ; these are": 1.0,
    "; these are further": 1.0,
    "these are further discussed": 1.0,
    "are further discussed below": 1.0,
    "further discussed below .": 1.0,
    "<s> stages the process": 1.0,
    "stages the process to": 1.0,
    "the process to generate": 0.5,
    "process to generate text": 1.0,
    "to generate text can": 1.0,
    "generate text can be": 1.0,
    "text can be as": 1.0,
    "can be as simple": 0.5,
    "as simple as keeping": 0.5,
    "simple as keeping a": 1.0,
    "as keeping a list": 1.0,
    "keeping a list of": 1.0,
    "a list of canned": 0.16666666666666666,
    "list of canned text": 1.0,
    "of canned text that": 1.0,
    "canned text that is": 1.0,
    "text that is copied": 1.0,
    "that is copied and": 1.0,
    "is copied and pasted": 1.0,
    "copied and pasted ,": 1.0,
    "and pasted , possibly": 1.0,
    "pasted , possibly linked": 1.0,
    ", possibly linked with": 1.0,
    "possibly linked with some": 1.0,
    "linked with some glue": 1.0,
    "with some glue text": 1.0,
    "some glue text .": 1.0,
    "<s> the results may": 1.0,
    "the results may be": 1.0,
    "results may be satisfactory": 1.0,
    "may be satisfactory in": 1.0,
    "be satisfactory in simple": 1.0,
    "satisfactory in simple domains": 1.0,
    "in simple domains such": 1.0,
    "simple domains such as": 1.0,
    "domains such as horoscope": 1.0,
    "such as horoscope machines": 1.0,
    "as horoscope machines or": 1.0,
    "horoscope machines or generators": 1.0,
    "machines or generators of": 1.0,
    "or generators of personalised": 1.0,
    "generators of personalised business": 1.0,
    "of personalised business letters": 1.0,
    "personalised business letters .": 1.0,
    "<s> however , a": 0.03125,
    "however , a sophisticated": 1.0,
    ", a sophisticated nlg": 1.0,
    "a sophisticated nlg system": 1.0,
    "sophisticated nlg system needs": 1.0,
    "nlg system needs to": 1.0,
    "system needs to include": 0.3333333333333333,
    "needs to include stages": 1.0,
    "to include stages of": 1.0,
    "include stages of planning": 1.0,
    "stages of planning and": 1.0,
    "of planning and merging": 1.0,
    "planning and merging of": 1.0,
    "and merging of information": 1.0,
    "merging of information to": 1.0,
    "of information to enable": 1.0,
    "information to enable the": 1.0,
    "to enable the generation": 1.0,
    "enable the generation of": 1.0,
    "the generation of text": 1.0,
    "generation of text that": 1.0,
    "of text that looks": 1.0,
    "text that looks natural": 1.0,
    "that looks natural and": 1.0,
    "looks natural and does": 1.0,
    "natural and does not": 1.0,
    "and does not become": 1.0,
    "does not become repetitive": 1.0,
    "not become repetitive .": 1.0,
    "<s> typical stages are": 1.0,
    "typical stages are :": 1.0,
    "stages are : content": 1.0,
    "are : content determination": 1.0,
    ": content determination :": 1.0,
    "content determination : deciding": 1.0,
    "determination : deciding what": 1.0,
    ": deciding what information": 1.0,
    "deciding what information to": 1.0,
    "what information to mention": 1.0,
    "information to mention in": 1.0,
    "to mention in the": 1.0,
    "mention in the text": 1.0,
    ", in the pollen": 0.125,
    "in the pollen example": 1.0,
    "the pollen example above": 1.0,
    "pollen example above ,": 1.0,
    "example above , deciding": 1.0,
    "above , deciding whether": 1.0,
    ", deciding whether to": 0.5,
    "deciding whether to explicitly": 1.0,
    "whether to explicitly mention": 1.0,
    "to explicitly mention that": 1.0,
    "explicitly mention that pollen": 1.0,
    "mention that pollen level": 1.0,
    "that pollen level is": 1.0,
    "pollen level is 7": 1.0,
    "level is 7 in": 1.0,
    "is 7 in the": 1.0,
    "<s> document structuring :": 1.0,
    "document structuring : overall": 1.0,
    "structuring : overall organization": 1.0,
    ": overall organization of": 1.0,
    "overall organization of the": 1.0,
    "organization of the information": 1.0,
    "of the information to": 0.5,
    "the information to convey": 1.0,
    "information to convey .": 1.0,
    "for example , deciding": 0.06382978723404255,
    "example , deciding to": 0.6666666666666666,
    ", deciding to describe": 0.5,
    "deciding to describe the": 1.0,
    "to describe the areas": 1.0,
    "describe the areas with": 1.0,
    "the areas with high": 0.5,
    "areas with high pollen": 1.0,
    "with high pollen levels": 1.0,
    "high pollen levels first": 1.0,
    "pollen levels first ,": 1.0,
    "levels first , instead": 1.0,
    "first , instead of": 1.0,
    ", instead of the": 1.0,
    "instead of the areas": 1.0,
    "of the areas with": 1.0,
    "the areas with low": 0.5,
    "areas with low pollen": 1.0,
    "with low pollen levels": 1.0,
    "low pollen levels .": 1.0,
    "<s> aggregation : merging": 1.0,
    "aggregation : merging of": 1.0,
    ": merging of similar": 1.0,
    "merging of similar sentences": 1.0,
    "of similar sentences to": 1.0,
    "similar sentences to improve": 0.5,
    "sentences to improve readability": 1.0,
    "to improve readability and": 1.0,
    "improve readability and naturalness": 1.0,
    "readability and naturalness .": 1.0,
    "for instance , merging": 0.1111111111111111,
    "instance , merging the": 1.0,
    ", merging the two": 1.0,
    "merging the two sentences": 1.0,
    "the two sentences grass": 1.0,
    "two sentences grass pollen": 1.0,
    "sentences grass pollen levels": 1.0,
    "levels of yesterday and": 0.3333333333333333,
    "of yesterday and grass": 1.0,
    "yesterday and grass pollen": 1.0,
    "and grass pollen levels": 1.0,
    "grass pollen levels will": 0.25,
    "levels will be around": 0.5,
    "will be around 6": 1.0,
    "be around 6 to": 1.0,
    "of the country into": 0.3333333333333333,
    "the country into the": 1.0,
    "country into the single": 1.0,
    "into the single sentence": 1.0,
    "the single sentence grass": 1.0,
    "single sentence grass pollen": 1.0,
    "sentence grass pollen levels": 1.0,
    "<s> lexical choice :": 1.0,
    "lexical choice : putting": 1.0,
    "choice : putting words": 1.0,
    ": putting words to": 1.0,
    "putting words to the": 1.0,
    "words to the concepts": 1.0,
    "to the concepts .": 1.0,
    "example , deciding whether": 0.3333333333333333,
    ", deciding whether medium": 0.5,
    "deciding whether medium or": 1.0,
    "whether medium or moderate": 1.0,
    "medium or moderate should": 1.0,
    "or moderate should be": 1.0,
    "moderate should be used": 1.0,
    "should be used when": 0.5,
    "be used when describing": 1.0,
    "used when describing a": 1.0,
    "when describing a pollen": 1.0,
    "describing a pollen level": 1.0,
    "a pollen level of": 1.0,
    "pollen level of 4": 1.0,
    "level of 4 .": 1.0,
    "<s> referring expression generation": 1.0,
    "referring expression generation :": 1.0,
    "expression generation : creating": 1.0,
    "generation : creating referring": 1.0,
    ": creating referring expressions": 1.0,
    "creating referring expressions that": 1.0,
    "referring expressions that identify": 1.0,
    "expressions that identify objects": 1.0,
    "that identify objects and": 1.0,
    "identify objects and regions": 1.0,
    "objects and regions .": 1.0,
    ", deciding to use": 0.5,
    "deciding to use in": 1.0,
    "to use in the": 1.0,
    "use in the northern": 1.0,
    "of mainland scotland to": 0.5,
    "mainland scotland to refer": 1.0,
    "scotland to refer to": 1.0,
    "to refer to a": 1.0,
    "refer to a certain": 0.5,
    "to a certain region": 1.0,
    "a certain region in": 1.0,
    "certain region in scotland": 1.0,
    "region in scotland .": 1.0,
    "<s> this task also": 0.5,
    "this task also includes": 1.0,
    "task also includes making": 1.0,
    "also includes making decisions": 1.0,
    "includes making decisions about": 1.0,
    "making decisions about pronouns": 1.0,
    "decisions about pronouns and": 1.0,
    "about pronouns and other": 1.0,
    "pronouns and other types": 1.0,
    "and other types of": 1.0,
    "other types of anaphora": 1.0,
    "types of anaphora .": 1.0,
    "<s> realisation : creating": 1.0,
    "realisation : creating the": 1.0,
    ": creating the actual": 1.0,
    "creating the actual text": 1.0,
    "the actual text ,": 1.0,
    "actual text , which": 1.0,
    "text , which should": 0.5,
    ", which should be": 1.0,
    "which should be correct": 1.0,
    "should be correct according": 1.0,
    "be correct according to": 1.0,
    "correct according to the": 1.0,
    "according to the rules": 0.3333333333333333,
    "to the rules of": 1.0,
    "the rules of syntax": 1.0,
    "rules of syntax ,": 1.0,
    "of syntax , morphology": 1.0,
    "syntax , morphology ,": 1.0,
    ", morphology , and": 0.5,
    "morphology , and orthography": 0.5,
    ", and orthography .": 1.0,
    "example , using will": 0.5,
    ", using will be": 1.0,
    "using will be for": 1.0,
    "will be for the": 1.0,
    "be for the future": 1.0,
    "for the future tense": 1.0,
    "the future tense of": 1.0,
    "future tense of to": 1.0,
    "tense of to be": 1.0,
    "of to be .": 1.0,
    "<s> applications the popular": 1.0,
    "applications the popular media": 1.0,
    "the popular media has": 1.0,
    "popular media has been": 1.0,
    "media has been especially": 1.0,
    "has been especially interested": 1.0,
    "been especially interested in": 1.0,
    "especially interested in nlg": 1.0,
    "interested in nlg systems": 1.0,
    "in nlg systems which": 1.0,
    "nlg systems which generate": 1.0,
    "systems which generate jokes": 0.5,
    "which generate jokes -lrb-": 1.0,
    "generate jokes -lrb- see": 1.0,
    "jokes -lrb- see computational": 1.0,
    "-lrb- see computational humor": 1.0,
    "see computational humor -rrb-": 1.0,
    "computational humor -rrb- .": 1.0,
    "<s> but from a": 1.0,
    "but from a commercial": 1.0,
    "from a commercial perspective": 1.0,
    "a commercial perspective ,": 1.0,
    "commercial perspective , the": 1.0,
    "perspective , the most": 1.0,
    ", the most successful": 0.5,
    "the most successful nlg": 1.0,
    "most successful nlg applications": 1.0,
    "successful nlg applications have": 1.0,
    "nlg applications have been": 1.0,
    "applications have been data-to-text": 1.0,
    "have been data-to-text systems": 1.0,
    "been data-to-text systems which": 1.0,
    "data-to-text systems which generate": 1.0,
    "systems which generate textual": 0.5,
    "which generate textual summaries": 1.0,
    "generate textual summaries of": 1.0,
    "textual summaries of databases": 1.0,
    "summaries of databases and": 1.0,
    "of databases and data": 1.0,
    "databases and data sets": 1.0,
    "and data sets ;": 0.5,
    "data sets ; these": 1.0,
    "sets ; these systems": 1.0,
    "; these systems usually": 1.0,
    "these systems usually perform": 0.5,
    "systems usually perform data": 1.0,
    "usually perform data analysis": 1.0,
    "perform data analysis as": 1.0,
    "data analysis as well": 1.0,
    "analysis as well as": 1.0,
    "as well as text": 0.07692307692307693,
    "well as text generation": 1.0,
    "as text generation .": 1.0,
    "in particular , several": 0.3333333333333333,
    "particular , several systems": 1.0,
    ", several systems have": 1.0,
    "several systems have been": 1.0,
    "systems have been built": 0.3333333333333333,
    "have been built that": 1.0,
    "been built that produce": 1.0,
    "built that produce textual": 1.0,
    "that produce textual weather": 1.0,
    "produce textual weather forecasts": 1.0,
    "textual weather forecasts from": 1.0,
    "weather forecasts from weather": 1.0,
    "forecasts from weather data": 1.0,
    "from weather data .": 1.0,
    "<s> the earliest such": 1.0,
    "the earliest such system": 1.0,
    "earliest such system to": 1.0,
    "such system to be": 1.0,
    "system to be deployed": 1.0,
    "to be deployed was": 1.0,
    "be deployed was fog": 1.0,
    "deployed was fog ,": 1.0,
    "was fog , which": 1.0,
    "fog , which was": 1.0,
    ", which was used": 0.25,
    "which was used by": 1.0,
    "was used by environment": 1.0,
    "used by environment canada": 1.0,
    "by environment canada to": 1.0,
    "environment canada to generate": 1.0,
    "canada to generate weather": 1.0,
    "to generate weather forecasts": 1.0,
    "generate weather forecasts in": 1.0,
    "weather forecasts in french": 1.0,
    "forecasts in french and": 1.0,
    "in french and english": 1.0,
    "french and english in": 1.0,
    "and english in the": 1.0,
    "english in the early": 1.0,
    "in the early 1990s": 1.0,
    "the early 1990s .": 1.0,
    "<s> the success of": 1.0,
    "the success of fog": 0.3333333333333333,
    "success of fog triggered": 1.0,
    "of fog triggered other": 1.0,
    "fog triggered other work": 1.0,
    "triggered other work ,": 1.0,
    "other work , both": 1.0,
    "work , both research": 1.0,
    ", both research and": 1.0,
    "both research and commercial": 1.0,
    "research and commercial .": 1.0,
    "<s> recent research in": 0.5,
    "recent research in this": 1.0,
    "research in this area": 1.0,
    "in this area include": 0.3333333333333333,
    "this area include an": 1.0,
    "area include an experiment": 1.0,
    "include an experiment which": 1.0,
    "an experiment which showed": 1.0,
    "experiment which showed that": 1.0,
    "which showed that users": 1.0,
    "showed that users sometimes": 1.0,
    "that users sometimes preferred": 1.0,
    "users sometimes preferred computer-generated": 1.0,
    "sometimes preferred computer-generated weather": 1.0,
    "preferred computer-generated weather forecasts": 1.0,
    "computer-generated weather forecasts to": 1.0,
    "weather forecasts to human-written": 1.0,
    "forecasts to human-written ones": 1.0,
    "to human-written ones ,": 1.0,
    "human-written ones , in": 1.0,
    "ones , in part": 1.0,
    ", in part because": 1.0,
    "in part because the": 1.0,
    "part because the computer": 1.0,
    "because the computer forecasts": 1.0,
    "the computer forecasts used": 1.0,
    "computer forecasts used more": 1.0,
    "forecasts used more consistent": 1.0,
    "used more consistent terminology": 1.0,
    "more consistent terminology ,": 1.0,
    "consistent terminology , and": 1.0,
    "terminology , and a": 1.0,
    "and a demonstration that": 0.5,
    "a demonstration that statistical": 1.0,
    "demonstration that statistical techniques": 1.0,
    "that statistical techniques could": 1.0,
    "statistical techniques could be": 1.0,
    "techniques could be used": 1.0,
    "could be used to": 0.3333333333333333,
    "be used to generate": 0.16666666666666666,
    "used to generate high-quality": 1.0,
    "to generate high-quality weather": 1.0,
    "generate high-quality weather forecasts": 1.0,
    "high-quality weather forecasts .": 1.0,
    "<s> recent applications include": 1.0,
    "recent applications include the": 1.0,
    "applications include the arns": 1.0,
    "include the arns system": 1.0,
    "the arns system used": 1.0,
    "arns system used to": 1.0,
    "system used to summarise": 1.0,
    "used to summarise conditions": 1.0,
    "to summarise conditions in": 1.0,
    "summarise conditions in us": 1.0,
    "conditions in us ports": 1.0,
    "in us ports .": 1.0,
    "<s> in the 1990s": 0.08333333333333333,
    "in the 1990s there": 0.5,
    "the 1990s there was": 1.0,
    "1990s there was considerable": 1.0,
    "there was considerable interest": 1.0,
    "was considerable interest in": 1.0,
    "considerable interest in using": 1.0,
    "interest in using nlg": 1.0,
    "in using nlg to": 1.0,
    "using nlg to summarise": 0.6666666666666666,
    "nlg to summarise financial": 0.5,
    "to summarise financial and": 1.0,
    "summarise financial and business": 1.0,
    "financial and business data": 1.0,
    "and business data .": 1.0,
    "<s> for example the": 0.02857142857142857,
    "for example the spotlight": 1.0,
    "example the spotlight system": 1.0,
    "the spotlight system developed": 1.0,
    "spotlight system developed at": 1.0,
    "system developed at a.c.": 1.0,
    "developed at a.c. nielsen": 1.0,
    "at a.c. nielsen automatically": 1.0,
    "a.c. nielsen automatically generated": 1.0,
    "nielsen automatically generated readable": 1.0,
    "automatically generated readable english": 1.0,
    "generated readable english text": 1.0,
    "readable english text based": 1.0,
    "english text based on": 1.0,
    "text based on the": 1.0,
    "based on the analysis": 0.18181818181818182,
    "on the analysis of": 1.0,
    "analysis of large amounts": 0.5,
    "of large amounts of": 1.0,
    "large amounts of retail": 1.0,
    "amounts of retail sales": 1.0,
    "of retail sales data": 1.0,
    "retail sales data .": 1.0,
    "<s> more recently there": 1.0,
    "more recently there is": 1.0,
    "recently there is growing": 1.0,
    "there is growing interest": 1.0,
    "is growing interest in": 1.0,
    "growing interest in using": 1.0,
    "nlg to summarise electronic": 0.5,
    "to summarise electronic medical": 1.0,
    "summarise electronic medical records": 1.0,
    "electronic medical records .": 0.5,
    "<s> commercial applications in": 1.0,
    "commercial applications in this": 1.0,
    "applications in this area": 1.0,
    "in this area are": 0.3333333333333333,
    "this area are starting": 1.0,
    "area are starting to": 1.0,
    "are starting to appear": 1.0,
    "starting to appear ,": 1.0,
    "to appear , and": 1.0,
    "appear , and researchers": 1.0,
    ", and researchers have": 1.0,
    "and researchers have shown": 1.0,
    "researchers have shown that": 1.0,
    "have shown that nlg": 1.0,
    "shown that nlg summaries": 1.0,
    "that nlg summaries of": 1.0,
    "nlg summaries of medical": 1.0,
    "summaries of medical data": 1.0,
    "of medical data can": 1.0,
    "medical data can be": 1.0,
    "data can be effective": 0.5,
    "can be effective decision-support": 1.0,
    "be effective decision-support aids": 1.0,
    "effective decision-support aids for": 1.0,
    "decision-support aids for medical": 1.0,
    "aids for medical professionals": 1.0,
    "for medical professionals .": 1.0,
    "<s> there is also": 0.5,
    "there is also growing": 0.5,
    "is also growing interest": 1.0,
    "also growing interest in": 1.0,
    "using nlg to enhance": 0.3333333333333333,
    "nlg to enhance accessibility": 1.0,
    "to enhance accessibility ,": 1.0,
    "enhance accessibility , for": 1.0,
    "accessibility , for example": 1.0,
    "for example by describing": 0.5,
    "example by describing graphs": 1.0,
    "by describing graphs and": 1.0,
    "describing graphs and data": 1.0,
    "graphs and data sets": 1.0,
    "and data sets to": 0.5,
    "data sets to blind": 1.0,
    "sets to blind people": 1.0,
    "to blind people .": 1.0,
    "<s> an example for": 0.5,
    "an example for a": 0.5,
    "example for a highly": 1.0,
    "for a highly interactive": 1.0,
    "a highly interactive use": 1.0,
    "highly interactive use of": 1.0,
    "interactive use of nlg": 1.0,
    "use of nlg is": 1.0,
    "of nlg is the": 1.0,
    "nlg is the wysiwym": 1.0,
    "is the wysiwym framework": 1.0,
    "the wysiwym framework .": 1.0,
    "<s> it stands for": 1.0,
    "it stands for what": 1.0,
    "stands for what you": 1.0,
    "for what you see": 1.0,
    "what you see is": 1.0,
    "you see is what": 1.0,
    "see is what you": 1.0,
    "is what you meant": 1.0,
    "what you meant and": 1.0,
    "you meant and allows": 1.0,
    "meant and allows users": 1.0,
    "and allows users to": 1.0,
    "allows users to see": 0.5,
    "users to see and": 1.0,
    "to see and manipulate": 1.0,
    "see and manipulate the": 1.0,
    "and manipulate the continuously": 1.0,
    "manipulate the continuously rendered": 1.0,
    "the continuously rendered view": 1.0,
    "continuously rendered view -lrb-": 1.0,
    "rendered view -lrb- nlg": 1.0,
    "view -lrb- nlg output": 1.0,
    "-lrb- nlg output -rrb-": 1.0,
    "nlg output -rrb- of": 1.0,
    "output -rrb- of an": 1.0,
    "-rrb- of an underlying": 1.0,
    "of an underlying formal": 1.0,
    "an underlying formal language": 1.0,
    "underlying formal language document": 1.0,
    "formal language document -lrb-": 1.0,
    "language document -lrb- nlg": 1.0,
    "document -lrb- nlg input": 1.0,
    "-lrb- nlg input -rrb-": 1.0,
    "nlg input -rrb- ,": 1.0,
    "input -rrb- , thereby": 1.0,
    "-rrb- , thereby editing": 1.0,
    ", thereby editing the": 1.0,
    "thereby editing the formal": 1.0,
    "editing the formal language": 1.0,
    "the formal language without": 1.0,
    "formal language without having": 1.0,
    "language without having to": 1.0,
    "without having to learn": 1.0,
    "having to learn it": 1.0,
    "to learn it .": 1.0,
    "<s> evaluation as in": 1.0,
    "evaluation as in other": 1.0,
    "as in other scientific": 0.3333333333333333,
    "in other scientific fields": 1.0,
    "other scientific fields ,": 1.0,
    "scientific fields , nlg": 1.0,
    "fields , nlg researchers": 1.0,
    ", nlg researchers need": 1.0,
    "nlg researchers need to": 1.0,
    "researchers need to be": 1.0,
    "need to be able": 1.0,
    "be able to test": 0.2,
    "able to test how": 1.0,
    "to test how well": 1.0,
    "test how well their": 1.0,
    "how well their systems": 1.0,
    "well their systems ,": 1.0,
    "their systems , modules": 1.0,
    "systems , modules ,": 1.0,
    ", modules , and": 1.0,
    "modules , and algorithms": 1.0,
    ", and algorithms work": 1.0,
    "and algorithms work .": 1.0,
    "<s> this is called": 0.07142857142857142,
    "this is called evaluation": 1.0,
    "is called evaluation .": 1.0,
    "<s> there are three": 0.2,
    "there are three basic": 1.0,
    "are three basic techniques": 1.0,
    "three basic techniques for": 1.0,
    "basic techniques for evaluating": 1.0,
    "techniques for evaluating nlg": 1.0,
    "for evaluating nlg systems": 1.0,
    "evaluating nlg systems :": 1.0,
    "nlg systems : task-based": 1.0,
    "systems : task-based -lrb-": 1.0,
    ": task-based -lrb- extrinsic": 1.0,
    "task-based -lrb- extrinsic -rrb-": 1.0,
    "-lrb- extrinsic -rrb- evaluation": 1.0,
    "extrinsic -rrb- evaluation :": 1.0,
    "-rrb- evaluation : give": 1.0,
    "evaluation : give the": 1.0,
    ": give the generated": 1.0,
    "give the generated text": 1.0,
    "the generated text to": 1.0,
    "generated text to a": 1.0,
    "text to a person": 1.0,
    "to a person ,": 1.0,
    "a person , and": 0.6666666666666666,
    "person , and assess": 0.5,
    ", and assess how": 1.0,
    "and assess how well": 1.0,
    "assess how well it": 0.5,
    "how well it helps": 0.5,
    "well it helps him": 1.0,
    "it helps him perform": 1.0,
    "helps him perform a": 1.0,
    "him perform a task": 1.0,
    "perform a task -lrb-": 1.0,
    "a task -lrb- or": 1.0,
    "task -lrb- or otherwise": 1.0,
    "-lrb- or otherwise achieves": 1.0,
    "or otherwise achieves its": 1.0,
    "otherwise achieves its communicative": 1.0,
    "achieves its communicative goal": 1.0,
    "its communicative goal -rrb-": 1.0,
    "communicative goal -rrb- .": 1.0,
    "example , a system": 0.2,
    ", a system which": 0.5,
    "a system which generates": 1.0,
    "system which generates summaries": 1.0,
    "which generates summaries of": 1.0,
    "generates summaries of medical": 1.0,
    "data can be evaluated": 0.5,
    "can be evaluated by": 0.5,
    "be evaluated by giving": 1.0,
    "evaluated by giving these": 1.0,
    "by giving these summaries": 1.0,
    "giving these summaries to": 1.0,
    "these summaries to doctors": 1.0,
    "summaries to doctors ,": 1.0,
    "to doctors , and": 1.0,
    "doctors , and assessing": 1.0,
    ", and assessing whether": 1.0,
    "and assessing whether the": 1.0,
    "assessing whether the summaries": 1.0,
    "whether the summaries helps": 1.0,
    "the summaries helps doctors": 1.0,
    "summaries helps doctors make": 1.0,
    "helps doctors make better": 1.0,
    "doctors make better decisions": 1.0,
    "make better decisions .": 1.0,
    "<s> human ratings :": 1.0,
    "human ratings : give": 1.0,
    "ratings : give the": 1.0,
    "person , and ask": 0.5,
    ", and ask him": 1.0,
    "and ask him or": 1.0,
    "ask him or her": 1.0,
    "him or her to": 1.0,
    "or her to rate": 1.0,
    "her to rate the": 1.0,
    "to rate the quality": 1.0,
    "rate the quality and": 1.0,
    "the quality and usefulness": 1.0,
    "quality and usefulness of": 1.0,
    "and usefulness of the": 1.0,
    "usefulness of the text": 1.0,
    "<s> metrics : compare": 1.0,
    "metrics : compare generated": 1.0,
    ": compare generated texts": 1.0,
    "compare generated texts to": 1.0,
    "generated texts to texts": 1.0,
    "texts to texts written": 1.0,
    "to texts written by": 1.0,
    "texts written by people": 1.0,
    "written by people from": 1.0,
    "by people from the": 1.0,
    "people from the same": 1.0,
    "from the same input": 1.0,
    "same input data ,": 0.5,
    "input data , using": 1.0,
    "data , using an": 1.0,
    ", using an automatic": 1.0,
    "using an automatic metric": 1.0,
    "an automatic metric such": 1.0,
    "automatic metric such as": 1.0,
    "metric such as bleu": 1.0,
    "such as bleu .": 1.0,
    "<s> generally speaking ,": 1.0,
    "generally speaking , what": 0.5,
    "speaking , what we": 1.0,
    ", what we ultimately": 1.0,
    "what we ultimately want": 1.0,
    "we ultimately want to": 1.0,
    "ultimately want to know": 1.0,
    "want to know is": 1.0,
    "to know is how": 1.0,
    "know is how useful": 1.0,
    "is how useful nlg": 1.0,
    "how useful nlg systems": 1.0,
    "useful nlg systems are": 1.0,
    "nlg systems are at": 1.0,
    "systems are at helping": 1.0,
    "are at helping people": 1.0,
    "at helping people ,": 1.0,
    "helping people , which": 1.0,
    "people , which is": 1.0,
    "which is the first": 0.3333333333333333,
    "is the first of": 1.0,
    "the first of the": 1.0,
    "first of the above": 1.0,
    "of the above techniques": 1.0,
    "the above techniques .": 1.0,
    "<s> however , task-based": 0.03125,
    "however , task-based evaluations": 1.0,
    ", task-based evaluations are": 1.0,
    "task-based evaluations are time-consuming": 0.5,
    "evaluations are time-consuming and": 1.0,
    "are time-consuming and expensive": 1.0,
    "time-consuming and expensive ,": 1.0,
    "and expensive , and": 1.0,
    "expensive , and can": 1.0,
    ", and can be": 0.4,
    "and can be difficult": 0.2,
    "can be difficult to": 1.0,
    "be difficult to carry": 1.0,
    "difficult to carry out": 1.0,
    "to carry out -lrb-": 1.0,
    "carry out -lrb- especially": 1.0,
    "out -lrb- especially if": 1.0,
    "-lrb- especially if they": 1.0,
    "especially if they require": 1.0,
    "if they require subjects": 1.0,
    "they require subjects with": 1.0,
    "require subjects with specialised": 1.0,
    "subjects with specialised expertise": 1.0,
    "with specialised expertise ,": 1.0,
    "specialised expertise , such": 1.0,
    "expertise , such as": 1.0,
    ", such as doctors": 0.030303030303030304,
    "such as doctors -rrb-": 1.0,
    "as doctors -rrb- .": 1.0,
    "<s> hence -lrb- as": 1.0,
    "hence -lrb- as in": 1.0,
    "-lrb- as in other": 0.25,
    "other areas of nlp": 0.5,
    "areas of nlp -rrb-": 1.0,
    "of nlp -rrb- task-based": 1.0,
    "nlp -rrb- task-based evaluations": 1.0,
    "-rrb- task-based evaluations are": 0.5,
    "task-based evaluations are the": 0.5,
    "evaluations are the exception": 1.0,
    "are the exception ,": 1.0,
    "the exception , not": 1.0,
    "exception , not the": 1.0,
    ", not the norm": 1.0,
    "not the norm .": 1.0,
    "<s> in recent years": 1.0,
    "in recent years researchers": 0.25,
    "recent years researchers have": 1.0,
    "years researchers have started": 1.0,
    "researchers have started trying": 1.0,
    "have started trying to": 1.0,
    "started trying to assess": 1.0,
    "trying to assess how": 1.0,
    "to assess how well": 1.0,
    "assess how well human-ratings": 0.5,
    "how well human-ratings and": 1.0,
    "well human-ratings and metrics": 1.0,
    "human-ratings and metrics correlate": 1.0,
    "and metrics correlate with": 1.0,
    "metrics correlate with -lrb-": 1.0,
    "correlate with -lrb- predict": 1.0,
    "with -lrb- predict -rrb-": 1.0,
    "-lrb- predict -rrb- task-based": 1.0,
    "predict -rrb- task-based evaluations": 1.0,
    "-rrb- task-based evaluations .": 0.5,
    "<s> much of this": 1.0,
    "much of this work": 1.0,
    "of this work is": 1.0,
    "this work is being": 0.5,
    "work is being conducted": 1.0,
    "is being conducted in": 1.0,
    "being conducted in the": 1.0,
    "conducted in the context": 1.0,
    "the context of generation": 0.2,
    "context of generation challenges": 1.0,
    "of generation challenges shared-task": 1.0,
    "generation challenges shared-task events": 1.0,
    "challenges shared-task events .": 1.0,
    "<s> initial results suggest": 1.0,
    "initial results suggest that": 1.0,
    "results suggest that human": 1.0,
    "suggest that human ratings": 1.0,
    "that human ratings are": 1.0,
    "human ratings are much": 0.5,
    "ratings are much better": 1.0,
    "are much better than": 1.0,
    "much better than metrics": 1.0,
    "better than metrics in": 1.0,
    "than metrics in this": 1.0,
    "metrics in this regard": 1.0,
    "in this regard .": 1.0,
    "<s> in other words": 0.5,
    "in other words ,": 1.0,
    "other words , human": 1.0,
    "words , human ratings": 1.0,
    ", human ratings usually": 0.5,
    "human ratings usually do": 1.0,
    "ratings usually do predict": 1.0,
    "usually do predict task-effectiveness": 1.0,
    "do predict task-effectiveness at": 1.0,
    "predict task-effectiveness at least": 1.0,
    "task-effectiveness at least to": 1.0,
    "at least to some": 1.0,
    "least to some degree": 1.0,
    "to some degree -lrb-": 0.5,
    "some degree -lrb- although": 1.0,
    "degree -lrb- although there": 1.0,
    "-lrb- although there are": 1.0,
    "although there are exceptions": 1.0,
    "there are exceptions -rrb-": 1.0,
    "are exceptions -rrb- ,": 1.0,
    "exceptions -rrb- , while": 1.0,
    "-rrb- , while ratings": 0.5,
    ", while ratings produced": 1.0,
    "while ratings produced by": 1.0,
    "ratings produced by metrics": 1.0,
    "produced by metrics often": 1.0,
    "by metrics often do": 1.0,
    "metrics often do not": 1.0,
    "often do not predict": 1.0,
    "do not predict task-effectiveness": 1.0,
    "not predict task-effectiveness well": 1.0,
    "predict task-effectiveness well .": 1.0,
    "<s> these results are": 1.0,
    "these results are very": 1.0,
    "results are very preliminary": 1.0,
    "are very preliminary ,": 1.0,
    "very preliminary , hopefully": 1.0,
    "preliminary , hopefully better": 1.0,
    ", hopefully better data": 1.0,
    "hopefully better data will": 1.0,
    "better data will be": 1.0,
    "data will be available": 1.0,
    "will be available soon": 1.0,
    "be available soon .": 1.0,
    "any case , human": 0.5,
    "case , human ratings": 1.0,
    ", human ratings are": 0.5,
    "human ratings are currently": 0.5,
    "ratings are currently the": 1.0,
    "are currently the most": 1.0,
    "currently the most popular": 1.0,
    "the most popular evaluation": 0.3333333333333333,
    "most popular evaluation technique": 1.0,
    "popular evaluation technique in": 1.0,
    "evaluation technique in nlg": 1.0,
    "technique in nlg ;": 1.0,
    "in nlg ; this": 1.0,
    "nlg ; this is": 1.0,
    "; this is contrast": 0.5,
    "this is contrast to": 1.0,
    "is contrast to machine": 1.0,
    "contrast to machine translation": 1.0,
    "to machine translation ,": 1.0,
    "machine translation , where": 0.14285714285714285,
    "translation , where metrics": 1.0,
    ", where metrics are": 1.0,
    "where metrics are very": 1.0,
    "metrics are very widely": 1.0,
    "are very widely used": 1.0,
    "very widely used .": 1.0,
    "language understanding is a": 0.5,
    "understanding is a subtopic": 1.0,
    "is a subtopic of": 1.0,
    "a subtopic of natural": 1.0,
    "subtopic of natural language": 1.0,
    "natural language processing in": 0.03571428571428571,
    "language processing in artificial": 1.0,
    "processing in artificial intelligence": 1.0,
    "in artificial intelligence that": 1.0,
    "artificial intelligence that deals": 0.5,
    "intelligence that deals with": 1.0,
    "that deals with machine": 1.0,
    "deals with machine reading": 1.0,
    "with machine reading comprehension": 1.0,
    "machine reading comprehension .": 1.0,
    "<s> the process of": 1.0,
    "the process of disassembling": 0.09090909090909091,
    "process of disassembling and": 1.0,
    "of disassembling and parsing": 1.0,
    "disassembling and parsing input": 1.0,
    "and parsing input is": 1.0,
    "parsing input is more": 1.0,
    "input is more complex": 1.0,
    "is more complex than": 1.0,
    "more complex than the": 1.0,
    "complex than the reverse": 0.5,
    "than the reverse process": 1.0,
    "the reverse process of": 1.0,
    "reverse process of assembling": 1.0,
    "process of assembling output": 1.0,
    "of assembling output in": 1.0,
    "assembling output in natural": 1.0,
    "output in natural language": 1.0,
    "in natural language generation": 0.16666666666666666,
    "natural language generation because": 0.2,
    "language generation because of": 1.0,
    "generation because of the": 1.0,
    "because of the occurrence": 0.25,
    "of the occurrence of": 1.0,
    "the occurrence of unknown": 1.0,
    "occurrence of unknown and": 1.0,
    "of unknown and unexpected": 1.0,
    "unknown and unexpected features": 1.0,
    "and unexpected features in": 1.0,
    "unexpected features in the": 1.0,
    "features in the input": 1.0,
    "in the input and": 1.0,
    "the input and the": 0.5,
    "input and the need": 1.0,
    "and the need to": 1.0,
    "the need to determine": 1.0,
    "need to determine the": 1.0,
    "to determine the appropriate": 0.25,
    "determine the appropriate syntactic": 1.0,
    "the appropriate syntactic and": 1.0,
    "appropriate syntactic and semantic": 1.0,
    "syntactic and semantic schemes": 0.5,
    "and semantic schemes to": 1.0,
    "semantic schemes to apply": 1.0,
    "schemes to apply to": 1.0,
    "to apply to it": 1.0,
    "apply to it ,": 1.0,
    "to it , factors": 1.0,
    "it , factors which": 1.0,
    ", factors which are": 1.0,
    "factors which are pre-determined": 1.0,
    "which are pre-determined when": 1.0,
    "are pre-determined when outputting": 1.0,
    "pre-determined when outputting language": 1.0,
    "when outputting language .": 1.0,
    "<s> there is considerable": 0.5,
    "there is considerable commercial": 1.0,
    "is considerable commercial interest": 1.0,
    "considerable commercial interest in": 1.0,
    "commercial interest in the": 1.0,
    "interest in the field": 1.0,
    "in the field because": 0.08333333333333333,
    "the field because of": 1.0,
    "field because of its": 1.0,
    "because of its application": 1.0,
    "of its application to": 1.0,
    "its application to news-gathering": 1.0,
    "application to news-gathering ,": 1.0,
    "to news-gathering , text": 1.0,
    "news-gathering , text categorization": 1.0,
    ", text categorization ,": 1.0,
    "text categorization , voice-activation": 1.0,
    "categorization , voice-activation ,": 1.0,
    ", voice-activation , archiving": 1.0,
    "voice-activation , archiving and": 1.0,
    ", archiving and large-scale": 1.0,
    "archiving and large-scale content-analysis": 1.0,
    "and large-scale content-analysis .": 1.0,
    "<s> eight years after": 1.0,
    "eight years after john": 1.0,
    "years after john mccarthy": 1.0,
    "after john mccarthy coined": 1.0,
    "john mccarthy coined the": 1.0,
    "mccarthy coined the term": 1.0,
    "coined the term artificial": 1.0,
    "the term artificial intelligence": 1.0,
    "term artificial intelligence ,": 1.0,
    "artificial intelligence , bobrow": 1.0,
    "intelligence , bobrow 's": 1.0,
    ", bobrow 's dissertation": 1.0,
    "bobrow 's dissertation -lrb-": 1.0,
    "'s dissertation -lrb- titled": 1.0,
    "dissertation -lrb- titled natural": 1.0,
    "-lrb- titled natural language": 1.0,
    "titled natural language input": 1.0,
    "natural language input for": 0.25,
    "language input for a": 1.0,
    "input for a computer": 1.0,
    "for a computer problem": 0.5,
    "a computer problem solving": 1.0,
    "computer problem solving system": 1.0,
    "problem solving system -rrb-": 1.0,
    "solving system -rrb- showed": 1.0,
    "system -rrb- showed how": 1.0,
    "-rrb- showed how a": 1.0,
    "showed how a computer": 1.0,
    "how a computer can": 1.0,
    "a computer can understand": 1.0,
    "computer can understand simple": 1.0,
    "can understand simple natural": 1.0,
    "understand simple natural language": 1.0,
    "simple natural language input": 1.0,
    "natural language input to": 0.25,
    "language input to solve": 1.0,
    "input to solve algebra": 1.0,
    "to solve algebra word": 1.0,
    "solve algebra word problems": 1.0,
    "algebra word problems .": 1.0,
    "<s> a year later": 1.0,
    "a year later ,": 1.0,
    "year later , in": 1.0,
    "later , in 1965": 0.5,
    ", in 1965 ,": 1.0,
    "in 1965 , joseph": 1.0,
    "1965 , joseph weizenbaum": 1.0,
    ", joseph weizenbaum at": 1.0,
    "joseph weizenbaum at mit": 1.0,
    "weizenbaum at mit wrote": 1.0,
    "at mit wrote eliza": 1.0,
    "mit wrote eliza ,": 1.0,
    "wrote eliza , an": 1.0,
    "eliza , an interactive": 1.0,
    ", an interactive program": 1.0,
    "an interactive program that": 1.0,
    "interactive program that carried": 1.0,
    "program that carried on": 1.0,
    "that carried on a": 1.0,
    "carried on a dialogue": 1.0,
    "on a dialogue in": 1.0,
    "a dialogue in english": 1.0,
    "dialogue in english on": 1.0,
    "in english on any": 1.0,
    "english on any topic": 1.0,
    "on any topic ,": 0.5,
    "any topic , the": 1.0,
    "topic , the most": 1.0,
    ", the most popular": 0.5,
    "the most popular being": 0.3333333333333333,
    "most popular being psychotherapy": 1.0,
    "popular being psychotherapy .": 1.0,
    "<s> eliza worked by": 1.0,
    "eliza worked by simple": 1.0,
    "worked by simple parsing": 1.0,
    "by simple parsing and": 1.0,
    "simple parsing and substitution": 1.0,
    "parsing and substitution of": 1.0,
    "and substitution of key": 1.0,
    "substitution of key words": 1.0,
    "of key words into": 1.0,
    "key words into canned": 1.0,
    "words into canned phrases": 1.0,
    "into canned phrases and": 1.0,
    "canned phrases and weizenbaum": 1.0,
    "phrases and weizenbaum sidestepped": 1.0,
    "and weizenbaum sidestepped the": 1.0,
    "weizenbaum sidestepped the problem": 1.0,
    "sidestepped the problem of": 1.0,
    "the problem of giving": 0.16666666666666666,
    "problem of giving the": 1.0,
    "of giving the program": 1.0,
    "giving the program a": 1.0,
    "the program a database": 1.0,
    "program a database of": 1.0,
    "a database of real-world": 0.5,
    "database of real-world knowledge": 1.0,
    "of real-world knowledge or": 1.0,
    "real-world knowledge or a": 1.0,
    "knowledge or a rich": 1.0,
    "or a rich lexicon": 1.0,
    "a rich lexicon .": 0.3333333333333333,
    "<s> yet eliza gained": 1.0,
    "yet eliza gained surprising": 1.0,
    "eliza gained surprising popularity": 1.0,
    "gained surprising popularity as": 1.0,
    "surprising popularity as a": 1.0,
    "popularity as a toy": 1.0,
    "as a toy project": 1.0,
    "a toy project and": 1.0,
    "toy project and can": 1.0,
    "project and can be": 1.0,
    "and can be seen": 0.4,
    "can be seen as": 0.6666666666666666,
    "be seen as a": 0.5,
    "seen as a very": 0.5,
    "as a very early": 1.0,
    "a very early precursor": 1.0,
    "very early precursor to": 1.0,
    "early precursor to current": 1.0,
    "precursor to current commercial": 1.0,
    "to current commercial systems": 1.0,
    "current commercial systems such": 1.0,
    "commercial systems such as": 1.0,
    "systems such as those": 1.0,
    "such as those used": 0.2,
    "as those used by": 1.0,
    "those used by ask.com": 1.0,
    "used by ask.com .": 1.0,
    "<s> in 1969 roger": 0.5,
    "in 1969 roger schank": 1.0,
    "1969 roger schank at": 1.0,
    "roger schank at stanford": 1.0,
    "schank at stanford university": 1.0,
    "at stanford university introduced": 1.0,
    "stanford university introduced the": 1.0,
    "university introduced the conceptual": 1.0,
    "introduced the conceptual dependency": 1.0,
    "the conceptual dependency theory": 1.0,
    "conceptual dependency theory for": 1.0,
    "dependency theory for natural": 1.0,
    "theory for natural language": 1.0,
    "for natural language understanding": 0.3333333333333333,
    "<s> this model ,": 0.5,
    "this model , partially": 1.0,
    "model , partially influenced": 1.0,
    ", partially influenced by": 1.0,
    "partially influenced by the": 1.0,
    "influenced by the work": 0.3333333333333333,
    "by the work of": 1.0,
    "the work of sydney": 0.5,
    "work of sydney lamb": 1.0,
    "of sydney lamb ,": 1.0,
    "sydney lamb , was": 1.0,
    "lamb , was extensively": 1.0,
    ", was extensively used": 1.0,
    "was extensively used by": 1.0,
    "extensively used by schank": 1.0,
    "used by schank 's": 1.0,
    "by schank 's students": 1.0,
    "schank 's students at": 1.0,
    "'s students at yale": 1.0,
    "students at yale university": 1.0,
    "at yale university ,": 1.0,
    "yale university , such": 1.0,
    "university , such as": 1.0,
    ", such as robert": 0.030303030303030304,
    "such as robert wilensky": 1.0,
    "as robert wilensky ,": 1.0,
    "robert wilensky , wendy": 1.0,
    "wilensky , wendy lehnert": 1.0,
    ", wendy lehnert ,": 1.0,
    "wendy lehnert , and": 1.0,
    "lehnert , and janet": 1.0,
    ", and janet kolodner": 1.0,
    "and janet kolodner .": 1.0,
    "<s> in 1970 ,": 1.0,
    "in 1970 , william": 1.0,
    "1970 , william a.": 1.0,
    ", william a. woods": 1.0,
    "william a. woods introduced": 1.0,
    "a. woods introduced the": 1.0,
    "woods introduced the augmented": 1.0,
    "introduced the augmented transition": 1.0,
    "the augmented transition network": 1.0,
    "augmented transition network -lrb-": 1.0,
    "transition network -lrb- atn": 1.0,
    "network -lrb- atn -rrb-": 1.0,
    "-lrb- atn -rrb- to": 1.0,
    "atn -rrb- to represent": 1.0,
    "-rrb- to represent natural": 1.0,
    "to represent natural language": 1.0,
    "represent natural language input": 1.0,
    "natural language input .": 0.25,
    "<s> instead of phrase": 0.5,
    "instead of phrase structure": 1.0,
    "of phrase structure rules": 1.0,
    "phrase structure rules atns": 1.0,
    "structure rules atns used": 1.0,
    "rules atns used an": 1.0,
    "atns used an equivalent": 1.0,
    "used an equivalent set": 1.0,
    "an equivalent set of": 1.0,
    "equivalent set of finite": 1.0,
    "set of finite state": 1.0,
    "of finite state automata": 1.0,
    "finite state automata that": 1.0,
    "state automata that were": 1.0,
    "automata that were called": 1.0,
    "that were called recursively": 1.0,
    "were called recursively .": 1.0,
    "<s> atns and their": 1.0,
    "atns and their more": 1.0,
    "and their more general": 1.0,
    "their more general format": 1.0,
    "more general format called": 1.0,
    "general format called ``": 1.0,
    "format called `` generalized": 1.0,
    "called `` generalized atns": 1.0,
    "`` generalized atns ''": 1.0,
    "generalized atns '' continued": 1.0,
    "atns '' continued to": 1.0,
    "'' continued to be": 1.0,
    "continued to be used": 0.5,
    "to be used for": 0.5,
    "be used for a": 0.3333333333333333,
    "used for a number": 0.5,
    "a number of years": 0.045454545454545456,
    "number of years .": 1.0,
    "<s> in 1971 terry": 1.0,
    "in 1971 terry winograd": 1.0,
    "1971 terry winograd finished": 1.0,
    "terry winograd finished writing": 1.0,
    "winograd finished writing shrdlu": 1.0,
    "finished writing shrdlu for": 1.0,
    "writing shrdlu for his": 1.0,
    "shrdlu for his phd": 1.0,
    "for his phd thesis": 1.0,
    "his phd thesis at": 1.0,
    "phd thesis at mit": 1.0,
    "thesis at mit .": 1.0,
    "<s> shrdlu could understand": 1.0,
    "shrdlu could understand simple": 1.0,
    "could understand simple english": 1.0,
    "understand simple english sentences": 1.0,
    "simple english sentences in": 1.0,
    "english sentences in a": 1.0,
    "sentences in a restricted": 1.0,
    "in a restricted world": 1.0,
    "a restricted world of": 1.0,
    "restricted world of children": 1.0,
    "world of children 's": 1.0,
    "of children 's blocks": 1.0,
    "children 's blocks to": 1.0,
    "'s blocks to direct": 1.0,
    "blocks to direct a": 1.0,
    "to direct a robotic": 1.0,
    "direct a robotic arm": 1.0,
    "a robotic arm to": 1.0,
    "robotic arm to move": 1.0,
    "arm to move items": 1.0,
    "to move items .": 1.0,
    "<s> the successful demonstration": 1.0,
    "the successful demonstration of": 1.0,
    "successful demonstration of shrdlu": 1.0,
    "demonstration of shrdlu provided": 1.0,
    "of shrdlu provided significant": 1.0,
    "shrdlu provided significant momentum": 1.0,
    "provided significant momentum for": 1.0,
    "significant momentum for continued": 1.0,
    "momentum for continued research": 1.0,
    "for continued research in": 1.0,
    "continued research in the": 1.0,
    "research in the field": 0.5,
    "in the field .": 0.16666666666666666,
    "<s> winograd continued to": 1.0,
    "winograd continued to be": 1.0,
    "continued to be a": 0.5,
    "to be a major": 0.2,
    "be a major influence": 1.0,
    "a major influence in": 1.0,
    "major influence in the": 1.0,
    "influence in the field": 1.0,
    "in the field with": 0.08333333333333333,
    "the field with the": 1.0,
    "field with the publication": 1.0,
    "with the publication of": 1.0,
    "the publication of his": 0.5,
    "publication of his book": 1.0,
    "of his book language": 1.0,
    "his book language as": 1.0,
    "book language as a": 1.0,
    "language as a cognitive": 1.0,
    "as a cognitive process": 1.0,
    "a cognitive process .": 1.0,
    "<s> at stanford ,": 1.0,
    "at stanford , winograd": 1.0,
    "stanford , winograd was": 1.0,
    ", winograd was later": 1.0,
    "winograd was later the": 1.0,
    "was later the adviser": 1.0,
    "later the adviser for": 1.0,
    "the adviser for larry": 1.0,
    "adviser for larry page": 1.0,
    "for larry page ,": 1.0,
    "larry page , who": 1.0,
    "page , who co-founded": 1.0,
    ", who co-founded google": 1.0,
    "who co-founded google .": 1.0,
    "<s> in the 1970s": 0.08333333333333333,
    "in the 1970s and": 1.0,
    "the 1970s and 1980s": 1.0,
    "1970s and 1980s the": 0.5,
    "and 1980s the natural": 1.0,
    "1980s the natural language": 1.0,
    "natural language processing group": 0.03571428571428571,
    "language processing group at": 1.0,
    "processing group at sri": 1.0,
    "group at sri international": 1.0,
    "at sri international continued": 1.0,
    "sri international continued research": 1.0,
    "international continued research and": 1.0,
    "continued research and development": 1.0,
    "research and development in": 0.5,
    "and development in the": 1.0,
    "development in the field": 1.0,
    "<s> a number of": 1.0,
    "a number of commercial": 0.045454545454545456,
    "number of commercial efforts": 1.0,
    "of commercial efforts based": 1.0,
    "commercial efforts based on": 1.0,
    "efforts based on the": 1.0,
    "based on the research": 0.09090909090909091,
    "on the research were": 1.0,
    "the research were undertaken": 1.0,
    "research were undertaken ,": 1.0,
    "were undertaken , e.g.": 1.0,
    "undertaken , e.g. ,": 1.0,
    ", e.g. , in": 0.14285714285714285,
    "e.g. , in 1982": 1.0,
    ", in 1982 gary": 1.0,
    "in 1982 gary hendrix": 1.0,
    "1982 gary hendrix formed": 1.0,
    "gary hendrix formed symantec": 1.0,
    "hendrix formed symantec corporation": 1.0,
    "formed symantec corporation originally": 1.0,
    "symantec corporation originally as": 1.0,
    "corporation originally as a": 1.0,
    "originally as a company": 1.0,
    "as a company for": 1.0,
    "a company for developing": 1.0,
    "company for developing a": 1.0,
    "for developing a natural": 1.0,
    "developing a natural language": 1.0,
    "a natural language interface": 0.25,
    "natural language interface for": 1.0,
    "language interface for database": 1.0,
    "interface for database queries": 1.0,
    "for database queries on": 1.0,
    "database queries on personal": 1.0,
    "queries on personal computers": 1.0,
    "on personal computers .": 1.0,
    "<s> however , with": 0.03125,
    "however , with the": 1.0,
    ", with the advent": 1.0,
    "with the advent of": 1.0,
    "the advent of mouse": 1.0,
    "advent of mouse driven": 1.0,
    "of mouse driven ,": 1.0,
    "mouse driven , graphic": 1.0,
    "driven , graphic user": 1.0,
    ", graphic user interfaces": 1.0,
    "graphic user interfaces symantec": 1.0,
    "user interfaces symantec changed": 1.0,
    "interfaces symantec changed direction": 1.0,
    "symantec changed direction .": 1.0,
    "a number of other": 0.045454545454545456,
    "number of other commercial": 1.0,
    "of other commercial efforts": 1.0,
    "other commercial efforts were": 1.0,
    "commercial efforts were started": 1.0,
    "efforts were started around": 1.0,
    "were started around the": 1.0,
    "started around the same": 1.0,
    "around the same time": 1.0,
    "same time , e.g.": 0.3333333333333333,
    "time , e.g. ,": 1.0,
    ", e.g. , larry": 0.14285714285714285,
    "e.g. , larry r.": 1.0,
    ", larry r. harris": 1.0,
    "larry r. harris at": 1.0,
    "r. harris at the": 1.0,
    "harris at the artificial": 1.0,
    "at the artificial intelligence": 1.0,
    "the artificial intelligence corporation": 1.0,
    "artificial intelligence corporation and": 1.0,
    "intelligence corporation and roger": 1.0,
    "corporation and roger schank": 1.0,
    "and roger schank and": 1.0,
    "roger schank and his": 0.5,
    "schank and his students": 1.0,
    "and his students at": 1.0,
    "his students at cognitive": 1.0,
    "students at cognitive systems": 1.0,
    "at cognitive systems corp.": 1.0,
    "cognitive systems corp. .": 1.0,
    "<s> in 1983 ,": 1.0,
    "in 1983 , michael": 1.0,
    "1983 , michael dyer": 1.0,
    ", michael dyer developed": 1.0,
    "michael dyer developed the": 1.0,
    "dyer developed the boris": 1.0,
    "developed the boris system": 1.0,
    "the boris system at": 1.0,
    "boris system at yale": 1.0,
    "system at yale which": 1.0,
    "at yale which bore": 1.0,
    "yale which bore similarities": 1.0,
    "which bore similarities to": 1.0,
    "bore similarities to the": 1.0,
    "similarities to the work": 1.0,
    "to the work of": 1.0,
    "the work of roger": 0.5,
    "work of roger schank": 1.0,
    "of roger schank and": 1.0,
    "roger schank and w.": 0.5,
    "schank and w. g.": 1.0,
    "and w. g. lehnart": 1.0,
    "w. g. lehnart .": 1.0,
    "<s> scope and context": 1.0,
    "scope and context the": 1.0,
    "and context the umbrella": 0.5,
    "context the umbrella term": 1.0,
    "the umbrella term ``": 1.0,
    "umbrella term `` natural": 1.0,
    "term `` natural language": 1.0,
    "`` natural language understanding": 1.0,
    "natural language understanding ''": 0.08333333333333333,
    "language understanding '' can": 1.0,
    "understanding '' can be": 1.0,
    "'' can be applied": 0.2,
    "can be applied to": 0.5,
    "be applied to a": 0.5,
    "applied to a diverse": 0.5,
    "to a diverse set": 1.0,
    "a diverse set of": 1.0,
    "diverse set of computer": 1.0,
    "set of computer applications": 1.0,
    "of computer applications ,": 1.0,
    "computer applications , ranging": 1.0,
    "applications , ranging from": 1.0,
    ", ranging from small": 0.5,
    "ranging from small ,": 1.0,
    "from small , relatively": 1.0,
    "small , relatively simple": 1.0,
    ", relatively simple tasks": 1.0,
    "relatively simple tasks such": 1.0,
    "simple tasks such as": 1.0,
    "tasks such as short": 0.5,
    "such as short commands": 1.0,
    "as short commands issued": 1.0,
    "short commands issued to": 1.0,
    "commands issued to robots": 1.0,
    "issued to robots ,": 1.0,
    "to robots , to": 1.0,
    "robots , to highly": 1.0,
    ", to highly complex": 1.0,
    "to highly complex endeavors": 1.0,
    "highly complex endeavors such": 1.0,
    "complex endeavors such as": 1.0,
    "endeavors such as the": 1.0,
    "such as the full": 0.07142857142857142,
    "as the full comprehension": 1.0,
    "the full comprehension of": 1.0,
    "full comprehension of newspaper": 1.0,
    "comprehension of newspaper articles": 1.0,
    "of newspaper articles or": 1.0,
    "newspaper articles or poetry": 1.0,
    "articles or poetry passages": 1.0,
    "or poetry passages .": 1.0,
    "<s> many real world": 1.0,
    "many real world applications": 1.0,
    "real world applications fall": 1.0,
    "world applications fall between": 1.0,
    "applications fall between the": 1.0,
    "fall between the two": 1.0,
    "between the two extremes": 0.3333333333333333,
    "the two extremes ,": 1.0,
    "two extremes , for": 1.0,
    "extremes , for instance": 1.0,
    ", for instance text": 0.25,
    "for instance text classification": 1.0,
    "instance text classification for": 1.0,
    "text classification for the": 1.0,
    "classification for the automatic": 1.0,
    "for the automatic analysis": 1.0,
    "the automatic analysis of": 1.0,
    "automatic analysis of emails": 1.0,
    "analysis of emails and": 1.0,
    "of emails and their": 1.0,
    "emails and their routing": 1.0,
    "and their routing to": 1.0,
    "their routing to a": 1.0,
    "routing to a suitable": 1.0,
    "to a suitable department": 1.0,
    "a suitable department in": 1.0,
    "suitable department in a": 1.0,
    "department in a corporation": 1.0,
    "in a corporation does": 1.0,
    "a corporation does not": 1.0,
    "corporation does not require": 1.0,
    "does not require in": 1.0,
    "not require in depth": 1.0,
    "require in depth understanding": 1.0,
    "in depth understanding of": 1.0,
    "depth understanding of the": 1.0,
    "understanding of the text": 1.0,
    "the text , but": 0.3333333333333333,
    "text , but is": 1.0,
    ", but is far": 0.5,
    "but is far more": 1.0,
    "is far more complex": 0.5,
    "far more complex than": 1.0,
    "complex than the management": 0.5,
    "than the management of": 1.0,
    "the management of simple": 0.5,
    "management of simple queries": 1.0,
    "of simple queries to": 1.0,
    "simple queries to database": 1.0,
    "queries to database tables": 1.0,
    "to database tables with": 1.0,
    "database tables with fixed": 1.0,
    "tables with fixed schemata": 1.0,
    "with fixed schemata .": 1.0,
    "<s> throughout the years": 1.0,
    "throughout the years various": 1.0,
    "the years various attempts": 1.0,
    "years various attempts at": 1.0,
    "various attempts at processing": 1.0,
    "attempts at processing natural": 1.0,
    "at processing natural language": 1.0,
    "processing natural language or": 1.0,
    "natural language or english-like": 1.0,
    "language or english-like sentences": 1.0,
    "or english-like sentences presented": 1.0,
    "english-like sentences presented to": 1.0,
    "sentences presented to computers": 1.0,
    "presented to computers have": 1.0,
    "to computers have taken": 1.0,
    "computers have taken place": 1.0,
    "have taken place at": 1.0,
    "taken place at varying": 1.0,
    "place at varying degrees": 1.0,
    "at varying degrees of": 1.0,
    "varying degrees of complexity": 1.0,
    "degrees of complexity .": 1.0,
    "<s> some attempts have": 1.0,
    "some attempts have not": 1.0,
    "attempts have not resulted": 1.0,
    "have not resulted in": 1.0,
    "not resulted in systems": 1.0,
    "resulted in systems with": 1.0,
    "in systems with deep": 1.0,
    "systems with deep understanding": 1.0,
    "with deep understanding ,": 1.0,
    "deep understanding , but": 0.5,
    "understanding , but have": 0.5,
    ", but have helped": 0.5,
    "but have helped overall": 1.0,
    "have helped overall system": 1.0,
    "helped overall system usability": 1.0,
    "overall system usability .": 1.0,
    "for example , wayne": 0.02127659574468085,
    "example , wayne ratliff": 1.0,
    ", wayne ratliff originally": 1.0,
    "wayne ratliff originally developed": 1.0,
    "ratliff originally developed the": 1.0,
    "originally developed the vulcan": 1.0,
    "developed the vulcan program": 1.0,
    "the vulcan program with": 1.0,
    "vulcan program with an": 1.0,
    "program with an english-like": 1.0,
    "with an english-like syntax": 1.0,
    "an english-like syntax to": 1.0,
    "english-like syntax to mimic": 1.0,
    "syntax to mimic the": 1.0,
    "to mimic the english": 1.0,
    "mimic the english speaking": 1.0,
    "the english speaking computer": 1.0,
    "english speaking computer in": 1.0,
    "speaking computer in star": 1.0,
    "computer in star trek": 1.0,
    "in star trek .": 1.0,
    "<s> vulcan later became": 1.0,
    "vulcan later became the": 1.0,
    "later became the dbase": 1.0,
    "became the dbase system": 1.0,
    "the dbase system whose": 1.0,
    "dbase system whose easy-to-use": 1.0,
    "system whose easy-to-use syntax": 1.0,
    "whose easy-to-use syntax effectively": 1.0,
    "easy-to-use syntax effectively launched": 1.0,
    "syntax effectively launched the": 1.0,
    "effectively launched the personal": 1.0,
    "launched the personal computer": 1.0,
    "the personal computer database": 1.0,
    "personal computer database industry": 1.0,
    "computer database industry .": 1.0,
    "<s> systems with an": 1.0,
    "systems with an easy": 1.0,
    "with an easy to": 1.0,
    "an easy to use": 1.0,
    "easy to use or": 1.0,
    "to use or english": 1.0,
    "use or english like": 1.0,
    "or english like syntax": 1.0,
    "english like syntax are": 1.0,
    "like syntax are ,": 1.0,
    "syntax are , however": 1.0,
    "are , however ,": 1.0,
    ", however , quite": 0.09090909090909091,
    "however , quite distinct": 1.0,
    ", quite distinct from": 1.0,
    "quite distinct from systems": 1.0,
    "distinct from systems that": 1.0,
    "from systems that use": 1.0,
    "systems that use a": 0.5,
    "that use a rich": 1.0,
    "use a rich lexicon": 1.0,
    "a rich lexicon and": 0.3333333333333333,
    "rich lexicon and include": 1.0,
    "lexicon and include an": 1.0,
    "and include an internal": 1.0,
    "include an internal representation": 1.0,
    "an internal representation -lrb-": 0.5,
    "internal representation -lrb- often": 1.0,
    "representation -lrb- often as": 1.0,
    "-lrb- often as first": 1.0,
    "often as first order": 1.0,
    "as first order logic": 1.0,
    "first order logic -rrb-": 1.0,
    "order logic -rrb- of": 1.0,
    "logic -rrb- of the": 1.0,
    "-rrb- of the semantics": 0.3333333333333333,
    "of the semantics of": 1.0,
    "the semantics of natural": 1.0,
    "semantics of natural language": 1.0,
    "of natural language sentences": 0.058823529411764705,
    "natural language sentences .": 1.0,
    "<s> hence the breadth": 1.0,
    "hence the breadth and": 1.0,
    "the breadth and depth": 1.0,
    "breadth and depth of": 1.0,
    "and depth of ``": 1.0,
    "depth of `` understanding": 1.0,
    "of `` understanding ''": 1.0,
    "`` understanding '' aimed": 1.0,
    "understanding '' aimed at": 1.0,
    "'' aimed at by": 1.0,
    "aimed at by a": 1.0,
    "at by a system": 1.0,
    "by a system determine": 1.0,
    "a system determine both": 1.0,
    "system determine both the": 1.0,
    "determine both the complexity": 1.0,
    "both the complexity of": 1.0,
    "complexity of the system": 0.16666666666666666,
    "of the system -lrb-": 0.25,
    "the system -lrb- and": 1.0,
    "system -lrb- and the": 1.0,
    "-lrb- and the implied": 0.5,
    "and the implied challenges": 1.0,
    "the implied challenges -rrb-": 1.0,
    "implied challenges -rrb- and": 1.0,
    "challenges -rrb- and the": 1.0,
    "-rrb- and the types": 0.2,
    "and the types of": 1.0,
    "the types of applications": 0.5,
    "types of applications it": 1.0,
    "of applications it can": 1.0,
    "applications it can deal": 1.0,
    "it can deal with": 1.0,
    "can deal with .": 1.0,
    "<s> the `` breadth": 0.5,
    "the `` breadth ''": 1.0,
    "`` breadth '' of": 1.0,
    "breadth '' of a": 1.0,
    "'' of a system": 1.0,
    "of a system is": 0.25,
    "a system is measured": 1.0,
    "system is measured by": 1.0,
    "is measured by the": 1.0,
    "measured by the sizes": 0.5,
    "by the sizes of": 1.0,
    "the sizes of its": 1.0,
    "sizes of its vocabulary": 1.0,
    "of its vocabulary and": 1.0,
    "its vocabulary and grammar": 1.0,
    "vocabulary and grammar .": 1.0,
    "<s> the `` depth": 0.5,
    "the `` depth ''": 1.0,
    "`` depth '' is": 1.0,
    "depth '' is measured": 1.0,
    "'' is measured by": 1.0,
    "measured by the degree": 0.5,
    "by the degree to": 1.0,
    "the degree to which": 1.0,
    "degree to which its": 1.0,
    "to which its understanding": 1.0,
    "which its understanding approximates": 1.0,
    "its understanding approximates that": 1.0,
    "understanding approximates that of": 1.0,
    "approximates that of a": 1.0,
    "that of a fluent": 0.5,
    "of a fluent native": 1.0,
    "a fluent native speaker": 1.0,
    "fluent native speaker .": 1.0,
    "<s> at the narrowest": 1.0,
    "at the narrowest and": 1.0,
    "the narrowest and shallowest": 1.0,
    "narrowest and shallowest ,": 1.0,
    "and shallowest , english-like": 1.0,
    "shallowest , english-like command": 1.0,
    ", english-like command interpreters": 1.0,
    "english-like command interpreters require": 1.0,
    "command interpreters require minimal": 1.0,
    "interpreters require minimal complexity": 1.0,
    "require minimal complexity ,": 1.0,
    "minimal complexity , but": 1.0,
    "complexity , but have": 0.5,
    ", but have a": 0.5,
    "but have a small": 1.0,
    "have a small range": 1.0,
    "a small range of": 1.0,
    "small range of applications": 1.0,
    "range of applications .": 1.0,
    "<s> narrow but deep": 1.0,
    "narrow but deep systems": 1.0,
    "but deep systems explore": 1.0,
    "deep systems explore and": 1.0,
    "systems explore and model": 1.0,
    "explore and model mechanisms": 1.0,
    "and model mechanisms of": 1.0,
    "model mechanisms of understanding": 1.0,
    "mechanisms of understanding ,": 1.0,
    "of understanding , but": 1.0,
    "understanding , but they": 0.5,
    ", but they still": 0.3333333333333333,
    "but they still have": 1.0,
    "they still have limited": 1.0,
    "still have limited application": 1.0,
    "have limited application .": 1.0,
    "<s> systems that attempt": 0.25,
    "systems that attempt to": 1.0,
    "that attempt to understand": 1.0,
    "attempt to understand the": 1.0,
    "to understand the contents": 0.5,
    "understand the contents of": 1.0,
    "the contents of a": 1.0,
    "contents of a document": 1.0,
    "of a document such": 0.5,
    "a document such as": 1.0,
    "document such as a": 1.0,
    "such as a news": 0.3333333333333333,
    "as a news release": 1.0,
    "a news release beyond": 1.0,
    "news release beyond simple": 1.0,
    "release beyond simple keyword": 1.0,
    "beyond simple keyword matching": 1.0,
    "simple keyword matching and": 1.0,
    "keyword matching and to": 1.0,
    "matching and to judge": 1.0,
    "and to judge its": 1.0,
    "to judge its suitability": 1.0,
    "judge its suitability for": 1.0,
    "its suitability for a": 1.0,
    "suitability for a user": 1.0,
    "for a user are": 1.0,
    "a user are broader": 1.0,
    "user are broader and": 1.0,
    "are broader and require": 1.0,
    "broader and require significant": 1.0,
    "and require significant complexity": 1.0,
    "require significant complexity ,": 1.0,
    "significant complexity , but": 1.0,
    "complexity , but they": 0.5,
    ", but they are": 0.3333333333333333,
    "but they are still": 1.0,
    "they are still somewhat": 1.0,
    "are still somewhat shallow": 1.0,
    "still somewhat shallow .": 1.0,
    "<s> systems that are": 0.25,
    "systems that are both": 0.5,
    "that are both very": 0.5,
    "are both very broad": 1.0,
    "both very broad and": 1.0,
    "very broad and very": 1.0,
    "broad and very deep": 1.0,
    "and very deep are": 1.0,
    "very deep are beyond": 1.0,
    "deep are beyond the": 1.0,
    "are beyond the current": 1.0,
    "beyond the current state": 1.0,
    "the current state of": 1.0,
    "current state of the": 0.5,
    "state of the art": 0.5,
    "of the art .": 0.5,
    "<s> components and architecture": 1.0,
    "components and architecture regardless": 1.0,
    "and architecture regardless of": 1.0,
    "architecture regardless of the": 1.0,
    "regardless of the approach": 0.5,
    "of the approach used": 1.0,
    "the approach used ,": 1.0,
    "approach used , some": 1.0,
    "used , some common": 1.0,
    ", some common components": 1.0,
    "some common components can": 1.0,
    "common components can be": 1.0,
    "components can be identified": 1.0,
    "can be identified in": 1.0,
    "be identified in most": 1.0,
    "identified in most natural": 1.0,
    "in most natural language": 1.0,
    "most natural language understanding": 0.5,
    "natural language understanding systems": 0.08333333333333333,
    "language understanding systems .": 1.0,
    "<s> the system needs": 0.16666666666666666,
    "the system needs a": 0.3333333333333333,
    "system needs a lexicon": 1.0,
    "needs a lexicon of": 1.0,
    "a lexicon of the": 0.5,
    "lexicon of the language": 1.0,
    "of the language and": 0.16666666666666666,
    "the language and a": 1.0,
    "language and a parser": 1.0,
    "and a parser and": 1.0,
    "a parser and grammar": 1.0,
    "parser and grammar rules": 1.0,
    "and grammar rules to": 1.0,
    "grammar rules to break": 1.0,
    "rules to break sentences": 1.0,
    "to break sentences into": 1.0,
    "break sentences into an": 1.0,
    "sentences into an internal": 1.0,
    "into an internal representation": 1.0,
    "an internal representation .": 0.5,
    "<s> the construction of": 1.0,
    "construction of a rich": 0.5,
    "of a rich lexicon": 1.0,
    "a rich lexicon with": 0.3333333333333333,
    "rich lexicon with a": 1.0,
    "lexicon with a suitable": 1.0,
    "with a suitable ontology": 1.0,
    "a suitable ontology requires": 1.0,
    "suitable ontology requires significant": 1.0,
    "ontology requires significant effort": 1.0,
    "requires significant effort ,": 1.0,
    "significant effort , e.g.": 1.0,
    "effort , e.g. ,": 1.0,
    ", e.g. , the": 0.2857142857142857,
    "e.g. , the wordnet": 0.5,
    ", the wordnet lexicon": 1.0,
    "the wordnet lexicon required": 1.0,
    "wordnet lexicon required many": 1.0,
    "lexicon required many person-years": 1.0,
    "required many person-years of": 1.0,
    "many person-years of effort": 1.0,
    "person-years of effort .": 1.0,
    "<s> the system also": 0.16666666666666666,
    "the system also needs": 1.0,
    "system also needs a": 1.0,
    "also needs a semantic": 1.0,
    "needs a semantic theory": 1.0,
    "a semantic theory to": 1.0,
    "semantic theory to guide": 1.0,
    "theory to guide the": 1.0,
    "to guide the comprehension": 1.0,
    "guide the comprehension .": 1.0,
    "<s> the interpretation capabilities": 1.0,
    "the interpretation capabilities of": 1.0,
    "interpretation capabilities of a": 1.0,
    "capabilities of a language": 1.0,
    "of a language understanding": 0.5,
    "a language understanding system": 1.0,
    "language understanding system depend": 1.0,
    "understanding system depend on": 1.0,
    "system depend on the": 1.0,
    "depend on the semantic": 1.0,
    "on the semantic theory": 1.0,
    "the semantic theory it": 1.0,
    "semantic theory it uses": 1.0,
    "theory it uses .": 1.0,
    "<s> competing semantic theories": 1.0,
    "competing semantic theories of": 1.0,
    "semantic theories of language": 1.0,
    "theories of language have": 1.0,
    "of language have specific": 1.0,
    "language have specific trade": 1.0,
    "have specific trade offs": 1.0,
    "specific trade offs in": 1.0,
    "trade offs in their": 1.0,
    "offs in their suitability": 1.0,
    "in their suitability as": 1.0,
    "their suitability as the": 1.0,
    "suitability as the basis": 1.0,
    "as the basis of": 1.0,
    "the basis of computer": 0.3333333333333333,
    "basis of computer automated": 1.0,
    "of computer automated semantic": 1.0,
    "computer automated semantic interpretation": 1.0,
    "automated semantic interpretation .": 1.0,
    "<s> these range from": 1.0,
    "these range from naive": 1.0,
    "range from naive semantics": 1.0,
    "from naive semantics or": 1.0,
    "naive semantics or stochastic": 1.0,
    "semantics or stochastic semantic": 1.0,
    "or stochastic semantic analysis": 1.0,
    "stochastic semantic analysis to": 1.0,
    "semantic analysis to the": 1.0,
    "analysis to the use": 1.0,
    "to the use of": 1.0,
    "the use of pragmatics": 0.06666666666666667,
    "use of pragmatics to": 1.0,
    "of pragmatics to derive": 1.0,
    "pragmatics to derive meaning": 1.0,
    "to derive meaning from": 1.0,
    "derive meaning from context": 1.0,
    "meaning from context .": 1.0,
    "<s> advanced applications of": 1.0,
    "advanced applications of natural": 1.0,
    "applications of natural language": 1.0,
    "natural language understanding also": 0.08333333333333333,
    "language understanding also attempt": 1.0,
    "understanding also attempt to": 1.0,
    "also attempt to incorporate": 1.0,
    "attempt to incorporate logical": 1.0,
    "to incorporate logical inference": 1.0,
    "incorporate logical inference within": 1.0,
    "logical inference within their": 1.0,
    "inference within their framework": 1.0,
    "within their framework .": 1.0,
    "<s> this is generally": 0.07142857142857142,
    "this is generally achieved": 1.0,
    "is generally achieved by": 1.0,
    "generally achieved by mapping": 1.0,
    "achieved by mapping the": 1.0,
    "by mapping the derived": 1.0,
    "mapping the derived meaning": 1.0,
    "the derived meaning into": 1.0,
    "derived meaning into a": 1.0,
    "meaning into a set": 1.0,
    "into a set of": 1.0,
    "a set of assertions": 0.07142857142857142,
    "set of assertions in": 1.0,
    "of assertions in predicate": 1.0,
    "assertions in predicate logic": 1.0,
    "in predicate logic ,": 1.0,
    "predicate logic , then": 1.0,
    "logic , then using": 1.0,
    ", then using logical": 1.0,
    "then using logical deduction": 1.0,
    "using logical deduction to": 1.0,
    "logical deduction to arrive": 1.0,
    "deduction to arrive at": 1.0,
    "to arrive at conclusions": 1.0,
    "arrive at conclusions .": 1.0,
    "systems based on functional": 0.2,
    "based on functional languages": 1.0,
    "on functional languages such": 1.0,
    "functional languages such as": 1.0,
    "languages such as lisp": 0.25,
    "such as lisp hence": 1.0,
    "as lisp hence need": 1.0,
    "lisp hence need to": 1.0,
    "hence need to include": 1.0,
    "need to include a": 1.0,
    "to include a subsystem": 1.0,
    "include a subsystem for": 1.0,
    "a subsystem for the": 1.0,
    "subsystem for the representation": 1.0,
    "for the representation of": 1.0,
    "the representation of logical": 1.0,
    "representation of logical assertions": 1.0,
    "of logical assertions ,": 1.0,
    "logical assertions , while": 1.0,
    "assertions , while logic": 1.0,
    ", while logic oriented": 1.0,
    "while logic oriented systems": 1.0,
    "logic oriented systems such": 1.0,
    "oriented systems such as": 1.0,
    "such as those using": 0.2,
    "as those using the": 1.0,
    "those using the language": 1.0,
    "using the language prolog": 1.0,
    "the language prolog generally": 1.0,
    "language prolog generally rely": 1.0,
    "prolog generally rely on": 1.0,
    "generally rely on an": 1.0,
    "rely on an extension": 1.0,
    "on an extension of": 1.0,
    "an extension of the": 1.0,
    "extension of the built": 1.0,
    "of the built in": 1.0,
    "the built in logical": 1.0,
    "built in logical representation": 1.0,
    "in logical representation framework": 1.0,
    "logical representation framework .": 1.0,
    "<s> the management of": 1.0,
    "the management of context": 0.5,
    "management of context in": 1.0,
    "of context in natural": 1.0,
    "context in natural language": 1.0,
    "natural language understanding can": 0.08333333333333333,
    "language understanding can present": 1.0,
    "understanding can present special": 1.0,
    "can present special challenges": 1.0,
    "present special challenges .": 1.0,
    "<s> a large variety": 1.0,
    "a large variety of": 1.0,
    "large variety of examples": 1.0,
    "variety of examples and": 1.0,
    "of examples and counter": 1.0,
    "examples and counter examples": 1.0,
    "and counter examples have": 1.0,
    "counter examples have resulted": 1.0,
    "examples have resulted in": 1.0,
    "have resulted in multiple": 1.0,
    "resulted in multiple approaches": 1.0,
    "in multiple approaches to": 1.0,
    "multiple approaches to the": 1.0,
    "approaches to the formal": 1.0,
    "to the formal modeling": 1.0,
    "the formal modeling of": 1.0,
    "formal modeling of context": 1.0,
    "modeling of context ,": 1.0,
    "of context , each": 1.0,
    "context , each with": 1.0,
    ", each with specific": 1.0,
    "each with specific strengths": 1.0,
    "with specific strengths and": 1.0,
    "specific strengths and weaknesses": 1.0,
    "strengths and weaknesses .": 1.0,
    "optical character recognition ,": 0.2,
    "character recognition , usually": 0.25,
    "recognition , usually abbreviated": 1.0,
    ", usually abbreviated to": 1.0,
    "usually abbreviated to ocr": 1.0,
    "abbreviated to ocr ,": 1.0,
    "to ocr , is": 1.0,
    "ocr , is the": 1.0,
    ", is the mechanical": 0.16666666666666666,
    "is the mechanical or": 1.0,
    "the mechanical or electronic": 1.0,
    "mechanical or electronic conversion": 1.0,
    "or electronic conversion of": 1.0,
    "electronic conversion of scanned": 1.0,
    "conversion of scanned images": 1.0,
    "of scanned images of": 1.0,
    "scanned images of handwritten": 1.0,
    "images of handwritten ,": 1.0,
    "of handwritten , typewritten": 1.0,
    "handwritten , typewritten or": 1.0,
    ", typewritten or printed": 1.0,
    "typewritten or printed text": 1.0,
    "or printed text into": 1.0,
    "printed text into machine-encoded": 1.0,
    "text into machine-encoded text": 1.0,
    "into machine-encoded text .": 1.0,
    "<s> it is widely": 0.05263157894736842,
    "it is widely used": 1.0,
    "is widely used as": 0.5,
    "widely used as a": 1.0,
    "used as a form": 0.5,
    "as a form of": 1.0,
    "a form of data": 1.0,
    "form of data entry": 1.0,
    "of data entry from": 1.0,
    "data entry from some": 1.0,
    "entry from some sort": 1.0,
    "from some sort of": 1.0,
    "some sort of original": 1.0,
    "sort of original paper": 1.0,
    "of original paper data": 1.0,
    "original paper data source": 1.0,
    "paper data source ,": 1.0,
    "data source , whether": 1.0,
    "source , whether documents": 1.0,
    ", whether documents ,": 1.0,
    "whether documents , sales": 1.0,
    "documents , sales receipts": 1.0,
    ", sales receipts ,": 1.0,
    "sales receipts , mail": 1.0,
    "receipts , mail ,": 1.0,
    ", mail , or": 1.0,
    "mail , or any": 1.0,
    ", or any number": 1.0,
    "or any number of": 1.0,
    "any number of printed": 1.0,
    "number of printed records": 1.0,
    "of printed records .": 1.0,
    "<s> it is crucial": 0.05263157894736842,
    "it is crucial to": 1.0,
    "is crucial to the": 1.0,
    "crucial to the computerization": 1.0,
    "to the computerization of": 1.0,
    "the computerization of printed": 1.0,
    "computerization of printed texts": 1.0,
    "of printed texts so": 1.0,
    "printed texts so that": 1.0,
    "texts so that they": 1.0,
    "so that they can": 1.0,
    "that they can be": 0.3333333333333333,
    "they can be electronically": 0.25,
    "can be electronically searched": 1.0,
    "be electronically searched ,": 1.0,
    "electronically searched , stored": 1.0,
    "searched , stored more": 1.0,
    ", stored more compactly": 1.0,
    "stored more compactly ,": 1.0,
    "more compactly , displayed": 1.0,
    "compactly , displayed on-line": 1.0,
    ", displayed on-line ,": 1.0,
    "displayed on-line , and": 1.0,
    "on-line , and used": 1.0,
    ", and used in": 1.0,
    "and used in machine": 1.0,
    "used in machine processes": 1.0,
    "in machine processes such": 1.0,
    "machine processes such as": 1.0,
    "processes such as machine": 1.0,
    "such as machine translation": 1.0,
    "as machine translation ,": 1.0,
    "machine translation , text-to-speech": 0.14285714285714285,
    "translation , text-to-speech and": 1.0,
    ", text-to-speech and text": 0.5,
    "text-to-speech and text mining": 1.0,
    "and text mining .": 1.0,
    "<s> ocr is a": 0.5,
    "ocr is a field": 1.0,
    "a field of research": 0.3333333333333333,
    "field of research in": 1.0,
    "of research in pattern": 0.5,
    "research in pattern recognition": 1.0,
    "in pattern recognition ,": 1.0,
    "pattern recognition , artificial": 1.0,
    "recognition , artificial intelligence": 1.0,
    ", artificial intelligence and": 0.5,
    "artificial intelligence and computer": 1.0,
    "intelligence and computer vision": 1.0,
    "and computer vision .": 1.0,
    "<s> early versions needed": 1.0,
    "early versions needed to": 1.0,
    "versions needed to be": 1.0,
    "needed to be programmed": 1.0,
    "to be programmed with": 1.0,
    "be programmed with images": 1.0,
    "programmed with images of": 1.0,
    "with images of each": 1.0,
    "images of each character": 1.0,
    "of each character ,": 1.0,
    "each character , and": 1.0,
    "character , and worked": 1.0,
    ", and worked on": 1.0,
    "and worked on one": 1.0,
    "worked on one font": 1.0,
    "on one font at": 1.0,
    "one font at a": 1.0,
    "font at a time": 1.0,
    "at a time .": 1.0,
    "<s> `` intelligent ''": 1.0,
    "`` intelligent '' systems": 1.0,
    "intelligent '' systems with": 1.0,
    "'' systems with a": 1.0,
    "systems with a high": 1.0,
    "with a high degree": 0.5,
    "a high degree of": 1.0,
    "high degree of recognition": 1.0,
    "degree of recognition accuracy": 1.0,
    "of recognition accuracy for": 1.0,
    "recognition accuracy for most": 1.0,
    "accuracy for most fonts": 1.0,
    "for most fonts are": 1.0,
    "most fonts are now": 1.0,
    "fonts are now common": 1.0,
    "are now common .": 1.0,
    "<s> some systems are": 0.5,
    "some systems are capable": 0.5,
    "systems are capable of": 1.0,
    "are capable of reproducing": 0.5,
    "capable of reproducing formatted": 1.0,
    "of reproducing formatted output": 1.0,
    "reproducing formatted output that": 1.0,
    "formatted output that closely": 1.0,
    "output that closely approximates": 1.0,
    "that closely approximates the": 1.0,
    "closely approximates the original": 1.0,
    "approximates the original scanned": 1.0,
    "the original scanned page": 1.0,
    "original scanned page including": 1.0,
    "scanned page including images": 1.0,
    "page including images ,": 1.0,
    "including images , columns": 1.0,
    "images , columns and": 1.0,
    ", columns and other": 1.0,
    "columns and other non-textual": 1.0,
    "and other non-textual components": 1.0,
    "other non-textual components .": 1.0,
    "<s> in 1914 ,": 1.0,
    "in 1914 , emanuel": 1.0,
    "1914 , emanuel goldberg": 1.0,
    ", emanuel goldberg developed": 1.0,
    "emanuel goldberg developed a": 1.0,
    "goldberg developed a machine": 1.0,
    "developed a machine that": 1.0,
    "a machine that read": 1.0,
    "machine that read characters": 1.0,
    "that read characters and": 1.0,
    "read characters and converted": 1.0,
    "characters and converted them": 1.0,
    "and converted them into": 1.0,
    "converted them into standard": 1.0,
    "them into standard telegraph": 1.0,
    "into standard telegraph code": 1.0,
    "standard telegraph code .": 1.0,
    "citation needed -rrb- around": 0.07692307692307693,
    "needed -rrb- around the": 1.0,
    "-rrb- around the same": 1.0,
    "same time , edmund": 0.3333333333333333,
    "time , edmund fournier": 1.0,
    ", edmund fournier d'albe": 1.0,
    "edmund fournier d'albe developed": 1.0,
    "fournier d'albe developed the": 1.0,
    "d'albe developed the optophone": 1.0,
    "developed the optophone ,": 1.0,
    "the optophone , a": 1.0,
    "optophone , a handheld": 1.0,
    ", a handheld scanner": 1.0,
    "a handheld scanner that": 1.0,
    "handheld scanner that when": 1.0,
    "scanner that when moved": 1.0,
    "that when moved across": 1.0,
    "when moved across a": 1.0,
    "moved across a printed": 1.0,
    "across a printed page": 1.0,
    "a printed page ,": 1.0,
    "printed page , produced": 1.0,
    "page , produced tones": 1.0,
    ", produced tones that": 1.0,
    "produced tones that corresponded": 1.0,
    "tones that corresponded to": 1.0,
    "that corresponded to specific": 1.0,
    "corresponded to specific letters": 1.0,
    "to specific letters or": 1.0,
    "specific letters or characters": 1.0,
    "letters or characters .": 1.0,
    "<s> goldberg continued to": 1.0,
    "goldberg continued to develop": 1.0,
    "continued to develop ocr": 1.0,
    "to develop ocr technology": 1.0,
    "develop ocr technology for": 1.0,
    "ocr technology for data": 1.0,
    "technology for data entry": 1.0,
    "for data entry .": 1.0,
    "<s> later , he": 1.0,
    "later , he proposed": 1.0,
    ", he proposed photographing": 1.0,
    "he proposed photographing data": 1.0,
    "proposed photographing data records": 1.0,
    "photographing data records and": 1.0,
    "data records and then": 1.0,
    "records and then ,": 1.0,
    "and then , using": 1.0,
    "then , using photocells": 1.0,
    ", using photocells ,": 1.0,
    "using photocells , matching": 1.0,
    "photocells , matching the": 1.0,
    ", matching the photos": 1.0,
    "matching the photos against": 1.0,
    "the photos against a": 1.0,
    "photos against a template": 1.0,
    "against a template containing": 1.0,
    "a template containing the": 1.0,
    "template containing the desired": 1.0,
    "containing the desired identification": 1.0,
    "the desired identification pattern": 1.0,
    "desired identification pattern .": 1.0,
    "<s> in 1929 gustav": 1.0,
    "in 1929 gustav tauschek": 1.0,
    "1929 gustav tauschek had": 1.0,
    "gustav tauschek had similar": 1.0,
    "tauschek had similar ideas": 1.0,
    "had similar ideas ,": 1.0,
    "similar ideas , and": 1.0,
    "ideas , and obtained": 1.0,
    ", and obtained a": 1.0,
    "and obtained a patent": 1.0,
    "obtained a patent on": 1.0,
    "a patent on ocr": 1.0,
    "patent on ocr in": 1.0,
    "on ocr in germany": 1.0,
    "ocr in germany .": 1.0,
    "<s> paul w. handel": 1.0,
    "paul w. handel also": 1.0,
    "w. handel also obtained": 1.0,
    "handel also obtained a": 1.0,
    "also obtained a us": 1.0,
    "obtained a us patent": 1.0,
    "a us patent on": 1.0,
    "us patent on such": 0.5,
    "patent on such template-matching": 1.0,
    "on such template-matching ocr": 1.0,
    "such template-matching ocr technology": 1.0,
    "template-matching ocr technology in": 1.0,
    "ocr technology in usa": 1.0,
    "technology in usa in": 1.0,
    "in usa in 1933": 1.0,
    "usa in 1933 -lrb-": 1.0,
    "in 1933 -lrb- u.s.": 1.0,
    "1933 -lrb- u.s. patent": 1.0,
    "-lrb- u.s. patent 1,915,993": 0.5,
    "u.s. patent 1,915,993 -rrb-": 1.0,
    "patent 1,915,993 -rrb- .": 1.0,
    "<s> in 1935 tauschek": 1.0,
    "in 1935 tauschek was": 1.0,
    "1935 tauschek was also": 1.0,
    "tauschek was also granted": 1.0,
    "was also granted a": 1.0,
    "also granted a us": 1.0,
    "granted a us patent": 1.0,
    "us patent on his": 0.5,
    "patent on his method": 1.0,
    "on his method -lrb-": 1.0,
    "his method -lrb- u.s.": 1.0,
    "method -lrb- u.s. patent": 1.0,
    "-lrb- u.s. patent 2,026,329": 0.5,
    "u.s. patent 2,026,329 -rrb-": 1.0,
    "patent 2,026,329 -rrb- .": 1.0,
    "<s> in 1949 rca": 1.0,
    "in 1949 rca engineers": 1.0,
    "1949 rca engineers worked": 1.0,
    "rca engineers worked on": 1.0,
    "engineers worked on the": 1.0,
    "worked on the first": 1.0,
    "on the first primitive": 1.0,
    "the first primitive computer-type": 1.0,
    "first primitive computer-type ocr": 1.0,
    "primitive computer-type ocr to": 1.0,
    "computer-type ocr to help": 1.0,
    "ocr to help blind": 1.0,
    "to help blind people": 1.0,
    "help blind people for": 1.0,
    "blind people for the": 1.0,
    "people for the us": 1.0,
    "for the us veterans": 1.0,
    "the us veterans administration": 1.0,
    "us veterans administration ,": 1.0,
    "veterans administration , but": 1.0,
    "administration , but instead": 1.0,
    ", but instead of": 1.0,
    "but instead of converting": 1.0,
    "instead of converting the": 1.0,
    "of converting the printed": 1.0,
    "converting the printed characters": 1.0,
    "the printed characters to": 1.0,
    "printed characters to machine": 1.0,
    "characters to machine language": 1.0,
    "to machine language ,": 0.5,
    "machine language , their": 1.0,
    "language , their device": 1.0,
    ", their device converted": 1.0,
    "their device converted it": 1.0,
    "device converted it to": 1.0,
    "converted it to machine": 1.0,
    "it to machine language": 1.0,
    "to machine language and": 0.5,
    "machine language and then": 1.0,
    "language and then spoke": 1.0,
    "and then spoke the": 1.0,
    "then spoke the letters": 1.0,
    "spoke the letters :": 1.0,
    "the letters : an": 1.0,
    "letters : an early": 1.0,
    ": an early text-to-speech": 1.0,
    "an early text-to-speech technology": 1.0,
    "early text-to-speech technology .": 1.0,
    "<s> it proved far": 1.0,
    "it proved far too": 1.0,
    "proved far too expensive": 1.0,
    "far too expensive and": 1.0,
    "too expensive and was": 1.0,
    "expensive and was not": 1.0,
    "and was not pursued": 1.0,
    "was not pursued after": 1.0,
    "not pursued after testing": 1.0,
    "pursued after testing .": 1.0,
    "in 1950 , david": 0.5,
    "1950 , david h.": 1.0,
    ", david h. shepard": 1.0,
    "david h. shepard ,": 1.0,
    "h. shepard , a": 1.0,
    "shepard , a cryptanalyst": 1.0,
    ", a cryptanalyst at": 1.0,
    "a cryptanalyst at the": 1.0,
    "cryptanalyst at the armed": 1.0,
    "at the armed forces": 1.0,
    "the armed forces security": 1.0,
    "armed forces security agency": 1.0,
    "forces security agency in": 1.0,
    "security agency in the": 1.0,
    "agency in the united": 1.0,
    "in the united states": 1.0,
    "the united states ,": 0.14285714285714285,
    "united states , addressed": 1.0,
    "states , addressed the": 1.0,
    ", addressed the problem": 1.0,
    "addressed the problem of": 1.0,
    "the problem of converting": 0.16666666666666666,
    "problem of converting printed": 1.0,
    "of converting printed messages": 1.0,
    "converting printed messages into": 1.0,
    "printed messages into machine": 1.0,
    "messages into machine language": 1.0,
    "into machine language for": 1.0,
    "machine language for computer": 1.0,
    "language for computer processing": 1.0,
    "for computer processing and": 1.0,
    "computer processing and built": 1.0,
    "processing and built a": 1.0,
    "and built a machine": 1.0,
    "built a machine to": 1.0,
    "a machine to do": 1.0,
    "machine to do this": 1.0,
    "to do this ,": 1.0,
    "do this , called": 1.0,
    "this , called ``": 1.0,
    ", called `` gismo": 1.0,
    "called `` gismo .": 1.0,
    "`` gismo . ''": 1.0,
    "gismo . '' .": 1.0,
    "<s> he received a": 1.0,
    "he received a patent": 1.0,
    "received a patent for": 1.0,
    "a patent for his": 1.0,
    "patent for his ``": 1.0,
    "for his `` apparatus": 1.0,
    "his `` apparatus for": 1.0,
    "`` apparatus for reading": 1.0,
    "apparatus for reading ''": 1.0,
    "for reading '' in": 1.0,
    "reading '' in 1953": 1.0,
    "'' in 1953 u.s.": 1.0,
    "in 1953 u.s. patent": 1.0,
    "1953 u.s. patent 2,663,758": 1.0,
    "u.s. patent 2,663,758 .": 1.0,
    "<s> `` gismo ''": 1.0,
    "`` gismo '' could": 1.0,
    "gismo '' could read": 1.0,
    "'' could read 23": 1.0,
    "could read 23 letters": 1.0,
    "read 23 letters of": 1.0,
    "23 letters of the": 1.0,
    "letters of the english": 1.0,
    "of the english alphabet": 1.0,
    "the english alphabet ,": 0.5,
    "english alphabet , comprehend": 1.0,
    "alphabet , comprehend morse": 1.0,
    ", comprehend morse code": 1.0,
    "comprehend morse code ,": 1.0,
    "morse code , read": 1.0,
    "code , read musical": 1.0,
    ", read musical notations": 1.0,
    "read musical notations ,": 1.0,
    "musical notations , read": 1.0,
    "notations , read aloud": 1.0,
    ", read aloud from": 1.0,
    "read aloud from printed": 1.0,
    "aloud from printed pages": 1.0,
    "from printed pages ,": 1.0,
    "printed pages , and": 1.0,
    "pages , and duplicate": 0.5,
    ", and duplicate typewritten": 1.0,
    "and duplicate typewritten pages": 1.0,
    "duplicate typewritten pages .": 1.0,
    "<s> shepard went on": 1.0,
    "shepard went on to": 1.0,
    "went on to found": 1.0,
    "on to found intelligent": 1.0,
    "to found intelligent machines": 1.0,
    "found intelligent machines research": 1.0,
    "intelligent machines research corporation": 1.0,
    "machines research corporation -lrb-": 1.0,
    "research corporation -lrb- imr": 1.0,
    "corporation -lrb- imr -rrb-": 1.0,
    "-lrb- imr -rrb- ,": 1.0,
    "imr -rrb- , which": 1.0,
    "-rrb- , which soon": 0.3333333333333333,
    ", which soon developed": 1.0,
    "which soon developed the": 1.0,
    "soon developed the world": 1.0,
    "developed the world 's": 1.0,
    "the world 's first": 1.0,
    "world 's first commercial": 1.0,
    "'s first commercial ocr": 1.0,
    "first commercial ocr systems": 1.0,
    "commercial ocr systems .": 1.0,
    "<s> in 1955 ,": 1.0,
    "in 1955 , the": 1.0,
    "1955 , the first": 1.0,
    ", the first commercial": 0.3333333333333333,
    "the first commercial system": 1.0,
    "first commercial system was": 1.0,
    "commercial system was installed": 1.0,
    "system was installed at": 1.0,
    "was installed at the": 1.0,
    "installed at the reader": 1.0,
    "at the reader 's": 1.0,
    "the reader 's digest": 1.0,
    "reader 's digest ,": 0.3333333333333333,
    "'s digest , which": 1.0,
    "digest , which used": 1.0,
    ", which used ocr": 1.0,
    "which used ocr to": 1.0,
    "used ocr to input": 1.0,
    "ocr to input sales": 1.0,
    "to input sales reports": 1.0,
    "input sales reports into": 1.0,
    "sales reports into a": 1.0,
    "reports into a computer": 1.0,
    "into a computer .": 1.0,
    "<s> it converted the": 1.0,
    "it converted the typewritten": 1.0,
    "converted the typewritten reports": 1.0,
    "the typewritten reports into": 1.0,
    "typewritten reports into punched": 1.0,
    "reports into punched cards": 1.0,
    "into punched cards for": 1.0,
    "punched cards for input": 1.0,
    "cards for input into": 1.0,
    "for input into the": 1.0,
    "input into the computer": 1.0,
    "into the computer in": 1.0,
    "the computer in the": 1.0,
    "computer in the magazine": 1.0,
    "in the magazine 's": 1.0,
    "the magazine 's subscription": 1.0,
    "magazine 's subscription department": 1.0,
    "'s subscription department ,": 1.0,
    "subscription department , for": 1.0,
    "department , for help": 1.0,
    ", for help in": 1.0,
    "for help in processing": 1.0,
    "help in processing the": 1.0,
    "in processing the shipment": 1.0,
    "processing the shipment of": 1.0,
    "the shipment of 15-20": 1.0,
    "shipment of 15-20 million": 1.0,
    "of 15-20 million books": 1.0,
    "15-20 million books a": 1.0,
    "million books a year": 1.0,
    "books a year .": 1.0,
    "<s> the second system": 1.0,
    "the second system was": 1.0,
    "second system was sold": 1.0,
    "system was sold to": 1.0,
    "was sold to the": 1.0,
    "sold to the standard": 1.0,
    "to the standard oil": 1.0,
    "the standard oil company": 1.0,
    "standard oil company for": 1.0,
    "oil company for reading": 1.0,
    "company for reading credit": 1.0,
    "for reading credit card": 1.0,
    "reading credit card imprints": 1.0,
    "credit card imprints for": 1.0,
    "card imprints for billing": 1.0,
    "imprints for billing purposes": 1.0,
    "for billing purposes .": 1.0,
    "<s> other systems sold": 1.0,
    "other systems sold by": 1.0,
    "systems sold by imr": 1.0,
    "sold by imr during": 1.0,
    "by imr during the": 1.0,
    "imr during the late": 1.0,
    "during the late 1950s": 1.0,
    "the late 1950s included": 1.0,
    "late 1950s included a": 1.0,
    "1950s included a bill": 1.0,
    "included a bill stub": 1.0,
    "a bill stub reader": 1.0,
    "bill stub reader to": 1.0,
    "stub reader to the": 1.0,
    "reader to the ohio": 1.0,
    "to the ohio bell": 1.0,
    "the ohio bell telephone": 1.0,
    "ohio bell telephone company": 1.0,
    "bell telephone company and": 1.0,
    "telephone company and a": 1.0,
    "company and a page": 1.0,
    "and a page scanner": 1.0,
    "a page scanner to": 1.0,
    "page scanner to the": 1.0,
    "scanner to the united": 1.0,
    "to the united states": 1.0,
    "the united states air": 0.14285714285714285,
    "united states air force": 1.0,
    "states air force for": 1.0,
    "air force for reading": 1.0,
    "force for reading and": 1.0,
    "for reading and transmitting": 1.0,
    "reading and transmitting by": 1.0,
    "and transmitting by teletype": 1.0,
    "transmitting by teletype typewritten": 1.0,
    "by teletype typewritten messages": 1.0,
    "teletype typewritten messages .": 1.0,
    "<s> ibm and others": 1.0,
    "ibm and others were": 1.0,
    "and others were later": 1.0,
    "others were later licensed": 1.0,
    "were later licensed on": 1.0,
    "later licensed on shepard": 1.0,
    "licensed on shepard 's": 1.0,
    "on shepard 's ocr": 1.0,
    "shepard 's ocr patents": 1.0,
    "'s ocr patents .": 1.0,
    "<s> in about 1965": 1.0,
    "in about 1965 ,": 1.0,
    "about 1965 , reader": 1.0,
    "1965 , reader 's": 1.0,
    ", reader 's digest": 1.0,
    "reader 's digest and": 0.3333333333333333,
    "'s digest and rca": 1.0,
    "digest and rca collaborated": 1.0,
    "and rca collaborated to": 1.0,
    "rca collaborated to build": 1.0,
    "collaborated to build an": 1.0,
    "to build an ocr": 1.0,
    "build an ocr document": 1.0,
    "an ocr document reader": 1.0,
    "ocr document reader designed": 1.0,
    "document reader designed to": 1.0,
    "reader designed to digitize": 0.5,
    "designed to digitize the": 1.0,
    "to digitize the serial": 1.0,
    "digitize the serial numbers": 1.0,
    "the serial numbers on": 1.0,
    "serial numbers on reader": 1.0,
    "numbers on reader 's": 1.0,
    "on reader 's digest": 1.0,
    "reader 's digest coupons": 0.3333333333333333,
    "'s digest coupons returned": 1.0,
    "digest coupons returned from": 1.0,
    "coupons returned from advertisements": 1.0,
    "returned from advertisements .": 1.0,
    "<s> the fonts used": 1.0,
    "the fonts used on": 1.0,
    "fonts used on the": 1.0,
    "used on the documents": 1.0,
    "on the documents were": 1.0,
    "the documents were printed": 1.0,
    "documents were printed by": 1.0,
    "were printed by an": 1.0,
    "printed by an rca": 1.0,
    "by an rca drum": 1.0,
    "an rca drum printer": 1.0,
    "rca drum printer using": 1.0,
    "drum printer using the": 1.0,
    "printer using the ocr-a": 1.0,
    "using the ocr-a font": 1.0,
    "the ocr-a font .": 1.0,
    "<s> the reader was": 1.0,
    "the reader was connected": 1.0,
    "reader was connected directly": 1.0,
    "was connected directly to": 1.0,
    "connected directly to an": 1.0,
    "directly to an rca": 1.0,
    "to an rca 301": 1.0,
    "an rca 301 computer": 1.0,
    "rca 301 computer -lrb-": 1.0,
    "301 computer -lrb- one": 1.0,
    "computer -lrb- one of": 1.0,
    "-lrb- one of the": 1.0,
    "one of the first": 0.25,
    "of the first solid": 0.25,
    "the first solid state": 1.0,
    "first solid state computers": 1.0,
    "solid state computers -rrb-": 1.0,
    "state computers -rrb- .": 1.0,
    "<s> this reader was": 1.0,
    "this reader was followed": 1.0,
    "reader was followed by": 1.0,
    "was followed by a": 1.0,
    "followed by a specialised": 1.0,
    "by a specialised document": 1.0,
    "a specialised document reader": 1.0,
    "specialised document reader installed": 1.0,
    "document reader installed at": 1.0,
    "reader installed at twa": 1.0,
    "installed at twa where": 1.0,
    "at twa where the": 1.0,
    "twa where the reader": 1.0,
    "where the reader processed": 1.0,
    "the reader processed airline": 1.0,
    "reader processed airline ticket": 1.0,
    "processed airline ticket stock": 1.0,
    "airline ticket stock .": 1.0,
    "<s> the readers processed": 1.0,
    "the readers processed documents": 1.0,
    "readers processed documents at": 1.0,
    "processed documents at a": 1.0,
    "documents at a rate": 1.0,
    "at a rate of": 1.0,
    "a rate of 1,500": 1.0,
    "rate of 1,500 documents": 1.0,
    "of 1,500 documents per": 1.0,
    "1,500 documents per minute": 1.0,
    "documents per minute ,": 1.0,
    "per minute , and": 1.0,
    "minute , and checked": 1.0,
    ", and checked each": 1.0,
    "and checked each document": 1.0,
    "checked each document ,": 1.0,
    "each document , rejecting": 1.0,
    "document , rejecting those": 1.0,
    ", rejecting those it": 1.0,
    "rejecting those it was": 1.0,
    "those it was not": 1.0,
    "it was not able": 1.0,
    "was not able to": 1.0,
    "not able to process": 1.0,
    "able to process correctly": 1.0,
    "to process correctly .": 1.0,
    "<s> the product became": 0.5,
    "the product became part": 1.0,
    "product became part of": 1.0,
    "became part of the": 1.0,
    "part of the rca": 0.5,
    "of the rca product": 1.0,
    "the rca product line": 1.0,
    "rca product line as": 1.0,
    "product line as a": 1.0,
    "line as a reader": 1.0,
    "as a reader designed": 1.0,
    "a reader designed to": 1.0,
    "reader designed to process": 0.5,
    "designed to process ``": 1.0,
    "to process `` turn": 1.0,
    "process `` turn around": 1.0,
    "`` turn around documents": 1.0,
    "turn around documents ''": 1.0,
    "around documents '' such": 1.0,
    "documents '' such as": 1.0,
    "'' such as those": 1.0,
    "such as those utility": 0.2,
    "as those utility and": 1.0,
    "those utility and insurance": 1.0,
    "utility and insurance bills": 1.0,
    "and insurance bills returned": 1.0,
    "insurance bills returned with": 1.0,
    "bills returned with payments": 1.0,
    "returned with payments .": 1.0,
    "<s> the united states": 1.0,
    "the united states postal": 0.14285714285714285,
    "united states postal service": 1.0,
    "states postal service has": 1.0,
    "postal service has been": 1.0,
    "service has been using": 1.0,
    "has been using ocr": 1.0,
    "been using ocr machines": 0.5,
    "using ocr machines to": 1.0,
    "ocr machines to sort": 1.0,
    "machines to sort mail": 1.0,
    "to sort mail since": 1.0,
    "sort mail since 1965": 1.0,
    "mail since 1965 based": 1.0,
    "since 1965 based on": 1.0,
    "1965 based on technology": 1.0,
    "based on technology devised": 1.0,
    "on technology devised primarily": 1.0,
    "technology devised primarily by": 1.0,
    "devised primarily by the": 1.0,
    "primarily by the prolific": 1.0,
    "by the prolific inventor": 1.0,
    "the prolific inventor jacob": 1.0,
    "prolific inventor jacob rabinow": 1.0,
    "inventor jacob rabinow .": 1.0,
    "<s> the first use": 0.16666666666666666,
    "the first use of": 1.0,
    "first use of ocr": 1.0,
    "use of ocr in": 1.0,
    "of ocr in europe": 1.0,
    "ocr in europe was": 1.0,
    "in europe was by": 1.0,
    "europe was by the": 1.0,
    "was by the british": 1.0,
    "by the british general": 1.0,
    "the british general post": 1.0,
    "british general post office": 1.0,
    "general post office -lrb-": 1.0,
    "post office -lrb- gpo": 1.0,
    "office -lrb- gpo -rrb-": 1.0,
    "-lrb- gpo -rrb- .": 1.0,
    "<s> in 1965 it": 1.0,
    "in 1965 it began": 1.0,
    "1965 it began planning": 1.0,
    "it began planning an": 1.0,
    "began planning an entire": 1.0,
    "planning an entire banking": 1.0,
    "an entire banking system": 1.0,
    "entire banking system ,": 1.0,
    "banking system , the": 1.0,
    "system , the national": 0.3333333333333333,
    ", the national giro": 1.0,
    "the national giro ,": 1.0,
    "national giro , using": 1.0,
    "giro , using ocr": 1.0,
    ", using ocr technology": 1.0,
    "using ocr technology ,": 1.0,
    "ocr technology , a": 1.0,
    "technology , a process": 1.0,
    "a process that revolutionized": 0.5,
    "process that revolutionized bill": 1.0,
    "that revolutionized bill payment": 1.0,
    "revolutionized bill payment systems": 1.0,
    "bill payment systems in": 1.0,
    "payment systems in the": 1.0,
    "systems in the uk": 1.0,
    "in the uk .": 0.6666666666666666,
    "<s> canada post has": 1.0,
    "canada post has been": 1.0,
    "post has been using": 1.0,
    "been using ocr systems": 0.5,
    "using ocr systems since": 1.0,
    "ocr systems since 1971": 1.0,
    "systems since 1971 -lrb-": 1.0,
    "since 1971 -lrb- citation": 1.0,
    "1971 -lrb- citation needed": 1.0,
    "citation needed -rrb- .": 0.46153846153846156,
    "<s> ocr systems read": 1.0,
    "ocr systems read the": 1.0,
    "systems read the name": 1.0,
    "read the name and": 1.0,
    "the name and address": 1.0,
    "name and address of": 1.0,
    "and address of the": 1.0,
    "address of the addressee": 1.0,
    "of the addressee at": 1.0,
    "the addressee at the": 1.0,
    "addressee at the first": 1.0,
    "at the first mechanized": 0.5,
    "the first mechanized sorting": 1.0,
    "first mechanized sorting center": 1.0,
    "mechanized sorting center ,": 1.0,
    "sorting center , and": 1.0,
    "center , and print": 1.0,
    ", and print a": 1.0,
    "and print a routing": 1.0,
    "print a routing bar": 1.0,
    "a routing bar code": 1.0,
    "routing bar code on": 1.0,
    "bar code on the": 1.0,
    "code on the envelope": 1.0,
    "on the envelope based": 1.0,
    "the envelope based on": 1.0,
    "envelope based on the": 1.0,
    "based on the postal": 0.09090909090909091,
    "on the postal code": 1.0,
    "the postal code .": 1.0,
    "<s> to avoid confusion": 1.0,
    "to avoid confusion with": 1.0,
    "avoid confusion with the": 1.0,
    "confusion with the human-readable": 1.0,
    "with the human-readable address": 1.0,
    "the human-readable address field": 1.0,
    "human-readable address field which": 1.0,
    "address field which can": 1.0,
    "field which can be": 1.0,
    "which can be located": 0.5,
    "can be located anywhere": 1.0,
    "be located anywhere on": 1.0,
    "located anywhere on the": 1.0,
    "anywhere on the letter": 1.0,
    "on the letter ,": 1.0,
    "the letter , special": 1.0,
    "letter , special ink": 1.0,
    ", special ink -lrb-": 1.0,
    "special ink -lrb- orange": 1.0,
    "ink -lrb- orange in": 1.0,
    "-lrb- orange in visible": 1.0,
    "orange in visible light": 1.0,
    "in visible light -rrb-": 1.0,
    "visible light -rrb- is": 1.0,
    "light -rrb- is used": 1.0,
    "-rrb- is used that": 1.0,
    "is used that is": 1.0,
    "used that is clearly": 1.0,
    "that is clearly visible": 1.0,
    "is clearly visible under": 1.0,
    "clearly visible under ultraviolet": 1.0,
    "visible under ultraviolet light": 1.0,
    "under ultraviolet light .": 1.0,
    "<s> envelopes may then": 1.0,
    "envelopes may then be": 1.0,
    "may then be processed": 1.0,
    "then be processed with": 1.0,
    "be processed with equipment": 1.0,
    "processed with equipment based": 1.0,
    "with equipment based on": 1.0,
    "equipment based on simple": 1.0,
    "based on simple bar": 1.0,
    "on simple bar code": 1.0,
    "simple bar code readers": 1.0,
    "bar code readers .": 1.0,
    "<s> importance of ocr": 1.0,
    "importance of ocr to": 1.0,
    "of ocr to the": 1.0,
    "ocr to the blind": 1.0,
    "to the blind in": 1.0,
    "the blind in 1974": 1.0,
    "blind in 1974 ray": 1.0,
    "in 1974 ray kurzweil": 1.0,
    "1974 ray kurzweil started": 1.0,
    "ray kurzweil started the": 1.0,
    "kurzweil started the company": 1.0,
    "started the company kurzweil": 1.0,
    "the company kurzweil computer": 1.0,
    "company kurzweil computer products": 1.0,
    "kurzweil computer products ,": 0.5,
    "computer products , inc.": 1.0,
    "products , inc. and": 1.0,
    ", inc. and continued": 1.0,
    "inc. and continued development": 1.0,
    "and continued development of": 1.0,
    "continued development of omni-font": 1.0,
    "development of omni-font ocr": 1.0,
    "of omni-font ocr ,": 1.0,
    "omni-font ocr , which": 1.0,
    "ocr , which could": 1.0,
    ", which could recognize": 1.0,
    "which could recognize text": 1.0,
    "could recognize text printed": 1.0,
    "recognize text printed in": 1.0,
    "text printed in virtually": 1.0,
    "printed in virtually any": 1.0,
    "in virtually any font": 1.0,
    "virtually any font .": 1.0,
    "<s> he decided that": 1.0,
    "he decided that the": 1.0,
    "decided that the best": 1.0,
    "that the best application": 1.0,
    "the best application of": 1.0,
    "best application of this": 1.0,
    "application of this technology": 1.0,
    "of this technology would": 1.0,
    "this technology would be": 1.0,
    "technology would be to": 1.0,
    "would be to create": 1.0,
    "be to create a": 1.0,
    "to create a reading": 0.2,
    "create a reading machine": 1.0,
    "a reading machine for": 1.0,
    "reading machine for the": 1.0,
    "machine for the blind": 1.0,
    "for the blind ,": 1.0,
    "the blind , which": 1.0,
    "blind , which would": 1.0,
    ", which would allow": 0.5,
    "which would allow blind": 1.0,
    "would allow blind people": 1.0,
    "allow blind people to": 1.0,
    "blind people to have": 1.0,
    "people to have a": 1.0,
    "to have a computer": 0.25,
    "have a computer read": 1.0,
    "a computer read text": 1.0,
    "computer read text to": 1.0,
    "read text to them": 1.0,
    "text to them out": 1.0,
    "to them out loud": 1.0,
    "them out loud .": 1.0,
    "<s> this device required": 1.0,
    "this device required the": 1.0,
    "device required the invention": 1.0,
    "required the invention of": 1.0,
    "the invention of two": 1.0,
    "invention of two enabling": 1.0,
    "of two enabling technologies": 1.0,
    "two enabling technologies --": 1.0,
    "enabling technologies -- the": 1.0,
    "technologies -- the ccd": 1.0,
    "-- the ccd flatbed": 1.0,
    "the ccd flatbed scanner": 1.0,
    "ccd flatbed scanner and": 1.0,
    "flatbed scanner and the": 1.0,
    "scanner and the text-to-speech": 1.0,
    "and the text-to-speech synthesizer": 1.0,
    "the text-to-speech synthesizer .": 1.0,
    "<s> on january 13": 1.0,
    "on january 13 ,": 1.0,
    "january 13 , 1976": 1.0,
    "13 , 1976 the": 1.0,
    ", 1976 the successful": 1.0,
    "1976 the successful finished": 1.0,
    "the successful finished product": 1.0,
    "successful finished product was": 1.0,
    "finished product was unveiled": 1.0,
    "product was unveiled during": 1.0,
    "was unveiled during a": 1.0,
    "unveiled during a widely-reported": 1.0,
    "during a widely-reported news": 1.0,
    "a widely-reported news conference": 1.0,
    "widely-reported news conference headed": 1.0,
    "news conference headed by": 1.0,
    "conference headed by kurzweil": 1.0,
    "headed by kurzweil and": 1.0,
    "by kurzweil and the": 1.0,
    "kurzweil and the leaders": 1.0,
    "and the leaders of": 1.0,
    "the leaders of the": 1.0,
    "leaders of the national": 1.0,
    "of the national federation": 1.0,
    "the national federation of": 1.0,
    "national federation of the": 1.0,
    "federation of the blind": 1.0,
    "of the blind -lrb-": 1.0,
    "the blind -lrb- citation": 1.0,
    "blind -lrb- citation needed": 1.0,
    "<s> in 1978 kurzweil": 1.0,
    "in 1978 kurzweil computer": 1.0,
    "1978 kurzweil computer products": 1.0,
    "kurzweil computer products began": 0.5,
    "computer products began selling": 1.0,
    "products began selling a": 1.0,
    "began selling a commercial": 1.0,
    "selling a commercial version": 1.0,
    "a commercial version of": 1.0,
    "commercial version of the": 1.0,
    "version of the optical": 1.0,
    "of the optical character": 1.0,
    "the optical character recognition": 1.0,
    "optical character recognition computer": 0.2,
    "character recognition computer program": 1.0,
    "recognition computer program .": 1.0,
    "<s> lexisnexis was one": 1.0,
    "lexisnexis was one of": 1.0,
    "was one of the": 1.0,
    "of the first customers": 0.25,
    "the first customers ,": 1.0,
    "first customers , and": 1.0,
    "customers , and bought": 1.0,
    ", and bought the": 1.0,
    "and bought the program": 1.0,
    "bought the program to": 1.0,
    "the program to upload": 1.0,
    "program to upload paper": 1.0,
    "to upload paper legal": 1.0,
    "upload paper legal and": 1.0,
    "paper legal and news": 1.0,
    "legal and news documents": 1.0,
    "and news documents onto": 1.0,
    "news documents onto its": 1.0,
    "documents onto its nascent": 1.0,
    "onto its nascent online": 1.0,
    "its nascent online databases": 1.0,
    "nascent online databases .": 1.0,
    "<s> two years later": 1.0,
    "two years later ,": 1.0,
    "years later , kurzweil": 0.3333333333333333,
    "later , kurzweil sold": 1.0,
    ", kurzweil sold his": 1.0,
    "kurzweil sold his company": 1.0,
    "sold his company to": 1.0,
    "his company to xerox": 1.0,
    "company to xerox ,": 1.0,
    "to xerox , which": 1.0,
    "xerox , which had": 1.0,
    ", which had an": 1.0,
    "which had an interest": 1.0,
    "had an interest in": 1.0,
    "an interest in further": 1.0,
    "interest in further commercializing": 1.0,
    "in further commercializing paper-to-computer": 1.0,
    "further commercializing paper-to-computer text": 1.0,
    "commercializing paper-to-computer text conversion": 1.0,
    "paper-to-computer text conversion .": 1.0,
    "<s> xerox eventually spun": 1.0,
    "xerox eventually spun it": 1.0,
    "eventually spun it off": 1.0,
    "spun it off as": 1.0,
    "it off as scansoft": 1.0,
    "off as scansoft ,": 1.0,
    "as scansoft , which": 1.0,
    "scansoft , which merged": 1.0,
    ", which merged with": 1.0,
    "which merged with nuance": 1.0,
    "merged with nuance communications": 1.0,
    "with nuance communications -lrb-": 1.0,
    "nuance communications -lrb- citation": 0.5,
    "communications -lrb- citation needed": 1.0,
    "<s> ocr software desktop": 1.0,
    "ocr software desktop &": 1.0,
    "software desktop & server": 1.0,
    "desktop & server ocr": 1.0,
    "& server ocr software": 1.0,
    "server ocr software ocr": 1.0,
    "ocr software ocr software": 1.0,
    "software ocr software and": 1.0,
    "ocr software and icr": 1.0,
    "software and icr software": 1.0,
    "and icr software technology": 1.0,
    "icr software technology are": 1.0,
    "software technology are analytical": 1.0,
    "technology are analytical artificial": 1.0,
    "are analytical artificial intelligence": 1.0,
    "analytical artificial intelligence systems": 1.0,
    "artificial intelligence systems that": 1.0,
    "intelligence systems that consider": 1.0,
    "systems that consider sequences": 1.0,
    "that consider sequences of": 1.0,
    "consider sequences of characters": 1.0,
    "sequences of characters rather": 1.0,
    "of characters rather than": 1.0,
    "characters rather than whole": 1.0,
    "rather than whole words": 1.0,
    "than whole words or": 1.0,
    "whole words or phrases": 1.0,
    "words or phrases .": 0.5,
    "<s> based on the": 1.0,
    "the analysis of sequential": 0.25,
    "analysis of sequential lines": 1.0,
    "of sequential lines and": 1.0,
    "sequential lines and curves": 1.0,
    "lines and curves ,": 1.0,
    "and curves , ocr": 1.0,
    "curves , ocr and": 1.0,
    ", ocr and icr": 1.0,
    "ocr and icr make": 1.0,
    "and icr make `": 1.0,
    "icr make ` best": 1.0,
    "make ` best guesses": 1.0,
    "` best guesses '": 1.0,
    "best guesses ' at": 1.0,
    "guesses ' at characters": 1.0,
    "' at characters using": 1.0,
    "at characters using database": 1.0,
    "characters using database look-up": 1.0,
    "using database look-up tables": 1.0,
    "database look-up tables to": 1.0,
    "look-up tables to closely": 1.0,
    "tables to closely associate": 1.0,
    "to closely associate or": 1.0,
    "closely associate or match": 1.0,
    "associate or match the": 1.0,
    "or match the strings": 1.0,
    "match the strings of": 1.0,
    "the strings of characters": 1.0,
    "strings of characters that": 1.0,
    "of characters that form": 1.0,
    "characters that form words": 1.0,
    "that form words .": 1.0,
    "<s> webocr & onlineocr": 1.0,
    "webocr & onlineocr with": 0.5,
    "& onlineocr with it": 1.0,
    "onlineocr with it technology": 1.0,
    "with it technology development": 1.0,
    "it technology development ,": 1.0,
    "technology development , the": 1.0,
    "development , the platform": 1.0,
    ", the platform for": 1.0,
    "the platform for people": 1.0,
    "platform for people to": 1.0,
    "for people to use": 1.0,
    "people to use software": 1.0,
    "to use software has": 1.0,
    "use software has been": 1.0,
    "software has been changed": 1.0,
    "has been changed from": 1.0,
    "been changed from single": 1.0,
    "changed from single pc": 1.0,
    "from single pc platform": 1.0,
    "single pc platform to": 1.0,
    "pc platform to multi-platforms": 1.0,
    "platform to multi-platforms such": 1.0,
    "to multi-platforms such as": 1.0,
    "multi-platforms such as pc": 1.0,
    "such as pc +": 1.0,
    "as pc + web-based": 1.0,
    "pc + web-based +": 1.0,
    "+ web-based + cloud": 1.0,
    "web-based + cloud computing": 1.0,
    "+ cloud computing +": 1.0,
    "cloud computing + mobile": 1.0,
    "computing + mobile devices": 1.0,
    "+ mobile devices .": 1.0,
    "<s> after 30 years": 1.0,
    "after 30 years development": 1.0,
    "30 years development ,": 0.5,
    "years development , ocr": 1.0,
    "development , ocr software": 1.0,
    ", ocr software started": 1.0,
    "ocr software started to": 1.0,
    "software started to adapt": 1.0,
    "started to adapt to": 1.0,
    "to adapt to new": 1.0,
    "adapt to new application": 1.0,
    "to new application requirements": 1.0,
    "new application requirements .": 1.0,
    "<s> webocr also known": 1.0,
    "webocr also known as": 1.0,
    "also known as onlineocr": 0.16666666666666666,
    "known as onlineocr or": 1.0,
    "as onlineocr or web-based": 1.0,
    "onlineocr or web-based ocr": 1.0,
    "or web-based ocr service": 1.0,
    "web-based ocr service ,": 1.0,
    "ocr service , has": 0.5,
    "service , has been": 1.0,
    ", has been a": 1.0,
    "has been a new": 1.0,
    "been a new trend": 1.0,
    "a new trend to": 1.0,
    "new trend to meet": 1.0,
    "trend to meet larger": 1.0,
    "to meet larger volume": 1.0,
    "meet larger volume and": 1.0,
    "larger volume and larger": 1.0,
    "volume and larger group": 1.0,
    "and larger group of": 1.0,
    "larger group of users": 1.0,
    "group of users after": 1.0,
    "of users after 30": 1.0,
    "users after 30 years": 1.0,
    "30 years development of": 0.5,
    "years development of the": 1.0,
    "development of the desktop": 1.0,
    "of the desktop ocr": 1.0,
    "the desktop ocr .": 1.0,
    "<s> internet and broadband": 1.0,
    "internet and broadband technologies": 1.0,
    "and broadband technologies have": 1.0,
    "broadband technologies have made": 1.0,
    "technologies have made webocr": 1.0,
    "have made webocr &": 1.0,
    "made webocr & onlineocr": 1.0,
    "webocr & onlineocr practically": 0.5,
    "& onlineocr practically available": 1.0,
    "onlineocr practically available to": 1.0,
    "practically available to both": 1.0,
    "available to both individual": 1.0,
    "to both individual users": 1.0,
    "both individual users and": 1.0,
    "individual users and enterprise": 1.0,
    "users and enterprise customers": 1.0,
    "and enterprise customers .": 1.0,
    "<s> since 2000 ,": 1.0,
    "since 2000 , some": 1.0,
    "2000 , some major": 1.0,
    ", some major ocr": 1.0,
    "some major ocr vendors": 1.0,
    "major ocr vendors began": 1.0,
    "ocr vendors began offering": 1.0,
    "vendors began offering webocr": 1.0,
    "began offering webocr &": 1.0,
    "offering webocr & online": 1.0,
    "webocr & online software": 1.0,
    "& online software ,": 1.0,
    "online software , a": 1.0,
    "software , a number": 1.0,
    "a number of new": 0.045454545454545456,
    "number of new entrants": 1.0,
    "of new entrants companies": 1.0,
    "new entrants companies to": 1.0,
    "entrants companies to seize": 1.0,
    "companies to seize the": 1.0,
    "to seize the opportunity": 1.0,
    "seize the opportunity to": 1.0,
    "the opportunity to develop": 1.0,
    "opportunity to develop innovative": 1.0,
    "to develop innovative web-based": 1.0,
    "develop innovative web-based ocr": 1.0,
    "innovative web-based ocr service": 1.0,
    "ocr service , some": 0.5,
    "service , some of": 1.0,
    ", some of which": 1.0,
    "of which are free": 0.25,
    "which are free of": 1.0,
    "are free of charge": 1.0,
    "free of charge services": 1.0,
    "of charge services .": 1.0,
    "<s> application-oriented ocr since": 1.0,
    "application-oriented ocr since ocr": 1.0,
    "ocr since ocr technology": 1.0,
    "since ocr technology has": 1.0,
    "ocr technology has been": 1.0,
    "technology has been more": 1.0,
    "has been more and": 1.0,
    "been more and more": 1.0,
    "more and more widely": 0.5,
    "and more widely applied": 1.0,
    "more widely applied to": 1.0,
    "widely applied to paper-intensive": 1.0,
    "applied to paper-intensive industry": 1.0,
    "to paper-intensive industry ,": 1.0,
    "paper-intensive industry , it": 1.0,
    "industry , it is": 1.0,
    ", it is facing": 0.07692307692307693,
    "it is facing more": 1.0,
    "is facing more complex": 1.0,
    "facing more complex images": 1.0,
    "more complex images environment": 1.0,
    "complex images environment in": 1.0,
    "images environment in the": 1.0,
    "environment in the real": 1.0,
    "in the real world": 1.0,
    "the real world .": 0.5,
    "<s> for example :": 0.02857142857142857,
    "for example : complicated": 0.5,
    "example : complicated backgrounds": 1.0,
    ": complicated backgrounds ,": 1.0,
    "complicated backgrounds , degraded-images": 1.0,
    "backgrounds , degraded-images ,": 1.0,
    ", degraded-images , heavy-noise": 1.0,
    "degraded-images , heavy-noise ,": 1.0,
    ", heavy-noise , paper": 1.0,
    "heavy-noise , paper skew": 1.0,
    ", paper skew ,": 1.0,
    "paper skew , picture": 1.0,
    "skew , picture distortion": 1.0,
    ", picture distortion ,": 1.0,
    "picture distortion , low-resolution": 1.0,
    "distortion , low-resolution ,": 1.0,
    ", low-resolution , disturbed": 1.0,
    "low-resolution , disturbed by": 1.0,
    ", disturbed by grid": 1.0,
    "disturbed by grid &": 1.0,
    "by grid & lines": 1.0,
    "grid & lines ,": 1.0,
    "& lines , text": 1.0,
    "lines , text image": 1.0,
    ", text image consisting": 1.0,
    "text image consisting of": 1.0,
    "image consisting of special": 1.0,
    "consisting of special fonts": 1.0,
    "of special fonts ,": 1.0,
    "special fonts , symbols": 1.0,
    "fonts , symbols ,": 1.0,
    ", symbols , glossary": 1.0,
    "symbols , glossary words": 1.0,
    ", glossary words and": 1.0,
    "glossary words and etc.": 1.0,
    "words and etc. .": 1.0,
    "<s> all the factors": 1.0,
    "all the factors affect": 1.0,
    "the factors affect ocr": 1.0,
    "factors affect ocr products": 1.0,
    "affect ocr products '": 1.0,
    "ocr products ' stability": 1.0,
    "products ' stability in": 1.0,
    "' stability in recognition": 1.0,
    "stability in recognition accuracy": 1.0,
    "in recognition accuracy .": 1.0,
    "in recent years ,": 0.25,
    "recent years , the": 1.0,
    "years , the major": 1.0,
    ", the major ocr": 1.0,
    "the major ocr technology": 1.0,
    "major ocr technology providers": 1.0,
    "ocr technology providers began": 1.0,
    "technology providers began to": 1.0,
    "providers began to develop": 1.0,
    "began to develop dedicated": 0.5,
    "to develop dedicated ocr": 1.0,
    "develop dedicated ocr systems": 1.0,
    "dedicated ocr systems ,": 1.0,
    "ocr systems , each": 1.0,
    "systems , each for": 1.0,
    ", each for special": 1.0,
    "each for special types": 1.0,
    "for special types of": 1.0,
    "special types of images": 1.0,
    "types of images .": 1.0,
    "<s> they combine various": 1.0,
    "they combine various optimization": 1.0,
    "combine various optimization methods": 1.0,
    "various optimization methods related": 1.0,
    "optimization methods related to": 1.0,
    "methods related to the": 1.0,
    "related to the special": 0.5,
    "to the special image": 1.0,
    "the special image ,": 1.0,
    "special image , such": 1.0,
    "image , such as": 1.0,
    ", such as business": 0.030303030303030304,
    "such as business rules": 1.0,
    "as business rules ,": 1.0,
    "business rules , standard": 1.0,
    "rules , standard expression": 1.0,
    ", standard expression ,": 1.0,
    "standard expression , glossary": 1.0,
    "expression , glossary or": 1.0,
    ", glossary or dictionary": 1.0,
    "glossary or dictionary and": 1.0,
    "or dictionary and rich": 1.0,
    "dictionary and rich information": 1.0,
    "and rich information contained": 1.0,
    "rich information contained in": 1.0,
    "information contained in color": 1.0,
    "contained in color images": 1.0,
    "in color images ,": 1.0,
    "color images , to": 1.0,
    "images , to improve": 1.0,
    ", to improve the": 0.5,
    "to improve the recognition": 1.0,
    "improve the recognition accuracy": 1.0,
    "the recognition accuracy .": 1.0,
    "<s> such strategy to": 1.0,
    "such strategy to customize": 1.0,
    "strategy to customize ocr": 1.0,
    "to customize ocr technology": 1.0,
    "customize ocr technology is": 1.0,
    "ocr technology is called": 0.5,
    "technology is called ``": 1.0,
    "is called `` application-oriented": 1.0,
    "called `` application-oriented ocr": 1.0,
    "`` application-oriented ocr ''": 1.0,
    "application-oriented ocr '' or": 1.0,
    "ocr '' or ``": 1.0,
    "'' or `` customized": 0.25,
    "or `` customized ocr": 1.0,
    "`` customized ocr ''": 1.0,
    "customized ocr '' ,": 1.0,
    "ocr '' , widely": 1.0,
    "'' , widely used": 1.0,
    ", widely used in": 1.0,
    "widely used in the": 0.6666666666666666,
    "used in the fields": 0.16666666666666666,
    "in the fields of": 1.0,
    "the fields of business-card": 1.0,
    "fields of business-card ocr": 1.0,
    "of business-card ocr ,": 1.0,
    "business-card ocr , invoice": 1.0,
    "ocr , invoice ocr": 1.0,
    ", invoice ocr ,": 1.0,
    "invoice ocr , screenshot": 1.0,
    "ocr , screenshot ocr": 1.0,
    ", screenshot ocr ,": 1.0,
    "screenshot ocr , id": 1.0,
    "ocr , id card": 1.0,
    ", id card ocr": 1.0,
    "id card ocr ,": 1.0,
    "card ocr , driver-license": 1.0,
    "ocr , driver-license ocr": 1.0,
    ", driver-license ocr or": 1.0,
    "driver-license ocr or auto": 1.0,
    "ocr or auto plant": 1.0,
    "or auto plant ocr": 1.0,
    "auto plant ocr ,": 1.0,
    "plant ocr , and": 1.0,
    "ocr , and so": 1.0,
    "<s> see also :": 1.0,
    "see also : list": 0.5,
    "also : list of": 1.0,
    ": list of optical": 1.0,
    "list of optical character": 1.0,
    "of optical character recognition": 1.0,
    "optical character recognition software": 0.2,
    "character recognition software current": 1.0,
    "recognition software current state": 1.0,
    "software current state of": 1.0,
    "current state of ocr": 0.5,
    "state of ocr technology": 1.0,
    "of ocr technology this": 1.0,
    "ocr technology this section": 1.0,
    "technology this section needs": 1.0,
    "this section needs additional": 1.0,
    "section needs additional citations": 1.0,
    "needs additional citations for": 1.0,
    "additional citations for verification": 1.0,
    "citations for verification .": 1.0,
    "<s> please help improve": 0.5,
    "please help improve this": 1.0,
    "help improve this article": 1.0,
    "improve this article by": 0.5,
    "this article by adding": 1.0,
    "article by adding citations": 1.0,
    "by adding citations to": 1.0,
    "adding citations to reliable": 1.0,
    "citations to reliable sources": 1.0,
    "to reliable sources .": 1.0,
    "<s> unsourced material may": 1.0,
    "unsourced material may be": 1.0,
    "material may be challenged": 1.0,
    "may be challenged and": 1.0,
    "be challenged and removed": 1.0,
    "challenged and removed .": 1.0,
    "<s> -lrb- may 2009": 0.5,
    "-lrb- may 2009 -rrb-": 1.0,
    "may 2009 -rrb- commissioned": 1.0,
    "2009 -rrb- commissioned by": 1.0,
    "-rrb- commissioned by the": 1.0,
    "commissioned by the u.s.": 1.0,
    "by the u.s. department": 0.5,
    "the u.s. department of": 1.0,
    "u.s. department of energy": 1.0,
    "department of energy -lrb-": 1.0,
    "of energy -lrb- doe": 1.0,
    "energy -lrb- doe -rrb-": 1.0,
    "-lrb- doe -rrb- ,": 1.0,
    "doe -rrb- , the": 1.0,
    "-rrb- , the information": 0.2,
    ", the information science": 1.0,
    "the information science research": 1.0,
    "information science research institute": 1.0,
    "science research institute -lrb-": 1.0,
    "research institute -lrb- isri": 1.0,
    "institute -lrb- isri -rrb-": 1.0,
    "-lrb- isri -rrb- had": 1.0,
    "isri -rrb- had the": 1.0,
    "-rrb- had the mission": 1.0,
    "had the mission to": 1.0,
    "the mission to foster": 1.0,
    "mission to foster the": 1.0,
    "to foster the improvement": 1.0,
    "foster the improvement of": 1.0,
    "the improvement of automated": 0.5,
    "improvement of automated technologies": 1.0,
    "of automated technologies for": 1.0,
    "automated technologies for understanding": 1.0,
    "technologies for understanding machine": 1.0,
    "for understanding machine printed": 1.0,
    "understanding machine printed documents": 1.0,
    "machine printed documents -lrb-": 1.0,
    "printed documents -lrb- citation": 1.0,
    "documents -lrb- citation needed": 1.0,
    "citation needed -rrb- ,": 0.07692307692307693,
    "needed -rrb- , and": 1.0,
    "-rrb- , and it": 0.18181818181818182,
    ", and it conducted": 0.25,
    "and it conducted the": 1.0,
    "it conducted the most": 1.0,
    "conducted the most authoritative": 1.0,
    "the most authoritative of": 1.0,
    "most authoritative of the": 1.0,
    "authoritative of the annual": 1.0,
    "of the annual test": 1.0,
    "the annual test of": 1.0,
    "annual test of ocr": 1.0,
    "test of ocr accuracy": 1.0,
    "of ocr accuracy for": 1.0,
    "ocr accuracy for 5": 0.5,
    "accuracy for 5 consecutive": 1.0,
    "for 5 consecutive years": 1.0,
    "5 consecutive years in": 1.0,
    "consecutive years in the": 1.0,
    "years in the mid-90s": 1.0,
    "in the mid-90s .": 1.0,
    "<s> recognition of latin-script": 0.5,
    "recognition of latin-script ,": 1.0,
    "of latin-script , typewritten": 1.0,
    "latin-script , typewritten text": 1.0,
    ", typewritten text is": 1.0,
    "typewritten text is still": 1.0,
    "text is still not": 1.0,
    "is still not 100": 1.0,
    "still not 100 %": 1.0,
    "not 100 % accurate": 1.0,
    "100 % accurate even": 1.0,
    "% accurate even where": 1.0,
    "accurate even where clear": 1.0,
    "even where clear imaging": 1.0,
    "where clear imaging is": 1.0,
    "clear imaging is available": 1.0,
    "imaging is available .": 1.0,
    "<s> one study based": 1.0,
    "one study based on": 1.0,
    "study based on recognition": 1.0,
    "based on recognition of": 1.0,
    "on recognition of 19th": 1.0,
    "recognition of 19th -": 1.0,
    "of 19th - and": 1.0,
    "19th - and early": 1.0,
    "- and early 20th-century": 1.0,
    "and early 20th-century newspaper": 1.0,
    "early 20th-century newspaper pages": 1.0,
    "20th-century newspaper pages concluded": 1.0,
    "newspaper pages concluded that": 1.0,
    "pages concluded that character-by-character": 1.0,
    "concluded that character-by-character ocr": 1.0,
    "that character-by-character ocr accuracy": 1.0,
    "character-by-character ocr accuracy for": 1.0,
    "ocr accuracy for commercial": 0.5,
    "accuracy for commercial ocr": 1.0,
    "for commercial ocr software": 1.0,
    "commercial ocr software varied": 1.0,
    "ocr software varied from": 1.0,
    "software varied from 71": 1.0,
    "varied from 71 %": 1.0,
    "from 71 % to": 1.0,
    "71 % to 98": 1.0,
    "% to 98 %": 1.0,
    "to 98 % ;": 1.0,
    "98 % ; total": 1.0,
    "% ; total accuracy": 1.0,
    "; total accuracy can": 1.0,
    "total accuracy can be": 1.0,
    "accuracy can be achieved": 1.0,
    "can be achieved only": 0.25,
    "be achieved only by": 1.0,
    "achieved only by human": 1.0,
    "only by human review": 1.0,
    "by human review .": 1.0,
    "<s> other areas --": 1.0,
    "other areas -- including": 1.0,
    "areas -- including recognition": 1.0,
    "-- including recognition of": 1.0,
    "including recognition of hand": 1.0,
    "recognition of hand printing": 1.0,
    "of hand printing ,": 1.0,
    "hand printing , cursive": 1.0,
    "printing , cursive handwriting": 1.0,
    ", cursive handwriting ,": 1.0,
    "cursive handwriting , and": 1.0,
    "handwriting , and printed": 1.0,
    ", and printed text": 1.0,
    "and printed text in": 1.0,
    "printed text in other": 1.0,
    "text in other scripts": 1.0,
    "in other scripts -lrb-": 1.0,
    "other scripts -lrb- especially": 1.0,
    "scripts -lrb- especially those": 1.0,
    "-lrb- especially those east": 1.0,
    "especially those east asian": 1.0,
    "those east asian language": 1.0,
    "east asian language characters": 1.0,
    "asian language characters which": 1.0,
    "language characters which have": 1.0,
    "characters which have many": 1.0,
    "which have many strokes": 1.0,
    "have many strokes for": 1.0,
    "many strokes for a": 1.0,
    "strokes for a single": 1.0,
    "for a single character": 1.0,
    "a single character -rrb-": 1.0,
    "single character -rrb- --": 1.0,
    "character -rrb- -- are": 1.0,
    "-rrb- -- are still": 1.0,
    "-- are still the": 1.0,
    "are still the subject": 1.0,
    "still the subject of": 1.0,
    "the subject of active": 0.5,
    "subject of active research": 1.0,
    "of active research .": 1.0,
    "<s> accuracy rates can": 0.5,
    "accuracy rates can be": 1.0,
    "rates can be measured": 1.0,
    "can be measured in": 1.0,
    "be measured in several": 1.0,
    "measured in several ways": 1.0,
    "in several ways ,": 1.0,
    "several ways , and": 1.0,
    "ways , and how": 1.0,
    ", and how they": 1.0,
    "and how they are": 0.5,
    "how they are measured": 0.5,
    "they are measured can": 1.0,
    "are measured can greatly": 1.0,
    "measured can greatly affect": 1.0,
    "can greatly affect the": 1.0,
    "greatly affect the reported": 1.0,
    "affect the reported accuracy": 1.0,
    "the reported accuracy rate": 1.0,
    "reported accuracy rate .": 1.0,
    "example , if word": 0.16666666666666666,
    ", if word context": 1.0,
    "if word context -lrb-": 1.0,
    "word context -lrb- basically": 1.0,
    "context -lrb- basically a": 1.0,
    "-lrb- basically a lexicon": 1.0,
    "basically a lexicon of": 1.0,
    "a lexicon of words": 0.5,
    "lexicon of words -rrb-": 1.0,
    "of words -rrb- is": 0.5,
    "words -rrb- is not": 1.0,
    "-rrb- is not used": 1.0,
    "is not used to": 0.5,
    "not used to correct": 1.0,
    "used to correct software": 1.0,
    "to correct software finding": 1.0,
    "correct software finding non-existent": 1.0,
    "software finding non-existent words": 1.0,
    "finding non-existent words ,": 1.0,
    "non-existent words , a": 1.0,
    "words , a character": 1.0,
    ", a character error": 1.0,
    "a character error rate": 1.0,
    "character error rate of": 1.0,
    "error rate of 1": 0.5,
    "rate of 1 %": 1.0,
    "of 1 % -lrb-": 1.0,
    "1 % -lrb- 99": 1.0,
    "% -lrb- 99 %": 1.0,
    "-lrb- 99 % accuracy": 1.0,
    "99 % accuracy -rrb-": 1.0,
    "% accuracy -rrb- may": 0.5,
    "accuracy -rrb- may result": 1.0,
    "-rrb- may result in": 1.0,
    "may result in an": 1.0,
    "result in an error": 1.0,
    "in an error rate": 1.0,
    "an error rate of": 1.0,
    "error rate of 5": 0.5,
    "rate of 5 %": 1.0,
    "of 5 % -lrb-": 1.0,
    "5 % -lrb- 95": 1.0,
    "% -lrb- 95 %": 1.0,
    "-lrb- 95 % accuracy": 1.0,
    "95 % accuracy -rrb-": 1.0,
    "% accuracy -rrb- or": 0.5,
    "accuracy -rrb- or worse": 1.0,
    "-rrb- or worse if": 1.0,
    "or worse if the": 1.0,
    "worse if the measurement": 1.0,
    "if the measurement is": 1.0,
    "the measurement is based": 1.0,
    "measurement is based on": 1.0,
    "is based on whether": 0.3333333333333333,
    "based on whether each": 1.0,
    "on whether each whole": 1.0,
    "whether each whole word": 1.0,
    "each whole word was": 1.0,
    "whole word was recognized": 1.0,
    "word was recognized with": 1.0,
    "was recognized with no": 1.0,
    "recognized with no incorrect": 1.0,
    "with no incorrect letters": 1.0,
    "no incorrect letters .": 1.0,
    "<s> on-line character recognition": 1.0,
    "on-line character recognition is": 0.6666666666666666,
    "character recognition is sometimes": 0.5,
    "recognition is sometimes confused": 1.0,
    "is sometimes confused with": 1.0,
    "sometimes confused with optical": 1.0,
    "confused with optical character": 1.0,
    "with optical character recognition": 1.0,
    "character recognition -lrb- see": 0.5,
    "recognition -lrb- see handwriting": 0.5,
    "-lrb- see handwriting recognition": 1.0,
    "see handwriting recognition -rrb-": 1.0,
    "handwriting recognition -rrb- .": 1.0,
    "<s> ocr is an": 0.5,
    "ocr is an instance": 1.0,
    "is an instance of": 1.0,
    "an instance of off-line": 1.0,
    "instance of off-line character": 1.0,
    "of off-line character recognition": 1.0,
    "off-line character recognition ,": 1.0,
    "character recognition , where": 0.25,
    "recognition , where the": 1.0,
    ", where the system": 0.2,
    "where the system recognizes": 1.0,
    "the system recognizes the": 1.0,
    "system recognizes the fixed": 1.0,
    "recognizes the fixed static": 1.0,
    "the fixed static shape": 1.0,
    "fixed static shape of": 1.0,
    "static shape of the": 1.0,
    "shape of the character": 1.0,
    "of the character ,": 1.0,
    "the character , while": 1.0,
    "character , while on-line": 1.0,
    ", while on-line character": 1.0,
    "while on-line character recognition": 1.0,
    "on-line character recognition instead": 0.3333333333333333,
    "character recognition instead recognizes": 1.0,
    "recognition instead recognizes the": 1.0,
    "instead recognizes the dynamic": 1.0,
    "recognizes the dynamic motion": 1.0,
    "the dynamic motion during": 1.0,
    "dynamic motion during handwriting": 1.0,
    "motion during handwriting .": 1.0,
    "for example , on-line": 0.02127659574468085,
    "example , on-line recognition": 1.0,
    ", on-line recognition ,": 1.0,
    "on-line recognition , such": 1.0,
    "recognition , such as": 1.0,
    ", such as that": 0.030303030303030304,
    "such as that used": 1.0,
    "as that used for": 1.0,
    "that used for gestures": 1.0,
    "used for gestures in": 1.0,
    "for gestures in the": 1.0,
    "gestures in the penpoint": 1.0,
    "in the penpoint os": 1.0,
    "the penpoint os or": 1.0,
    "penpoint os or the": 1.0,
    "os or the tablet": 1.0,
    "or the tablet pc": 1.0,
    "the tablet pc can": 1.0,
    "tablet pc can tell": 1.0,
    "pc can tell whether": 1.0,
    "can tell whether a": 1.0,
    "tell whether a horizontal": 1.0,
    "whether a horizontal mark": 1.0,
    "a horizontal mark was": 1.0,
    "horizontal mark was drawn": 1.0,
    "mark was drawn right-to-left": 1.0,
    "was drawn right-to-left ,": 1.0,
    "drawn right-to-left , or": 1.0,
    "right-to-left , or left-to-right": 1.0,
    ", or left-to-right .": 1.0,
    "character recognition is also": 0.5,
    "recognition is also referred": 0.5,
    "is also referred to": 1.0,
    "also referred to by": 1.0,
    "referred to by other": 0.5,
    "to by other terms": 1.0,
    "by other terms such": 1.0,
    "other terms such as": 1.0,
    "terms such as dynamic": 1.0,
    "such as dynamic character": 1.0,
    "as dynamic character recognition": 1.0,
    "dynamic character recognition ,": 1.0,
    "character recognition , real-time": 0.25,
    "recognition , real-time character": 1.0,
    ", real-time character recognition": 1.0,
    "real-time character recognition ,": 1.0,
    "character recognition , and": 0.25,
    "recognition , and intelligent": 0.3333333333333333,
    ", and intelligent character": 1.0,
    "and intelligent character recognition": 1.0,
    "intelligent character recognition or": 0.5,
    "character recognition or icr": 1.0,
    "recognition or icr .": 1.0,
    "<s> on-line systems for": 1.0,
    "on-line systems for recognizing": 1.0,
    "systems for recognizing hand-printed": 1.0,
    "for recognizing hand-printed text": 1.0,
    "recognizing hand-printed text on": 1.0,
    "hand-printed text on the": 1.0,
    "text on the fly": 1.0,
    "on the fly have": 1.0,
    "the fly have become": 1.0,
    "fly have become well": 1.0,
    "have become well known": 1.0,
    "become well known as": 1.0,
    "well known as commercial": 1.0,
    "known as commercial products": 1.0,
    "as commercial products in": 1.0,
    "commercial products in recent": 1.0,
    "products in recent years": 1.0,
    "in recent years -lrb-": 0.25,
    "recent years -lrb- see": 1.0,
    "years -lrb- see tablet": 1.0,
    "-lrb- see tablet pc": 1.0,
    "see tablet pc history": 1.0,
    "tablet pc history -rrb-": 1.0,
    "pc history -rrb- .": 1.0,
    "<s> among these are": 1.0,
    "among these are the": 1.0,
    "these are the input": 1.0,
    "are the input devices": 1.0,
    "the input devices for": 1.0,
    "input devices for personal": 1.0,
    "devices for personal digital": 1.0,
    "for personal digital assistants": 1.0,
    "personal digital assistants such": 1.0,
    "digital assistants such as": 1.0,
    "assistants such as those": 1.0,
    "such as those running": 0.2,
    "as those running palm": 1.0,
    "those running palm os": 1.0,
    "running palm os .": 1.0,
    "<s> the apple newton": 1.0,
    "the apple newton pioneered": 1.0,
    "apple newton pioneered this": 1.0,
    "newton pioneered this product": 1.0,
    "pioneered this product .": 1.0,
    "<s> the algorithms used": 0.5,
    "the algorithms used in": 1.0,
    "algorithms used in these": 1.0,
    "used in these devices": 1.0,
    "in these devices take": 1.0,
    "these devices take advantage": 1.0,
    "devices take advantage of": 1.0,
    "take advantage of the": 0.5,
    "advantage of the fact": 1.0,
    "of the fact that": 1.0,
    "fact that the order": 0.5,
    "that the order ,": 1.0,
    "the order , speed": 1.0,
    "order , speed ,": 1.0,
    ", speed , and": 1.0,
    "speed , and direction": 1.0,
    ", and direction of": 1.0,
    "and direction of individual": 1.0,
    "direction of individual lines": 1.0,
    "of individual lines segments": 1.0,
    "individual lines segments at": 1.0,
    "lines segments at input": 1.0,
    "segments at input are": 1.0,
    "at input are known": 1.0,
    "input are known .": 1.0,
    "<s> also , the": 0.3333333333333333,
    "also , the user": 1.0,
    ", the user can": 1.0,
    "the user can be": 1.0,
    "user can be retrained": 1.0,
    "can be retrained to": 1.0,
    "be retrained to use": 1.0,
    "retrained to use only": 1.0,
    "to use only specific": 1.0,
    "use only specific letter": 1.0,
    "only specific letter shapes": 1.0,
    "specific letter shapes .": 1.0,
    "<s> these methods can": 0.5,
    "these methods can not": 1.0,
    "methods can not be": 1.0,
    "can not be used": 0.25,
    "not be used in": 1.0,
    "be used in software": 1.0,
    "used in software that": 1.0,
    "in software that scans": 1.0,
    "software that scans paper": 1.0,
    "that scans paper documents": 1.0,
    "scans paper documents ,": 1.0,
    "paper documents , so": 1.0,
    "documents , so accurate": 1.0,
    ", so accurate recognition": 1.0,
    "so accurate recognition of": 1.0,
    "accurate recognition of hand-printed": 1.0,
    "recognition of hand-printed documents": 1.0,
    "of hand-printed documents is": 1.0,
    "hand-printed documents is still": 1.0,
    "documents is still largely": 1.0,
    "is still largely an": 1.0,
    "still largely an open": 1.0,
    "largely an open problem": 1.0,
    "an open problem .": 1.0,
    "<s> accuracy rates of": 0.5,
    "accuracy rates of 80": 1.0,
    "rates of 80 %": 1.0,
    "of 80 % to": 1.0,
    "80 % to 90": 1.0,
    "% to 90 %": 1.0,
    "to 90 % on": 1.0,
    "90 % on neat": 1.0,
    "% on neat ,": 1.0,
    "on neat , clean": 1.0,
    "neat , clean hand-printed": 1.0,
    ", clean hand-printed characters": 1.0,
    "clean hand-printed characters can": 1.0,
    "hand-printed characters can be": 1.0,
    "characters can be achieved": 0.5,
    "can be achieved ,": 0.25,
    "be achieved , but": 1.0,
    "achieved , but that": 1.0,
    ", but that accuracy": 0.5,
    "but that accuracy rate": 1.0,
    "that accuracy rate still": 1.0,
    "accuracy rate still translates": 1.0,
    "rate still translates to": 1.0,
    "still translates to dozens": 1.0,
    "translates to dozens of": 1.0,
    "to dozens of errors": 1.0,
    "dozens of errors per": 1.0,
    "of errors per page": 1.0,
    "errors per page ,": 1.0,
    "per page , making": 1.0,
    "page , making the": 1.0,
    ", making the technology": 1.0,
    "making the technology useful": 1.0,
    "the technology useful only": 1.0,
    "technology useful only in": 1.0,
    "useful only in very": 1.0,
    "only in very limited": 0.5,
    "in very limited applications": 1.0,
    "very limited applications .": 1.0,
    "<s> recognition of cursive": 0.5,
    "recognition of cursive text": 1.0,
    "of cursive text is": 1.0,
    "cursive text is an": 1.0,
    "text is an active": 1.0,
    "is an active area": 1.0,
    "an active area of": 1.0,
    "active area of research": 1.0,
    "area of research ,": 0.3333333333333333,
    "of research , with": 1.0,
    "research , with recognition": 1.0,
    ", with recognition rates": 1.0,
    "with recognition rates even": 1.0,
    "recognition rates even lower": 1.0,
    "rates even lower than": 1.0,
    "even lower than that": 1.0,
    "lower than that of": 1.0,
    "than that of hand-printed": 0.5,
    "that of hand-printed text": 1.0,
    "of hand-printed text .": 1.0,
    "<s> higher rates of": 1.0,
    "higher rates of recognition": 1.0,
    "rates of recognition of": 1.0,
    "of recognition of general": 1.0,
    "recognition of general cursive": 1.0,
    "of general cursive script": 1.0,
    "general cursive script will": 1.0,
    "cursive script will likely": 1.0,
    "script will likely not": 1.0,
    "will likely not be": 1.0,
    "likely not be possible": 1.0,
    "not be possible without": 1.0,
    "be possible without the": 1.0,
    "possible without the use": 1.0,
    "without the use of": 1.0,
    "the use of contextual": 0.06666666666666667,
    "use of contextual or": 1.0,
    "of contextual or grammatical": 1.0,
    "contextual or grammatical information": 1.0,
    "or grammatical information .": 1.0,
    "for example , recognizing": 0.02127659574468085,
    "example , recognizing entire": 1.0,
    ", recognizing entire words": 1.0,
    "recognizing entire words from": 1.0,
    "entire words from a": 1.0,
    "words from a dictionary": 1.0,
    "from a dictionary is": 0.5,
    "a dictionary is easier": 1.0,
    "dictionary is easier than": 1.0,
    "is easier than trying": 1.0,
    "easier than trying to": 1.0,
    "than trying to parse": 1.0,
    "trying to parse individual": 1.0,
    "to parse individual characters": 1.0,
    "parse individual characters from": 1.0,
    "individual characters from script": 1.0,
    "characters from script .": 1.0,
    "<s> reading the amount": 1.0,
    "reading the amount line": 1.0,
    "the amount line of": 1.0,
    "amount line of a": 1.0,
    "line of a cheque": 1.0,
    "of a cheque -lrb-": 1.0,
    "a cheque -lrb- which": 1.0,
    "cheque -lrb- which is": 1.0,
    "-lrb- which is always": 1.0,
    "which is always a": 1.0,
    "is always a written-out": 1.0,
    "always a written-out number": 1.0,
    "a written-out number -rrb-": 1.0,
    "written-out number -rrb- is": 1.0,
    "number -rrb- is an": 1.0,
    "-rrb- is an example": 1.0,
    "is an example where": 1.0,
    "an example where using": 1.0,
    "example where using a": 1.0,
    "where using a smaller": 1.0,
    "using a smaller dictionary": 1.0,
    "a smaller dictionary can": 1.0,
    "smaller dictionary can increase": 1.0,
    "dictionary can increase recognition": 1.0,
    "can increase recognition rates": 1.0,
    "increase recognition rates greatly": 1.0,
    "recognition rates greatly .": 1.0,
    "<s> knowledge of the": 1.0,
    "of the grammar of": 0.3333333333333333,
    "the grammar of the": 1.0,
    "grammar of the language": 1.0,
    "the language being scanned": 0.5,
    "language being scanned can": 1.0,
    "being scanned can also": 1.0,
    "scanned can also help": 1.0,
    "can also help determine": 1.0,
    "also help determine if": 1.0,
    "help determine if a": 1.0,
    "determine if a word": 1.0,
    "if a word is": 1.0,
    "a word is likely": 0.5,
    "word is likely to": 1.0,
    "is likely to be": 0.3333333333333333,
    "likely to be a": 0.5,
    "to be a verb": 0.2,
    "be a verb or": 0.5,
    "a verb or a": 1.0,
    "verb or a noun": 0.5,
    "or a noun ,": 0.5,
    "a noun , for": 0.5,
    "noun , for example": 1.0,
    "for example , allowing": 0.02127659574468085,
    "example , allowing greater": 1.0,
    ", allowing greater accuracy": 1.0,
    "allowing greater accuracy .": 1.0,
    "<s> the shapes of": 1.0,
    "the shapes of individual": 1.0,
    "shapes of individual cursive": 1.0,
    "of individual cursive characters": 1.0,
    "individual cursive characters themselves": 1.0,
    "cursive characters themselves simply": 1.0,
    "characters themselves simply do": 1.0,
    "themselves simply do not": 1.0,
    "simply do not contain": 1.0,
    "do not contain enough": 1.0,
    "not contain enough information": 1.0,
    "contain enough information to": 1.0,
    "enough information to accurately": 1.0,
    "information to accurately -lrb-": 1.0,
    "to accurately -lrb- greater": 1.0,
    "accurately -lrb- greater than": 1.0,
    "-lrb- greater than 98": 1.0,
    "greater than 98 %": 1.0,
    "than 98 % -rrb-": 1.0,
    "98 % -rrb- recognize": 1.0,
    "% -rrb- recognize all": 1.0,
    "-rrb- recognize all handwritten": 1.0,
    "recognize all handwritten cursive": 1.0,
    "all handwritten cursive script": 1.0,
    "handwritten cursive script .": 1.0,
    "<s> it is necessary": 0.05263157894736842,
    "it is necessary to": 1.0,
    "is necessary to understand": 1.0,
    "necessary to understand that": 1.0,
    "to understand that ocr": 1.0,
    "understand that ocr technology": 1.0,
    "that ocr technology is": 1.0,
    "ocr technology is a": 0.5,
    "technology is a basic": 1.0,
    "is a basic technology": 1.0,
    "a basic technology also": 1.0,
    "basic technology also used": 1.0,
    "technology also used in": 1.0,
    "also used in advanced": 1.0,
    "used in advanced scanning": 1.0,
    "in advanced scanning applications": 1.0,
    "advanced scanning applications .": 1.0,
    "<s> due to this": 1.0,
    "due to this ,": 1.0,
    "to this , an": 1.0,
    "this , an advanced": 1.0,
    ", an advanced scanning": 1.0,
    "an advanced scanning solution": 1.0,
    "advanced scanning solution can": 1.0,
    "scanning solution can be": 1.0,
    "solution can be unique": 1.0,
    "can be unique and": 1.0,
    "be unique and patented": 1.0,
    "unique and patented and": 1.0,
    "and patented and not": 1.0,
    "patented and not easily": 1.0,
    "and not easily copied": 1.0,
    "not easily copied despite": 1.0,
    "easily copied despite being": 1.0,
    "copied despite being based": 1.0,
    "despite being based on": 1.0,
    "being based on this": 1.0,
    "based on this basic": 1.0,
    "on this basic ocr": 1.0,
    "this basic ocr technology": 1.0,
    "basic ocr technology .": 1.0,
    "<s> for more complex": 0.5,
    "for more complex recognition": 1.0,
    "more complex recognition problems": 1.0,
    "complex recognition problems ,": 1.0,
    "recognition problems , intelligent": 1.0,
    "problems , intelligent character": 1.0,
    ", intelligent character recognition": 1.0,
    "intelligent character recognition systems": 0.5,
    "character recognition systems are": 1.0,
    "recognition systems are generally": 0.5,
    "systems are generally used": 1.0,
    "are generally used ,": 1.0,
    "generally used , as": 1.0,
    "used , as artificial": 1.0,
    ", as artificial neural": 1.0,
    "as artificial neural networks": 1.0,
    "artificial neural networks can": 1.0,
    "neural networks can be": 1.0,
    "networks can be made": 1.0,
    "can be made indifferent": 0.5,
    "be made indifferent to": 1.0,
    "made indifferent to both": 1.0,
    "indifferent to both affine": 1.0,
    "to both affine and": 1.0,
    "both affine and non-linear": 1.0,
    "affine and non-linear transformations": 1.0,
    "and non-linear transformations .": 1.0,
    "<s> a technique which": 1.0,
    "a technique which is": 1.0,
    "technique which is having": 1.0,
    "which is having considerable": 1.0,
    "is having considerable success": 1.0,
    "having considerable success in": 1.0,
    "considerable success in recognizing": 1.0,
    "success in recognizing difficult": 1.0,
    "in recognizing difficult words": 1.0,
    "recognizing difficult words and": 1.0,
    "difficult words and character": 1.0,
    "words and character groups": 1.0,
    "and character groups within": 1.0,
    "character groups within documents": 1.0,
    "groups within documents generally": 1.0,
    "within documents generally amenable": 1.0,
    "documents generally amenable to": 1.0,
    "generally amenable to computer": 1.0,
    "amenable to computer ocr": 1.0,
    "to computer ocr is": 1.0,
    "computer ocr is to": 1.0,
    "ocr is to submit": 1.0,
    "is to submit them": 1.0,
    "to submit them automatically": 1.0,
    "submit them automatically to": 1.0,
    "them automatically to humans": 1.0,
    "automatically to humans in": 1.0,
    "to humans in the": 1.0,
    "humans in the recaptcha": 1.0,
    "in the recaptcha system": 1.0,
    "the recaptcha system .": 1.0,
    "<s> in corpus linguistics": 1.0,
    "in corpus linguistics ,": 1.0,
    "corpus linguistics , part-of-speech": 1.0,
    "linguistics , part-of-speech tagging": 1.0,
    ", part-of-speech tagging -lrb-": 0.5,
    "part-of-speech tagging -lrb- pos": 1.0,
    "tagging -lrb- pos tagging": 1.0,
    "-lrb- pos tagging or": 1.0,
    "pos tagging or post": 1.0,
    "tagging or post -rrb-": 1.0,
    "or post -rrb- ,": 1.0,
    "post -rrb- , also": 1.0,
    "-rrb- , also called": 0.5,
    ", also called grammatical": 0.5,
    "also called grammatical tagging": 1.0,
    "called grammatical tagging or": 1.0,
    "grammatical tagging or word-category": 1.0,
    "tagging or word-category disambiguation": 1.0,
    "or word-category disambiguation ,": 1.0,
    "word-category disambiguation , is": 1.0,
    "disambiguation , is the": 1.0,
    ", is the process": 0.3333333333333333,
    "the process of marking": 0.09090909090909091,
    "process of marking up": 1.0,
    "of marking up a": 1.0,
    "marking up a word": 1.0,
    "up a word in": 1.0,
    "word in a text": 0.3333333333333333,
    "in a text -lrb-": 0.25,
    "a text -lrb- corpus": 1.0,
    "text -lrb- corpus -rrb-": 1.0,
    "-lrb- corpus -rrb- as": 1.0,
    "corpus -rrb- as corresponding": 1.0,
    "-rrb- as corresponding to": 1.0,
    "as corresponding to a": 1.0,
    "corresponding to a particular": 1.0,
    "to a particular part": 1.0,
    "a particular part of": 1.0,
    "particular part of speech": 1.0,
    "part of speech ,": 0.07142857142857142,
    "of speech , based": 0.16666666666666666,
    "speech , based on": 1.0,
    ", based on both": 0.5,
    "based on both its": 1.0,
    "on both its definition": 1.0,
    "both its definition ,": 1.0,
    "its definition , as": 1.0,
    "definition , as well": 1.0,
    "as well as its": 0.07692307692307693,
    "well as its context": 1.0,
    "as its context --": 1.0,
    "its context -- i.e.": 1.0,
    "context -- i.e. relationship": 1.0,
    "-- i.e. relationship with": 1.0,
    "i.e. relationship with adjacent": 1.0,
    "relationship with adjacent and": 1.0,
    "with adjacent and related": 1.0,
    "adjacent and related words": 1.0,
    "and related words in": 1.0,
    "related words in a": 1.0,
    "words in a phrase": 0.3333333333333333,
    "in a phrase ,": 1.0,
    "a phrase , sentence": 1.0,
    "phrase , sentence ,": 1.0,
    ", sentence , or": 1.0,
    "sentence , or paragraph": 1.0,
    ", or paragraph .": 1.0,
    "<s> a simplified form": 1.0,
    "a simplified form of": 1.0,
    "simplified form of this": 1.0,
    "form of this is": 1.0,
    "of this is commonly": 1.0,
    "this is commonly taught": 1.0,
    "is commonly taught to": 1.0,
    "commonly taught to school-age": 1.0,
    "taught to school-age children": 1.0,
    "to school-age children ,": 1.0,
    "school-age children , in": 1.0,
    "children , in the": 1.0,
    ", in the identification": 0.125,
    "in the identification of": 1.0,
    "the identification of words": 0.5,
    "identification of words as": 1.0,
    "of words as nouns": 1.0,
    "words as nouns ,": 1.0,
    "as nouns , verbs": 1.0,
    "nouns , verbs ,": 1.0,
    ", verbs , adjectives": 0.5,
    "verbs , adjectives ,": 1.0,
    ", adjectives , adverbs": 1.0,
    "adjectives , adverbs ,": 1.0,
    ", adverbs , etc.": 1.0,
    "adverbs , etc. .": 1.0,
    "<s> once performed by": 0.5,
    "once performed by hand": 1.0,
    "performed by hand ,": 1.0,
    "by hand , pos": 0.5,
    "hand , pos tagging": 1.0,
    ", pos tagging is": 1.0,
    "pos tagging is now": 1.0,
    "tagging is now done": 1.0,
    "is now done in": 1.0,
    "now done in the": 1.0,
    "done in the context": 1.0,
    "the context of computational": 0.2,
    "context of computational linguistics": 1.0,
    "of computational linguistics ,": 0.3333333333333333,
    "computational linguistics , using": 0.3333333333333333,
    "linguistics , using algorithms": 1.0,
    ", using algorithms which": 1.0,
    "using algorithms which associate": 1.0,
    "algorithms which associate discrete": 1.0,
    "which associate discrete terms": 1.0,
    "associate discrete terms ,": 1.0,
    "discrete terms , as": 1.0,
    "terms , as well": 1.0,
    "as well as hidden": 0.07692307692307693,
    "well as hidden parts": 1.0,
    "as hidden parts of": 1.0,
    "hidden parts of speech": 1.0,
    "parts of speech ,": 0.36363636363636365,
    "of speech , in": 0.16666666666666666,
    "speech , in accordance": 1.0,
    ", in accordance with": 1.0,
    "in accordance with a": 1.0,
    "accordance with a set": 1.0,
    "with a set of": 1.0,
    "a set of descriptive": 0.07142857142857142,
    "set of descriptive tags": 1.0,
    "of descriptive tags .": 1.0,
    "<s> pos-tagging algorithms fall": 1.0,
    "pos-tagging algorithms fall into": 1.0,
    "algorithms fall into two": 1.0,
    "fall into two distinctive": 1.0,
    "into two distinctive groups": 1.0,
    "two distinctive groups :": 1.0,
    "distinctive groups : rule-based": 1.0,
    "groups : rule-based and": 1.0,
    ": rule-based and stochastic": 1.0,
    "rule-based and stochastic .": 1.0,
    "<s> e. brill 's": 1.0,
    "e. brill 's tagger": 1.0,
    "brill 's tagger ,": 1.0,
    "'s tagger , one": 1.0,
    "tagger , one of": 1.0,
    ", one of the": 1.0,
    "of the first and": 0.25,
    "the first and widely": 1.0,
    "first and widely used": 1.0,
    "and widely used english": 1.0,
    "widely used english pos-taggers": 1.0,
    "used english pos-taggers ,": 1.0,
    "english pos-taggers , employs": 1.0,
    "pos-taggers , employs rule-based": 1.0,
    ", employs rule-based algorithms": 1.0,
    "employs rule-based algorithms .": 1.0,
    "this is not rare": 0.5,
    "is not rare --": 1.0,
    "not rare -- in": 1.0,
    "rare -- in natural": 1.0,
    "-- in natural languages": 1.0,
    "in natural languages -lrb-": 1.0,
    "natural languages -lrb- as": 1.0,
    "languages -lrb- as opposed": 1.0,
    "-lrb- as opposed to": 1.0,
    "as opposed to many": 1.0,
    "opposed to many artificial": 1.0,
    "to many artificial languages": 1.0,
    "many artificial languages -rrb-": 1.0,
    "artificial languages -rrb- ,": 1.0,
    "languages -rrb- , a": 1.0,
    "-rrb- , a large": 0.3333333333333333,
    ", a large percentage": 1.0,
    "a large percentage of": 1.0,
    "large percentage of word-forms": 1.0,
    "percentage of word-forms are": 1.0,
    "of word-forms are ambiguous": 1.0,
    "word-forms are ambiguous .": 1.0,
    "for example , even": 0.02127659574468085,
    "example , even ``": 1.0,
    ", even `` dogs": 1.0,
    "even `` dogs ''": 1.0,
    "`` dogs '' ,": 0.25,
    "dogs '' , which": 1.0,
    "'' , which is": 0.5,
    ", which is usually": 0.14285714285714285,
    "which is usually thought": 1.0,
    "is usually thought of": 1.0,
    "usually thought of as": 1.0,
    "thought of as just": 0.5,
    "of as just a": 1.0,
    "as just a plural": 1.0,
    "just a plural noun": 1.0,
    "a plural noun ,": 1.0,
    "plural noun , can": 0.5,
    "noun , can also": 1.0,
    ", can also be": 1.0,
    "can also be a": 0.25,
    "also be a verb": 1.0,
    "be a verb :": 0.5,
    "a verb : the": 1.0,
    "verb : the sailor": 1.0,
    ": the sailor dogs": 1.0,
    "the sailor dogs the": 1.0,
    "sailor dogs the barmaid": 1.0,
    "dogs the barmaid .": 1.0,
    "<s> performing grammatical tagging": 1.0,
    "performing grammatical tagging will": 1.0,
    "grammatical tagging will indicate": 1.0,
    "tagging will indicate that": 1.0,
    "will indicate that ``": 1.0,
    "indicate that `` dogs": 1.0,
    "that `` dogs ''": 1.0,
    "`` dogs '' is": 0.5,
    "dogs '' is a": 1.0,
    "'' is a verb": 0.3333333333333333,
    "is a verb ,": 1.0,
    "a verb , and": 0.6666666666666666,
    "verb , and not": 0.3333333333333333,
    ", and not the": 0.3333333333333333,
    "and not the more": 1.0,
    "not the more common": 1.0,
    "the more common plural": 1.0,
    "more common plural noun": 1.0,
    "common plural noun ,": 1.0,
    "plural noun , since": 0.5,
    "noun , since one": 1.0,
    ", since one of": 1.0,
    "since one of the": 1.0,
    "one of the words": 0.08333333333333333,
    "of the words must": 0.3333333333333333,
    "the words must be": 1.0,
    "words must be the": 1.0,
    "must be the main": 1.0,
    "be the main verb": 1.0,
    "the main verb ,": 1.0,
    "main verb , and": 1.0,
    "verb , and the": 0.3333333333333333,
    ", and the noun": 0.1,
    "and the noun reading": 1.0,
    "the noun reading is": 1.0,
    "noun reading is less": 1.0,
    "reading is less likely": 1.0,
    "is less likely following": 1.0,
    "less likely following ``": 1.0,
    "likely following `` sailor": 1.0,
    "following `` sailor ''": 1.0,
    "`` sailor '' -lrb-": 0.5,
    "sailor '' -lrb- sailor": 1.0,
    "'' -lrb- sailor !": 1.0,
    "<s> \u2192 dogs -rrb-": 1.0,
    "\u2192 dogs -rrb- .": 1.0,
    "<s> semantic analysis can": 1.0,
    "semantic analysis can then": 1.0,
    "analysis can then extrapolate": 1.0,
    "can then extrapolate that": 1.0,
    "then extrapolate that ``": 1.0,
    "extrapolate that `` sailor": 1.0,
    "that `` sailor ''": 1.0,
    "`` sailor '' and": 0.5,
    "sailor '' and ``": 1.0,
    "'' and `` barmaid": 0.1111111111111111,
    "and `` barmaid ''": 1.0,
    "`` barmaid '' implicate": 0.5,
    "barmaid '' implicate ``": 1.0,
    "'' implicate `` dogs": 1.0,
    "implicate `` dogs ''": 1.0,
    "`` dogs '' as": 0.25,
    "dogs '' as 1": 1.0,
    "'' as 1 -rrb-": 1.0,
    "as 1 -rrb- in": 1.0,
    "1 -rrb- in the": 1.0,
    "-rrb- in the nautical": 0.3333333333333333,
    "in the nautical context": 1.0,
    "the nautical context -lrb-": 1.0,
    "nautical context -lrb- sailor": 1.0,
    "context -lrb- sailor \u2192": 1.0,
    "-lrb- sailor \u2192 <verb>": 1.0,
    "sailor \u2192 <verb> \u2190": 1.0,
    "\u2192 <verb> \u2190 barmaid": 1.0,
    "<verb> \u2190 barmaid -rrb-": 1.0,
    "\u2190 barmaid -rrb- and": 1.0,
    "barmaid -rrb- and 2": 1.0,
    "-rrb- and 2 -rrb-": 1.0,
    "and 2 -rrb- an": 1.0,
    "2 -rrb- an action": 1.0,
    "-rrb- an action applied": 1.0,
    "an action applied to": 1.0,
    "action applied to the": 1.0,
    "applied to the object": 0.5,
    "to the object ``": 1.0,
    "the object `` barmaid": 1.0,
    "object `` barmaid ''": 1.0,
    "`` barmaid '' -lrb-": 0.5,
    "barmaid '' -lrb- -lrb-": 1.0,
    "'' -lrb- -lrb- subject": 1.0,
    "-lrb- -lrb- subject -rrb-": 1.0,
    "-lrb- subject -rrb- dogs": 1.0,
    "subject -rrb- dogs \u2192": 1.0,
    "-rrb- dogs \u2192 barmaid": 1.0,
    "dogs \u2192 barmaid -rrb-": 1.0,
    "\u2192 barmaid -rrb- .": 1.0,
    "<s> in this context": 0.4,
    "in this context ,": 1.0,
    "this context , ``": 0.5,
    "context , `` dogs": 1.0,
    ", `` dogs ''": 1.0,
    "'' is a nautical": 0.3333333333333333,
    "is a nautical term": 1.0,
    "a nautical term meaning": 1.0,
    "nautical term meaning ``": 1.0,
    "term meaning `` fastens": 1.0,
    "meaning `` fastens -lrb-": 1.0,
    "`` fastens -lrb- a": 1.0,
    "fastens -lrb- a watertight": 1.0,
    "-lrb- a watertight barmaid": 1.0,
    "a watertight barmaid -rrb-": 1.0,
    "watertight barmaid -rrb- securely": 1.0,
    "barmaid -rrb- securely ;": 1.0,
    "-rrb- securely ; applies": 1.0,
    "securely ; applies a": 1.0,
    "; applies a dog": 1.0,
    "applies a dog to": 1.0,
    "a dog to ''": 1.0,
    "dog to '' .": 1.0,
    "<s> `` dogged ''": 1.0,
    "`` dogged '' ,": 1.0,
    "dogged '' , on": 1.0,
    "'' , on the": 1.0,
    "other hand , can": 0.2,
    "hand , can be": 1.0,
    ", can be either": 0.5,
    "can be either an": 1.0,
    "be either an adjective": 1.0,
    "either an adjective or": 1.0,
    "an adjective or a": 1.0,
    "adjective or a past-tense": 0.3333333333333333,
    "or a past-tense verb": 1.0,
    "a past-tense verb .": 1.0,
    "<s> just which parts": 1.0,
    "just which parts of": 1.0,
    "which parts of speech": 1.0,
    "parts of speech a": 0.09090909090909091,
    "of speech a word": 1.0,
    "speech a word can": 1.0,
    "a word can represent": 0.5,
    "word can represent varies": 1.0,
    "can represent varies greatly": 1.0,
    "represent varies greatly .": 1.0,
    "<s> trained linguists can": 1.0,
    "trained linguists can identify": 1.0,
    "linguists can identify the": 1.0,
    "can identify the grammatical": 1.0,
    "identify the grammatical parts": 1.0,
    "the grammatical parts of": 1.0,
    "grammatical parts of speech": 1.0,
    "parts of speech to": 0.09090909090909091,
    "of speech to various": 1.0,
    "speech to various fine": 1.0,
    "to various fine degrees": 1.0,
    "various fine degrees depending": 1.0,
    "fine degrees depending on": 1.0,
    "degrees depending on the": 1.0,
    "depending on the tagging": 0.5,
    "on the tagging system": 1.0,
    "the tagging system .": 1.0,
    "<s> schools commonly teach": 1.0,
    "schools commonly teach that": 1.0,
    "commonly teach that there": 1.0,
    "teach that there are": 1.0,
    "that there are 9": 0.5,
    "there are 9 parts": 1.0,
    "are 9 parts of": 1.0,
    "9 parts of speech": 1.0,
    "parts of speech in": 0.09090909090909091,
    "of speech in english": 1.0,
    "speech in english :": 1.0,
    "in english : noun": 1.0,
    "english : noun ,": 1.0,
    ": noun , verb": 1.0,
    "noun , verb ,": 0.5,
    ", verb , article": 1.0,
    "verb , article ,": 1.0,
    ", article , adjective": 0.5,
    "article , adjective ,": 1.0,
    ", adjective , preposition": 1.0,
    "adjective , preposition ,": 1.0,
    ", preposition , pronoun": 1.0,
    "preposition , pronoun ,": 1.0,
    ", pronoun , adverb": 1.0,
    "pronoun , adverb ,": 1.0,
    ", adverb , conjunction": 1.0,
    "adverb , conjunction ,": 1.0,
    ", conjunction , and": 1.0,
    "conjunction , and interjection": 1.0,
    ", and interjection .": 1.0,
    "however , there are": 0.3333333333333333,
    ", there are clearly": 0.3333333333333333,
    "there are clearly many": 1.0,
    "are clearly many more": 1.0,
    "clearly many more categories": 1.0,
    "many more categories and": 1.0,
    "more categories and sub-categories": 1.0,
    "categories and sub-categories .": 1.0,
    "<s> for nouns ,": 1.0,
    "for nouns , plural": 1.0,
    "nouns , plural ,": 1.0,
    ", plural , possessive": 1.0,
    "plural , possessive ,": 1.0,
    ", possessive , and": 1.0,
    "possessive , and singular": 1.0,
    ", and singular forms": 1.0,
    "and singular forms can": 1.0,
    "singular forms can be": 1.0,
    "forms can be distinguished": 1.0,
    "can be distinguished .": 1.0,
    "<s> in many languages": 1.0,
    "in many languages words": 1.0,
    "many languages words are": 1.0,
    "languages words are also": 1.0,
    "words are also marked": 1.0,
    "are also marked for": 1.0,
    "also marked for their": 1.0,
    "marked for their ``": 1.0,
    "for their `` case": 1.0,
    "their `` case ''": 1.0,
    "`` case '' -lrb-": 1.0,
    "case '' -lrb- role": 1.0,
    "'' -lrb- role as": 1.0,
    "-lrb- role as subject": 1.0,
    "role as subject ,": 1.0,
    "as subject , object": 1.0,
    "subject , object ,": 1.0,
    ", object , etc.": 1.0,
    "object , etc. -rrb-": 1.0,
    "etc. -rrb- , grammatical": 0.3333333333333333,
    "-rrb- , grammatical gender": 1.0,
    ", grammatical gender ,": 1.0,
    "grammatical gender , and": 1.0,
    "gender , and so": 1.0,
    "and so on ;": 0.2,
    "so on ; while": 1.0,
    "on ; while verbs": 1.0,
    "; while verbs are": 1.0,
    "while verbs are marked": 1.0,
    "verbs are marked for": 1.0,
    "are marked for tense": 1.0,
    "marked for tense ,": 1.0,
    "for tense , aspect": 1.0,
    "tense , aspect ,": 1.0,
    ", aspect , and": 1.0,
    "aspect , and other": 1.0,
    ", and other things": 0.3333333333333333,
    "and other things .": 1.0,
    "<s> in part-of-speech tagging": 1.0,
    "in part-of-speech tagging by": 1.0,
    "part-of-speech tagging by computer": 1.0,
    "tagging by computer ,": 1.0,
    "by computer , it": 1.0,
    "computer , it is": 1.0,
    ", it is typical": 0.07692307692307693,
    "it is typical to": 1.0,
    "is typical to distinguish": 1.0,
    "typical to distinguish from": 1.0,
    "to distinguish from 50": 1.0,
    "distinguish from 50 to": 1.0,
    "from 50 to 150": 1.0,
    "50 to 150 separate": 1.0,
    "to 150 separate parts": 1.0,
    "150 separate parts of": 1.0,
    "separate parts of speech": 1.0,
    "parts of speech for": 0.09090909090909091,
    "of speech for english": 0.25,
    "speech for english ,": 1.0,
    "for english , for": 1.0,
    "english , for example": 1.0,
    "for example , nn": 0.02127659574468085,
    "example , nn for": 1.0,
    ", nn for singular": 1.0,
    "nn for singular common": 1.0,
    "for singular common nouns": 1.0,
    "singular common nouns ,": 1.0,
    "common nouns , nns": 0.5,
    "nouns , nns for": 1.0,
    ", nns for plural": 1.0,
    "nns for plural common": 1.0,
    "for plural common nouns": 1.0,
    "plural common nouns ,": 1.0,
    "common nouns , np": 0.5,
    "nouns , np for": 1.0,
    ", np for singular": 1.0,
    "np for singular proper": 1.0,
    "for singular proper nouns": 1.0,
    "singular proper nouns -lrb-": 1.0,
    "proper nouns -lrb- see": 1.0,
    "nouns -lrb- see the": 1.0,
    "-lrb- see the pos": 1.0,
    "see the pos tags": 1.0,
    "the pos tags used": 1.0,
    "pos tags used in": 0.5,
    "tags used in the": 1.0,
    "used in the brown": 0.16666666666666666,
    "in the brown corpus": 1.0,
    "the brown corpus -rrb-": 0.2727272727272727,
    "brown corpus -rrb- .": 0.3333333333333333,
    "<s> work on stochastic": 1.0,
    "work on stochastic methods": 1.0,
    "on stochastic methods for": 1.0,
    "stochastic methods for tagging": 1.0,
    "methods for tagging koine": 1.0,
    "for tagging koine greek": 1.0,
    "tagging koine greek -lrb-": 1.0,
    "koine greek -lrb- derose": 1.0,
    "greek -lrb- derose 1990": 1.0,
    "-lrb- derose 1990 -rrb-": 1.0,
    "derose 1990 -rrb- has": 1.0,
    "1990 -rrb- has used": 1.0,
    "-rrb- has used over": 1.0,
    "has used over 1,000": 1.0,
    "used over 1,000 parts": 1.0,
    "over 1,000 parts of": 1.0,
    "1,000 parts of speech": 1.0,
    "of speech , and": 0.16666666666666666,
    "speech , and found": 1.0,
    ", and found that": 1.0,
    "and found that about": 1.0,
    "found that about as": 1.0,
    "that about as many": 1.0,
    "about as many words": 1.0,
    "as many words were": 1.0,
    "many words were ambiguous": 1.0,
    "words were ambiguous there": 1.0,
    "were ambiguous there as": 1.0,
    "ambiguous there as in": 1.0,
    "there as in english": 1.0,
    "as in english .": 1.0,
    "<s> a morphosyntactic descriptor": 1.0,
    "a morphosyntactic descriptor in": 1.0,
    "morphosyntactic descriptor in the": 1.0,
    "descriptor in the case": 1.0,
    "the case of morphologically": 0.2,
    "case of morphologically rich": 1.0,
    "of morphologically rich languages": 1.0,
    "morphologically rich languages can": 1.0,
    "rich languages can be": 1.0,
    "languages can be expressed": 1.0,
    "can be expressed like": 0.3333333333333333,
    "be expressed like ncmsan": 1.0,
    "expressed like ncmsan ,": 1.0,
    "like ncmsan , which": 1.0,
    "ncmsan , which means": 1.0,
    ", which means category": 0.25,
    "which means category =": 1.0,
    "means category = noun": 1.0,
    "category = noun ,": 1.0,
    "= noun , type": 1.0,
    "noun , type =": 1.0,
    ", type = common": 1.0,
    "type = common ,": 1.0,
    "= common , gender": 1.0,
    "common , gender =": 1.0,
    ", gender = masculine": 1.0,
    "gender = masculine ,": 1.0,
    "= masculine , number": 1.0,
    "masculine , number =": 1.0,
    ", number = singular": 1.0,
    "number = singular ,": 1.0,
    "= singular , case": 1.0,
    "singular , case =": 1.0,
    ", case = accusative": 1.0,
    "case = accusative ,": 1.0,
    "= accusative , animate": 1.0,
    "accusative , animate =": 1.0,
    ", animate = no.": 1.0,
    "animate = no. .": 1.0,
    "<s> history the brown": 1.0,
    "history the brown corpus": 1.0,
    "the brown corpus research": 0.09090909090909091,
    "brown corpus research on": 1.0,
    "corpus research on part-of-speech": 1.0,
    "research on part-of-speech tagging": 1.0,
    "on part-of-speech tagging has": 1.0,
    "part-of-speech tagging has been": 1.0,
    "tagging has been closely": 1.0,
    "has been closely tied": 1.0,
    "been closely tied to": 1.0,
    "closely tied to corpus": 1.0,
    "tied to corpus linguistics": 1.0,
    "to corpus linguistics .": 1.0,
    "<s> the first major": 0.16666666666666666,
    "the first major corpus": 0.5,
    "first major corpus of": 1.0,
    "major corpus of english": 1.0,
    "corpus of english for": 1.0,
    "of english for computer": 1.0,
    "english for computer analysis": 1.0,
    "for computer analysis was": 1.0,
    "computer analysis was the": 1.0,
    "analysis was the brown": 1.0,
    "was the brown corpus": 1.0,
    "the brown corpus developed": 0.09090909090909091,
    "brown corpus developed at": 1.0,
    "corpus developed at brown": 1.0,
    "developed at brown university": 1.0,
    "at brown university by": 0.5,
    "brown university by henry": 1.0,
    "university by henry kucera": 1.0,
    "by henry kucera and": 1.0,
    "henry kucera and nelson": 1.0,
    "kucera and nelson francis": 1.0,
    "and nelson francis ,": 1.0,
    "nelson francis , in": 1.0,
    "francis , in the": 1.0,
    ", in the mid-1960s": 0.125,
    "in the mid-1960s .": 1.0,
    "<s> it consists of": 1.0,
    "it consists of about": 1.0,
    "consists of about 1,000,000": 1.0,
    "of about 1,000,000 words": 1.0,
    "about 1,000,000 words of": 1.0,
    "1,000,000 words of running": 1.0,
    "words of running english": 1.0,
    "of running english prose": 1.0,
    "running english prose text": 1.0,
    "english prose text ,": 1.0,
    "prose text , made": 1.0,
    "text , made up": 0.5,
    ", made up of": 1.0,
    "made up of 500": 1.0,
    "up of 500 samples": 1.0,
    "of 500 samples from": 1.0,
    "500 samples from randomly": 1.0,
    "samples from randomly chosen": 1.0,
    "from randomly chosen publications": 1.0,
    "randomly chosen publications .": 1.0,
    "<s> each sample is": 1.0,
    "each sample is 2,000": 1.0,
    "sample is 2,000 or": 1.0,
    "is 2,000 or more": 1.0,
    "2,000 or more words": 1.0,
    "or more words -lrb-": 1.0,
    "more words -lrb- ending": 1.0,
    "words -lrb- ending at": 1.0,
    "-lrb- ending at the": 1.0,
    "ending at the first": 1.0,
    "at the first sentence-end": 0.5,
    "the first sentence-end after": 1.0,
    "first sentence-end after 2,000": 1.0,
    "sentence-end after 2,000 words": 1.0,
    "after 2,000 words ,": 1.0,
    "2,000 words , so": 1.0,
    "words , so that": 1.0,
    ", so that the": 0.5,
    "so that the corpus": 0.5,
    "that the corpus contains": 1.0,
    "the corpus contains only": 1.0,
    "corpus contains only complete": 1.0,
    "contains only complete sentences": 1.0,
    "only complete sentences -rrb-": 1.0,
    "complete sentences -rrb- .": 1.0,
    "<s> the brown corpus": 1.0,
    "the brown corpus was": 0.18181818181818182,
    "brown corpus was painstakingly": 0.5,
    "corpus was painstakingly ``": 1.0,
    "was painstakingly `` tagged": 1.0,
    "painstakingly `` tagged ''": 1.0,
    "`` tagged '' with": 0.5,
    "tagged '' with part-of-speech": 1.0,
    "'' with part-of-speech markers": 1.0,
    "with part-of-speech markers over": 1.0,
    "part-of-speech markers over many": 1.0,
    "markers over many years": 1.0,
    "over many years .": 1.0,
    "<s> a first approximation": 1.0,
    "a first approximation was": 1.0,
    "first approximation was done": 1.0,
    "approximation was done with": 1.0,
    "was done with a": 1.0,
    "done with a program": 1.0,
    "with a program by": 1.0,
    "a program by greene": 1.0,
    "program by greene and": 1.0,
    "by greene and rubin": 1.0,
    "greene and rubin ,": 1.0,
    "and rubin , which": 1.0,
    "rubin , which consisted": 1.0,
    ", which consisted of": 1.0,
    "which consisted of a": 1.0,
    "consisted of a huge": 1.0,
    "of a huge handmade": 1.0,
    "a huge handmade list": 1.0,
    "huge handmade list of": 1.0,
    "handmade list of what": 1.0,
    "list of what categories": 1.0,
    "of what categories could": 1.0,
    "what categories could co-occur": 1.0,
    "categories could co-occur at": 1.0,
    "could co-occur at all": 1.0,
    "co-occur at all .": 1.0,
    "for example , article": 0.02127659574468085,
    "example , article then": 1.0,
    ", article then noun": 1.0,
    "article then noun can": 1.0,
    "then noun can occur": 1.0,
    "noun can occur ,": 1.0,
    "can occur , but": 1.0,
    "occur , but article": 1.0,
    ", but article verb": 1.0,
    "but article verb -lrb-": 1.0,
    "article verb -lrb- arguably": 1.0,
    "verb -lrb- arguably -rrb-": 1.0,
    "-lrb- arguably -rrb- can": 1.0,
    "arguably -rrb- can not": 1.0,
    "-rrb- can not .": 1.0,
    "<s> the program got": 1.0,
    "the program got about": 1.0,
    "program got about 70": 1.0,
    "got about 70 %": 1.0,
    "about 70 % correct": 0.5,
    "70 % correct .": 1.0,
    "<s> its results were": 1.0,
    "its results were repeatedly": 1.0,
    "results were repeatedly reviewed": 1.0,
    "were repeatedly reviewed and": 1.0,
    "repeatedly reviewed and corrected": 1.0,
    "reviewed and corrected by": 1.0,
    "and corrected by hand": 1.0,
    "corrected by hand ,": 1.0,
    "by hand , and": 0.5,
    "hand , and later": 1.0,
    ", and later users": 1.0,
    "and later users sent": 1.0,
    "later users sent in": 1.0,
    "users sent in errata": 1.0,
    "sent in errata ,": 1.0,
    "in errata , so": 1.0,
    "errata , so that": 1.0,
    ", so that by": 0.5,
    "so that by the": 1.0,
    "that by the late": 1.0,
    "by the late 70s": 1.0,
    "the late 70s the": 1.0,
    "late 70s the tagging": 1.0,
    "70s the tagging was": 1.0,
    "the tagging was nearly": 1.0,
    "tagging was nearly perfect": 1.0,
    "was nearly perfect -lrb-": 1.0,
    "nearly perfect -lrb- allowing": 1.0,
    "perfect -lrb- allowing for": 1.0,
    "-lrb- allowing for some": 1.0,
    "allowing for some cases": 1.0,
    "for some cases on": 1.0,
    "some cases on which": 1.0,
    "cases on which even": 1.0,
    "on which even human": 1.0,
    "which even human speakers": 1.0,
    "even human speakers might": 1.0,
    "human speakers might not": 1.0,
    "speakers might not agree": 1.0,
    "might not agree -rrb-": 1.0,
    "not agree -rrb- .": 1.0,
    "<s> this corpus has": 0.5,
    "this corpus has been": 1.0,
    "corpus has been used": 1.0,
    "has been used for": 0.5,
    "been used for innumerable": 1.0,
    "used for innumerable studies": 1.0,
    "for innumerable studies of": 1.0,
    "innumerable studies of word-frequency": 1.0,
    "studies of word-frequency and": 1.0,
    "of word-frequency and of": 1.0,
    "word-frequency and of part-of-speech": 1.0,
    "and of part-of-speech ,": 1.0,
    "of part-of-speech , and": 1.0,
    "part-of-speech , and inspired": 1.0,
    ", and inspired the": 1.0,
    "and inspired the development": 1.0,
    "inspired the development of": 1.0,
    "the development of similar": 0.2,
    "development of similar ``": 1.0,
    "of similar `` tagged": 1.0,
    "similar `` tagged ''": 1.0,
    "`` tagged '' corpora": 0.5,
    "tagged '' corpora in": 1.0,
    "'' corpora in many": 1.0,
    "corpora in many other": 1.0,
    "in many other languages": 1.0,
    "many other languages .": 0.3333333333333333,
    "<s> statistics derived by": 1.0,
    "statistics derived by analyzing": 1.0,
    "derived by analyzing it": 0.5,
    "by analyzing it formed": 1.0,
    "analyzing it formed the": 1.0,
    "it formed the basis": 1.0,
    "formed the basis for": 1.0,
    "the basis for most": 1.0,
    "basis for most later": 1.0,
    "for most later part-of-speech": 1.0,
    "most later part-of-speech tagging": 1.0,
    "later part-of-speech tagging systems": 1.0,
    "part-of-speech tagging systems ,": 1.0,
    "tagging systems , such": 1.0,
    "systems , such as": 1.0,
    ", such as claws": 0.030303030303030304,
    "such as claws -lrb-": 1.0,
    "as claws -lrb- linguistics": 1.0,
    "claws -lrb- linguistics -rrb-": 1.0,
    "-lrb- linguistics -rrb- and": 0.5,
    "linguistics -rrb- and volsunga": 1.0,
    "-rrb- and volsunga .": 1.0,
    "<s> however , by": 0.03125,
    "however , by this": 1.0,
    ", by this time": 1.0,
    "by this time -lrb-": 1.0,
    "this time -lrb- 2005": 1.0,
    "time -lrb- 2005 -rrb-": 1.0,
    "-lrb- 2005 -rrb- it": 1.0,
    "2005 -rrb- it has": 1.0,
    "-rrb- it has been": 1.0,
    "it has been superseded": 0.3333333333333333,
    "has been superseded by": 1.0,
    "been superseded by larger": 1.0,
    "superseded by larger corpora": 1.0,
    "by larger corpora such": 1.0,
    "larger corpora such as": 1.0,
    "corpora such as the": 1.0,
    "such as the 100": 0.07142857142857142,
    "as the 100 million": 1.0,
    "the 100 million word": 1.0,
    "100 million word british": 1.0,
    "million word british national": 1.0,
    "word british national corpus": 1.0,
    "british national corpus .": 1.0,
    "<s> for some time": 1.0,
    "for some time ,": 0.5,
    "some time , part-of-speech": 1.0,
    "time , part-of-speech tagging": 1.0,
    ", part-of-speech tagging was": 0.5,
    "part-of-speech tagging was considered": 1.0,
    "tagging was considered an": 1.0,
    "was considered an inseparable": 1.0,
    "considered an inseparable part": 1.0,
    "an inseparable part of": 1.0,
    "inseparable part of natural": 1.0,
    "part of natural language": 1.0,
    "language processing , because": 0.16666666666666666,
    "processing , because there": 1.0,
    ", because there are": 0.5,
    "because there are certain": 1.0,
    "there are certain cases": 1.0,
    "are certain cases where": 1.0,
    "certain cases where the": 1.0,
    "cases where the correct": 1.0,
    "where the correct part": 1.0,
    "part of speech can": 0.07142857142857142,
    "of speech can not": 1.0,
    "speech can not be": 1.0,
    "can not be decided": 0.25,
    "not be decided without": 1.0,
    "be decided without understanding": 1.0,
    "decided without understanding the": 1.0,
    "without understanding the semantics": 1.0,
    "understanding the semantics or": 1.0,
    "the semantics or even": 1.0,
    "semantics or even the": 1.0,
    "or even the pragmatics": 1.0,
    "even the pragmatics of": 1.0,
    "the pragmatics of the": 1.0,
    "pragmatics of the context": 1.0,
    "of the context .": 1.0,
    "<s> this is extremely": 0.07142857142857142,
    "this is extremely expensive": 1.0,
    "is extremely expensive ,": 1.0,
    "extremely expensive , especially": 1.0,
    "expensive , especially because": 1.0,
    ", especially because analyzing": 1.0,
    "especially because analyzing the": 1.0,
    "because analyzing the higher": 1.0,
    "analyzing the higher levels": 1.0,
    "the higher levels is": 1.0,
    "higher levels is much": 1.0,
    "levels is much harder": 1.0,
    "is much harder when": 1.0,
    "much harder when multiple": 1.0,
    "harder when multiple part-of-speech": 1.0,
    "when multiple part-of-speech possibilities": 1.0,
    "multiple part-of-speech possibilities must": 1.0,
    "part-of-speech possibilities must be": 1.0,
    "possibilities must be considered": 1.0,
    "must be considered for": 1.0,
    "be considered for each": 1.0,
    "considered for each word": 1.0,
    "<s> use of hidden": 1.0,
    "use of hidden markov": 1.0,
    "of hidden markov models": 1.0,
    "hidden markov models in": 0.14285714285714285,
    "markov models in the": 1.0,
    "models in the mid": 1.0,
    "in the mid 1980s": 1.0,
    "the mid 1980s ,": 1.0,
    "mid 1980s , researchers": 1.0,
    "1980s , researchers in": 1.0,
    ", researchers in europe": 1.0,
    "researchers in europe began": 1.0,
    "in europe began to": 1.0,
    "europe began to use": 1.0,
    "began to use hidden": 1.0,
    "to use hidden markov": 1.0,
    "use hidden markov models": 1.0,
    "hidden markov models -lrb-": 0.2857142857142857,
    "markov models -lrb- hmms": 1.0,
    "models -lrb- hmms -rrb-": 1.0,
    "-lrb- hmms -rrb- to": 0.5,
    "hmms -rrb- to disambiguate": 1.0,
    "-rrb- to disambiguate parts": 1.0,
    "to disambiguate parts of": 1.0,
    "disambiguate parts of speech": 1.0,
    "of speech , when": 0.16666666666666666,
    "speech , when working": 0.5,
    ", when working to": 1.0,
    "when working to tag": 1.0,
    "working to tag the": 1.0,
    "to tag the lancaster-oslo-bergen": 1.0,
    "tag the lancaster-oslo-bergen corpus": 1.0,
    "the lancaster-oslo-bergen corpus of": 1.0,
    "lancaster-oslo-bergen corpus of british": 1.0,
    "corpus of british english": 1.0,
    "of british english .": 1.0,
    "<s> hmms involve counting": 1.0,
    "hmms involve counting cases": 1.0,
    "involve counting cases -lrb-": 1.0,
    "counting cases -lrb- such": 1.0,
    "cases -lrb- such as": 1.0,
    "-lrb- such as from": 0.125,
    "such as from the": 1.0,
    "as from the brown": 1.0,
    "brown corpus -rrb- ,": 0.6666666666666666,
    "corpus -rrb- , and": 0.3333333333333333,
    "-rrb- , and making": 0.09090909090909091,
    ", and making a": 0.5,
    "and making a table": 1.0,
    "making a table of": 1.0,
    "a table of the": 0.3333333333333333,
    "table of the probabilities": 1.0,
    "of the probabilities of": 1.0,
    "the probabilities of certain": 0.3333333333333333,
    "probabilities of certain sequences": 1.0,
    "of certain sequences .": 1.0,
    "for example , once": 0.02127659574468085,
    "example , once you": 1.0,
    ", once you 've": 1.0,
    "once you 've seen": 1.0,
    "you 've seen an": 1.0,
    "'ve seen an article": 1.0,
    "seen an article such": 0.5,
    "an article such as": 1.0,
    "article such as `": 1.0,
    "such as ` the": 1.0,
    "as ` the '": 1.0,
    "` the ' ,": 1.0,
    "the ' , perhaps": 1.0,
    "' , perhaps the": 1.0,
    ", perhaps the next": 1.0,
    "perhaps the next word": 1.0,
    "the next word is": 0.5,
    "next word is a": 1.0,
    "word is a noun": 1.0,
    "is a noun 40": 1.0,
    "a noun 40 %": 1.0,
    "noun 40 % of": 1.0,
    "40 % of the": 1.0,
    "% of the time": 0.6,
    "of the time ,": 0.75,
    "the time , an": 0.2,
    "time , an adjective": 1.0,
    ", an adjective 40": 1.0,
    "an adjective 40 %": 1.0,
    "adjective 40 % ,": 1.0,
    "40 % , and": 1.0,
    "% , and a": 1.0,
    ", and a number": 0.16666666666666666,
    "and a number 20": 1.0,
    "a number 20 %": 1.0,
    "number 20 % .": 1.0,
    "<s> knowing this ,": 1.0,
    "knowing this , a": 1.0,
    "this , a program": 1.0,
    ", a program can": 1.0,
    "a program can decide": 1.0,
    "program can decide that": 1.0,
    "can decide that ``": 1.0,
    "decide that `` can": 1.0,
    "that `` can ''": 1.0,
    "`` can '' in": 1.0,
    "can '' in ``": 1.0,
    "'' in `` the": 1.0,
    "in `` the can": 1.0,
    "`` the can ''": 1.0,
    "the can '' is": 1.0,
    "can '' is far": 1.0,
    "'' is far more": 1.0,
    "is far more likely": 0.5,
    "far more likely to": 1.0,
    "more likely to be": 1.0,
    "to be a noun": 0.2,
    "be a noun than": 0.3333333333333333,
    "a noun than a": 1.0,
    "noun than a verb": 1.0,
    "than a verb or": 1.0,
    "verb or a modal": 0.5,
    "or a modal .": 1.0,
    "<s> the same method": 1.0,
    "the same method can": 1.0,
    "same method can of": 1.0,
    "method can of course": 1.0,
    "can of course be": 1.0,
    "of course be used": 1.0,
    "course be used to": 1.0,
    "be used to benefit": 0.16666666666666666,
    "used to benefit from": 1.0,
    "to benefit from knowledge": 1.0,
    "benefit from knowledge about": 1.0,
    "from knowledge about following": 1.0,
    "knowledge about following words": 1.0,
    "about following words .": 1.0,
    "<s> more advanced -lrb-": 1.0,
    "more advanced -lrb- ``": 1.0,
    "advanced -lrb- `` higher": 1.0,
    "-lrb- `` higher order": 1.0,
    "`` higher order ''": 1.0,
    "higher order '' -rrb-": 1.0,
    "order '' -rrb- hmms": 1.0,
    "'' -rrb- hmms learn": 1.0,
    "-rrb- hmms learn the": 1.0,
    "hmms learn the probabilities": 1.0,
    "learn the probabilities not": 1.0,
    "the probabilities not only": 1.0,
    "probabilities not only of": 1.0,
    "not only of pairs": 1.0,
    "only of pairs ,": 1.0,
    "of pairs , but": 0.5,
    "pairs , but triples": 1.0,
    ", but triples or": 1.0,
    "but triples or even": 1.0,
    "triples or even larger": 1.0,
    "or even larger sequences": 1.0,
    "even larger sequences .": 1.0,
    "<s> so , for": 1.0,
    "so , for example": 1.0,
    "example , if you": 0.16666666666666666,
    ", if you 've": 0.5,
    "if you 've just": 1.0,
    "you 've just seen": 1.0,
    "'ve just seen an": 1.0,
    "just seen an article": 1.0,
    "seen an article and": 0.5,
    "an article and a": 1.0,
    "article and a verb": 1.0,
    "and a verb ,": 1.0,
    "a verb , the": 0.3333333333333333,
    "verb , the next": 1.0,
    ", the next item": 1.0,
    "the next item may": 1.0,
    "next item may be": 1.0,
    "item may be very": 1.0,
    "may be very likely": 1.0,
    "be very likely a": 1.0,
    "very likely a preposition": 1.0,
    "likely a preposition ,": 1.0,
    "a preposition , article": 1.0,
    "preposition , article ,": 1.0,
    ", article , or": 0.5,
    "article , or noun": 1.0,
    ", or noun ,": 1.0,
    "or noun , but": 1.0,
    "noun , but much": 1.0,
    ", but much less": 1.0,
    "but much less likely": 1.0,
    "much less likely another": 1.0,
    "less likely another verb": 1.0,
    "likely another verb .": 1.0,
    "<s> when several ambiguous": 1.0,
    "when several ambiguous words": 1.0,
    "several ambiguous words occur": 1.0,
    "ambiguous words occur together": 1.0,
    "words occur together ,": 1.0,
    "occur together , the": 1.0,
    "together , the possibilities": 1.0,
    ", the possibilities multiply": 1.0,
    "the possibilities multiply .": 1.0,
    "<s> however , it": 0.03125,
    "however , it is": 1.0,
    ", it is easy": 0.07692307692307693,
    "it is easy to": 1.0,
    "is easy to enumerate": 1.0,
    "easy to enumerate every": 1.0,
    "to enumerate every combination": 1.0,
    "enumerate every combination and": 1.0,
    "every combination and to": 1.0,
    "combination and to assign": 1.0,
    "and to assign a": 1.0,
    "to assign a relative": 1.0,
    "assign a relative probability": 1.0,
    "a relative probability to": 1.0,
    "relative probability to each": 1.0,
    "probability to each one": 1.0,
    "to each one ,": 1.0,
    "each one , by": 1.0,
    "one , by multiplying": 1.0,
    ", by multiplying together": 1.0,
    "by multiplying together the": 1.0,
    "multiplying together the probabilities": 1.0,
    "together the probabilities of": 1.0,
    "the probabilities of each": 0.3333333333333333,
    "probabilities of each choice": 1.0,
    "of each choice in": 1.0,
    "each choice in turn": 1.0,
    "choice in turn .": 1.0,
    "<s> the combination with": 1.0,
    "the combination with highest": 1.0,
    "combination with highest probability": 1.0,
    "with highest probability is": 1.0,
    "highest probability is then": 1.0,
    "probability is then chosen": 1.0,
    "is then chosen .": 1.0,
    "<s> the european group": 1.0,
    "the european group developed": 1.0,
    "european group developed claws": 1.0,
    "group developed claws ,": 1.0,
    "developed claws , a": 1.0,
    "claws , a tagging": 1.0,
    ", a tagging program": 1.0,
    "a tagging program that": 1.0,
    "tagging program that did": 1.0,
    "program that did exactly": 1.0,
    "that did exactly this": 1.0,
    "did exactly this ,": 1.0,
    "exactly this , and": 1.0,
    "this , and achieved": 1.0,
    ", and achieved accuracy": 1.0,
    "and achieved accuracy in": 1.0,
    "achieved accuracy in the": 1.0,
    "accuracy in the 93-95": 1.0,
    "in the 93-95 %": 1.0,
    "the 93-95 % range": 1.0,
    "93-95 % range .": 1.0,
    "<s> it is worth": 0.05263157894736842,
    "it is worth remembering": 0.5,
    "is worth remembering ,": 1.0,
    "worth remembering , as": 1.0,
    "remembering , as eugene": 1.0,
    ", as eugene charniak": 1.0,
    "as eugene charniak points": 1.0,
    "eugene charniak points out": 1.0,
    "charniak points out in": 1.0,
    "points out in statistical": 1.0,
    "out in statistical techniques": 1.0,
    "in statistical techniques for": 1.0,
    "statistical techniques for natural": 1.0,
    "techniques for natural language": 1.0,
    "for natural language parsing": 0.3333333333333333,
    "natural language parsing ,": 0.5,
    "language parsing , that": 1.0,
    "parsing , that merely": 1.0,
    ", that merely assigning": 1.0,
    "that merely assigning the": 1.0,
    "merely assigning the most": 1.0,
    "assigning the most common": 1.0,
    "the most common tag": 0.16666666666666666,
    "most common tag to": 1.0,
    "common tag to each": 1.0,
    "tag to each known": 1.0,
    "to each known word": 1.0,
    "each known word and": 1.0,
    "known word and the": 1.0,
    "word and the tag": 1.0,
    "and the tag ``": 1.0,
    "the tag `` proper": 1.0,
    "tag `` proper noun": 1.0,
    "`` proper noun ''": 1.0,
    "proper noun '' to": 1.0,
    "noun '' to all": 1.0,
    "'' to all unknowns": 1.0,
    "to all unknowns ,": 1.0,
    "all unknowns , will": 1.0,
    "unknowns , will approach": 1.0,
    ", will approach 90": 1.0,
    "will approach 90 %": 1.0,
    "approach 90 % accuracy": 1.0,
    "90 % accuracy because": 1.0,
    "% accuracy because many": 1.0,
    "accuracy because many words": 1.0,
    "because many words are": 1.0,
    "many words are unambiguous": 1.0,
    "words are unambiguous .": 1.0,
    "<s> claws pioneered the": 1.0,
    "claws pioneered the field": 1.0,
    "pioneered the field of": 1.0,
    "the field of hmm-based": 0.1111111111111111,
    "field of hmm-based part": 1.0,
    "of hmm-based part of": 1.0,
    "hmm-based part of speech": 1.0,
    "speech tagging , but": 0.5,
    "tagging , but was": 1.0,
    ", but was quite": 1.0,
    "but was quite expensive": 1.0,
    "was quite expensive since": 1.0,
    "quite expensive since it": 1.0,
    "expensive since it enumerated": 1.0,
    "since it enumerated all": 1.0,
    "it enumerated all possibilities": 1.0,
    "enumerated all possibilities .": 1.0,
    "<s> it sometimes had": 1.0,
    "it sometimes had to": 1.0,
    "sometimes had to resort": 1.0,
    "had to resort to": 1.0,
    "to resort to backup": 1.0,
    "resort to backup methods": 1.0,
    "to backup methods when": 1.0,
    "backup methods when there": 1.0,
    "methods when there were": 1.0,
    "when there were simply": 1.0,
    "there were simply too": 1.0,
    "were simply too many": 1.0,
    "simply too many -lrb-": 1.0,
    "too many -lrb- the": 1.0,
    "many -lrb- the brown": 1.0,
    "-lrb- the brown corpus": 1.0,
    "the brown corpus contains": 0.09090909090909091,
    "brown corpus contains a": 1.0,
    "corpus contains a case": 1.0,
    "contains a case with": 1.0,
    "a case with 17": 1.0,
    "case with 17 ambiguous": 1.0,
    "with 17 ambiguous words": 1.0,
    "17 ambiguous words in": 1.0,
    "ambiguous words in a": 1.0,
    "words in a row": 0.3333333333333333,
    "in a row ,": 1.0,
    "a row , and": 1.0,
    "row , and there": 1.0,
    "and there are words": 0.5,
    "there are words such": 1.0,
    "are words such as": 1.0,
    "words such as ``": 1.0,
    "such as `` still": 0.125,
    "as `` still ''": 1.0,
    "`` still '' that": 1.0,
    "still '' that can": 1.0,
    "'' that can represent": 1.0,
    "that can represent as": 1.0,
    "can represent as many": 1.0,
    "represent as many as": 1.0,
    "as many as 7": 1.0,
    "many as 7 distinct": 1.0,
    "as 7 distinct parts": 1.0,
    "7 distinct parts of": 1.0,
    "distinct parts of speech": 1.0,
    "parts of speech -rrb-": 0.09090909090909091,
    "of speech -rrb- .": 1.0,
    "<s> hmms underlie the": 1.0,
    "hmms underlie the functioning": 1.0,
    "underlie the functioning of": 1.0,
    "the functioning of stochastic": 1.0,
    "functioning of stochastic taggers": 1.0,
    "of stochastic taggers and": 1.0,
    "stochastic taggers and are": 1.0,
    "taggers and are used": 1.0,
    "and are used in": 1.0,
    "are used in various": 0.5,
    "used in various algorithms": 1.0,
    "in various algorithms one": 1.0,
    "various algorithms one of": 1.0,
    "algorithms one of the": 1.0,
    "of the most widely": 0.16666666666666666,
    "the most widely used": 1.0,
    "most widely used being": 1.0,
    "widely used being the": 1.0,
    "used being the bi-directional": 1.0,
    "being the bi-directional inference": 1.0,
    "the bi-directional inference algorithm": 1.0,
    "bi-directional inference algorithm .": 1.0,
    "<s> dynamic programming methods": 1.0,
    "dynamic programming methods in": 1.0,
    "programming methods in 1987": 1.0,
    "methods in 1987 ,": 1.0,
    "in 1987 , steven": 0.5,
    "1987 , steven derose": 1.0,
    ", steven derose and": 1.0,
    "steven derose and ken": 1.0,
    "derose and ken church": 1.0,
    "and ken church independently": 1.0,
    "ken church independently developed": 1.0,
    "church independently developed dynamic": 1.0,
    "independently developed dynamic programming": 1.0,
    "developed dynamic programming algorithms": 1.0,
    "dynamic programming algorithms to": 1.0,
    "programming algorithms to solve": 1.0,
    "algorithms to solve the": 1.0,
    "to solve the same": 1.0,
    "solve the same problem": 1.0,
    "the same problem in": 1.0,
    "same problem in vastly": 1.0,
    "problem in vastly less": 1.0,
    "in vastly less time": 1.0,
    "vastly less time .": 1.0,
    "<s> their methods were": 1.0,
    "their methods were similar": 1.0,
    "methods were similar to": 1.0,
    "were similar to the": 1.0,
    "similar to the viterbi": 0.2,
    "to the viterbi algorithm": 1.0,
    "the viterbi algorithm known": 0.25,
    "viterbi algorithm known for": 1.0,
    "algorithm known for some": 1.0,
    "known for some time": 1.0,
    "for some time in": 0.5,
    "some time in other": 1.0,
    "time in other fields": 1.0,
    "in other fields .": 1.0,
    "<s> derose used a": 1.0,
    "derose used a table": 1.0,
    "used a table of": 1.0,
    "a table of pairs": 0.3333333333333333,
    "table of pairs ,": 1.0,
    "of pairs , while": 0.5,
    "pairs , while church": 1.0,
    ", while church used": 1.0,
    "while church used a": 1.0,
    "church used a table": 1.0,
    "a table of triples": 0.3333333333333333,
    "table of triples and": 1.0,
    "of triples and a": 1.0,
    "triples and a method": 1.0,
    "and a method of": 1.0,
    "a method of estimating": 1.0,
    "method of estimating the": 1.0,
    "of estimating the values": 1.0,
    "estimating the values for": 1.0,
    "the values for triples": 1.0,
    "values for triples that": 1.0,
    "for triples that were": 1.0,
    "triples that were rare": 1.0,
    "that were rare or": 1.0,
    "were rare or nonexistent": 1.0,
    "rare or nonexistent in": 1.0,
    "or nonexistent in the": 1.0,
    "nonexistent in the brown": 1.0,
    "the brown corpus -lrb-": 0.09090909090909091,
    "brown corpus -lrb- actual": 1.0,
    "corpus -lrb- actual measurement": 1.0,
    "-lrb- actual measurement of": 1.0,
    "actual measurement of triple": 1.0,
    "measurement of triple probabilities": 1.0,
    "of triple probabilities would": 1.0,
    "triple probabilities would require": 1.0,
    "probabilities would require a": 1.0,
    "would require a much": 0.5,
    "require a much larger": 1.0,
    "a much larger corpus": 0.5,
    "much larger corpus -rrb-": 1.0,
    "larger corpus -rrb- .": 0.5,
    "<s> both methods achieved": 1.0,
    "both methods achieved accuracy": 1.0,
    "methods achieved accuracy over": 1.0,
    "achieved accuracy over 95": 1.0,
    "accuracy over 95 %": 1.0,
    "over 95 % .": 1.0,
    "<s> derose 's 1990": 1.0,
    "derose 's 1990 dissertation": 1.0,
    "'s 1990 dissertation at": 1.0,
    "1990 dissertation at brown": 1.0,
    "dissertation at brown university": 1.0,
    "at brown university included": 0.5,
    "brown university included analyses": 1.0,
    "university included analyses of": 1.0,
    "included analyses of the": 1.0,
    "analyses of the specific": 1.0,
    "of the specific error": 0.5,
    "the specific error types": 1.0,
    "specific error types ,": 1.0,
    "error types , probabilities": 1.0,
    "types , probabilities ,": 1.0,
    ", probabilities , and": 1.0,
    "probabilities , and other": 1.0,
    ", and other related": 0.3333333333333333,
    "and other related data": 1.0,
    "other related data ,": 1.0,
    "related data , and": 1.0,
    "data , and replicated": 0.3333333333333333,
    ", and replicated his": 1.0,
    "and replicated his work": 1.0,
    "replicated his work for": 1.0,
    "his work for greek": 1.0,
    "work for greek ,": 1.0,
    "for greek , where": 1.0,
    "greek , where it": 1.0,
    ", where it proved": 1.0,
    "where it proved similarly": 1.0,
    "it proved similarly effective": 1.0,
    "proved similarly effective .": 1.0,
    "<s> these findings were": 1.0,
    "these findings were surprisingly": 1.0,
    "findings were surprisingly disruptive": 1.0,
    "were surprisingly disruptive to": 1.0,
    "surprisingly disruptive to the": 1.0,
    "disruptive to the field": 1.0,
    "to the field of": 1.0,
    "the field of natural": 0.2222222222222222,
    "field of natural language": 1.0,
    "natural language processing .": 0.10714285714285714,
    "<s> the accuracy reported": 1.0,
    "the accuracy reported was": 1.0,
    "accuracy reported was higher": 1.0,
    "reported was higher than": 1.0,
    "was higher than the": 1.0,
    "higher than the typical": 1.0,
    "than the typical accuracy": 1.0,
    "the typical accuracy of": 1.0,
    "typical accuracy of very": 1.0,
    "accuracy of very sophisticated": 1.0,
    "of very sophisticated algorithms": 1.0,
    "very sophisticated algorithms that": 1.0,
    "sophisticated algorithms that integrated": 1.0,
    "algorithms that integrated part": 1.0,
    "that integrated part of": 1.0,
    "integrated part of speech": 1.0,
    "part of speech choice": 0.07142857142857142,
    "of speech choice with": 1.0,
    "speech choice with many": 1.0,
    "choice with many higher": 1.0,
    "with many higher levels": 1.0,
    "many higher levels of": 1.0,
    "higher levels of linguistic": 1.0,
    "levels of linguistic analysis": 1.0,
    "of linguistic analysis :": 1.0,
    "linguistic analysis : syntax": 1.0,
    "analysis : syntax ,": 1.0,
    ": syntax , morphology": 1.0,
    ", morphology , semantics": 0.5,
    "morphology , semantics ,": 1.0,
    ", semantics , and": 0.3333333333333333,
    "semantics , and so": 0.5,
    "<s> claws , derose": 1.0,
    "claws , derose 's": 1.0,
    ", derose 's and": 1.0,
    "derose 's and church": 1.0,
    "'s and church 's": 1.0,
    "and church 's methods": 1.0,
    "church 's methods did": 1.0,
    "'s methods did fail": 1.0,
    "methods did fail for": 1.0,
    "did fail for some": 1.0,
    "fail for some of": 1.0,
    "for some of the": 1.0,
    "some of the known": 0.1,
    "of the known cases": 1.0,
    "the known cases where": 1.0,
    "known cases where semantics": 1.0,
    "cases where semantics is": 1.0,
    "where semantics is required": 1.0,
    "semantics is required ,": 1.0,
    "is required , but": 1.0,
    "required , but those": 1.0,
    ", but those proved": 1.0,
    "but those proved negligibly": 1.0,
    "those proved negligibly rare": 1.0,
    "proved negligibly rare .": 1.0,
    "<s> this convinced many": 1.0,
    "this convinced many in": 1.0,
    "convinced many in the": 1.0,
    "many in the field": 1.0,
    "in the field that": 0.08333333333333333,
    "the field that part-of-speech": 1.0,
    "field that part-of-speech tagging": 1.0,
    "that part-of-speech tagging could": 1.0,
    "part-of-speech tagging could usefully": 1.0,
    "tagging could usefully be": 1.0,
    "could usefully be separated": 1.0,
    "usefully be separated out": 1.0,
    "be separated out from": 1.0,
    "separated out from the": 1.0,
    "out from the other": 1.0,
    "from the other levels": 1.0,
    "the other levels of": 1.0,
    "other levels of processing": 1.0,
    "levels of processing ;": 1.0,
    "of processing ; this": 1.0,
    "processing ; this in": 1.0,
    "; this in turn": 1.0,
    "this in turn simplified": 1.0,
    "in turn simplified the": 1.0,
    "turn simplified the theory": 1.0,
    "simplified the theory and": 1.0,
    "the theory and practice": 1.0,
    "theory and practice of": 1.0,
    "and practice of computerized": 1.0,
    "practice of computerized language": 1.0,
    "of computerized language analysis": 1.0,
    "computerized language analysis ,": 1.0,
    "language analysis , and": 1.0,
    "analysis , and encouraged": 0.5,
    ", and encouraged researchers": 1.0,
    "and encouraged researchers to": 1.0,
    "encouraged researchers to find": 1.0,
    "researchers to find ways": 1.0,
    "to find ways to": 1.0,
    "find ways to separate": 1.0,
    "ways to separate out": 1.0,
    "to separate out other": 1.0,
    "separate out other pieces": 1.0,
    "out other pieces as": 1.0,
    "other pieces as well": 1.0,
    "pieces as well .": 1.0,
    "<s> markov models are": 1.0,
    "markov models are now": 1.0,
    "models are now the": 1.0,
    "are now the standard": 1.0,
    "now the standard method": 1.0,
    "the standard method for": 1.0,
    "standard method for part-of-speech": 1.0,
    "method for part-of-speech assignment": 1.0,
    "for part-of-speech assignment .": 1.0,
    "<s> unsupervised taggers the": 1.0,
    "unsupervised taggers the methods": 1.0,
    "taggers the methods already": 1.0,
    "the methods already discussed": 1.0,
    "methods already discussed involve": 1.0,
    "already discussed involve working": 1.0,
    "discussed involve working from": 1.0,
    "involve working from a": 1.0,
    "working from a pre-existing": 1.0,
    "from a pre-existing corpus": 1.0,
    "a pre-existing corpus to": 1.0,
    "pre-existing corpus to learn": 1.0,
    "corpus to learn tag": 1.0,
    "to learn tag probabilities": 1.0,
    "learn tag probabilities .": 1.0,
    "<s> it is ,": 0.05263157894736842,
    "it is , however": 1.0,
    "is , however ,": 1.0,
    ", however , also": 0.09090909090909091,
    "however , also possible": 1.0,
    ", also possible to": 1.0,
    "also possible to bootstrap": 1.0,
    "possible to bootstrap using": 1.0,
    "to bootstrap using ``": 1.0,
    "bootstrap using `` unsupervised": 1.0,
    "using `` unsupervised ''": 1.0,
    "`` unsupervised '' tagging": 1.0,
    "unsupervised '' tagging .": 1.0,
    "<s> unsupervised tagging techniques": 1.0,
    "unsupervised tagging techniques use": 1.0,
    "tagging techniques use an": 1.0,
    "techniques use an untagged": 1.0,
    "use an untagged corpus": 1.0,
    "an untagged corpus for": 1.0,
    "untagged corpus for their": 1.0,
    "corpus for their training": 1.0,
    "for their training data": 1.0,
    "their training data and": 1.0,
    "training data and produce": 1.0,
    "data and produce the": 1.0,
    "and produce the tagset": 1.0,
    "produce the tagset by": 1.0,
    "the tagset by induction": 1.0,
    "tagset by induction .": 1.0,
    "<s> that is ,": 0.6666666666666666,
    "that is , they": 0.6,
    "is , they observe": 0.3333333333333333,
    ", they observe patterns": 1.0,
    "they observe patterns in": 1.0,
    "observe patterns in word": 1.0,
    "patterns in word use": 1.0,
    "in word use ,": 1.0,
    "word use , and": 1.0,
    "use , and derive": 0.3333333333333333,
    ", and derive part-of-speech": 1.0,
    "and derive part-of-speech categories": 1.0,
    "derive part-of-speech categories themselves": 1.0,
    "part-of-speech categories themselves .": 1.0,
    "for example , statistics": 0.02127659574468085,
    "example , statistics readily": 1.0,
    ", statistics readily reveal": 1.0,
    "statistics readily reveal that": 1.0,
    "readily reveal that ``": 1.0,
    "reveal that `` the": 1.0,
    "that `` the ''": 1.0,
    "`` the '' ,": 1.0,
    "the '' , ``": 1.0,
    "'' , `` a": 0.09090909090909091,
    ", `` a ''": 1.0,
    "`` a '' ,": 1.0,
    "a '' , and": 1.0,
    ", and `` an": 0.2,
    "and `` an ''": 1.0,
    "`` an '' occur": 1.0,
    "an '' occur in": 1.0,
    "'' occur in similar": 1.0,
    "occur in similar contexts": 1.0,
    "in similar contexts ,": 1.0,
    "similar contexts , while": 1.0,
    "contexts , while ``": 1.0,
    ", while `` eat": 1.0,
    "while `` eat ''": 1.0,
    "`` eat '' occurs": 1.0,
    "eat '' occurs in": 1.0,
    "'' occurs in very": 1.0,
    "occurs in very different": 1.0,
    "in very different ones": 1.0,
    "very different ones .": 1.0,
    "<s> with sufficient iteration": 1.0,
    "with sufficient iteration ,": 1.0,
    "sufficient iteration , similarity": 1.0,
    "iteration , similarity classes": 1.0,
    ", similarity classes of": 1.0,
    "similarity classes of words": 1.0,
    "classes of words emerge": 1.0,
    "of words emerge that": 1.0,
    "words emerge that are": 1.0,
    "emerge that are remarkably": 1.0,
    "that are remarkably similar": 1.0,
    "are remarkably similar to": 1.0,
    "remarkably similar to those": 1.0,
    "similar to those human": 0.5,
    "to those human linguists": 1.0,
    "those human linguists would": 1.0,
    "human linguists would expect": 1.0,
    "linguists would expect ;": 1.0,
    "would expect ; and": 1.0,
    "expect ; and the": 1.0,
    "; and the differences": 1.0,
    "and the differences themselves": 1.0,
    "the differences themselves sometimes": 1.0,
    "differences themselves sometimes suggest": 1.0,
    "themselves sometimes suggest valuable": 1.0,
    "sometimes suggest valuable new": 1.0,
    "suggest valuable new insights": 1.0,
    "valuable new insights .": 1.0,
    "<s> these two categories": 1.0,
    "these two categories can": 1.0,
    "two categories can be": 1.0,
    "categories can be further": 1.0,
    "can be further subdivided": 1.0,
    "be further subdivided into": 1.0,
    "further subdivided into rule-based": 1.0,
    "subdivided into rule-based ,": 1.0,
    "into rule-based , stochastic": 1.0,
    "rule-based , stochastic ,": 1.0,
    ", stochastic , and": 1.0,
    "stochastic , and neural": 1.0,
    ", and neural approaches": 0.5,
    "and neural approaches .": 1.0,
    "<s> other taggers and": 1.0,
    "other taggers and methods": 1.0,
    "taggers and methods some": 1.0,
    "and methods some current": 1.0,
    "methods some current major": 1.0,
    "some current major algorithms": 1.0,
    "current major algorithms for": 1.0,
    "major algorithms for part-of-speech": 1.0,
    "algorithms for part-of-speech tagging": 1.0,
    "for part-of-speech tagging include": 1.0,
    "part-of-speech tagging include the": 1.0,
    "tagging include the viterbi": 1.0,
    "include the viterbi algorithm": 1.0,
    "the viterbi algorithm ,": 0.25,
    "viterbi algorithm , brill": 1.0,
    "algorithm , brill tagger": 1.0,
    ", brill tagger ,": 1.0,
    "brill tagger , constraint": 1.0,
    "tagger , constraint grammar": 1.0,
    ", constraint grammar ,": 1.0,
    "constraint grammar , and": 1.0,
    "grammar , and the": 0.5,
    ", and the baum-welch": 0.1,
    "and the baum-welch algorithm": 1.0,
    "the baum-welch algorithm -lrb-": 1.0,
    "baum-welch algorithm -lrb- also": 1.0,
    "algorithm -lrb- also known": 1.0,
    "also known as the": 0.16666666666666666,
    "known as the forward-backward": 1.0,
    "as the forward-backward algorithm": 1.0,
    "the forward-backward algorithm -rrb-": 1.0,
    "forward-backward algorithm -rrb- .": 1.0,
    "<s> hidden markov model": 0.3333333333333333,
    "hidden markov model and": 0.16666666666666666,
    "markov model and visible": 1.0,
    "model and visible markov": 1.0,
    "and visible markov model": 1.0,
    "visible markov model taggers": 1.0,
    "markov model taggers can": 1.0,
    "model taggers can both": 1.0,
    "taggers can both be": 1.0,
    "can both be implemented": 1.0,
    "both be implemented using": 1.0,
    "be implemented using the": 1.0,
    "implemented using the viterbi": 1.0,
    "using the viterbi algorithm": 1.0,
    "the viterbi algorithm .": 0.25,
    "<s> the brill tagger": 1.0,
    "the brill tagger is": 1.0,
    "brill tagger is unusual": 1.0,
    "tagger is unusual in": 1.0,
    "is unusual in that": 1.0,
    "unusual in that it": 1.0,
    "in that it learns": 1.0,
    "that it learns a": 1.0,
    "it learns a set": 1.0,
    "learns a set of": 1.0,
    "a set of patterns": 0.07142857142857142,
    "set of patterns ,": 1.0,
    "of patterns , and": 1.0,
    "patterns , and then": 1.0,
    ", and then applies": 0.25,
    "and then applies those": 1.0,
    "then applies those patterns": 1.0,
    "applies those patterns rather": 1.0,
    "those patterns rather than": 1.0,
    "patterns rather than optimizing": 1.0,
    "rather than optimizing a": 1.0,
    "than optimizing a statistical": 1.0,
    "optimizing a statistical quantity": 1.0,
    "a statistical quantity .": 1.0,
    "<s> many machine learning": 1.0,
    "many machine learning methods": 1.0,
    "machine learning methods have": 1.0,
    "learning methods have also": 1.0,
    "methods have also been": 1.0,
    "have also been applied": 1.0,
    "also been applied to": 0.5,
    "been applied to the": 0.2,
    "applied to the problem": 0.5,
    "to the problem of": 1.0,
    "the problem of pos": 0.16666666666666666,
    "problem of pos tagging": 1.0,
    "of pos tagging .": 1.0,
    "<s> methods such as": 1.0,
    "methods such as svm": 1.0,
    "such as svm ,": 1.0,
    "as svm , maximum": 1.0,
    "svm , maximum entropy": 1.0,
    ", maximum entropy classifier": 0.5,
    "maximum entropy classifier ,": 1.0,
    "entropy classifier , perceptron": 1.0,
    "classifier , perceptron ,": 1.0,
    ", perceptron , and": 1.0,
    "perceptron , and nearest-neighbor": 1.0,
    ", and nearest-neighbor have": 1.0,
    "and nearest-neighbor have all": 1.0,
    "nearest-neighbor have all been": 1.0,
    "have all been tried": 1.0,
    "all been tried ,": 1.0,
    "been tried , and": 1.0,
    "tried , and most": 1.0,
    ", and most can": 1.0,
    "and most can achieve": 1.0,
    "most can achieve accuracy": 1.0,
    "can achieve accuracy above": 1.0,
    "achieve accuracy above 95": 1.0,
    "accuracy above 95 %": 1.0,
    "above 95 % .": 1.0,
    "<s> a direct comparison": 1.0,
    "a direct comparison of": 1.0,
    "direct comparison of several": 1.0,
    "comparison of several methods": 1.0,
    "of several methods is": 1.0,
    "several methods is reported": 1.0,
    "methods is reported -lrb-": 1.0,
    "is reported -lrb- with": 1.0,
    "reported -lrb- with references": 1.0,
    "-lrb- with references -rrb-": 1.0,
    "with references -rrb- at": 1.0,
    "references -rrb- at .": 1.0,
    "<s> this comparison uses": 1.0,
    "this comparison uses the": 1.0,
    "comparison uses the penn": 1.0,
    "uses the penn tag": 1.0,
    "the penn tag set": 1.0,
    "penn tag set on": 0.5,
    "tag set on some": 1.0,
    "set on some of": 1.0,
    "on some of the": 1.0,
    "some of the penn": 0.1,
    "of the penn treebank": 1.0,
    "the penn treebank data": 0.16666666666666666,
    "penn treebank data ,": 1.0,
    "treebank data , so": 1.0,
    "data , so the": 1.0,
    ", so the results": 0.25,
    "so the results are": 1.0,
    "the results are directly": 1.0,
    "results are directly comparable": 1.0,
    "are directly comparable .": 1.0,
    "<s> however , many": 0.03125,
    "however , many significant": 1.0,
    ", many significant taggers": 1.0,
    "many significant taggers are": 1.0,
    "significant taggers are not": 1.0,
    "taggers are not included": 1.0,
    "are not included -lrb-": 1.0,
    "not included -lrb- perhaps": 1.0,
    "included -lrb- perhaps because": 1.0,
    "-lrb- perhaps because of": 1.0,
    "perhaps because of the": 1.0,
    "because of the labor": 0.25,
    "of the labor involved": 1.0,
    "the labor involved in": 1.0,
    "labor involved in reconfiguring": 1.0,
    "involved in reconfiguring them": 1.0,
    "in reconfiguring them for": 1.0,
    "reconfiguring them for this": 1.0,
    "them for this particular": 1.0,
    "for this particular dataset": 1.0,
    "this particular dataset -rrb-": 1.0,
    "particular dataset -rrb- .": 1.0,
    "<s> thus , it": 0.18181818181818182,
    "thus , it should": 0.5,
    ", it should not": 1.0,
    "it should not be": 1.0,
    "should not be assumed": 1.0,
    "not be assumed that": 1.0,
    "be assumed that the": 1.0,
    "assumed that the results": 1.0,
    "that the results reported": 1.0,
    "the results reported there": 1.0,
    "results reported there are": 1.0,
    "reported there are the": 1.0,
    "there are the best": 1.0,
    "are the best that": 1.0,
    "the best that can": 0.5,
    "best that can be": 1.0,
    "that can be achieved": 0.2,
    "can be achieved with": 0.25,
    "be achieved with a": 1.0,
    "achieved with a given": 1.0,
    "with a given approach": 1.0,
    "a given approach ;": 0.5,
    "given approach ; nor": 1.0,
    "approach ; nor even": 1.0,
    "; nor even the": 1.0,
    "nor even the best": 1.0,
    "even the best that": 1.0,
    "the best that have": 0.5,
    "best that have been": 1.0,
    "that have been achieved": 0.3333333333333333,
    "have been achieved with": 0.5,
    "been achieved with a": 1.0,
    "a given approach .": 0.5,
    "<s> issues while there": 1.0,
    "issues while there is": 1.0,
    "while there is broad": 1.0,
    "there is broad agreement": 1.0,
    "is broad agreement about": 1.0,
    "broad agreement about basic": 1.0,
    "agreement about basic categories": 1.0,
    "about basic categories ,": 1.0,
    "basic categories , a": 1.0,
    "categories , a number": 1.0,
    "a number of edge": 0.045454545454545456,
    "number of edge cases": 1.0,
    "of edge cases make": 1.0,
    "edge cases make it": 1.0,
    "cases make it difficult": 1.0,
    "make it difficult to": 1.0,
    "it difficult to settle": 1.0,
    "difficult to settle on": 1.0,
    "to settle on a": 1.0,
    "settle on a single": 1.0,
    "on a single ``": 0.5,
    "a single `` correct": 1.0,
    "single `` correct ''": 1.0,
    "`` correct '' set": 1.0,
    "correct '' set of": 1.0,
    "'' set of tags": 1.0,
    "set of tags ,": 1.0,
    "of tags , even": 1.0,
    "tags , even in": 1.0,
    ", even in a": 1.0,
    "even in a single": 1.0,
    "in a single language": 1.0,
    "a single language such": 1.0,
    "single language such as": 1.0,
    "language such as english": 1.0,
    "such as english .": 0.3333333333333333,
    "for example , it": 0.02127659574468085,
    "example , it is": 1.0,
    ", it is hard": 0.07692307692307693,
    "it is hard to": 1.0,
    "is hard to say": 0.5,
    "hard to say whether": 1.0,
    "to say whether ``": 1.0,
    "say whether `` fire": 1.0,
    "whether `` fire ''": 1.0,
    "`` fire '' is": 1.0,
    "fire '' is functioning": 1.0,
    "'' is functioning as": 1.0,
    "is functioning as an": 1.0,
    "functioning as an adjective": 1.0,
    "as an adjective or": 0.6666666666666666,
    "adjective or a noun": 0.3333333333333333,
    "or a noun in": 0.5,
    "a noun in the": 1.0,
    "noun in the big": 1.0,
    "in the big green": 1.0,
    "the big green fire": 1.0,
    "big green fire truck": 1.0,
    "green fire truck a": 1.0,
    "fire truck a second": 1.0,
    "truck a second important": 1.0,
    "a second important example": 1.0,
    "second important example is": 1.0,
    "important example is the": 1.0,
    "example is the use\\/mention": 1.0,
    "is the use\\/mention distinction": 1.0,
    "the use\\/mention distinction ,": 1.0,
    "use\\/mention distinction , as": 1.0,
    "distinction , as in": 1.0,
    ", as in the": 1.0,
    "as in the following": 0.25,
    "in the following example": 0.3333333333333333,
    "the following example ,": 0.5,
    "following example , where": 1.0,
    "example , where ``": 1.0,
    ", where `` blue": 1.0,
    "where `` blue ''": 1.0,
    "`` blue '' is": 0.5,
    "blue '' is clearly": 1.0,
    "'' is clearly not": 1.0,
    "is clearly not functioning": 1.0,
    "clearly not functioning as": 1.0,
    "not functioning as an": 1.0,
    "as an adjective -lrb-": 0.3333333333333333,
    "an adjective -lrb- the": 1.0,
    "adjective -lrb- the brown": 1.0,
    "the brown corpus tag": 0.09090909090909091,
    "brown corpus tag set": 1.0,
    "corpus tag set appends": 1.0,
    "tag set appends the": 1.0,
    "set appends the suffix": 1.0,
    "appends the suffix ''": 1.0,
    "the suffix '' -": 1.0,
    "suffix '' - nc": 1.0,
    "'' - nc ''": 1.0,
    "- nc '' in": 1.0,
    "nc '' in such": 1.0,
    "'' in such cases": 1.0,
    "in such cases -rrb-": 0.5,
    "such cases -rrb- :": 1.0,
    "cases -rrb- : the": 1.0,
    "-rrb- : the word": 1.0,
    ": the word ``": 1.0,
    "the word `` blue": 1.0,
    "word `` blue ''": 1.0,
    "`` blue '' has": 0.5,
    "blue '' has 4": 1.0,
    "'' has 4 letters": 1.0,
    "has 4 letters .": 1.0,
    "<s> words in a": 1.0,
    "words in a language": 0.3333333333333333,
    "in a language other": 1.0,
    "a language other than": 1.0,
    "language other than that": 1.0,
    "other than that of": 1.0,
    "than that of the": 0.5,
    "that of the ``": 1.0,
    "of the `` main": 1.0,
    "the `` main ''": 1.0,
    "`` main '' text": 1.0,
    "main '' text ,": 1.0,
    "'' text , are": 1.0,
    "text , are commonly": 1.0,
    ", are commonly tagged": 1.0,
    "are commonly tagged as": 1.0,
    "commonly tagged as ``": 1.0,
    "tagged as `` foreign": 1.0,
    "as `` foreign ''": 1.0,
    "`` foreign '' ,": 1.0,
    "foreign '' , usually": 1.0,
    "'' , usually in": 1.0,
    ", usually in addition": 1.0,
    "usually in addition to": 1.0,
    "in addition to a": 0.3333333333333333,
    "addition to a tag": 1.0,
    "to a tag for": 1.0,
    "a tag for the": 1.0,
    "tag for the role": 1.0,
    "for the role the": 1.0,
    "the role the foreign": 1.0,
    "role the foreign word": 1.0,
    "the foreign word is": 1.0,
    "foreign word is actually": 1.0,
    "word is actually playing": 1.0,
    "is actually playing in": 1.0,
    "actually playing in context": 1.0,
    "playing in context .": 1.0,
    "<s> there are also": 0.2,
    "there are also many": 1.0,
    "are also many cases": 1.0,
    "also many cases where": 1.0,
    "many cases where pos": 1.0,
    "cases where pos categories": 1.0,
    "where pos categories and": 1.0,
    "pos categories and ``": 1.0,
    "categories and `` words": 1.0,
    "and `` words ''": 1.0,
    "`` words '' do": 1.0,
    "words '' do not": 1.0,
    "'' do not map": 1.0,
    "do not map one": 1.0,
    "not map one to": 1.0,
    "map one to one": 1.0,
    "one to one ,": 1.0,
    "to one , for": 1.0,
    "one , for example": 1.0,
    ", for example :": 0.1,
    "for example : david": 0.5,
    "example : david 's": 1.0,
    ": david 's gonna": 1.0,
    "david 's gonna do": 1.0,
    "'s gonna do n't": 1.0,
    "gonna do n't vice": 1.0,
    "do n't vice versa": 1.0,
    "n't vice versa first-cut": 1.0,
    "vice versa first-cut can": 1.0,
    "versa first-cut can not": 1.0,
    "first-cut can not pre": 1.0,
    "can not pre -": 1.0,
    "not pre - and": 1.0,
    "pre - and post-secondary": 1.0,
    "- and post-secondary look": 1.0,
    "and post-secondary look -lrb-": 1.0,
    "post-secondary look -lrb- a": 1.0,
    "look -lrb- a word": 1.0,
    "-lrb- a word -rrb-": 1.0,
    "a word -rrb- up": 1.0,
    "word -rrb- up in": 1.0,
    "-rrb- up in the": 1.0,
    "up in the last": 1.0,
    "in the last example": 0.3333333333333333,
    "the last example ,": 1.0,
    "last example , ``": 1.0,
    "example , `` look": 0.5,
    ", `` look ''": 1.0,
    "`` look '' and": 1.0,
    "look '' and ``": 1.0,
    "'' and `` up": 0.1111111111111111,
    "and `` up ''": 1.0,
    "`` up '' arguably": 1.0,
    "up '' arguably function": 1.0,
    "'' arguably function as": 1.0,
    "arguably function as a": 1.0,
    "function as a single": 1.0,
    "as a single verbal": 1.0,
    "a single verbal unit": 1.0,
    "single verbal unit ,": 1.0,
    "verbal unit , despite": 1.0,
    "unit , despite the": 1.0,
    ", despite the possibility": 1.0,
    "despite the possibility of": 1.0,
    "the possibility of other": 0.3333333333333333,
    "possibility of other words": 1.0,
    "of other words coming": 1.0,
    "other words coming between": 1.0,
    "words coming between them": 1.0,
    "coming between them .": 1.0,
    "<s> some tag sets": 1.0,
    "some tag sets -lrb-": 1.0,
    "tag sets -lrb- such": 1.0,
    "sets -lrb- such as": 1.0,
    "-lrb- such as penn": 0.125,
    "such as penn -rrb-": 1.0,
    "as penn -rrb- break": 1.0,
    "penn -rrb- break hyphenated": 1.0,
    "-rrb- break hyphenated words": 1.0,
    "break hyphenated words ,": 1.0,
    "hyphenated words , contractions": 1.0,
    "words , contractions ,": 1.0,
    ", contractions , and": 1.0,
    "contractions , and possessives": 1.0,
    ", and possessives into": 1.0,
    "and possessives into separate": 1.0,
    "possessives into separate tokens": 1.0,
    "into separate tokens ,": 1.0,
    "separate tokens , thus": 1.0,
    "tokens , thus avoiding": 1.0,
    ", thus avoiding some": 1.0,
    "thus avoiding some but": 1.0,
    "avoiding some but far": 1.0,
    "some but far from": 1.0,
    "but far from all": 1.0,
    "far from all such": 1.0,
    "from all such problems": 1.0,
    "all such problems .": 1.0,
    "<s> it is unclear": 0.05263157894736842,
    "it is unclear whether": 1.0,
    "is unclear whether it": 1.0,
    "unclear whether it is": 1.0,
    "whether it is best": 1.0,
    "it is best to": 1.0,
    "is best to treat": 1.0,
    "best to treat words": 1.0,
    "to treat words such": 1.0,
    "treat words such as": 1.0,
    "such as `` be": 0.125,
    "as `` be ''": 1.0,
    "`` be '' ,": 0.5,
    "be '' , ``": 1.0,
    "'' , `` have": 0.09090909090909091,
    ", `` have ''": 1.0,
    "`` have '' ,": 1.0,
    "have '' , and": 1.0,
    ", and `` do": 0.2,
    "and `` do ''": 1.0,
    "`` do '' as": 1.0,
    "do '' as categories": 1.0,
    "'' as categories in": 1.0,
    "as categories in their": 1.0,
    "categories in their own": 1.0,
    "in their own right": 1.0,
    "their own right -lrb-": 1.0,
    "own right -lrb- as": 1.0,
    "right -lrb- as in": 1.0,
    "as in the brown": 0.25,
    "corpus -rrb- , or": 0.3333333333333333,
    "-rrb- , or as": 0.3333333333333333,
    ", or as simply": 1.0,
    "or as simply verbs": 1.0,
    "as simply verbs -lrb-": 1.0,
    "simply verbs -lrb- as": 1.0,
    "verbs -lrb- as in": 1.0,
    "as in the lob": 0.25,
    "in the lob corpus": 1.0,
    "the lob corpus and": 1.0,
    "lob corpus and the": 1.0,
    "corpus and the penn": 1.0,
    "and the penn treebank": 1.0,
    "the penn treebank -rrb-": 0.16666666666666666,
    "penn treebank -rrb- .": 1.0,
    "<s> `` be ''": 1.0,
    "`` be '' has": 0.5,
    "be '' has more": 1.0,
    "'' has more forms": 1.0,
    "has more forms than": 1.0,
    "more forms than other": 1.0,
    "forms than other english": 1.0,
    "than other english verbs": 1.0,
    "other english verbs ,": 1.0,
    "english verbs , and": 1.0,
    "verbs , and occurs": 1.0,
    ", and occurs in": 1.0,
    "and occurs in quite": 1.0,
    "occurs in quite different": 1.0,
    "in quite different grammatical": 1.0,
    "quite different grammatical contexts": 1.0,
    "different grammatical contexts ,": 1.0,
    "grammatical contexts , complicating": 1.0,
    "contexts , complicating the": 1.0,
    ", complicating the issue": 1.0,
    "complicating the issue .": 1.0,
    "<s> the most popular": 0.3333333333333333,
    "the most popular ``": 0.3333333333333333,
    "most popular `` tag": 1.0,
    "popular `` tag set": 1.0,
    "`` tag set ''": 1.0,
    "tag set '' for": 1.0,
    "set '' for pos": 1.0,
    "'' for pos tagging": 1.0,
    "for pos tagging for": 1.0,
    "pos tagging for american": 1.0,
    "tagging for american english": 1.0,
    "for american english is": 1.0,
    "american english is probably": 1.0,
    "english is probably the": 1.0,
    "is probably the penn": 1.0,
    "probably the penn tag": 1.0,
    "penn tag set ,": 0.5,
    "tag set , developed": 0.5,
    "set , developed in": 1.0,
    ", developed in the": 1.0,
    "developed in the penn": 0.16666666666666666,
    "in the penn treebank": 1.0,
    "the penn treebank project": 0.3333333333333333,
    "penn treebank project .": 0.5,
    "<s> it is largely": 0.05263157894736842,
    "it is largely similar": 1.0,
    "is largely similar to": 1.0,
    "largely similar to the": 1.0,
    "similar to the earlier": 0.2,
    "to the earlier brown": 1.0,
    "the earlier brown corpus": 1.0,
    "earlier brown corpus and": 1.0,
    "brown corpus and lob": 1.0,
    "corpus and lob corpus": 1.0,
    "and lob corpus tag": 1.0,
    "lob corpus tag sets": 1.0,
    "corpus tag sets ,": 1.0,
    "tag sets , though": 1.0,
    "sets , though much": 1.0,
    ", though much smaller": 1.0,
    "though much smaller .": 1.0,
    "in europe , tag": 0.5,
    "europe , tag sets": 1.0,
    ", tag sets from": 1.0,
    "tag sets from the": 1.0,
    "sets from the eagles": 1.0,
    "from the eagles guidelines": 1.0,
    "the eagles guidelines see": 1.0,
    "eagles guidelines see wide": 1.0,
    "guidelines see wide use": 1.0,
    "see wide use ,": 1.0,
    "wide use , and": 1.0,
    "use , and include": 0.3333333333333333,
    ", and include versions": 1.0,
    "and include versions for": 1.0,
    "include versions for multiple": 1.0,
    "versions for multiple languages": 1.0,
    "for multiple languages .": 1.0,
    "<s> pos tagging work": 1.0,
    "pos tagging work has": 1.0,
    "tagging work has been": 1.0,
    "been done in a": 0.5,
    "done in a variety": 1.0,
    "a variety of languages": 0.14285714285714285,
    "variety of languages ,": 1.0,
    "of languages , and": 1.0,
    "languages , and the": 0.5,
    ", and the set": 0.1,
    "and the set of": 1.0,
    "the set of pos": 0.3333333333333333,
    "set of pos tags": 1.0,
    "of pos tags used": 1.0,
    "pos tags used varies": 0.5,
    "tags used varies greatly": 1.0,
    "used varies greatly with": 1.0,
    "varies greatly with language": 1.0,
    "greatly with language .": 1.0,
    "<s> tags usually are": 1.0,
    "tags usually are designed": 1.0,
    "usually are designed to": 1.0,
    "are designed to include": 1.0,
    "designed to include overt": 1.0,
    "to include overt morphological": 1.0,
    "include overt morphological distinctions": 1.0,
    "overt morphological distinctions -lrb-": 1.0,
    "morphological distinctions -lrb- this": 1.0,
    "distinctions -lrb- this makes": 1.0,
    "-lrb- this makes the": 1.0,
    "this makes the tag": 1.0,
    "makes the tag sets": 1.0,
    "the tag sets for": 1.0,
    "tag sets for heavily": 1.0,
    "sets for heavily inflected": 1.0,
    "for heavily inflected languages": 1.0,
    "heavily inflected languages such": 1.0,
    "inflected languages such as": 1.0,
    "languages such as greek": 0.25,
    "such as greek and": 1.0,
    "as greek and latin": 1.0,
    "greek and latin very": 1.0,
    "and latin very large": 1.0,
    "latin very large ;": 1.0,
    "very large ; and": 1.0,
    "large ; and makes": 1.0,
    "; and makes tagging": 1.0,
    "and makes tagging words": 1.0,
    "makes tagging words in": 1.0,
    "tagging words in agglutinative": 1.0,
    "words in agglutinative languages": 1.0,
    "in agglutinative languages such": 1.0,
    "agglutinative languages such an": 1.0,
    "languages such an inuit": 1.0,
    "such an inuit virtually": 1.0,
    "an inuit virtually impossible": 1.0,
    "inuit virtually impossible .": 1.0,
    "<s> however , petrov": 0.03125,
    "however , petrov ,": 1.0,
    ", petrov , d.": 1.0,
    "petrov , d. das": 1.0,
    ", d. das ,": 1.0,
    "d. das , and": 1.0,
    "das , and r.": 1.0,
    ", and r. mcdonald": 1.0,
    "and r. mcdonald -lrb-": 1.0,
    "r. mcdonald -lrb- ``": 1.0,
    "mcdonald -lrb- `` a": 1.0,
    "-lrb- `` a universal": 1.0,
    "`` a universal part-of-speech": 1.0,
    "a universal part-of-speech tagset": 1.0,
    "universal part-of-speech tagset ''": 1.0,
    "part-of-speech tagset '' http:\\/\\/arxiv.org\\/abs\\/1104.2086": 1.0,
    "tagset '' http:\\/\\/arxiv.org\\/abs\\/1104.2086 -rrb-": 1.0,
    "'' http:\\/\\/arxiv.org\\/abs\\/1104.2086 -rrb- have": 1.0,
    "http:\\/\\/arxiv.org\\/abs\\/1104.2086 -rrb- have proposed": 1.0,
    "-rrb- have proposed a": 1.0,
    "have proposed a ``": 1.0,
    "proposed a `` universal": 1.0,
    "a `` universal ''": 0.5,
    "`` universal '' tag": 1.0,
    "universal '' tag set": 1.0,
    "'' tag set ,": 1.0,
    "tag set , with": 0.5,
    "set , with 12": 1.0,
    ", with 12 categories": 1.0,
    "with 12 categories -lrb-": 1.0,
    "12 categories -lrb- for": 1.0,
    "categories -lrb- for example": 1.0,
    "for example , no": 0.02127659574468085,
    "example , no subtypes": 1.0,
    ", no subtypes of": 1.0,
    "no subtypes of nouns": 1.0,
    "subtypes of nouns ,": 1.0,
    "of nouns , verbs": 1.0,
    ", verbs , punctuation": 0.5,
    "verbs , punctuation ,": 1.0,
    ", punctuation , etc.": 1.0,
    "punctuation , etc. ;": 1.0,
    ", etc. ; no": 1.0,
    "etc. ; no distinction": 1.0,
    "; no distinction of": 1.0,
    "no distinction of ``": 1.0,
    "distinction of `` to": 1.0,
    "of `` to ''": 1.0,
    "`` to '' as": 1.0,
    "to '' as an": 1.0,
    "'' as an infinitive": 1.0,
    "as an infinitive marker": 1.0,
    "an infinitive marker vs.": 1.0,
    "infinitive marker vs. preposition": 1.0,
    "marker vs. preposition ,": 1.0,
    "vs. preposition , etc.": 1.0,
    "preposition , etc. -rrb-": 1.0,
    "<s> whether a very": 1.0,
    "whether a very small": 1.0,
    "a very small set": 1.0,
    "very small set of": 1.0,
    "small set of very": 1.0,
    "set of very broad": 1.0,
    "of very broad tags": 1.0,
    "very broad tags ,": 1.0,
    "broad tags , or": 1.0,
    "tags , or a": 1.0,
    ", or a much": 0.5,
    "or a much larger": 1.0,
    "a much larger set": 0.5,
    "much larger set of": 1.0,
    "larger set of more": 1.0,
    "set of more precise": 0.5,
    "of more precise ones": 1.0,
    "more precise ones ,": 1.0,
    "precise ones , is": 1.0,
    "ones , is preferable": 1.0,
    ", is preferable ,": 1.0,
    "is preferable , depends": 1.0,
    "preferable , depends on": 1.0,
    ", depends on the": 1.0,
    "depends on the purpose": 0.2,
    "on the purpose at": 1.0,
    "the purpose at hand": 1.0,
    "purpose at hand .": 1.0,
    "<s> automatic tagging is": 1.0,
    "automatic tagging is easier": 1.0,
    "tagging is easier on": 1.0,
    "is easier on smaller": 1.0,
    "easier on smaller tag-sets": 1.0,
    "on smaller tag-sets .": 1.0,
    "<s> a different issue": 0.5,
    "a different issue is": 1.0,
    "different issue is that": 1.0,
    "issue is that some": 1.0,
    "is that some cases": 1.0,
    "that some cases are": 1.0,
    "some cases are in": 1.0,
    "cases are in fact": 1.0,
    "are in fact ambiguous": 1.0,
    "in fact ambiguous .": 1.0,
    "<s> beatrice santorini gives": 1.0,
    "beatrice santorini gives examples": 1.0,
    "santorini gives examples in": 1.0,
    "gives examples in ``": 1.0,
    "examples in `` part-of-speech": 1.0,
    "in `` part-of-speech tagging": 1.0,
    "`` part-of-speech tagging guidelines": 1.0,
    "part-of-speech tagging guidelines for": 1.0,
    "tagging guidelines for the": 1.0,
    "guidelines for the penn": 1.0,
    "for the penn treebank": 1.0,
    "penn treebank project ,": 0.5,
    "treebank project , ''": 1.0,
    "project , '' -lrb-": 1.0,
    ", '' -lrb- 3rd": 1.0,
    "'' -lrb- 3rd rev": 1.0,
    "-lrb- 3rd rev ,": 1.0,
    "3rd rev , june": 1.0,
    "rev , june 1990": 1.0,
    ", june 1990 -rrb-": 1.0,
    "june 1990 -rrb- ,": 1.0,
    "1990 -rrb- , including": 1.0,
    "-rrb- , including the": 1.0,
    ", including the following": 1.0,
    "including the following -lrb-": 1.0,
    "the following -lrb- p.": 1.0,
    "following -lrb- p. 32": 1.0,
    "-lrb- p. 32 -rrb-": 1.0,
    "p. 32 -rrb- case": 1.0,
    "32 -rrb- case in": 1.0,
    "-rrb- case in which": 1.0,
    "case in which entertaining": 1.0,
    "in which entertaining can": 1.0,
    "which entertaining can function": 1.0,
    "entertaining can function either": 1.0,
    "can function either as": 1.0,
    "function either as an": 1.0,
    "either as an adjective": 0.5,
    "adjective or a verb": 0.3333333333333333,
    "or a verb ,": 1.0,
    "verb , and there": 0.3333333333333333,
    ", and there is": 0.3333333333333333,
    "and there is no": 1.0,
    "there is no evident": 1.0,
    "is no evident way": 1.0,
    "no evident way to": 1.0,
    "evident way to decide": 1.0,
    "way to decide :": 1.0,
    "to decide : the": 1.0,
    "decide : the duchess": 1.0,
    ": the duchess was": 1.0,
    "the duchess was entertaining": 1.0,
    "duchess was entertaining last": 1.0,
    "was entertaining last night": 1.0,
    "entertaining last night .": 1.0,
    "<s> in computer science": 1.0,
    "in computer science and": 1.0,
    "computer science and linguistics": 1.0,
    "science and linguistics ,": 1.0,
    "and linguistics , parsing": 1.0,
    "linguistics , parsing ,": 1.0,
    ", parsing , or": 1.0,
    "parsing , or ,": 1.0,
    ", or , more": 1.0,
    "or , more formally": 1.0,
    ", more formally ,": 1.0,
    "more formally , syntactic": 1.0,
    "formally , syntactic analysis": 1.0,
    ", syntactic analysis ,": 1.0,
    "syntactic analysis , is": 0.5,
    "analysis , is the": 1.0,
    "the process of analyzing": 0.09090909090909091,
    "process of analyzing a": 1.0,
    "of analyzing a text": 1.0,
    "analyzing a text ,": 1.0,
    "a text , made": 0.25,
    "text , made of": 0.5,
    ", made of a": 1.0,
    "made of a sequence": 1.0,
    "of a sequence of": 1.0,
    "a sequence of tokens": 0.16666666666666666,
    "sequence of tokens -lrb-": 1.0,
    "of tokens -lrb- for": 1.0,
    "tokens -lrb- for example": 1.0,
    "for example , words": 0.02127659574468085,
    "example , words -rrb-": 1.0,
    ", words -rrb- ,": 1.0,
    "words -rrb- , to": 1.0,
    "-rrb- , to determine": 1.0,
    ", to determine its": 0.5,
    "to determine its grammatical": 1.0,
    "determine its grammatical structure": 1.0,
    "its grammatical structure with": 1.0,
    "grammatical structure with respect": 1.0,
    "structure with respect to": 1.0,
    "respect to a given": 0.5,
    "to a given -lrb-": 0.3333333333333333,
    "a given -lrb- more": 1.0,
    "given -lrb- more or": 1.0,
    "-lrb- more or less": 1.0,
    "more or less -rrb-": 0.3333333333333333,
    "or less -rrb- formal": 1.0,
    "less -rrb- formal grammar": 1.0,
    "-rrb- formal grammar .": 1.0,
    "<s> parsing can also": 1.0,
    "parsing can also be": 1.0,
    "can also be used": 0.5,
    "also be used as": 0.5,
    "be used as a": 0.5,
    "used as a linguistic": 0.5,
    "as a linguistic term": 1.0,
    "a linguistic term ,": 1.0,
    "linguistic term , for": 1.0,
    "term , for instance": 1.0,
    ", for instance when": 0.25,
    "for instance when discussing": 1.0,
    "instance when discussing how": 1.0,
    "when discussing how phrases": 1.0,
    "discussing how phrases are": 1.0,
    "how phrases are divided": 1.0,
    "phrases are divided up": 1.0,
    "are divided up in": 1.0,
    "divided up in garden": 1.0,
    "up in garden path": 1.0,
    "in garden path sentences": 1.0,
    "garden path sentences .": 1.0,
    "<s> parsing is also": 0.5,
    "parsing is also an": 1.0,
    "is also an earlier": 1.0,
    "also an earlier term": 1.0,
    "an earlier term for": 1.0,
    "earlier term for the": 1.0,
    "term for the diagramming": 1.0,
    "for the diagramming of": 1.0,
    "the diagramming of sentences": 0.5,
    "diagramming of sentences of": 1.0,
    "of sentences of natural": 1.0,
    "sentences of natural languages": 1.0,
    "of natural languages ,": 0.2,
    "natural languages , and": 0.5,
    "languages , and is": 0.5,
    ", and is still": 0.3333333333333333,
    "and is still used": 1.0,
    "is still used for": 1.0,
    "still used for the": 1.0,
    "used for the diagramming": 1.0,
    "the diagramming of inflected": 0.5,
    "diagramming of inflected languages": 1.0,
    "of inflected languages ,": 1.0,
    "inflected languages , such": 1.0,
    "languages , such as": 1.0,
    "such as the romance": 0.07142857142857142,
    "as the romance languages": 1.0,
    "the romance languages or": 1.0,
    "romance languages or latin": 1.0,
    "languages or latin .": 1.0,
    "<s> the term parsing": 0.25,
    "the term parsing comes": 1.0,
    "term parsing comes from": 1.0,
    "parsing comes from latin": 1.0,
    "comes from latin pars": 1.0,
    "from latin pars -lrb-": 1.0,
    "latin pars -lrb- \u014dr\u0101ti\u014dnis": 1.0,
    "pars -lrb- \u014dr\u0101ti\u014dnis -rrb-": 1.0,
    "-lrb- \u014dr\u0101ti\u014dnis -rrb- ,": 1.0,
    "\u014dr\u0101ti\u014dnis -rrb- , meaning": 1.0,
    "-rrb- , meaning part": 1.0,
    ", meaning part -lrb-": 1.0,
    "meaning part -lrb- of": 1.0,
    "part -lrb- of speech": 1.0,
    "-lrb- of speech -rrb-": 1.0,
    "<s> parsing is a": 0.5,
    "parsing is a common": 1.0,
    "is a common term": 0.5,
    "a common term used": 1.0,
    "common term used in": 1.0,
    "term used in psycholinguistics": 1.0,
    "used in psycholinguistics when": 1.0,
    "in psycholinguistics when describing": 1.0,
    "psycholinguistics when describing language": 1.0,
    "when describing language comprehension": 1.0,
    "describing language comprehension .": 1.0,
    "this context , parsing": 0.5,
    "context , parsing refers": 1.0,
    ", parsing refers to": 1.0,
    "parsing refers to the": 1.0,
    "refers to the way": 0.3333333333333333,
    "to the way that": 1.0,
    "the way that human": 1.0,
    "way that human beings": 1.0,
    "that human beings ,": 1.0,
    "human beings , rather": 1.0,
    "beings , rather than": 1.0,
    ", rather than computers": 0.5,
    "rather than computers ,": 1.0,
    "than computers , analyze": 1.0,
    "computers , analyze a": 1.0,
    ", analyze a sentence": 1.0,
    "analyze a sentence or": 1.0,
    "a sentence or phrase": 0.5,
    "sentence or phrase -lrb-": 1.0,
    "or phrase -lrb- in": 1.0,
    "phrase -lrb- in spoken": 1.0,
    "-lrb- in spoken language": 1.0,
    "in spoken language or": 1.0,
    "spoken language or text": 1.0,
    "language or text -rrb-": 1.0,
    "or text -rrb- ``": 1.0,
    "text -rrb- `` in": 1.0,
    "-rrb- `` in terms": 1.0,
    "`` in terms of": 1.0,
    "in terms of grammatical": 0.14285714285714285,
    "terms of grammatical constituents": 1.0,
    "of grammatical constituents ,": 1.0,
    "grammatical constituents , identifying": 1.0,
    "constituents , identifying the": 1.0,
    ", identifying the parts": 0.5,
    "identifying the parts of": 1.0,
    "the parts of speech": 1.0,
    "of speech , syntactic": 0.16666666666666666,
    "speech , syntactic relations": 1.0,
    ", syntactic relations ,": 1.0,
    "syntactic relations , etc.": 1.0,
    "relations , etc. ''": 1.0,
    ", etc. '' this": 1.0,
    "etc. '' this term": 1.0,
    "'' this term is": 1.0,
    "this term is especially": 1.0,
    "term is especially common": 1.0,
    "is especially common when": 1.0,
    "especially common when discussing": 1.0,
    "common when discussing what": 1.0,
    "when discussing what linguistic": 1.0,
    "discussing what linguistic cues": 1.0,
    "what linguistic cues help": 1.0,
    "linguistic cues help speakers": 1.0,
    "cues help speakers to": 1.0,
    "help speakers to parse": 1.0,
    "speakers to parse garden-path": 1.0,
    "to parse garden-path sentences": 1.0,
    "parse garden-path sentences .": 1.0,
    "<s> the parser often": 1.0,
    "the parser often uses": 1.0,
    "parser often uses a": 1.0,
    "often uses a separate": 1.0,
    "uses a separate lexical": 1.0,
    "a separate lexical analyser": 1.0,
    "separate lexical analyser to": 1.0,
    "lexical analyser to create": 1.0,
    "analyser to create tokens": 1.0,
    "to create tokens from": 1.0,
    "create tokens from the": 1.0,
    "tokens from the sequence": 1.0,
    "from the sequence of": 1.0,
    "the sequence of input": 1.0,
    "sequence of input characters": 1.0,
    "of input characters .": 1.0,
    "<s> parsers may be": 1.0,
    "parsers may be programmed": 1.0,
    "may be programmed by": 1.0,
    "be programmed by hand": 1.0,
    "programmed by hand or": 1.0,
    "by hand or may": 0.5,
    "hand or may be": 1.0,
    "or may be -lrb-": 1.0,
    "may be -lrb- semi": 1.0,
    "be -lrb- semi -": 1.0,
    "-lrb- semi - -rrb-": 1.0,
    "semi - -rrb- automatically": 1.0,
    "- -rrb- automatically generated": 1.0,
    "-rrb- automatically generated -lrb-": 1.0,
    "automatically generated -lrb- in": 1.0,
    "generated -lrb- in some": 1.0,
    "-lrb- in some programming": 1.0,
    "in some programming languages": 1.0,
    "some programming languages -rrb-": 1.0,
    "programming languages -rrb- by": 1.0,
    "languages -rrb- by a": 1.0,
    "-rrb- by a tool": 1.0,
    "by a tool .": 1.0,
    "<s> human languages see": 1.0,
    "human languages see also": 1.0,
    "languages see also :": 1.0,
    "see also : category": 0.5,
    "also : category :": 1.0,
    ": category : natural": 1.0,
    "category : natural language": 1.0,
    ": natural language parsing": 1.0,
    "natural language parsing in": 0.5,
    "language parsing in some": 1.0,
    "parsing in some machine": 1.0,
    "in some machine translation": 1.0,
    "some machine translation and": 1.0,
    "machine translation and natural": 0.5,
    "translation and natural language": 1.0,
    "and natural language processing": 0.8,
    "language processing systems ,": 0.3333333333333333,
    "processing systems , human": 1.0,
    "systems , human languages": 1.0,
    ", human languages are": 1.0,
    "human languages are parsed": 1.0,
    "languages are parsed by": 1.0,
    "are parsed by computer": 1.0,
    "parsed by computer programs": 1.0,
    "by computer programs .": 1.0,
    "<s> human sentences are": 1.0,
    "human sentences are not": 1.0,
    "sentences are not easily": 1.0,
    "are not easily parsed": 1.0,
    "not easily parsed by": 1.0,
    "easily parsed by programs": 1.0,
    "parsed by programs ,": 1.0,
    "by programs , as": 1.0,
    "programs , as there": 1.0,
    ", as there is": 1.0,
    "as there is substantial": 1.0,
    "there is substantial ambiguity": 1.0,
    "is substantial ambiguity in": 1.0,
    "substantial ambiguity in the": 1.0,
    "ambiguity in the structure": 1.0,
    "in the structure of": 1.0,
    "the structure of human": 0.3333333333333333,
    "structure of human language": 1.0,
    "of human language ,": 1.0,
    "human language , whose": 1.0,
    "language , whose usage": 1.0,
    ", whose usage is": 1.0,
    "whose usage is to": 1.0,
    "usage is to convey": 1.0,
    "is to convey meaning": 1.0,
    "to convey meaning -lrb-": 1.0,
    "convey meaning -lrb- or": 1.0,
    "meaning -lrb- or semantics": 1.0,
    "-lrb- or semantics -rrb-": 1.0,
    "or semantics -rrb- amongst": 1.0,
    "semantics -rrb- amongst a": 1.0,
    "-rrb- amongst a potentially": 1.0,
    "amongst a potentially unlimited": 1.0,
    "a potentially unlimited range": 1.0,
    "potentially unlimited range of": 1.0,
    "unlimited range of possibilities": 1.0,
    "range of possibilities but": 1.0,
    "of possibilities but only": 1.0,
    "possibilities but only some": 1.0,
    "but only some of": 1.0,
    "of which are germane": 0.25,
    "which are germane to": 1.0,
    "are germane to the": 1.0,
    "germane to the particular": 1.0,
    "to the particular case": 1.0,
    "the particular case .": 1.0,
    "<s> so an utterance": 1.0,
    "so an utterance ``": 1.0,
    "an utterance `` man": 1.0,
    "utterance `` man bites": 1.0,
    "`` man bites dog": 1.0,
    "man bites dog ''": 1.0,
    "bites dog '' versus": 1.0,
    "dog '' versus ``": 1.0,
    "'' versus `` dog": 1.0,
    "versus `` dog bites": 1.0,
    "`` dog bites man": 1.0,
    "dog bites man ''": 1.0,
    "bites man '' is": 1.0,
    "man '' is definite": 1.0,
    "'' is definite on": 1.0,
    "is definite on one": 1.0,
    "definite on one detail": 1.0,
    "on one detail but": 1.0,
    "one detail but in": 1.0,
    "detail but in another": 1.0,
    "but in another language": 1.0,
    "in another language might": 0.5,
    "another language might appear": 1.0,
    "language might appear as": 1.0,
    "might appear as ``": 1.0,
    "appear as `` man": 1.0,
    "as `` man dog": 1.0,
    "`` man dog bites": 1.0,
    "man dog bites ''": 1.0,
    "dog bites '' with": 1.0,
    "bites '' with a": 1.0,
    "'' with a reliance": 1.0,
    "with a reliance on": 1.0,
    "a reliance on the": 1.0,
    "reliance on the larger": 1.0,
    "on the larger context": 1.0,
    "the larger context to": 1.0,
    "larger context to distinguish": 1.0,
    "context to distinguish between": 1.0,
    "to distinguish between those": 0.5,
    "distinguish between those two": 1.0,
    "between those two possibilities": 1.0,
    "those two possibilities ,": 1.0,
    "two possibilities , if": 1.0,
    "possibilities , if indeed": 1.0,
    ", if indeed that": 1.0,
    "if indeed that difference": 1.0,
    "indeed that difference was": 1.0,
    "that difference was of": 1.0,
    "difference was of concern": 1.0,
    "was of concern .": 1.0,
    "<s> it is difficult": 0.05263157894736842,
    "it is difficult to": 1.0,
    "is difficult to prepare": 0.3333333333333333,
    "difficult to prepare formal": 1.0,
    "to prepare formal rules": 1.0,
    "prepare formal rules to": 1.0,
    "formal rules to describe": 1.0,
    "rules to describe informal": 1.0,
    "to describe informal behavior": 1.0,
    "describe informal behavior even": 1.0,
    "informal behavior even though": 1.0,
    "behavior even though it": 1.0,
    "even though it is": 1.0,
    "though it is clear": 1.0,
    "it is clear that": 1.0,
    "is clear that some": 1.0,
    "clear that some rules": 1.0,
    "that some rules are": 1.0,
    "some rules are being": 1.0,
    "rules are being followed": 1.0,
    "are being followed .": 1.0,
    "<s> in order to": 1.0,
    "in order to parse": 0.125,
    "order to parse natural": 1.0,
    "to parse natural language": 1.0,
    "parse natural language data": 1.0,
    "natural language data ,": 1.0,
    "language data , researchers": 1.0,
    "data , researchers must": 1.0,
    ", researchers must first": 1.0,
    "researchers must first agree": 1.0,
    "must first agree on": 1.0,
    "first agree on the": 1.0,
    "agree on the grammar": 1.0,
    "on the grammar to": 0.5,
    "the grammar to be": 1.0,
    "grammar to be used": 1.0,
    "to be used .": 0.5,
    "<s> the choice of": 1.0,
    "the choice of syntax": 0.5,
    "choice of syntax is": 1.0,
    "of syntax is affected": 1.0,
    "syntax is affected by": 1.0,
    "is affected by both": 1.0,
    "affected by both linguistic": 1.0,
    "by both linguistic and": 1.0,
    "both linguistic and computational": 1.0,
    "linguistic and computational concerns": 1.0,
    "and computational concerns ;": 1.0,
    "computational concerns ; for": 1.0,
    "concerns ; for instance": 1.0,
    "; for instance some": 1.0,
    "for instance some parsing": 1.0,
    "instance some parsing systems": 1.0,
    "some parsing systems use": 1.0,
    "parsing systems use lexical": 1.0,
    "systems use lexical functional": 0.5,
    "use lexical functional grammar": 1.0,
    "lexical functional grammar ,": 1.0,
    "functional grammar , but": 1.0,
    "grammar , but in": 1.0,
    ", but in general": 1.0,
    "but in general ,": 1.0,
    "in general , parsing": 0.16666666666666666,
    "general , parsing for": 1.0,
    ", parsing for grammars": 1.0,
    "parsing for grammars of": 1.0,
    "for grammars of this": 1.0,
    "grammars of this type": 1.0,
    "of this type is": 1.0,
    "this type is known": 1.0,
    "type is known to": 1.0,
    "known to be np-complete": 0.5,
    "to be np-complete .": 1.0,
    "<s> head-driven phrase structure": 1.0,
    "head-driven phrase structure grammar": 1.0,
    "phrase structure grammar is": 1.0,
    "structure grammar is another": 1.0,
    "grammar is another linguistic": 1.0,
    "is another linguistic formalism": 1.0,
    "another linguistic formalism which": 1.0,
    "linguistic formalism which has": 1.0,
    "formalism which has been": 1.0,
    "which has been popular": 0.3333333333333333,
    "has been popular in": 1.0,
    "been popular in the": 1.0,
    "popular in the parsing": 1.0,
    "in the parsing community": 1.0,
    "the parsing community ,": 1.0,
    "parsing community , but": 1.0,
    "community , but other": 1.0,
    ", but other research": 1.0,
    "but other research efforts": 1.0,
    "other research efforts have": 1.0,
    "research efforts have focused": 1.0,
    "efforts have focused on": 1.0,
    "have focused on less": 0.5,
    "focused on less complex": 1.0,
    "on less complex formalisms": 1.0,
    "less complex formalisms such": 1.0,
    "complex formalisms such as": 1.0,
    "formalisms such as the": 1.0,
    "such as the one": 0.07142857142857142,
    "as the one used": 1.0,
    "the one used in": 1.0,
    "one used in the": 1.0,
    "used in the penn": 0.16666666666666666,
    "<s> shallow parsing aims": 1.0,
    "shallow parsing aims to": 1.0,
    "parsing aims to find": 1.0,
    "aims to find only": 1.0,
    "to find only the": 1.0,
    "find only the boundaries": 1.0,
    "only the boundaries of": 1.0,
    "the boundaries of major": 1.0,
    "boundaries of major constituents": 1.0,
    "of major constituents such": 1.0,
    "major constituents such as": 1.0,
    "constituents such as noun": 1.0,
    "such as noun phrases": 1.0,
    "as noun phrases .": 1.0,
    "<s> another popular strategy": 1.0,
    "another popular strategy for": 1.0,
    "popular strategy for avoiding": 1.0,
    "strategy for avoiding linguistic": 1.0,
    "for avoiding linguistic controversy": 1.0,
    "avoiding linguistic controversy is": 1.0,
    "linguistic controversy is dependency": 1.0,
    "controversy is dependency grammar": 1.0,
    "is dependency grammar parsing": 1.0,
    "dependency grammar parsing .": 1.0,
    "<s> most modern parsers": 1.0,
    "most modern parsers are": 1.0,
    "modern parsers are at": 1.0,
    "parsers are at least": 1.0,
    "are at least partly": 1.0,
    "at least partly statistical": 1.0,
    "least partly statistical ;": 1.0,
    "partly statistical ; that": 1.0,
    "statistical ; that is": 1.0,
    "; that is ,": 1.0,
    "is , they rely": 0.3333333333333333,
    ", they rely on": 1.0,
    "they rely on a": 1.0,
    "rely on a corpus": 1.0,
    "on a corpus of": 1.0,
    "of training data which": 0.3333333333333333,
    "training data which has": 1.0,
    "data which has already": 1.0,
    "which has already been": 1.0,
    "has already been annotated": 1.0,
    "already been annotated -lrb-": 1.0,
    "been annotated -lrb- parsed": 1.0,
    "annotated -lrb- parsed by": 1.0,
    "-lrb- parsed by hand": 1.0,
    "parsed by hand -rrb-": 1.0,
    "by hand -rrb- .": 1.0,
    "<s> this approach allows": 0.5,
    "this approach allows the": 1.0,
    "approach allows the system": 1.0,
    "allows the system to": 1.0,
    "the system to gather": 0.5,
    "system to gather information": 1.0,
    "to gather information about": 1.0,
    "gather information about the": 1.0,
    "information about the frequency": 1.0,
    "about the frequency with": 1.0,
    "the frequency with which": 1.0,
    "frequency with which various": 1.0,
    "with which various constructions": 1.0,
    "which various constructions occur": 1.0,
    "various constructions occur in": 1.0,
    "constructions occur in specific": 1.0,
    "occur in specific contexts": 1.0,
    "in specific contexts .": 1.0,
    "<s> -lrb- see machine": 0.3333333333333333,
    "-lrb- see machine learning": 1.0,
    "see machine learning .": 1.0,
    "machine learning . -rrb-": 1.0,
    "<s> approaches which have": 1.0,
    "approaches which have been": 1.0,
    "which have been used": 1.0,
    "have been used include": 0.3333333333333333,
    "been used include straightforward": 1.0,
    "used include straightforward pcfgs": 1.0,
    "include straightforward pcfgs -lrb-": 1.0,
    "straightforward pcfgs -lrb- probabilistic": 1.0,
    "pcfgs -lrb- probabilistic context-free": 1.0,
    "-lrb- probabilistic context-free grammars": 1.0,
    "probabilistic context-free grammars -rrb-": 1.0,
    "context-free grammars -rrb- ,": 1.0,
    "grammars -rrb- , maximum": 1.0,
    "-rrb- , maximum entropy": 1.0,
    ", maximum entropy ,": 0.5,
    "maximum entropy , and": 1.0,
    "entropy , and neural": 1.0,
    ", and neural nets": 0.5,
    "and neural nets .": 1.0,
    "<s> most of the": 1.0,
    "most of the more": 0.3333333333333333,
    "of the more successful": 1.0,
    "the more successful systems": 0.5,
    "more successful systems use": 1.0,
    "successful systems use lexical": 1.0,
    "systems use lexical statistics": 0.5,
    "use lexical statistics -lrb-": 1.0,
    "lexical statistics -lrb- that": 1.0,
    "statistics -lrb- that is": 1.0,
    "-lrb- that is ,": 0.5,
    "is , they consider": 0.3333333333333333,
    ", they consider the": 1.0,
    "they consider the identities": 1.0,
    "consider the identities of": 1.0,
    "the identities of the": 1.0,
    "identities of the words": 1.0,
    "of the words involved": 0.3333333333333333,
    "the words involved ,": 1.0,
    "words involved , as": 1.0,
    "involved , as well": 1.0,
    "as well as their": 0.07692307692307693,
    "well as their part": 1.0,
    "as their part of": 1.0,
    "their part of speech": 1.0,
    "part of speech -rrb-": 0.07142857142857142,
    "<s> however such systems": 1.0,
    "however such systems are": 1.0,
    "such systems are vulnerable": 1.0,
    "systems are vulnerable to": 1.0,
    "are vulnerable to overfitting": 1.0,
    "vulnerable to overfitting and": 1.0,
    "to overfitting and require": 1.0,
    "overfitting and require some": 1.0,
    "and require some kind": 1.0,
    "require some kind of": 1.0,
    "some kind of smoothing": 0.25,
    "kind of smoothing to": 1.0,
    "of smoothing to be": 1.0,
    "smoothing to be effective": 1.0,
    "to be effective .": 1.0,
    "citation needed -rrb- parsing": 0.07692307692307693,
    "needed -rrb- parsing algorithms": 1.0,
    "-rrb- parsing algorithms for": 1.0,
    "parsing algorithms for natural": 1.0,
    "algorithms for natural language": 1.0,
    "for natural language can": 0.3333333333333333,
    "natural language can not": 1.0,
    "language can not rely": 1.0,
    "can not rely on": 1.0,
    "not rely on the": 0.5,
    "rely on the grammar": 1.0,
    "on the grammar having": 0.5,
    "the grammar having `": 1.0,
    "grammar having ` nice": 1.0,
    "having ` nice '": 1.0,
    "` nice ' properties": 1.0,
    "nice ' properties as": 1.0,
    "' properties as with": 1.0,
    "properties as with manually": 1.0,
    "as with manually designed": 1.0,
    "with manually designed grammars": 1.0,
    "manually designed grammars for": 1.0,
    "designed grammars for programming": 1.0,
    "grammars for programming languages": 1.0,
    "for programming languages .": 1.0,
    "<s> as mentioned earlier": 1.0,
    "as mentioned earlier some": 0.5,
    "mentioned earlier some grammar": 1.0,
    "earlier some grammar formalisms": 1.0,
    "some grammar formalisms are": 1.0,
    "grammar formalisms are very": 1.0,
    "formalisms are very difficult": 1.0,
    "are very difficult to": 1.0,
    "very difficult to parse": 1.0,
    "difficult to parse computationally": 1.0,
    "to parse computationally ;": 1.0,
    "parse computationally ; in": 1.0,
    "computationally ; in general": 1.0,
    "; in general ,": 1.0,
    "in general , even": 0.16666666666666666,
    "general , even if": 1.0,
    ", even if the": 0.5,
    "even if the desired": 1.0,
    "if the desired structure": 1.0,
    "the desired structure is": 1.0,
    "desired structure is not": 1.0,
    "structure is not context-free": 1.0,
    "is not context-free ,": 1.0,
    "not context-free , some": 1.0,
    "context-free , some kind": 1.0,
    ", some kind of": 1.0,
    "some kind of context-free": 0.25,
    "kind of context-free approximation": 1.0,
    "of context-free approximation to": 1.0,
    "context-free approximation to the": 1.0,
    "approximation to the grammar": 0.5,
    "to the grammar is": 0.5,
    "the grammar is used": 1.0,
    "grammar is used to": 1.0,
    "is used to perform": 0.14285714285714285,
    "used to perform a": 1.0,
    "to perform a first": 1.0,
    "perform a first pass": 1.0,
    "a first pass .": 1.0,
    "<s> algorithms which use": 1.0,
    "algorithms which use context-free": 1.0,
    "which use context-free grammars": 1.0,
    "use context-free grammars often": 1.0,
    "context-free grammars often rely": 1.0,
    "grammars often rely on": 1.0,
    "often rely on some": 1.0,
    "rely on some variant": 1.0,
    "on some variant of": 1.0,
    "some variant of the": 1.0,
    "variant of the cky": 1.0,
    "of the cky algorithm": 1.0,
    "the cky algorithm ,": 1.0,
    "cky algorithm , usually": 1.0,
    "algorithm , usually with": 1.0,
    ", usually with some": 0.5,
    "usually with some heuristic": 1.0,
    "with some heuristic to": 1.0,
    "some heuristic to prune": 1.0,
    "heuristic to prune away": 1.0,
    "to prune away unlikely": 1.0,
    "prune away unlikely analyses": 1.0,
    "away unlikely analyses to": 1.0,
    "unlikely analyses to save": 1.0,
    "analyses to save time": 1.0,
    "to save time .": 1.0,
    "<s> -lrb- see chart": 0.3333333333333333,
    "-lrb- see chart parsing": 1.0,
    "see chart parsing .": 1.0,
    "chart parsing . -rrb-": 1.0,
    "<s> however some systems": 1.0,
    "however some systems trade": 1.0,
    "some systems trade speed": 1.0,
    "systems trade speed for": 1.0,
    "trade speed for accuracy": 1.0,
    "speed for accuracy using": 1.0,
    "for accuracy using ,": 1.0,
    "accuracy using , e.g.": 1.0,
    "using , e.g. ,": 1.0,
    ", e.g. , linear-time": 0.14285714285714285,
    "e.g. , linear-time versions": 1.0,
    ", linear-time versions of": 1.0,
    "linear-time versions of the": 1.0,
    "versions of the shift-reduce": 1.0,
    "of the shift-reduce algorithm": 1.0,
    "the shift-reduce algorithm .": 1.0,
    "<s> a somewhat recent": 1.0,
    "a somewhat recent development": 1.0,
    "somewhat recent development has": 1.0,
    "recent development has been": 1.0,
    "development has been parse": 1.0,
    "has been parse reranking": 1.0,
    "been parse reranking in": 1.0,
    "parse reranking in which": 1.0,
    "reranking in which the": 1.0,
    "in which the parser": 1.0,
    "which the parser proposes": 1.0,
    "the parser proposes some": 1.0,
    "parser proposes some large": 1.0,
    "proposes some large number": 1.0,
    "some large number of": 1.0,
    "large number of analyses": 0.5,
    "number of analyses ,": 1.0,
    "of analyses , and": 1.0,
    "analyses , and a": 1.0,
    ", and a more": 0.16666666666666666,
    "and a more complex": 1.0,
    "a more complex system": 0.5,
    "more complex system selects": 1.0,
    "complex system selects the": 1.0,
    "system selects the best": 1.0,
    "selects the best option": 1.0,
    "the best option .": 1.0,
    "<s> programming languages the": 0.5,
    "programming languages the most": 1.0,
    "languages the most common": 1.0,
    "the most common use": 0.16666666666666666,
    "most common use of": 1.0,
    "common use of a": 1.0,
    "use of a parser": 0.25,
    "of a parser is": 1.0,
    "a parser is as": 1.0,
    "parser is as a": 1.0,
    "is as a component": 1.0,
    "component of a compiler": 0.5,
    "of a compiler or": 0.5,
    "a compiler or interpreter": 1.0,
    "compiler or interpreter .": 1.0,
    "<s> this parses the": 1.0,
    "this parses the source": 1.0,
    "parses the source code": 1.0,
    "the source code of": 1.0,
    "source code of a": 1.0,
    "code of a computer": 1.0,
    "of a computer programming": 0.3333333333333333,
    "a computer programming language": 1.0,
    "computer programming language to": 1.0,
    "programming language to create": 1.0,
    "language to create some": 1.0,
    "to create some form": 1.0,
    "create some form of": 1.0,
    "some form of internal": 0.25,
    "form of internal representation": 1.0,
    "of internal representation .": 1.0,
    "<s> programming languages tend": 0.5,
    "programming languages tend to": 1.0,
    "languages tend to be": 1.0,
    "tend to be specified": 1.0,
    "to be specified in": 1.0,
    "be specified in terms": 1.0,
    "specified in terms of": 1.0,
    "in terms of a": 0.14285714285714285,
    "terms of a context-free": 1.0,
    "of a context-free grammar": 1.0,
    "a context-free grammar because": 0.3333333333333333,
    "context-free grammar because fast": 1.0,
    "grammar because fast and": 1.0,
    "because fast and efficient": 1.0,
    "fast and efficient parsers": 1.0,
    "and efficient parsers can": 1.0,
    "efficient parsers can be": 1.0,
    "parsers can be written": 1.0,
    "can be written for": 1.0,
    "be written for them": 1.0,
    "written for them .": 1.0,
    "<s> parsers are written": 1.0,
    "parsers are written by": 1.0,
    "are written by hand": 1.0,
    "written by hand or": 1.0,
    "by hand or generated": 0.5,
    "hand or generated by": 1.0,
    "or generated by parser": 1.0,
    "generated by parser generators": 1.0,
    "by parser generators .": 1.0,
    "<s> context-free grammars are": 1.0,
    "context-free grammars are limited": 1.0,
    "grammars are limited in": 1.0,
    "are limited in the": 1.0,
    "limited in the extent": 1.0,
    "in the extent to": 1.0,
    "the extent to which": 1.0,
    "extent to which they": 1.0,
    "to which they can": 1.0,
    "which they can express": 1.0,
    "they can express all": 0.5,
    "can express all of": 1.0,
    "express all of the": 1.0,
    "all of the requirements": 0.3333333333333333,
    "of the requirements of": 1.0,
    "the requirements of a": 1.0,
    "requirements of a language": 1.0,
    "of a language .": 0.5,
    "<s> informally , the": 1.0,
    "informally , the reason": 1.0,
    ", the reason is": 1.0,
    "the reason is that": 1.0,
    "reason is that the": 1.0,
    "is that the memory": 0.3333333333333333,
    "that the memory of": 1.0,
    "the memory of such": 1.0,
    "memory of such a": 1.0,
    "of such a language": 0.3333333333333333,
    "such a language is": 1.0,
    "a language is limited": 1.0,
    "language is limited .": 1.0,
    "<s> the grammar can": 0.5,
    "the grammar can not": 1.0,
    "grammar can not remember": 1.0,
    "can not remember the": 1.0,
    "not remember the presence": 1.0,
    "remember the presence of": 1.0,
    "the presence of a": 1.0,
    "presence of a construct": 1.0,
    "of a construct over": 1.0,
    "a construct over an": 1.0,
    "construct over an arbitrarily": 1.0,
    "over an arbitrarily long": 1.0,
    "an arbitrarily long input": 1.0,
    "arbitrarily long input ;": 1.0,
    "long input ; this": 1.0,
    "input ; this is": 1.0,
    "; this is necessary": 0.5,
    "this is necessary for": 1.0,
    "is necessary for a": 1.0,
    "necessary for a language": 1.0,
    "for a language in": 0.5,
    "a language in which": 1.0,
    "language in which ,": 1.0,
    "in which , for": 1.0,
    "which , for example": 1.0,
    "example , a name": 0.2,
    ", a name must": 1.0,
    "a name must be": 1.0,
    "name must be declared": 1.0,
    "must be declared before": 1.0,
    "be declared before it": 1.0,
    "declared before it may": 1.0,
    "before it may be": 1.0,
    "it may be referenced": 1.0,
    "may be referenced .": 1.0,
    "<s> more powerful grammars": 1.0,
    "more powerful grammars that": 1.0,
    "powerful grammars that can": 1.0,
    "grammars that can express": 1.0,
    "that can express this": 1.0,
    "can express this constraint": 1.0,
    "express this constraint ,": 1.0,
    "this constraint , however": 1.0,
    "constraint , however ,": 1.0,
    ", however , can": 0.09090909090909091,
    "however , can not": 1.0,
    ", can not be": 1.0,
    "can not be parsed": 0.25,
    "not be parsed efficiently": 1.0,
    "be parsed efficiently .": 1.0,
    "thus , it is": 0.5,
    ", it is a": 0.23076923076923078,
    "it is a common": 0.16666666666666666,
    "is a common strategy": 0.5,
    "a common strategy to": 1.0,
    "common strategy to create": 1.0,
    "strategy to create a": 1.0,
    "to create a relaxed": 0.2,
    "create a relaxed parser": 1.0,
    "a relaxed parser for": 1.0,
    "relaxed parser for a": 1.0,
    "parser for a context-free": 1.0,
    "for a context-free grammar": 1.0,
    "a context-free grammar which": 0.6666666666666666,
    "context-free grammar which accepts": 0.5,
    "grammar which accepts a": 1.0,
    "which accepts a superset": 1.0,
    "accepts a superset of": 1.0,
    "a superset of the": 1.0,
    "superset of the desired": 1.0,
    "of the desired language": 1.0,
    "the desired language constructs": 1.0,
    "desired language constructs -lrb-": 1.0,
    "language constructs -lrb- that": 1.0,
    "constructs -lrb- that is": 1.0,
    "that is , it": 0.2,
    "is , it accepts": 1.0,
    ", it accepts some": 1.0,
    "it accepts some invalid": 1.0,
    "accepts some invalid constructs": 1.0,
    "some invalid constructs -rrb-": 1.0,
    "invalid constructs -rrb- ;": 1.0,
    "constructs -rrb- ; later": 1.0,
    "-rrb- ; later ,": 1.0,
    "; later , the": 1.0,
    "later , the unwanted": 0.5,
    ", the unwanted constructs": 1.0,
    "the unwanted constructs can": 1.0,
    "unwanted constructs can be": 1.0,
    "constructs can be filtered": 1.0,
    "can be filtered out": 0.3333333333333333,
    "be filtered out .": 1.0,
    "<s> overview of process": 0.5,
    "overview of process flow": 1.0,
    "of process flow of": 1.0,
    "process flow of data": 1.0,
    "flow of data in": 1.0,
    "of data in a": 1.0,
    "data in a typical": 1.0,
    "in a typical parser": 1.0,
    "a typical parser the": 1.0,
    "typical parser the following": 1.0,
    "parser the following example": 1.0,
    "the following example demonstrates": 0.5,
    "following example demonstrates the": 1.0,
    "example demonstrates the common": 1.0,
    "demonstrates the common case": 1.0,
    "the common case of": 1.0,
    "common case of parsing": 1.0,
    "case of parsing a": 1.0,
    "of parsing a computer": 1.0,
    "parsing a computer language": 1.0,
    "a computer language with": 1.0,
    "computer language with two": 1.0,
    "language with two levels": 1.0,
    "with two levels of": 1.0,
    "two levels of grammar": 1.0,
    "levels of grammar :": 1.0,
    "of grammar : lexical": 1.0,
    "grammar : lexical and": 1.0,
    ": lexical and syntactic": 1.0,
    "lexical and syntactic .": 0.5,
    "<s> the first stage": 0.16666666666666666,
    "the first stage is": 1.0,
    "first stage is the": 1.0,
    "stage is the token": 1.0,
    "is the token generation": 1.0,
    "the token generation ,": 1.0,
    "token generation , or": 1.0,
    "generation , or lexical": 1.0,
    ", or lexical analysis": 1.0,
    "or lexical analysis ,": 1.0,
    "lexical analysis , by": 1.0,
    "analysis , by which": 1.0,
    ", by which the": 1.0,
    "by which the input": 1.0,
    "which the input character": 1.0,
    "the input character stream": 1.0,
    "input character stream is": 1.0,
    "character stream is split": 1.0,
    "stream is split into": 1.0,
    "is split into meaningful": 0.5,
    "split into meaningful symbols": 1.0,
    "into meaningful symbols defined": 1.0,
    "meaningful symbols defined by": 1.0,
    "symbols defined by a": 1.0,
    "defined by a grammar": 1.0,
    "by a grammar of": 0.5,
    "a grammar of regular": 1.0,
    "grammar of regular expressions": 1.0,
    "of regular expressions .": 1.0,
    "example , a calculator": 0.2,
    ", a calculator program": 1.0,
    "a calculator program would": 1.0,
    "calculator program would look": 1.0,
    "program would look at": 1.0,
    "would look at an": 0.5,
    "look at an input": 1.0,
    "at an input such": 1.0,
    "an input such as": 1.0,
    "input such as ``": 1.0,
    "such as `` 12": 0.125,
    "as `` 12 \\*": 1.0,
    "`` 12 \\* -lrb-": 0.5,
    "12 \\* -lrb- 3": 1.0,
    "\\* -lrb- 3 +4": 1.0,
    "-lrb- 3 +4 -rrb-": 1.0,
    "3 +4 -rrb- ^": 1.0,
    "+4 -rrb- ^ 2": 1.0,
    "-rrb- ^ 2 ''": 1.0,
    "^ 2 '' and": 1.0,
    "2 '' and split": 1.0,
    "'' and split it": 1.0,
    "and split it into": 1.0,
    "split it into the": 1.0,
    "it into the tokens": 1.0,
    "into the tokens 12": 1.0,
    "the tokens 12 ,": 1.0,
    "tokens 12 , \\*": 1.0,
    "12 , \\* ,": 1.0,
    ", \\* , -lrb-": 1.0,
    "\\* , -lrb- ,": 1.0,
    ", -lrb- , 3": 1.0,
    "-lrb- , 3 ,": 1.0,
    ", 3 , +": 1.0,
    "3 , + ,": 1.0,
    ", + , 4": 0.5,
    "+ , 4 ,": 1.0,
    ", 4 , -rrb-": 1.0,
    "4 , -rrb- ,": 1.0,
    ", -rrb- , ^": 1.0,
    "-rrb- , ^ ,": 1.0,
    ", ^ , 2": 0.5,
    "^ , 2 ,": 1.0,
    ", 2 , each": 1.0,
    "2 , each of": 1.0,
    "of which is a": 0.3333333333333333,
    "which is a meaningful": 0.5,
    "is a meaningful symbol": 1.0,
    "a meaningful symbol in": 1.0,
    "meaningful symbol in the": 1.0,
    "symbol in the context": 1.0,
    "the context of an": 0.2,
    "context of an arithmetic": 1.0,
    "of an arithmetic expression": 1.0,
    "an arithmetic expression .": 1.0,
    "<s> the lexer would": 1.0,
    "the lexer would contain": 1.0,
    "lexer would contain rules": 1.0,
    "would contain rules to": 1.0,
    "contain rules to tell": 1.0,
    "rules to tell it": 1.0,
    "to tell it that": 1.0,
    "tell it that the": 1.0,
    "it that the characters": 1.0,
    "that the characters \\*": 1.0,
    "the characters \\* ,": 1.0,
    "characters \\* , +": 1.0,
    "\\* , + ,": 1.0,
    ", + , ^": 0.5,
    "+ , ^ ,": 1.0,
    ", ^ , -lrb-": 0.5,
    "^ , -lrb- and": 1.0,
    ", -lrb- and -rrb-": 1.0,
    "-lrb- and -rrb- mark": 1.0,
    "and -rrb- mark the": 1.0,
    "-rrb- mark the start": 1.0,
    "mark the start of": 1.0,
    "the start of a": 0.5,
    "start of a new": 1.0,
    "of a new token": 1.0,
    "a new token ,": 1.0,
    "new token , so": 1.0,
    "token , so meaningless": 1.0,
    ", so meaningless tokens": 1.0,
    "so meaningless tokens like": 1.0,
    "meaningless tokens like ``": 1.0,
    "tokens like `` 12": 1.0,
    "like `` 12 \\*": 1.0,
    "`` 12 \\* ''": 0.5,
    "12 \\* '' or": 1.0,
    "\\* '' or ''": 1.0,
    "'' or '' -lrb-": 1.0,
    "or '' -lrb- 3": 1.0,
    "'' -lrb- 3 ''": 1.0,
    "-lrb- 3 '' will": 1.0,
    "3 '' will not": 1.0,
    "'' will not be": 1.0,
    "will not be generated": 0.5,
    "not be generated .": 1.0,
    "<s> the next stage": 1.0,
    "the next stage is": 0.5,
    "next stage is parsing": 1.0,
    "stage is parsing or": 1.0,
    "is parsing or syntactic": 1.0,
    "parsing or syntactic analysis": 1.0,
    "or syntactic analysis ,": 1.0,
    "syntactic analysis , which": 0.5,
    "analysis , which is": 1.0,
    ", which is checking": 0.14285714285714285,
    "which is checking that": 1.0,
    "is checking that the": 1.0,
    "checking that the tokens": 1.0,
    "that the tokens form": 1.0,
    "the tokens form an": 1.0,
    "tokens form an allowable": 1.0,
    "form an allowable expression": 1.0,
    "an allowable expression .": 1.0,
    "<s> this is usually": 0.14285714285714285,
    "this is usually done": 0.5,
    "is usually done with": 0.5,
    "usually done with reference": 1.0,
    "done with reference to": 1.0,
    "with reference to a": 1.0,
    "reference to a context-free": 1.0,
    "to a context-free grammar": 1.0,
    "context-free grammar which recursively": 0.5,
    "grammar which recursively defines": 1.0,
    "which recursively defines components": 1.0,
    "recursively defines components that": 1.0,
    "defines components that can": 1.0,
    "components that can make": 1.0,
    "that can make up": 0.5,
    "can make up an": 1.0,
    "make up an expression": 1.0,
    "up an expression and": 1.0,
    "an expression and the": 1.0,
    "expression and the order": 0.5,
    "and the order in": 1.0,
    "the order in which": 1.0,
    "order in which they": 1.0,
    "in which they must": 1.0,
    "which they must appear": 1.0,
    "they must appear .": 1.0,
    "<s> however , not": 0.03125,
    "however , not all": 1.0,
    ", not all rules": 0.5,
    "not all rules defining": 1.0,
    "all rules defining programming": 1.0,
    "rules defining programming languages": 1.0,
    "defining programming languages can": 1.0,
    "programming languages can be": 1.0,
    "can be expressed by": 0.3333333333333333,
    "be expressed by context-free": 1.0,
    "expressed by context-free grammars": 1.0,
    "by context-free grammars alone": 1.0,
    "context-free grammars alone ,": 1.0,
    "grammars alone , for": 1.0,
    "alone , for example": 1.0,
    ", for example type": 0.1,
    "for example type validity": 1.0,
    "example type validity and": 1.0,
    "type validity and proper": 1.0,
    "validity and proper declaration": 1.0,
    "and proper declaration of": 1.0,
    "proper declaration of identifiers": 1.0,
    "declaration of identifiers .": 1.0,
    "<s> these rules can": 1.0,
    "these rules can be": 1.0,
    "rules can be formally": 0.5,
    "can be formally expressed": 1.0,
    "be formally expressed with": 1.0,
    "formally expressed with attribute": 1.0,
    "expressed with attribute grammars": 1.0,
    "with attribute grammars .": 1.0,
    "<s> the final phase": 1.0,
    "the final phase is": 1.0,
    "final phase is semantic": 1.0,
    "phase is semantic parsing": 1.0,
    "is semantic parsing or": 1.0,
    "semantic parsing or analysis": 1.0,
    "parsing or analysis ,": 1.0,
    "or analysis , which": 1.0,
    ", which is working": 0.14285714285714285,
    "which is working out": 1.0,
    "is working out the": 1.0,
    "working out the implications": 1.0,
    "out the implications of": 1.0,
    "the implications of the": 1.0,
    "implications of the expression": 1.0,
    "of the expression just": 1.0,
    "the expression just validated": 1.0,
    "expression just validated and": 1.0,
    "just validated and taking": 1.0,
    "validated and taking the": 1.0,
    "and taking the appropriate": 1.0,
    "taking the appropriate action": 1.0,
    "the appropriate action .": 1.0,
    "the case of a": 0.2,
    "case of a calculator": 1.0,
    "of a calculator or": 1.0,
    "a calculator or interpreter": 1.0,
    "calculator or interpreter ,": 1.0,
    "or interpreter , the": 1.0,
    "interpreter , the action": 1.0,
    ", the action is": 1.0,
    "the action is to": 1.0,
    "action is to evaluate": 1.0,
    "is to evaluate the": 1.0,
    "to evaluate the expression": 0.5,
    "evaluate the expression or": 1.0,
    "the expression or program": 1.0,
    "expression or program ,": 1.0,
    "or program , a": 1.0,
    "program , a compiler": 1.0,
    ", a compiler ,": 1.0,
    "a compiler , on": 1.0,
    "compiler , on the": 1.0,
    "other hand , would": 0.2,
    "hand , would generate": 1.0,
    ", would generate some": 1.0,
    "would generate some kind": 1.0,
    "generate some kind of": 1.0,
    "some kind of code": 0.25,
    "kind of code .": 1.0,
    "<s> attribute grammars can": 1.0,
    "attribute grammars can also": 1.0,
    "grammars can also be": 1.0,
    "also be used to": 0.5,
    "be used to define": 0.16666666666666666,
    "used to define these": 1.0,
    "to define these actions": 1.0,
    "define these actions .": 1.0,
    "<s> types of parser": 0.5,
    "types of parser the": 1.0,
    "of parser the task": 1.0,
    "parser the task of": 1.0,
    "the task of the": 0.16666666666666666,
    "task of the parser": 0.5,
    "of the parser is": 1.0,
    "the parser is essentially": 1.0,
    "parser is essentially to": 1.0,
    "is essentially to determine": 1.0,
    "essentially to determine if": 1.0,
    "to determine if and": 0.5,
    "determine if and how": 1.0,
    "if and how the": 1.0,
    "and how the input": 1.0,
    "how the input can": 1.0,
    "the input can be": 1.0,
    "input can be derived": 1.0,
    "be derived from the": 0.5,
    "derived from the start": 1.0,
    "from the start symbol": 1.0,
    "the start symbol of": 0.5,
    "start symbol of the": 1.0,
    "symbol of the grammar": 1.0,
    "of the grammar .": 0.3333333333333333,
    "<s> this can be": 1.0,
    "can be done in": 0.5,
    "be done in essentially": 0.5,
    "done in essentially two": 1.0,
    "in essentially two ways": 1.0,
    "essentially two ways :": 1.0,
    "two ways : top-down": 1.0,
    "ways : top-down parsing": 1.0,
    ": top-down parsing -": 1.0,
    "top-down parsing - top-down": 1.0,
    "parsing - top-down parsing": 1.0,
    "- top-down parsing can": 1.0,
    "top-down parsing can be": 0.5,
    "parsing can be viewed": 1.0,
    "viewed as an attempt": 0.5,
    "as an attempt to": 1.0,
    "an attempt to find": 0.3333333333333333,
    "attempt to find left-most": 1.0,
    "to find left-most derivations": 1.0,
    "find left-most derivations of": 1.0,
    "left-most derivations of an": 1.0,
    "derivations of an input-stream": 0.5,
    "of an input-stream by": 1.0,
    "an input-stream by searching": 1.0,
    "input-stream by searching for": 1.0,
    "by searching for parse": 1.0,
    "searching for parse trees": 1.0,
    "for parse trees using": 1.0,
    "parse trees using a": 1.0,
    "trees using a top-down": 1.0,
    "using a top-down expansion": 1.0,
    "a top-down expansion of": 1.0,
    "top-down expansion of the": 1.0,
    "expansion of the given": 1.0,
    "of the given formal": 0.5,
    "the given formal grammar": 1.0,
    "given formal grammar rules": 1.0,
    "formal grammar rules .": 1.0,
    "<s> tokens are consumed": 1.0,
    "tokens are consumed from": 1.0,
    "are consumed from left": 1.0,
    "consumed from left to": 1.0,
    "from left to right": 1.0,
    "left to right .": 1.0,
    "<s> inclusive choice is": 1.0,
    "inclusive choice is used": 1.0,
    "choice is used to": 1.0,
    "is used to accommodate": 0.14285714285714285,
    "used to accommodate ambiguity": 1.0,
    "to accommodate ambiguity by": 1.0,
    "accommodate ambiguity by expanding": 1.0,
    "ambiguity by expanding all": 1.0,
    "by expanding all alternative": 1.0,
    "expanding all alternative right-hand-sides": 1.0,
    "all alternative right-hand-sides of": 1.0,
    "alternative right-hand-sides of grammar": 1.0,
    "right-hand-sides of grammar rules": 1.0,
    "of grammar rules .": 1.0,
    "<s> bottom-up parsing -": 1.0,
    "bottom-up parsing - a": 1.0,
    "parsing - a parser": 1.0,
    "- a parser can": 1.0,
    "a parser can start": 1.0,
    "parser can start with": 1.0,
    "can start with the": 1.0,
    "start with the input": 1.0,
    "with the input and": 1.0,
    "the input and attempt": 0.5,
    "input and attempt to": 1.0,
    "and attempt to rewrite": 1.0,
    "attempt to rewrite it": 1.0,
    "to rewrite it to": 1.0,
    "rewrite it to the": 1.0,
    "it to the start": 1.0,
    "to the start symbol": 1.0,
    "the start symbol .": 0.5,
    "<s> intuitively , the": 1.0,
    "intuitively , the parser": 1.0,
    ", the parser attempts": 1.0,
    "the parser attempts to": 1.0,
    "parser attempts to locate": 1.0,
    "attempts to locate the": 1.0,
    "to locate the most": 1.0,
    "locate the most basic": 1.0,
    "the most basic elements": 1.0,
    "most basic elements ,": 1.0,
    "basic elements , then": 1.0,
    "elements , then the": 1.0,
    ", then the elements": 0.5,
    "then the elements containing": 1.0,
    "the elements containing these": 1.0,
    "elements containing these ,": 1.0,
    "containing these , and": 1.0,
    "these , and so": 1.0,
    "<s> lr parsers are": 1.0,
    "lr parsers are examples": 1.0,
    "parsers are examples of": 1.0,
    "are examples of bottom-up": 0.3333333333333333,
    "examples of bottom-up parsers": 1.0,
    "of bottom-up parsers .": 1.0,
    "<s> another term used": 1.0,
    "another term used for": 1.0,
    "term used for this": 1.0,
    "used for this type": 1.0,
    "for this type of": 1.0,
    "this type of parser": 0.5,
    "type of parser is": 1.0,
    "of parser is shift-reduce": 1.0,
    "parser is shift-reduce parsing": 1.0,
    "is shift-reduce parsing .": 1.0,
    "<s> ll parsers and": 0.5,
    "ll parsers and recursive-descent": 1.0,
    "parsers and recursive-descent parser": 1.0,
    "and recursive-descent parser are": 1.0,
    "recursive-descent parser are examples": 1.0,
    "parser are examples of": 1.0,
    "are examples of top-down": 0.3333333333333333,
    "examples of top-down parsers": 1.0,
    "of top-down parsers which": 1.0,
    "top-down parsers which can": 1.0,
    "parsers which can not": 1.0,
    "which can not accommodate": 1.0,
    "can not accommodate left": 0.5,
    "not accommodate left recursive": 1.0,
    "accommodate left recursive productions": 1.0,
    "left recursive productions .": 1.0,
    "<s> although it has": 1.0,
    "although it has been": 1.0,
    "it has been believed": 0.3333333333333333,
    "has been believed that": 1.0,
    "been believed that simple": 1.0,
    "believed that simple implementations": 1.0,
    "that simple implementations of": 1.0,
    "simple implementations of top-down": 1.0,
    "implementations of top-down parsing": 1.0,
    "of top-down parsing can": 1.0,
    "top-down parsing can not": 0.5,
    "parsing can not accommodate": 1.0,
    "can not accommodate direct": 0.5,
    "not accommodate direct and": 1.0,
    "accommodate direct and indirect": 1.0,
    "direct and indirect left-recursion": 1.0,
    "and indirect left-recursion and": 1.0,
    "indirect left-recursion and may": 1.0,
    "left-recursion and may require": 1.0,
    "and may require exponential": 1.0,
    "may require exponential time": 1.0,
    "require exponential time and": 1.0,
    "exponential time and space": 1.0,
    "time and space complexity": 1.0,
    "and space complexity while": 1.0,
    "space complexity while parsing": 1.0,
    "complexity while parsing ambiguous": 1.0,
    "while parsing ambiguous context-free": 1.0,
    "parsing ambiguous context-free grammars": 1.0,
    "ambiguous context-free grammars ,": 1.0,
    "context-free grammars , more": 1.0,
    "grammars , more sophisticated": 1.0,
    ", more sophisticated algorithms": 1.0,
    "more sophisticated algorithms for": 1.0,
    "sophisticated algorithms for top-down": 1.0,
    "algorithms for top-down parsing": 1.0,
    "for top-down parsing have": 1.0,
    "top-down parsing have been": 1.0,
    "parsing have been created": 1.0,
    "have been created by": 0.5,
    "been created by frost": 1.0,
    "created by frost ,": 1.0,
    "by frost , hafiz": 1.0,
    "frost , hafiz ,": 1.0,
    ", hafiz , and": 1.0,
    "hafiz , and callaghan": 1.0,
    ", and callaghan which": 1.0,
    "and callaghan which accommodate": 1.0,
    "callaghan which accommodate ambiguity": 1.0,
    "which accommodate ambiguity and": 1.0,
    "accommodate ambiguity and left": 1.0,
    "ambiguity and left recursion": 1.0,
    "and left recursion in": 1.0,
    "left recursion in polynomial": 1.0,
    "recursion in polynomial time": 1.0,
    "in polynomial time and": 1.0,
    "polynomial time and which": 1.0,
    "time and which generate": 1.0,
    "and which generate polynomial-size": 1.0,
    "which generate polynomial-size representations": 1.0,
    "generate polynomial-size representations of": 1.0,
    "polynomial-size representations of the": 1.0,
    "representations of the potentially": 1.0,
    "of the potentially exponential": 1.0,
    "the potentially exponential number": 1.0,
    "potentially exponential number of": 1.0,
    "exponential number of parse": 1.0,
    "number of parse trees": 1.0,
    "of parse trees .": 1.0,
    "<s> their algorithm is": 1.0,
    "their algorithm is able": 1.0,
    "algorithm is able to": 1.0,
    "is able to produce": 1.0,
    "able to produce both": 0.5,
    "to produce both left-most": 1.0,
    "produce both left-most and": 1.0,
    "both left-most and right-most": 1.0,
    "left-most and right-most derivations": 1.0,
    "and right-most derivations of": 1.0,
    "right-most derivations of an": 1.0,
    "derivations of an input": 0.5,
    "of an input with": 1.0,
    "an input with regard": 1.0,
    "input with regard to": 1.0,
    "with regard to a": 0.25,
    "regard to a given": 1.0,
    "to a given cfg": 0.3333333333333333,
    "a given cfg -lrb-": 1.0,
    "given cfg -lrb- context-free": 1.0,
    "cfg -lrb- context-free grammar": 1.0,
    "-lrb- context-free grammar -rrb-": 1.0,
    "context-free grammar -rrb- .": 1.0,
    "<s> an important distinction": 0.5,
    "an important distinction with": 1.0,
    "important distinction with regard": 1.0,
    "distinction with regard to": 1.0,
    "with regard to parsers": 0.25,
    "regard to parsers is": 1.0,
    "to parsers is whether": 1.0,
    "parsers is whether a": 1.0,
    "is whether a parser": 1.0,
    "whether a parser generates": 1.0,
    "a parser generates a": 1.0,
    "parser generates a leftmost": 1.0,
    "generates a leftmost derivation": 1.0,
    "a leftmost derivation or": 0.5,
    "leftmost derivation or a": 1.0,
    "derivation or a rightmost": 1.0,
    "or a rightmost derivation": 1.0,
    "a rightmost derivation -lrb-": 1.0,
    "rightmost derivation -lrb- see": 0.5,
    "derivation -lrb- see context-free": 1.0,
    "-lrb- see context-free grammar": 1.0,
    "see context-free grammar -rrb-": 1.0,
    "<s> ll parsers will": 0.5,
    "ll parsers will generate": 1.0,
    "parsers will generate a": 1.0,
    "will generate a leftmost": 0.3333333333333333,
    "generate a leftmost derivation": 1.0,
    "a leftmost derivation and": 0.5,
    "leftmost derivation and lr": 1.0,
    "derivation and lr parsers": 1.0,
    "and lr parsers will": 1.0,
    "lr parsers will generate": 1.0,
    "will generate a rightmost": 0.3333333333333333,
    "generate a rightmost derivation": 1.0,
    "rightmost derivation -lrb- although": 0.5,
    "derivation -lrb- although usually": 1.0,
    "-lrb- although usually in": 1.0,
    "although usually in reverse": 1.0,
    "usually in reverse -rrb-": 1.0,
    "in reverse -rrb- .": 1.0,
    "<s> in information retrieval": 1.0,
    "in information retrieval and": 0.5,
    "information retrieval and natural": 0.5,
    "retrieval and natural language": 1.0,
    "-lrb- nlp -rrb- ,": 0.3333333333333333,
    "nlp -rrb- , question": 1.0,
    "-rrb- , question answering": 1.0,
    ", question answering -lrb-": 1.0,
    "question answering -lrb- qa": 1.0,
    "answering -lrb- qa -rrb-": 1.0,
    "-lrb- qa -rrb- is": 1.0,
    "qa -rrb- is the": 1.0,
    "-rrb- is the task": 0.3333333333333333,
    "is the task of": 1.0,
    "the task of automatically": 0.16666666666666666,
    "task of automatically answering": 1.0,
    "of automatically answering a": 1.0,
    "automatically answering a question": 1.0,
    "answering a question posed": 1.0,
    "a question posed in": 1.0,
    "question posed in natural": 0.5,
    "posed in natural language": 1.0,
    "in natural language .": 0.16666666666666666,
    "<s> to find the": 1.0,
    "to find the answer": 0.6666666666666666,
    "find the answer to": 0.5,
    "the answer to a": 0.5,
    "answer to a question": 1.0,
    "to a question ,": 0.5,
    "a question , a": 0.5,
    "question , a qa": 1.0,
    ", a qa computer": 1.0,
    "a qa computer program": 1.0,
    "qa computer program may": 1.0,
    "computer program may use": 1.0,
    "program may use either": 1.0,
    "may use either a": 1.0,
    "use either a pre-structured": 1.0,
    "either a pre-structured database": 1.0,
    "a pre-structured database or": 1.0,
    "pre-structured database or a": 1.0,
    "database or a collection": 1.0,
    "or a collection of": 1.0,
    "a collection of natural": 0.5,
    "collection of natural language": 1.0,
    "of natural language documents": 0.058823529411764705,
    "natural language documents -lrb-": 1.0,
    "language documents -lrb- a": 1.0,
    "documents -lrb- a text": 1.0,
    "-lrb- a text corpus": 1.0,
    "a text corpus such": 1.0,
    "text corpus such as": 1.0,
    "corpus such as the": 1.0,
    "such as the world": 0.07142857142857142,
    "as the world wide": 1.0,
    "world wide web or": 0.25,
    "wide web or some": 1.0,
    "web or some local": 1.0,
    "or some local collection": 1.0,
    "some local collection -rrb-": 1.0,
    "local collection -rrb- .": 1.0,
    "<s> qa research attempts": 1.0,
    "qa research attempts to": 1.0,
    "research attempts to deal": 0.5,
    "attempts to deal with": 1.0,
    "to deal with a": 1.0,
    "deal with a wide": 1.0,
    "with a wide range": 1.0,
    "a wide range of": 1.0,
    "wide range of question": 0.5,
    "range of question types": 1.0,
    "of question types including": 1.0,
    "question types including :": 1.0,
    "types including : fact": 1.0,
    "including : fact ,": 1.0,
    ": fact , list": 1.0,
    "fact , list ,": 1.0,
    ", list , definition": 1.0,
    "list , definition ,": 1.0,
    ", definition , how": 1.0,
    "definition , how ,": 1.0,
    ", how , why": 1.0,
    "how , why ,": 1.0,
    ", why , hypothetical": 1.0,
    "why , hypothetical ,": 1.0,
    ", hypothetical , semantically": 1.0,
    "hypothetical , semantically constrained": 1.0,
    ", semantically constrained ,": 1.0,
    "semantically constrained , and": 1.0,
    "constrained , and cross-lingual": 1.0,
    ", and cross-lingual questions": 1.0,
    "and cross-lingual questions .": 1.0,
    "<s> search collections vary": 1.0,
    "search collections vary from": 1.0,
    "collections vary from small": 1.0,
    "vary from small local": 1.0,
    "from small local document": 1.0,
    "small local document collections": 1.0,
    "local document collections ,": 1.0,
    "document collections , to": 1.0,
    "collections , to internal": 1.0,
    ", to internal organization": 1.0,
    "to internal organization documents": 1.0,
    "internal organization documents ,": 1.0,
    "organization documents , to": 1.0,
    "documents , to compiled": 1.0,
    ", to compiled newswire": 1.0,
    "to compiled newswire reports": 1.0,
    "compiled newswire reports ,": 1.0,
    "newswire reports , to": 1.0,
    "reports , to the": 1.0,
    ", to the world": 0.5,
    "to the world wide": 1.0,
    "world wide web .": 0.25,
    "<s> closed-domain question answering": 1.0,
    "closed-domain question answering deals": 1.0,
    "question answering deals with": 1.0,
    "answering deals with questions": 1.0,
    "deals with questions under": 0.5,
    "with questions under a": 1.0,
    "questions under a specific": 1.0,
    "under a specific domain": 1.0,
    "a specific domain -lrb-": 0.5,
    "specific domain -lrb- for": 1.0,
    "domain -lrb- for example": 1.0,
    "for example , medicine": 0.02127659574468085,
    "example , medicine or": 1.0,
    ", medicine or automotive": 1.0,
    "medicine or automotive maintenance": 1.0,
    "or automotive maintenance -rrb-": 1.0,
    "automotive maintenance -rrb- ,": 1.0,
    "maintenance -rrb- , and": 1.0,
    "-rrb- , and can": 0.09090909090909091,
    "be seen as an": 0.5,
    "seen as an easier": 1.0,
    "as an easier task": 1.0,
    "an easier task because": 1.0,
    "easier task because nlp": 1.0,
    "task because nlp systems": 1.0,
    "because nlp systems can": 1.0,
    "nlp systems can exploit": 1.0,
    "systems can exploit domain-specific": 1.0,
    "can exploit domain-specific knowledge": 1.0,
    "exploit domain-specific knowledge frequently": 1.0,
    "domain-specific knowledge frequently formalized": 1.0,
    "knowledge frequently formalized in": 1.0,
    "frequently formalized in ontologies": 1.0,
    "formalized in ontologies .": 1.0,
    "<s> alternatively , closed-domain": 0.5,
    "alternatively , closed-domain might": 1.0,
    ", closed-domain might refer": 1.0,
    "closed-domain might refer to": 1.0,
    "might refer to a": 1.0,
    "refer to a situation": 0.5,
    "to a situation where": 1.0,
    "a situation where only": 1.0,
    "situation where only a": 1.0,
    "where only a limited": 1.0,
    "only a limited type": 1.0,
    "a limited type of": 1.0,
    "limited type of questions": 1.0,
    "type of questions are": 1.0,
    "of questions are accepted": 1.0,
    "questions are accepted ,": 1.0,
    "are accepted , such": 1.0,
    "accepted , such as": 1.0,
    ", such as questions": 0.030303030303030304,
    "such as questions asking": 1.0,
    "as questions asking for": 1.0,
    "questions asking for descriptive": 1.0,
    "asking for descriptive rather": 1.0,
    "for descriptive rather than": 1.0,
    "descriptive rather than procedural": 1.0,
    "rather than procedural information": 1.0,
    "than procedural information .": 1.0,
    "<s> open-domain question answering": 1.0,
    "open-domain question answering deals": 1.0,
    "deals with questions about": 0.5,
    "with questions about nearly": 1.0,
    "questions about nearly anything": 1.0,
    "about nearly anything ,": 1.0,
    "nearly anything , and": 1.0,
    "anything , and can": 1.0,
    ", and can only": 0.2,
    "and can only rely": 1.0,
    "can only rely on": 1.0,
    "only rely on general": 1.0,
    "rely on general ontologies": 1.0,
    "on general ontologies and": 1.0,
    "general ontologies and world": 1.0,
    "ontologies and world knowledge": 1.0,
    "and world knowledge .": 1.0,
    "other hand , these": 0.2,
    "hand , these systems": 1.0,
    ", these systems usually": 1.0,
    "these systems usually have": 0.5,
    "systems usually have much": 1.0,
    "usually have much more": 1.0,
    "have much more data": 1.0,
    "much more data available": 1.0,
    "more data available from": 1.0,
    "data available from which": 1.0,
    "available from which to": 1.0,
    "from which to extract": 1.0,
    "which to extract the": 1.0,
    "to extract the answer": 1.0,
    "extract the answer .": 1.0,
    "in contrast , current": 0.2,
    "contrast , current qa": 1.0,
    ", current qa systems": 1.0,
    "current qa systems use": 0.5,
    "qa systems use text": 1.0,
    "systems use text documents": 1.0,
    "use text documents as": 1.0,
    "text documents as their": 1.0,
    "documents as their underlying": 1.0,
    "as their underlying knowledge": 1.0,
    "their underlying knowledge source": 1.0,
    "underlying knowledge source and": 1.0,
    "knowledge source and combine": 1.0,
    "source and combine various": 1.0,
    "and combine various natural": 1.0,
    "combine various natural language": 1.0,
    "various natural language processing": 1.0,
    "natural language processing techniques": 0.07142857142857142,
    "language processing techniques to": 1.0,
    "processing techniques to search": 0.5,
    "techniques to search for": 1.0,
    "to search for the": 1.0,
    "search for the answers": 1.0,
    "for the answers .": 1.0,
    "<s> current qa systems": 1.0,
    "current qa systems typically": 0.5,
    "qa systems typically include": 1.0,
    "systems typically include a": 1.0,
    "typically include a question": 1.0,
    "include a question classifier": 1.0,
    "a question classifier module": 1.0,
    "question classifier module that": 1.0,
    "classifier module that determines": 1.0,
    "module that determines the": 1.0,
    "that determines the type": 1.0,
    "determines the type of": 1.0,
    "the type of question": 0.25,
    "type of question and": 1.0,
    "of question and the": 1.0,
    "question and the type": 1.0,
    "and the type of": 1.0,
    "the type of answer": 0.25,
    "type of answer .": 1.0,
    "<s> after the question": 1.0,
    "after the question is": 1.0,
    "the question is analyzed": 0.3333333333333333,
    "question is analyzed ,": 1.0,
    "is analyzed , the": 1.0,
    "analyzed , the system": 1.0,
    ", the system typically": 0.25,
    "the system typically uses": 1.0,
    "system typically uses several": 1.0,
    "typically uses several modules": 1.0,
    "uses several modules that": 1.0,
    "several modules that apply": 1.0,
    "modules that apply increasingly": 1.0,
    "that apply increasingly complex": 1.0,
    "apply increasingly complex nlp": 1.0,
    "increasingly complex nlp techniques": 1.0,
    "complex nlp techniques on": 0.5,
    "nlp techniques on a": 1.0,
    "techniques on a gradually": 1.0,
    "on a gradually reduced": 1.0,
    "a gradually reduced amount": 1.0,
    "gradually reduced amount of": 1.0,
    "reduced amount of text": 1.0,
    "amount of text .": 1.0,
    "<s> thus , a": 0.18181818181818182,
    "thus , a document": 0.5,
    ", a document retrieval": 1.0,
    "a document retrieval module": 1.0,
    "document retrieval module uses": 1.0,
    "retrieval module uses search": 1.0,
    "module uses search engines": 1.0,
    "uses search engines to": 1.0,
    "search engines to identify": 1.0,
    "engines to identify the": 1.0,
    "to identify the documents": 0.5,
    "identify the documents or": 1.0,
    "the documents or paragraphs": 1.0,
    "documents or paragraphs in": 1.0,
    "or paragraphs in the": 1.0,
    "paragraphs in the document": 1.0,
    "in the document set": 0.25,
    "the document set that": 1.0,
    "document set that are": 1.0,
    "set that are likely": 1.0,
    "that are likely to": 1.0,
    "are likely to contain": 0.3333333333333333,
    "likely to contain the": 1.0,
    "to contain the answer": 1.0,
    "contain the answer .": 1.0,
    "<s> subsequently a filter": 1.0,
    "subsequently a filter preselects": 1.0,
    "a filter preselects small": 1.0,
    "filter preselects small text": 1.0,
    "preselects small text fragments": 1.0,
    "small text fragments that": 1.0,
    "text fragments that contain": 1.0,
    "fragments that contain strings": 1.0,
    "that contain strings of": 1.0,
    "contain strings of the": 1.0,
    "strings of the same": 1.0,
    "of the same type": 1.0,
    "the same type as": 1.0,
    "same type as the": 1.0,
    "type as the expected": 1.0,
    "as the expected answer": 1.0,
    "the expected answer .": 1.0,
    "example , if the": 0.16666666666666666,
    ", if the question": 0.5,
    "if the question is": 1.0,
    "the question is ``": 0.3333333333333333,
    "question is `` who": 1.0,
    "is `` who invented": 1.0,
    "`` who invented penicillin": 1.0,
    "who invented penicillin ''": 1.0,
    "invented penicillin '' the": 1.0,
    "penicillin '' the filter": 1.0,
    "'' the filter returns": 1.0,
    "the filter returns text": 1.0,
    "filter returns text that": 1.0,
    "returns text that contain": 1.0,
    "text that contain names": 1.0,
    "that contain names of": 1.0,
    "contain names of people": 1.0,
    "names of people .": 1.0,
    "<s> finally , an": 1.0,
    "finally , an answer": 1.0,
    ", an answer extraction": 1.0,
    "an answer extraction module": 1.0,
    "answer extraction module looks": 1.0,
    "extraction module looks for": 1.0,
    "module looks for further": 1.0,
    "looks for further clues": 1.0,
    "for further clues in": 1.0,
    "further clues in the": 1.0,
    "clues in the text": 1.0,
    "in the text to": 0.125,
    "the text to determine": 0.5,
    "text to determine if": 1.0,
    "to determine if the": 0.5,
    "determine if the answer": 0.3333333333333333,
    "if the answer candidate": 0.5,
    "the answer candidate can": 1.0,
    "answer candidate can indeed": 1.0,
    "candidate can indeed answer": 1.0,
    "can indeed answer the": 1.0,
    "indeed answer the question": 1.0,
    "answer the question .": 1.0,
    "<s> question answering methods": 0.5,
    "question answering methods qa": 1.0,
    "answering methods qa is": 1.0,
    "methods qa is very": 1.0,
    "qa is very dependent": 1.0,
    "is very dependent on": 1.0,
    "very dependent on a": 1.0,
    "dependent on a good": 1.0,
    "on a good search": 1.0,
    "a good search corpus": 1.0,
    "good search corpus -": 1.0,
    "search corpus - for": 1.0,
    "corpus - for without": 1.0,
    "- for without documents": 1.0,
    "for without documents containing": 1.0,
    "without documents containing the": 1.0,
    "documents containing the answer": 1.0,
    "containing the answer ,": 1.0,
    "the answer , there": 1.0,
    "answer , there is": 1.0,
    ", there is little": 0.16666666666666666,
    "there is little any": 1.0,
    "is little any qa": 1.0,
    "little any qa system": 1.0,
    "any qa system can": 1.0,
    "qa system can do": 1.0,
    "system can do .": 1.0,
    "<s> it thus makes": 1.0,
    "it thus makes sense": 1.0,
    "thus makes sense that": 1.0,
    "makes sense that larger": 1.0,
    "sense that larger collection": 1.0,
    "that larger collection sizes": 1.0,
    "larger collection sizes generally": 1.0,
    "collection sizes generally lend": 1.0,
    "sizes generally lend well": 1.0,
    "generally lend well to": 1.0,
    "lend well to better": 1.0,
    "well to better qa": 1.0,
    "to better qa performance": 1.0,
    "better qa performance ,": 1.0,
    "qa performance , unless": 1.0,
    "performance , unless the": 1.0,
    ", unless the question": 1.0,
    "unless the question domain": 1.0,
    "the question domain is": 1.0,
    "question domain is orthogonal": 1.0,
    "domain is orthogonal to": 1.0,
    "is orthogonal to the": 1.0,
    "orthogonal to the collection": 1.0,
    "to the collection .": 1.0,
    "<s> the notion of": 0.5,
    "the notion of data": 0.3333333333333333,
    "notion of data redundancy": 1.0,
    "of data redundancy in": 1.0,
    "data redundancy in massive": 1.0,
    "redundancy in massive collections": 1.0,
    "in massive collections ,": 1.0,
    "massive collections , such": 1.0,
    "collections , such as": 1.0,
    "such as the web": 0.07142857142857142,
    "as the web ,": 1.0,
    "the web , means": 1.0,
    "web , means that": 1.0,
    ", means that nuggets": 1.0,
    "means that nuggets of": 1.0,
    "that nuggets of information": 1.0,
    "nuggets of information are": 1.0,
    "of information are likely": 1.0,
    "information are likely to": 1.0,
    "likely to be phrased": 0.25,
    "to be phrased in": 1.0,
    "be phrased in many": 1.0,
    "phrased in many different": 1.0,
    "in many different ways": 1.0,
    "many different ways in": 1.0,
    "different ways in differing": 1.0,
    "ways in differing contexts": 1.0,
    "in differing contexts and": 1.0,
    "differing contexts and documents": 1.0,
    "contexts and documents ,": 1.0,
    "and documents , leading": 1.0,
    "documents , leading to": 1.0,
    ", leading to two": 1.0,
    "leading to two benefits": 1.0,
    "to two benefits :": 1.0,
    "two benefits : by": 1.0,
    "benefits : by having": 1.0,
    ": by having the": 1.0,
    "by having the right": 1.0,
    "having the right information": 1.0,
    "the right information appear": 1.0,
    "right information appear in": 1.0,
    "information appear in many": 1.0,
    "appear in many forms": 1.0,
    "in many forms ,": 1.0,
    "many forms , the": 1.0,
    "forms , the burden": 1.0,
    ", the burden on": 1.0,
    "the burden on the": 1.0,
    "burden on the qa": 1.0,
    "on the qa system": 1.0,
    "the qa system to": 1.0,
    "qa system to perform": 1.0,
    "system to perform complex": 1.0,
    "to perform complex nlp": 1.0,
    "perform complex nlp techniques": 1.0,
    "complex nlp techniques to": 0.5,
    "nlp techniques to understand": 1.0,
    "techniques to understand the": 1.0,
    "to understand the text": 0.5,
    "understand the text is": 1.0,
    "the text is lessened": 1.0,
    "text is lessened .": 1.0,
    "<s> correct answers can": 1.0,
    "correct answers can be": 1.0,
    "answers can be filtered": 1.0,
    "can be filtered from": 0.3333333333333333,
    "be filtered from false": 1.0,
    "filtered from false positives": 1.0,
    "from false positives by": 1.0,
    "false positives by relying": 1.0,
    "positives by relying on": 1.0,
    "by relying on the": 1.0,
    "relying on the correct": 1.0,
    "on the correct answer": 1.0,
    "the correct answer to": 1.0,
    "correct answer to appear": 1.0,
    "answer to appear more": 1.0,
    "to appear more times": 1.0,
    "appear more times in": 1.0,
    "more times in the": 1.0,
    "times in the documents": 1.0,
    "in the documents than": 1.0,
    "the documents than instances": 1.0,
    "documents than instances of": 1.0,
    "than instances of incorrect": 1.0,
    "instances of incorrect ones": 1.0,
    "of incorrect ones .": 1.0,
    "<s> issues in 2002": 1.0,
    "issues in 2002 a": 1.0,
    "in 2002 a group": 1.0,
    "2002 a group of": 1.0,
    "a group of researchers": 1.0,
    "group of researchers wrote": 1.0,
    "of researchers wrote a": 1.0,
    "researchers wrote a roadmap": 1.0,
    "wrote a roadmap of": 1.0,
    "a roadmap of research": 1.0,
    "roadmap of research in": 1.0,
    "of research in question": 0.5,
    "research in question answering": 1.0,
    "in question answering .": 1.0,
    "<s> the following issues": 1.0,
    "the following issues were": 1.0,
    "following issues were identified": 1.0,
    "issues were identified .": 1.0,
    "<s> question classes different": 0.5,
    "question classes different types": 1.0,
    "classes different types of": 1.0,
    "different types of questions": 0.25,
    "types of questions -lrb-": 1.0,
    "of questions -lrb- e.g.": 1.0,
    "questions -lrb- e.g. ,": 1.0,
    "-lrb- e.g. , ``": 0.15789473684210525,
    "e.g. , `` what": 0.3333333333333333,
    ", `` what is": 1.0,
    "the capital of lichtenstein": 0.5,
    "capital of lichtenstein ?": 1.0,
    "of lichtenstein ? ''": 1.0,
    "<s> vs. `` why": 0.5,
    "vs. `` why does": 1.0,
    "`` why does a": 1.0,
    "why does a rainbow": 0.5,
    "does a rainbow form": 1.0,
    "a rainbow form ?": 1.0,
    "rainbow form ? ''": 1.0,
    "<s> vs. `` did": 0.5,
    "vs. `` did marilyn": 1.0,
    "`` did marilyn monroe": 1.0,
    "did marilyn monroe and": 1.0,
    "marilyn monroe and cary": 1.0,
    "monroe and cary grant": 1.0,
    "and cary grant ever": 1.0,
    "cary grant ever appear": 1.0,
    "grant ever appear in": 1.0,
    "ever appear in a": 1.0,
    "appear in a movie": 1.0,
    "in a movie together": 1.0,
    "a movie together ?": 1.0,
    "movie together ? ''": 1.0,
    "together ? '' -rrb-": 1.0,
    "<s> require the use": 1.0,
    "the use of different": 0.06666666666666667,
    "use of different strategies": 1.0,
    "of different strategies to": 1.0,
    "different strategies to find": 1.0,
    "strategies to find the": 1.0,
    "find the answer .": 0.5,
    "<s> question classes are": 0.5,
    "question classes are arranged": 1.0,
    "classes are arranged hierarchically": 1.0,
    "are arranged hierarchically in": 1.0,
    "arranged hierarchically in taxonomies": 1.0,
    "hierarchically in taxonomies .": 1.0,
    "<s> question processing the": 1.0,
    "question processing the same": 1.0,
    "processing the same information": 1.0,
    "the same information request": 1.0,
    "same information request can": 1.0,
    "information request can be": 1.0,
    "request can be expressed": 1.0,
    "can be expressed in": 0.3333333333333333,
    "be expressed in various": 1.0,
    "expressed in various ways": 1.0,
    "in various ways ,": 0.5,
    "various ways , some": 1.0,
    "ways , some interrogative": 1.0,
    ", some interrogative -lrb-": 1.0,
    "some interrogative -lrb- ``": 1.0,
    "interrogative -lrb- `` who": 1.0,
    "-lrb- `` who is": 1.0,
    "`` who is the": 1.0,
    "who is the president": 0.3333333333333333,
    "is the president of": 1.0,
    "the president of the": 1.0,
    "president of the united": 1.0,
    "the united states ?": 0.14285714285714285,
    "united states ? ''": 1.0,
    "states ? '' -rrb-": 1.0,
    "<s> and some assertive": 1.0,
    "and some assertive -lrb-": 1.0,
    "some assertive -lrb- ``": 1.0,
    "assertive -lrb- `` tell": 1.0,
    "-lrb- `` tell me": 1.0,
    "`` tell me the": 1.0,
    "tell me the name": 1.0,
    "me the name of": 1.0,
    "the name of the": 1.0,
    "name of the president": 1.0,
    "of the president of": 1.0,
    "united states . ''": 1.0,
    "states . '' -rrb-": 1.0,
    ". '' -rrb- .": 1.0,
    "<s> a semantic model": 1.0,
    "a semantic model of": 1.0,
    "semantic model of question": 1.0,
    "model of question understanding": 1.0,
    "of question understanding and": 1.0,
    "question understanding and processing": 1.0,
    "understanding and processing would": 1.0,
    "and processing would recognize": 1.0,
    "processing would recognize equivalent": 1.0,
    "would recognize equivalent questions": 1.0,
    "recognize equivalent questions ,": 1.0,
    "equivalent questions , regardless": 1.0,
    "questions , regardless of": 1.0,
    ", regardless of how": 0.3333333333333333,
    "regardless of how they": 1.0,
    "of how they are": 1.0,
    "how they are presented": 0.5,
    "they are presented .": 1.0,
    "<s> this model would": 0.5,
    "this model would enable": 1.0,
    "model would enable the": 1.0,
    "would enable the translation": 1.0,
    "enable the translation of": 1.0,
    "the translation of a": 0.3333333333333333,
    "translation of a complex": 0.5,
    "of a complex question": 0.5,
    "a complex question into": 1.0,
    "complex question into a": 1.0,
    "question into a series": 1.0,
    "into a series of": 1.0,
    "a series of simpler": 0.14285714285714285,
    "series of simpler questions": 1.0,
    "of simpler questions ,": 1.0,
    "simpler questions , would": 1.0,
    "questions , would identify": 1.0,
    ", would identify ambiguities": 1.0,
    "would identify ambiguities and": 1.0,
    "identify ambiguities and treat": 1.0,
    "ambiguities and treat them": 1.0,
    "and treat them in": 1.0,
    "treat them in context": 1.0,
    "them in context or": 1.0,
    "in context or by": 1.0,
    "context or by interactive": 1.0,
    "or by interactive clarification": 1.0,
    "by interactive clarification .": 1.0,
    "<s> context and qa": 1.0,
    "context and qa questions": 1.0,
    "and qa questions are": 1.0,
    "qa questions are usually": 1.0,
    "questions are usually asked": 1.0,
    "are usually asked within": 1.0,
    "usually asked within a": 1.0,
    "asked within a context": 1.0,
    "within a context and": 1.0,
    "a context and answers": 1.0,
    "context and answers are": 1.0,
    "and answers are provided": 1.0,
    "answers are provided within": 1.0,
    "are provided within that": 1.0,
    "provided within that specific": 1.0,
    "within that specific context": 1.0,
    "that specific context .": 1.0,
    "<s> the context can": 1.0,
    "the context can be": 1.0,
    "context can be used": 1.0,
    "can be used to": 0.6,
    "be used to clarify": 0.16666666666666666,
    "used to clarify a": 1.0,
    "to clarify a question": 1.0,
    "clarify a question ,": 1.0,
    "a question , resolve": 0.5,
    "question , resolve ambiguities": 1.0,
    ", resolve ambiguities or": 1.0,
    "resolve ambiguities or keep": 1.0,
    "ambiguities or keep track": 1.0,
    "or keep track of": 1.0,
    "keep track of an": 1.0,
    "track of an investigation": 1.0,
    "of an investigation performed": 1.0,
    "an investigation performed through": 1.0,
    "investigation performed through a": 1.0,
    "performed through a series": 1.0,
    "through a series of": 1.0,
    "a series of questions": 0.14285714285714285,
    "series of questions .": 1.0,
    "<s> -lrb- for example": 1.0,
    "example , the question": 0.25,
    ", the question ,": 1.0,
    "the question , ``": 0.4,
    "question , `` why": 0.5,
    ", `` why did": 1.0,
    "`` why did joe": 1.0,
    "why did joe biden": 1.0,
    "did joe biden visit": 1.0,
    "joe biden visit iraq": 1.0,
    "biden visit iraq in": 1.0,
    "visit iraq in january": 1.0,
    "iraq in january 2010": 1.0,
    "in january 2010 ?": 0.5,
    "january 2010 ? ''": 1.0,
    "<s> might be asking": 1.0,
    "might be asking why": 1.0,
    "be asking why vice": 1.0,
    "asking why vice president": 1.0,
    "why vice president biden": 1.0,
    "vice president biden visited": 1.0,
    "president biden visited and": 1.0,
    "biden visited and not": 1.0,
    "visited and not president": 1.0,
    "and not president obama": 1.0,
    "not president obama ,": 1.0,
    "president obama , why": 1.0,
    "obama , why he": 1.0,
    ", why he went": 1.0,
    "why he went to": 0.5,
    "he went to iraq": 1.0,
    "went to iraq and": 1.0,
    "to iraq and not": 1.0,
    "iraq and not afghanistan": 1.0,
    "and not afghanistan or": 1.0,
    "not afghanistan or some": 1.0,
    "afghanistan or some other": 1.0,
    "or some other country": 0.5,
    "some other country ,": 1.0,
    "other country , why": 1.0,
    "country , why he": 1.0,
    "why he went in": 0.5,
    "he went in january": 1.0,
    "went in january 2010": 1.0,
    "in january 2010 and": 0.5,
    "january 2010 and not": 1.0,
    "2010 and not before": 1.0,
    "and not before or": 1.0,
    "not before or after": 1.0,
    "before or after ,": 1.0,
    "or after , or": 1.0,
    "after , or what": 1.0,
    ", or what biden": 0.5,
    "or what biden was": 1.0,
    "what biden was hoping": 1.0,
    "biden was hoping to": 1.0,
    "was hoping to accomplish": 1.0,
    "hoping to accomplish with": 1.0,
    "to accomplish with his": 1.0,
    "accomplish with his visit": 1.0,
    "with his visit .": 1.0,
    "<s> if the question": 0.5,
    "the question is one": 0.3333333333333333,
    "question is one of": 1.0,
    "is one of a": 0.3333333333333333,
    "one of a series": 1.0,
    "a series of related": 0.14285714285714285,
    "series of related questions": 1.0,
    "of related questions ,": 1.0,
    "related questions , the": 1.0,
    "questions , the previous": 1.0,
    ", the previous questions": 1.0,
    "the previous questions and": 1.0,
    "previous questions and their": 1.0,
    "questions and their answers": 1.0,
    "and their answers might": 1.0,
    "their answers might shed": 1.0,
    "answers might shed light": 1.0,
    "might shed light on": 1.0,
    "shed light on the": 1.0,
    "light on the questioner": 1.0,
    "on the questioner 's": 1.0,
    "the questioner 's intent": 1.0,
    "questioner 's intent .": 1.0,
    "'s intent . -rrb-": 1.0,
    "<s> data sources for": 1.0,
    "data sources for qa": 1.0,
    "sources for qa before": 1.0,
    "for qa before a": 1.0,
    "qa before a question": 1.0,
    "before a question can": 1.0,
    "a question can be": 1.0,
    "question can be answered": 1.0,
    "can be answered ,": 1.0,
    "be answered , it": 1.0,
    "answered , it must": 1.0,
    ", it must be": 1.0,
    "it must be known": 1.0,
    "must be known what": 1.0,
    "be known what knowledge": 1.0,
    "known what knowledge sources": 1.0,
    "what knowledge sources are": 1.0,
    "knowledge sources are available": 1.0,
    "sources are available and": 1.0,
    "are available and relevant": 1.0,
    "available and relevant .": 1.0,
    "<s> if the answer": 0.5,
    "if the answer to": 0.5,
    "to a question is": 0.5,
    "a question is not": 1.0,
    "question is not present": 1.0,
    "is not present in": 1.0,
    "not present in the": 0.3333333333333333,
    "present in the data": 0.5,
    "in the data sources": 1.0,
    "the data sources ,": 0.5,
    "data sources , no": 1.0,
    "sources , no matter": 1.0,
    ", no matter how": 1.0,
    "no matter how well": 1.0,
    "matter how well the": 1.0,
    "how well the question": 1.0,
    "well the question processing": 1.0,
    "the question processing ,": 0.5,
    "question processing , information": 0.5,
    "processing , information retrieval": 1.0,
    ", information retrieval and": 1.0,
    "information retrieval and answer": 0.5,
    "retrieval and answer extraction": 1.0,
    "and answer extraction is": 1.0,
    "answer extraction is performed": 1.0,
    "extraction is performed ,": 1.0,
    "is performed , a": 1.0,
    "performed , a correct": 1.0,
    ", a correct result": 1.0,
    "a correct result will": 1.0,
    "correct result will not": 1.0,
    "result will not be": 1.0,
    "will not be obtained": 0.5,
    "not be obtained .": 1.0,
    "<s> answer extraction answer": 1.0,
    "answer extraction answer extraction": 1.0,
    "extraction answer extraction depends": 1.0,
    "answer extraction depends on": 1.0,
    "extraction depends on the": 1.0,
    "depends on the complexity": 0.2,
    "complexity of the question": 0.3333333333333333,
    "of the question ,": 0.6666666666666666,
    "the question , on": 0.2,
    "question , on the": 1.0,
    ", on the answer": 0.16666666666666666,
    "on the answer type": 1.0,
    "the answer type provided": 0.5,
    "answer type provided by": 1.0,
    "type provided by question": 1.0,
    "provided by question processing": 1.0,
    "by question processing ,": 1.0,
    "question processing , on": 0.5,
    "processing , on the": 1.0,
    ", on the actual": 0.16666666666666666,
    "on the actual data": 1.0,
    "the actual data where": 1.0,
    "actual data where the": 1.0,
    "data where the answer": 1.0,
    "where the answer is": 1.0,
    "the answer is searched": 0.5,
    "answer is searched ,": 1.0,
    "is searched , on": 1.0,
    "searched , on the": 1.0,
    ", on the search": 0.16666666666666666,
    "on the search method": 1.0,
    "the search method and": 1.0,
    "search method and on": 1.0,
    "method and on the": 1.0,
    "and on the question": 1.0,
    "on the question focus": 1.0,
    "the question focus and": 1.0,
    "question focus and context": 1.0,
    "focus and context .": 1.0,
    "<s> answer formulation the": 1.0,
    "answer formulation the result": 1.0,
    "formulation the result of": 1.0,
    "the result of a": 0.5,
    "result of a qa": 1.0,
    "of a qa system": 1.0,
    "a qa system should": 0.3333333333333333,
    "qa system should be": 1.0,
    "system should be presented": 1.0,
    "should be presented in": 1.0,
    "be presented in a": 1.0,
    "presented in a way": 0.5,
    "in a way as": 1.0,
    "a way as natural": 1.0,
    "way as natural as": 1.0,
    "as natural as possible": 1.0,
    "natural as possible .": 1.0,
    "some cases , simple": 0.5,
    "cases , simple extraction": 1.0,
    ", simple extraction is": 1.0,
    "simple extraction is sufficient": 1.0,
    "extraction is sufficient .": 1.0,
    "for example , when": 0.0425531914893617,
    "example , when the": 0.5,
    ", when the question": 0.3333333333333333,
    "when the question classification": 1.0,
    "the question classification indicates": 1.0,
    "question classification indicates that": 1.0,
    "classification indicates that the": 1.0,
    "indicates that the answer": 1.0,
    "that the answer type": 1.0,
    "the answer type is": 0.5,
    "answer type is a": 1.0,
    "type is a name": 1.0,
    "is a name -lrb-": 1.0,
    "a name -lrb- of": 1.0,
    "name -lrb- of a": 1.0,
    "-lrb- of a person": 1.0,
    "of a person ,": 0.3333333333333333,
    "a person , organization": 0.3333333333333333,
    "person , organization ,": 1.0,
    ", organization , shop": 1.0,
    "organization , shop or": 1.0,
    ", shop or disease": 1.0,
    "shop or disease ,": 1.0,
    "or disease , etc.": 1.0,
    "disease , etc. -rrb-": 1.0,
    "etc. -rrb- , a": 0.3333333333333333,
    "-rrb- , a quantity": 0.3333333333333333,
    ", a quantity -lrb-": 1.0,
    "a quantity -lrb- monetary": 1.0,
    "quantity -lrb- monetary value": 1.0,
    "-lrb- monetary value ,": 1.0,
    "monetary value , length": 1.0,
    "value , length ,": 1.0,
    ", length , size": 1.0,
    "length , size ,": 1.0,
    ", size , distance": 1.0,
    "size , distance ,": 1.0,
    ", distance , etc.": 1.0,
    "distance , etc. -rrb-": 1.0,
    ", etc. -rrb- or": 0.1111111111111111,
    "etc. -rrb- or a": 1.0,
    "-rrb- or a date": 1.0,
    "or a date -lrb-": 1.0,
    "a date -lrb- e.g.": 1.0,
    "date -lrb- e.g. the": 1.0,
    "-lrb- e.g. the answer": 0.3333333333333333,
    "e.g. the answer to": 1.0,
    "the answer to the": 0.25,
    "answer to the question": 1.0,
    "to the question ,": 1.0,
    "question , `` on": 0.5,
    ", `` on what": 1.0,
    "`` on what day": 1.0,
    "on what day did": 1.0,
    "what day did christmas": 1.0,
    "day did christmas fall": 1.0,
    "did christmas fall in": 1.0,
    "christmas fall in 1989": 1.0,
    "fall in 1989 ?": 1.0,
    "in 1989 ? ''": 1.0,
    "1989 ? '' -rrb-": 1.0,
    "<s> the extraction of": 1.0,
    "the extraction of a": 0.3333333333333333,
    "extraction of a single": 1.0,
    "of a single datum": 1.0,
    "a single datum is": 1.0,
    "single datum is sufficient": 1.0,
    "datum is sufficient .": 1.0,
    "<s> for other cases": 1.0,
    "for other cases ,": 1.0,
    "other cases , the": 1.0,
    "cases , the presentation": 0.5,
    ", the presentation of": 1.0,
    "the presentation of the": 1.0,
    "presentation of the answer": 1.0,
    "of the answer may": 1.0,
    "the answer may require": 1.0,
    "answer may require the": 1.0,
    "may require the use": 1.0,
    "the use of fusion": 0.06666666666666667,
    "use of fusion techniques": 1.0,
    "of fusion techniques that": 1.0,
    "fusion techniques that combine": 1.0,
    "techniques that combine the": 1.0,
    "that combine the partial": 1.0,
    "combine the partial answers": 1.0,
    "the partial answers from": 1.0,
    "partial answers from multiple": 1.0,
    "answers from multiple documents": 1.0,
    "from multiple documents .": 1.0,
    "<s> real time question": 1.0,
    "real time question answering": 1.0,
    "time question answering there": 1.0,
    "question answering there is": 1.0,
    "answering there is need": 1.0,
    "there is need for": 1.0,
    "is need for developing": 1.0,
    "need for developing q&a": 1.0,
    "for developing q&a systems": 1.0,
    "developing q&a systems that": 1.0,
    "q&a systems that are": 1.0,
    "systems that are capable": 0.5,
    "that are capable of": 1.0,
    "are capable of extracting": 0.5,
    "capable of extracting answers": 1.0,
    "of extracting answers from": 1.0,
    "extracting answers from large": 1.0,
    "answers from large data": 1.0,
    "from large data sets": 1.0,
    "large data sets in": 1.0,
    "data sets in several": 1.0,
    "sets in several seconds": 1.0,
    "in several seconds ,": 1.0,
    "several seconds , regardless": 1.0,
    "seconds , regardless of": 1.0,
    ", regardless of the": 0.3333333333333333,
    "regardless of the complexity": 0.5,
    "of the complexity of": 1.0,
    "the question , the": 0.2,
    "question , the size": 0.5,
    ", the size and": 1.0,
    "the size and multitude": 1.0,
    "size and multitude of": 1.0,
    "and multitude of the": 1.0,
    "multitude of the data": 1.0,
    "of the data sources": 1.0,
    "the data sources or": 0.5,
    "data sources or the": 1.0,
    "sources or the ambiguity": 1.0,
    "or the ambiguity of": 1.0,
    "the ambiguity of the": 1.0,
    "ambiguity of the question": 1.0,
    "of the question .": 0.3333333333333333,
    "<s> multilingual -lrb- or": 1.0,
    "multilingual -lrb- or cross-lingual": 1.0,
    "-lrb- or cross-lingual -rrb-": 1.0,
    "or cross-lingual -rrb- question": 1.0,
    "cross-lingual -rrb- question answering": 1.0,
    "-rrb- question answering the": 1.0,
    "question answering the ability": 1.0,
    "answering the ability to": 1.0,
    "the ability to answer": 0.5,
    "ability to answer a": 1.0,
    "to answer a question": 1.0,
    "answer a question posed": 1.0,
    "question posed in one": 0.5,
    "posed in one language": 1.0,
    "in one language using": 1.0,
    "one language using an": 1.0,
    "language using an answer": 1.0,
    "using an answer corpus": 1.0,
    "an answer corpus in": 1.0,
    "answer corpus in another": 1.0,
    "corpus in another language": 1.0,
    "in another language -lrb-": 0.5,
    "another language -lrb- or": 1.0,
    "language -lrb- or even": 1.0,
    "-lrb- or even several": 1.0,
    "or even several -rrb-": 1.0,
    "even several -rrb- .": 1.0,
    "<s> this allows users": 0.5,
    "this allows users to": 1.0,
    "allows users to consult": 0.5,
    "users to consult information": 1.0,
    "to consult information that": 1.0,
    "consult information that they": 1.0,
    "information that they can": 1.0,
    "that they can not": 0.3333333333333333,
    "they can not use": 1.0,
    "can not use directly": 1.0,
    "not use directly .": 1.0,
    "<s> -lrb- see also": 0.3333333333333333,
    "-lrb- see also machine": 1.0,
    "see also machine translation": 1.0,
    "also machine translation .": 1.0,
    "machine translation . -rrb-": 1.0,
    "<s> interactive qa it": 1.0,
    "interactive qa it is": 1.0,
    "qa it is often": 1.0,
    "it is often the": 0.16666666666666666,
    "is often the case": 1.0,
    "often the case that": 1.0,
    "the case that the": 1.0,
    "case that the information": 1.0,
    "that the information need": 1.0,
    "the information need is": 1.0,
    "information need is not": 1.0,
    "need is not well": 1.0,
    "is not well captured": 1.0,
    "not well captured by": 1.0,
    "well captured by a": 1.0,
    "captured by a qa": 1.0,
    "by a qa system": 1.0,
    "a qa system ,": 0.3333333333333333,
    "qa system , as": 1.0,
    "system , as the": 1.0,
    ", as the question": 1.0,
    "as the question processing": 1.0,
    "the question processing part": 0.5,
    "question processing part may": 1.0,
    "processing part may fail": 1.0,
    "part may fail to": 1.0,
    "may fail to classify": 1.0,
    "fail to classify properly": 1.0,
    "to classify properly the": 1.0,
    "classify properly the question": 1.0,
    "properly the question or": 1.0,
    "the question or the": 1.0,
    "question or the information": 1.0,
    "or the information needed": 1.0,
    "the information needed for": 1.0,
    "information needed for extracting": 1.0,
    "needed for extracting and": 1.0,
    "for extracting and generating": 1.0,
    "extracting and generating the": 1.0,
    "and generating the answer": 1.0,
    "generating the answer is": 1.0,
    "the answer is not": 0.5,
    "answer is not easily": 1.0,
    "is not easily retrieved": 1.0,
    "not easily retrieved .": 1.0,
    "<s> in such cases": 1.0,
    "in such cases ,": 0.5,
    "such cases , the": 1.0,
    "cases , the questioner": 0.5,
    ", the questioner might": 1.0,
    "the questioner might want": 1.0,
    "questioner might want not": 1.0,
    "might want not only": 1.0,
    "want not only to": 1.0,
    "not only to reformulate": 1.0,
    "only to reformulate the": 1.0,
    "to reformulate the question": 1.0,
    "reformulate the question ,": 1.0,
    "the question , but": 0.2,
    "question , but to": 1.0,
    ", but to have": 1.0,
    "but to have a": 1.0,
    "to have a dialogue": 0.25,
    "have a dialogue with": 1.0,
    "a dialogue with the": 1.0,
    "dialogue with the system": 1.0,
    "with the system .": 1.0,
    "example , the system": 0.25,
    ", the system might": 0.25,
    "the system might ask": 1.0,
    "system might ask for": 1.0,
    "might ask for a": 1.0,
    "ask for a clarification": 1.0,
    "for a clarification of": 1.0,
    "a clarification of what": 1.0,
    "clarification of what sense": 1.0,
    "of what sense a": 1.0,
    "what sense a word": 1.0,
    "sense a word is": 1.0,
    "a word is being": 0.5,
    "word is being used": 1.0,
    "is being used ,": 1.0,
    "being used , or": 1.0,
    "used , or what": 1.0,
    ", or what type": 0.5,
    "or what type of": 1.0,
    "what type of information": 1.0,
    "type of information is": 1.0,
    "of information is being": 1.0,
    "information is being asked": 1.0,
    "is being asked for": 1.0,
    "being asked for .": 1.0,
    "asked for . -rrb-": 1.0,
    "<s> advanced reasoning for": 1.0,
    "advanced reasoning for qa": 1.0,
    "reasoning for qa more": 1.0,
    "for qa more sophisticated": 1.0,
    "qa more sophisticated questioners": 1.0,
    "more sophisticated questioners expect": 1.0,
    "sophisticated questioners expect answers": 1.0,
    "questioners expect answers that": 1.0,
    "expect answers that are": 1.0,
    "answers that are outside": 1.0,
    "that are outside the": 1.0,
    "are outside the scope": 1.0,
    "outside the scope of": 1.0,
    "the scope of written": 0.5,
    "scope of written texts": 1.0,
    "of written texts or": 1.0,
    "written texts or structured": 1.0,
    "texts or structured databases": 1.0,
    "or structured databases .": 1.0,
    "<s> to upgrade a": 1.0,
    "to upgrade a qa": 1.0,
    "upgrade a qa system": 1.0,
    "a qa system with": 0.3333333333333333,
    "qa system with such": 1.0,
    "system with such capabilities": 1.0,
    "with such capabilities ,": 1.0,
    "such capabilities , it": 1.0,
    "capabilities , it would": 1.0,
    ", it would be": 1.0,
    "it would be necessary": 0.5,
    "would be necessary to": 1.0,
    "be necessary to integrate": 1.0,
    "necessary to integrate reasoning": 1.0,
    "to integrate reasoning components": 1.0,
    "integrate reasoning components operating": 1.0,
    "reasoning components operating on": 1.0,
    "components operating on a": 1.0,
    "operating on a variety": 1.0,
    "on a variety of": 1.0,
    "a variety of knowledge": 0.14285714285714285,
    "variety of knowledge bases": 1.0,
    "of knowledge bases ,": 1.0,
    "knowledge bases , encoding": 1.0,
    "bases , encoding world": 1.0,
    ", encoding world knowledge": 1.0,
    "encoding world knowledge and": 1.0,
    "world knowledge and common-sense": 1.0,
    "knowledge and common-sense reasoning": 1.0,
    "and common-sense reasoning mechanisms": 1.0,
    "common-sense reasoning mechanisms ,": 1.0,
    "reasoning mechanisms , as": 1.0,
    "mechanisms , as well": 1.0,
    "as well as knowledge": 0.07692307692307693,
    "well as knowledge specific": 1.0,
    "as knowledge specific to": 1.0,
    "knowledge specific to a": 1.0,
    "specific to a variety": 1.0,
    "to a variety of": 1.0,
    "a variety of domains": 0.14285714285714285,
    "variety of domains .": 1.0,
    "<s> user profiling for": 1.0,
    "user profiling for qa": 1.0,
    "profiling for qa the": 1.0,
    "for qa the user": 1.0,
    "qa the user profile": 1.0,
    "the user profile captures": 1.0,
    "user profile captures data": 1.0,
    "profile captures data about": 1.0,
    "captures data about the": 1.0,
    "data about the questioner": 1.0,
    "about the questioner ,": 1.0,
    "the questioner , comprising": 0.5,
    "questioner , comprising context": 1.0,
    ", comprising context data": 1.0,
    "comprising context data ,": 1.0,
    "context data , domain": 1.0,
    "data , domain of": 1.0,
    ", domain of interest": 1.0,
    "domain of interest ,": 1.0,
    "of interest , reasoning": 1.0,
    "interest , reasoning schemes": 1.0,
    ", reasoning schemes frequently": 1.0,
    "reasoning schemes frequently used": 1.0,
    "schemes frequently used by": 1.0,
    "frequently used by the": 1.0,
    "used by the questioner": 1.0,
    "by the questioner ,": 1.0,
    "the questioner , common": 0.5,
    "questioner , common ground": 1.0,
    ", common ground established": 1.0,
    "common ground established within": 1.0,
    "ground established within different": 1.0,
    "established within different dialogues": 1.0,
    "within different dialogues between": 1.0,
    "different dialogues between the": 1.0,
    "dialogues between the system": 1.0,
    "between the system and": 1.0,
    "the system and the": 1.0,
    "system and the user": 1.0,
    "and the user ,": 1.0,
    "the user , and": 1.0,
    "user , and so": 1.0,
    ", and so forth": 0.16666666666666666,
    "and so forth .": 1.0,
    "<s> the profile may": 1.0,
    "the profile may be": 1.0,
    "profile may be represented": 1.0,
    "may be represented as": 1.0,
    "be represented as a": 1.0,
    "represented as a predefined": 1.0,
    "as a predefined template": 1.0,
    "a predefined template ,": 1.0,
    "predefined template , where": 1.0,
    "template , where each": 1.0,
    ", where each template": 1.0,
    "where each template slot": 1.0,
    "each template slot represents": 1.0,
    "template slot represents a": 1.0,
    "slot represents a different": 1.0,
    "represents a different profile": 1.0,
    "a different profile feature": 1.0,
    "different profile feature .": 1.0,
    "<s> profile templates may": 1.0,
    "profile templates may be": 1.0,
    "templates may be nested": 1.0,
    "may be nested one": 1.0,
    "be nested one within": 1.0,
    "nested one within another": 1.0,
    "one within another .": 1.0,
    "<s> history some of": 1.0,
    "history some of the": 1.0,
    "some of the early": 0.2,
    "of the early ai": 1.0,
    "the early ai systems": 1.0,
    "early ai systems were": 0.5,
    "ai systems were question": 1.0,
    "systems were question answering": 1.0,
    "were question answering systems": 1.0,
    "question answering systems .": 1.0,
    "<s> two of the": 1.0,
    "two of the most": 1.0,
    "of the most famous": 0.3333333333333333,
    "the most famous qa": 0.5,
    "most famous qa systems": 1.0,
    "famous qa systems of": 1.0,
    "qa systems of that": 1.0,
    "systems of that time": 1.0,
    "of that time are": 1.0,
    "that time are baseball": 1.0,
    "time are baseball and": 1.0,
    "are baseball and lunar": 1.0,
    "baseball and lunar ,": 1.0,
    "and lunar , both": 1.0,
    "lunar , both of": 1.0,
    "both of which were": 0.5,
    "of which were developed": 1.0,
    "which were developed in": 1.0,
    "were developed in the": 1.0,
    "in the 1960s .": 0.5,
    "<s> baseball answered questions": 1.0,
    "baseball answered questions about": 1.0,
    "answered questions about the": 1.0,
    "questions about the us": 0.3333333333333333,
    "about the us baseball": 1.0,
    "the us baseball league": 1.0,
    "us baseball league over": 1.0,
    "baseball league over a": 1.0,
    "league over a period": 1.0,
    "over a period of": 1.0,
    "a period of one": 1.0,
    "period of one year": 1.0,
    "of one year .": 1.0,
    "<s> lunar , in": 1.0,
    "lunar , in turn": 1.0,
    ", in turn ,": 1.0,
    "in turn , answered": 1.0,
    "turn , answered questions": 1.0,
    ", answered questions about": 1.0,
    "questions about the geological": 0.3333333333333333,
    "about the geological analysis": 1.0,
    "the geological analysis of": 1.0,
    "geological analysis of rocks": 1.0,
    "analysis of rocks returned": 1.0,
    "of rocks returned by": 1.0,
    "rocks returned by the": 1.0,
    "returned by the apollo": 1.0,
    "by the apollo moon": 1.0,
    "the apollo moon missions": 1.0,
    "apollo moon missions .": 1.0,
    "<s> both qa systems": 1.0,
    "both qa systems were": 1.0,
    "qa systems were very": 0.5,
    "systems were very effective": 1.0,
    "were very effective in": 1.0,
    "very effective in their": 1.0,
    "effective in their chosen": 1.0,
    "in their chosen domains": 1.0,
    "their chosen domains .": 1.0,
    "in fact , lunar": 0.25,
    "fact , lunar was": 1.0,
    ", lunar was demonstrated": 1.0,
    "lunar was demonstrated at": 1.0,
    "was demonstrated at a": 1.0,
    "demonstrated at a lunar": 1.0,
    "at a lunar science": 1.0,
    "a lunar science convention": 1.0,
    "lunar science convention in": 1.0,
    "science convention in 1971": 1.0,
    "convention in 1971 and": 1.0,
    "in 1971 and it": 1.0,
    "1971 and it was": 1.0,
    "and it was able": 1.0,
    "it was able to": 1.0,
    "was able to answer": 0.25,
    "able to answer 90": 1.0,
    "to answer 90 %": 1.0,
    "answer 90 % of": 1.0,
    "90 % of the": 0.5,
    "% of the questions": 0.2,
    "of the questions in": 1.0,
    "the questions in its": 1.0,
    "questions in its domain": 1.0,
    "in its domain posed": 1.0,
    "its domain posed by": 1.0,
    "domain posed by people": 1.0,
    "posed by people untrained": 1.0,
    "by people untrained on": 1.0,
    "people untrained on the": 1.0,
    "untrained on the system": 1.0,
    "on the system .": 1.0,
    "<s> further restricted-domain qa": 1.0,
    "further restricted-domain qa systems": 1.0,
    "restricted-domain qa systems were": 1.0,
    "qa systems were developed": 0.5,
    "systems were developed in": 0.5,
    "developed in the following": 0.16666666666666666,
    "in the following years": 0.3333333333333333,
    "the following years .": 1.0,
    "<s> the common feature": 1.0,
    "the common feature of": 1.0,
    "common feature of all": 1.0,
    "feature of all these": 1.0,
    "of all these systems": 1.0,
    "all these systems is": 1.0,
    "these systems is that": 1.0,
    "systems is that they": 1.0,
    "is that they had": 0.5,
    "that they had a": 1.0,
    "they had a core": 1.0,
    "had a core database": 1.0,
    "a core database or": 1.0,
    "core database or knowledge": 1.0,
    "database or knowledge system": 1.0,
    "or knowledge system that": 1.0,
    "knowledge system that was": 1.0,
    "system that was hand-written": 1.0,
    "that was hand-written by": 1.0,
    "was hand-written by experts": 1.0,
    "hand-written by experts of": 1.0,
    "by experts of the": 1.0,
    "experts of the chosen": 1.0,
    "of the chosen domain": 1.0,
    "the chosen domain .": 1.0,
    "early ai systems included": 0.5,
    "ai systems included question-answering": 1.0,
    "systems included question-answering abilities": 1.0,
    "included question-answering abilities .": 1.0,
    "the most famous early": 0.5,
    "most famous early systems": 1.0,
    "famous early systems are": 1.0,
    "early systems are shrdlu": 1.0,
    "systems are shrdlu and": 1.0,
    "are shrdlu and eliza": 1.0,
    "shrdlu and eliza .": 1.0,
    "<s> shrdlu simulated the": 1.0,
    "shrdlu simulated the operation": 1.0,
    "simulated the operation of": 1.0,
    "the operation of a": 1.0,
    "operation of a robot": 1.0,
    "of a robot in": 1.0,
    "a robot in a": 1.0,
    "robot in a toy": 1.0,
    "in a toy world": 1.0,
    "a toy world -lrb-": 1.0,
    "toy world -lrb- the": 1.0,
    "world -lrb- the ``": 1.0,
    "-lrb- the `` blocks": 1.0,
    "the `` blocks world": 1.0,
    "`` blocks world ''": 1.0,
    "blocks world '' -rrb-": 1.0,
    "world '' -rrb- ,": 1.0,
    ", and it offered": 0.25,
    "and it offered the": 1.0,
    "it offered the possibility": 1.0,
    "offered the possibility to": 1.0,
    "the possibility to ask": 1.0,
    "possibility to ask the": 1.0,
    "to ask the robot": 1.0,
    "ask the robot questions": 1.0,
    "the robot questions about": 1.0,
    "robot questions about the": 1.0,
    "questions about the state": 0.3333333333333333,
    "about the state of": 1.0,
    "the state of the": 1.0,
    "state of the world": 0.25,
    "of the world .": 0.5,
    "<s> again , the": 1.0,
    "again , the strength": 1.0,
    ", the strength of": 1.0,
    "the strength of this": 0.5,
    "strength of this system": 1.0,
    "of this system was": 1.0,
    "this system was the": 1.0,
    "system was the choice": 0.5,
    "was the choice of": 1.0,
    "the choice of a": 0.5,
    "choice of a very": 1.0,
    "of a very specific": 1.0,
    "a very specific domain": 1.0,
    "very specific domain and": 1.0,
    "specific domain and a": 1.0,
    "domain and a very": 1.0,
    "and a very simple": 1.0,
    "a very simple world": 1.0,
    "very simple world with": 1.0,
    "simple world with rules": 1.0,
    "world with rules of": 1.0,
    "with rules of physics": 1.0,
    "rules of physics that": 1.0,
    "of physics that were": 1.0,
    "physics that were easy": 1.0,
    "that were easy to": 1.0,
    "were easy to encode": 1.0,
    "easy to encode in": 1.0,
    "to encode in a": 1.0,
    "encode in a computer": 1.0,
    "in a computer program": 1.0,
    "<s> eliza , in": 1.0,
    "eliza , in contrast": 1.0,
    ", in contrast ,": 1.0,
    "in contrast , simulated": 0.2,
    "contrast , simulated a": 1.0,
    ", simulated a conversation": 1.0,
    "simulated a conversation with": 1.0,
    "a conversation with a": 1.0,
    "conversation with a psychologist": 0.5,
    "with a psychologist .": 1.0,
    "<s> eliza was able": 1.0,
    "eliza was able to": 1.0,
    "was able to converse": 0.25,
    "able to converse on": 1.0,
    "to converse on any": 1.0,
    "converse on any topic": 1.0,
    "on any topic by": 0.5,
    "any topic by resorting": 1.0,
    "topic by resorting to": 1.0,
    "by resorting to very": 1.0,
    "resorting to very simple": 1.0,
    "to very simple rules": 1.0,
    "very simple rules that": 1.0,
    "simple rules that detected": 1.0,
    "rules that detected important": 1.0,
    "that detected important words": 1.0,
    "detected important words in": 1.0,
    "important words in the": 1.0,
    "words in the person": 0.25,
    "in the person 's": 1.0,
    "the person 's input": 0.5,
    "person 's input .": 1.0,
    "<s> it had a": 1.0,
    "it had a very": 1.0,
    "had a very rudimentary": 1.0,
    "a very rudimentary way": 1.0,
    "very rudimentary way to": 1.0,
    "rudimentary way to answer": 1.0,
    "way to answer questions": 1.0,
    "to answer questions ,": 1.0,
    "answer questions , and": 1.0,
    "questions , and on": 0.5,
    ", and on its": 1.0,
    "and on its own": 1.0,
    "on its own it": 0.5,
    "its own it led": 1.0,
    "own it led to": 1.0,
    "it led to a": 1.0,
    "led to a series": 1.0,
    "to a series of": 1.0,
    "a series of chatterbots": 0.14285714285714285,
    "series of chatterbots such": 1.0,
    "of chatterbots such as": 1.0,
    "chatterbots such as the": 1.0,
    "such as the ones": 0.07142857142857142,
    "as the ones that": 1.0,
    "the ones that participate": 1.0,
    "ones that participate in": 1.0,
    "that participate in the": 1.0,
    "participate in the annual": 1.0,
    "in the annual loebner": 1.0,
    "the annual loebner prize": 1.0,
    "annual loebner prize .": 1.0,
    "<s> the 1970s and": 1.0,
    "1970s and 1980s saw": 0.5,
    "and 1980s saw the": 1.0,
    "1980s saw the development": 1.0,
    "saw the development of": 1.0,
    "the development of comprehensive": 0.2,
    "development of comprehensive theories": 1.0,
    "of comprehensive theories in": 1.0,
    "comprehensive theories in computational": 1.0,
    "theories in computational linguistics": 1.0,
    "in computational linguistics ,": 1.0,
    "computational linguistics , which": 0.3333333333333333,
    "linguistics , which led": 1.0,
    ", which led to": 1.0,
    "which led to the": 1.0,
    "led to the development": 1.0,
    "to the development of": 1.0,
    "the development of ambitious": 0.2,
    "development of ambitious projects": 1.0,
    "of ambitious projects in": 1.0,
    "ambitious projects in text": 1.0,
    "projects in text comprehension": 1.0,
    "in text comprehension and": 1.0,
    "text comprehension and question": 1.0,
    "comprehension and question answering": 1.0,
    "and question answering .": 1.0,
    "<s> one example of": 1.0,
    "one example of such": 1.0,
    "of such a system": 0.3333333333333333,
    "such a system was": 1.0,
    "a system was the": 1.0,
    "system was the unix": 0.5,
    "was the unix consultant": 1.0,
    "the unix consultant -lrb-": 1.0,
    "unix consultant -lrb- uc": 1.0,
    "consultant -lrb- uc -rrb-": 1.0,
    "-lrb- uc -rrb- ,": 1.0,
    "uc -rrb- , a": 1.0,
    "-rrb- , a system": 0.3333333333333333,
    ", a system that": 0.5,
    "a system that answered": 1.0,
    "system that answered questions": 1.0,
    "that answered questions pertaining": 1.0,
    "answered questions pertaining to": 1.0,
    "questions pertaining to the": 1.0,
    "pertaining to the unix": 1.0,
    "to the unix operating": 1.0,
    "the unix operating system": 1.0,
    "unix operating system .": 1.0,
    "<s> the system had": 0.16666666666666666,
    "the system had a": 1.0,
    "system had a comprehensive": 1.0,
    "had a comprehensive hand-crafted": 1.0,
    "a comprehensive hand-crafted knowledge": 1.0,
    "comprehensive hand-crafted knowledge base": 1.0,
    "hand-crafted knowledge base of": 1.0,
    "knowledge base of its": 1.0,
    "base of its domain": 1.0,
    "of its domain ,": 1.0,
    "its domain , and": 1.0,
    "domain , and it": 1.0,
    ", and it aimed": 0.25,
    "and it aimed at": 1.0,
    "it aimed at phrasing": 1.0,
    "aimed at phrasing the": 1.0,
    "at phrasing the answer": 1.0,
    "phrasing the answer to": 1.0,
    "the answer to accommodate": 0.25,
    "answer to accommodate various": 1.0,
    "to accommodate various types": 1.0,
    "accommodate various types of": 1.0,
    "various types of users": 0.5,
    "types of users .": 1.0,
    "<s> another project was": 1.0,
    "another project was lilog": 1.0,
    "project was lilog ,": 1.0,
    "was lilog , a": 1.0,
    "lilog , a text-understanding": 1.0,
    ", a text-understanding system": 1.0,
    "a text-understanding system that": 1.0,
    "text-understanding system that operated": 1.0,
    "system that operated on": 1.0,
    "that operated on the": 1.0,
    "operated on the domain": 1.0,
    "on the domain of": 1.0,
    "the domain of tourism": 1.0,
    "domain of tourism information": 1.0,
    "of tourism information in": 1.0,
    "tourism information in a": 1.0,
    "information in a german": 1.0,
    "in a german city": 1.0,
    "a german city .": 1.0,
    "<s> the systems developed": 1.0,
    "the systems developed in": 1.0,
    "developed in the uc": 0.16666666666666666,
    "in the uc and": 1.0,
    "the uc and lilog": 1.0,
    "uc and lilog projects": 1.0,
    "and lilog projects never": 1.0,
    "lilog projects never went": 1.0,
    "projects never went past": 1.0,
    "never went past the": 1.0,
    "went past the stage": 1.0,
    "past the stage of": 1.0,
    "the stage of simple": 1.0,
    "stage of simple demonstrations": 1.0,
    "of simple demonstrations ,": 1.0,
    "simple demonstrations , but": 1.0,
    "demonstrations , but they": 1.0,
    ", but they helped": 0.3333333333333333,
    "but they helped the": 1.0,
    "they helped the development": 1.0,
    "helped the development of": 1.0,
    "the development of theories": 0.2,
    "development of theories on": 1.0,
    "of theories on computational": 1.0,
    "theories on computational linguistics": 1.0,
    "on computational linguistics and": 1.0,
    "computational linguistics and reasoning": 1.0,
    "linguistics and reasoning .": 1.0,
    "<s> an increasing number": 1.0,
    "an increasing number of": 1.0,
    "increasing number of systems": 1.0,
    "number of systems include": 1.0,
    "of systems include the": 1.0,
    "systems include the world": 1.0,
    "include the world wide": 1.0,
    "world wide web as": 0.25,
    "wide web as one": 1.0,
    "web as one more": 1.0,
    "as one more corpus": 1.0,
    "one more corpus of": 1.0,
    "more corpus of text": 1.0,
    "corpus of text .": 0.5,
    "of text . .": 1.0,
    "<s> however , these": 0.03125,
    "however , these tools": 1.0,
    ", these tools mostly": 1.0,
    "these tools mostly work": 1.0,
    "tools mostly work by": 1.0,
    "mostly work by using": 1.0,
    "work by using shallow": 1.0,
    "by using shallow methods": 1.0,
    "using shallow methods ,": 1.0,
    "shallow methods , as": 1.0,
    "methods , as described": 1.0,
    ", as described above": 1.0,
    "as described above --": 0.5,
    "described above -- thus": 1.0,
    "above -- thus returning": 1.0,
    "-- thus returning a": 1.0,
    "thus returning a list": 1.0,
    "returning a list of": 1.0,
    "a list of documents": 0.16666666666666666,
    "list of documents ,": 1.0,
    "of documents , usually": 0.5,
    "documents , usually with": 1.0,
    ", usually with an": 0.5,
    "usually with an excerpt": 1.0,
    "with an excerpt containing": 1.0,
    "an excerpt containing the": 1.0,
    "excerpt containing the probable": 1.0,
    "containing the probable answer": 1.0,
    "the probable answer highlighted": 1.0,
    "probable answer highlighted ,": 1.0,
    "answer highlighted , plus": 1.0,
    "highlighted , plus some": 1.0,
    ", plus some context": 1.0,
    "plus some context .": 1.0,
    "<s> furthermore , highly-specialized": 0.16666666666666666,
    "furthermore , highly-specialized natural": 1.0,
    ", highly-specialized natural language": 1.0,
    "highly-specialized natural language question-answering": 1.0,
    "natural language question-answering engines": 1.0,
    "language question-answering engines ,": 1.0,
    "question-answering engines , such": 1.0,
    "engines , such as": 1.0,
    ", such as eagli": 0.030303030303030304,
    "such as eagli for": 1.0,
    "as eagli for health": 1.0,
    "eagli for health and": 1.0,
    "for health and life": 1.0,
    "health and life scientists": 1.0,
    "and life scientists ,": 1.0,
    "life scientists , have": 1.0,
    "scientists , have been": 1.0,
    ", have been made": 1.0,
    "have been made available": 1.0,
    "been made available .": 1.0,
    "<s> the future of": 1.0,
    "the future of question": 1.0,
    "future of question answering": 1.0,
    "of question answering qa": 1.0,
    "question answering qa systems": 1.0,
    "answering qa systems have": 1.0,
    "qa systems have been": 1.0,
    "systems have been extended": 0.3333333333333333,
    "have been extended in": 1.0,
    "been extended in recent": 1.0,
    "extended in recent years": 1.0,
    "in recent years to": 0.25,
    "recent years to explore": 1.0,
    "years to explore critical": 1.0,
    "to explore critical new": 1.0,
    "explore critical new scientific": 1.0,
    "critical new scientific and": 1.0,
    "new scientific and practical": 1.0,
    "scientific and practical dimensions": 1.0,
    "and practical dimensions for": 1.0,
    "practical dimensions for example": 1.0,
    "dimensions for example ,": 1.0,
    "for example , systems": 0.02127659574468085,
    "example , systems have": 1.0,
    ", systems have been": 1.0,
    "systems have been developed": 0.3333333333333333,
    "have been developed to": 1.0,
    "been developed to automatically": 1.0,
    "developed to automatically answer": 1.0,
    "to automatically answer temporal": 1.0,
    "automatically answer temporal and": 1.0,
    "answer temporal and geospatial": 1.0,
    "temporal and geospatial questions": 1.0,
    "and geospatial questions ,": 1.0,
    "geospatial questions , definitional": 1.0,
    "questions , definitional questions": 1.0,
    ", definitional questions ,": 1.0,
    "definitional questions , biographical": 1.0,
    "questions , biographical questions": 1.0,
    ", biographical questions ,": 1.0,
    "biographical questions , multilingual": 1.0,
    "questions , multilingual questions": 1.0,
    ", multilingual questions ,": 1.0,
    "multilingual questions , and": 1.0,
    "questions , and questions": 0.5,
    ", and questions from": 1.0,
    "and questions from multimedia": 1.0,
    "questions from multimedia -lrb-": 1.0,
    "from multimedia -lrb- e.g.": 1.0,
    "multimedia -lrb- e.g. ,": 1.0,
    "-lrb- e.g. , audio": 0.05263157894736842,
    "e.g. , audio ,": 1.0,
    ", audio , imagery": 0.5,
    "audio , imagery ,": 1.0,
    ", imagery , video": 1.0,
    "imagery , video -rrb-": 1.0,
    ", video -rrb- .": 1.0,
    "<s> additional aspects such": 1.0,
    "additional aspects such as": 1.0,
    "aspects such as interactivity": 1.0,
    "such as interactivity -lrb-": 1.0,
    "as interactivity -lrb- often": 1.0,
    "interactivity -lrb- often required": 1.0,
    "-lrb- often required for": 1.0,
    "often required for clarification": 1.0,
    "required for clarification of": 1.0,
    "for clarification of questions": 1.0,
    "clarification of questions or": 1.0,
    "of questions or answers": 1.0,
    "questions or answers -rrb-": 1.0,
    "or answers -rrb- ,": 1.0,
    "answers -rrb- , answer": 1.0,
    "-rrb- , answer reuse": 1.0,
    ", answer reuse ,": 1.0,
    "answer reuse , and": 1.0,
    "reuse , and knowledge": 1.0,
    ", and knowledge representation": 1.0,
    "and knowledge representation and": 1.0,
    "knowledge representation and reasoning": 1.0,
    "representation and reasoning to": 1.0,
    "and reasoning to support": 1.0,
    "reasoning to support question": 1.0,
    "to support question answering": 1.0,
    "support question answering have": 1.0,
    "question answering have been": 1.0,
    "answering have been explored": 1.0,
    "have been explored .": 1.0,
    "<s> future research may": 1.0,
    "future research may explore": 1.0,
    "research may explore what": 1.0,
    "may explore what kinds": 1.0,
    "explore what kinds of": 1.0,
    "what kinds of questions": 1.0,
    "kinds of questions can": 1.0,
    "of questions can be": 1.0,
    "questions can be asked": 1.0,
    "can be asked and": 1.0,
    "be asked and answered": 1.0,
    "asked and answered about": 1.0,
    "and answered about social": 1.0,
    "answered about social media": 1.0,
    "about social media ,": 1.0,
    "social media , including": 0.5,
    "media , including sentiment": 1.0,
    ", including sentiment analysis": 1.0,
    "including sentiment analysis .": 1.0,
    "<s> a relationship extraction": 1.0,
    "a relationship extraction task": 1.0,
    "relationship extraction task requires": 1.0,
    "extraction task requires the": 1.0,
    "task requires the detection": 1.0,
    "requires the detection and": 1.0,
    "the detection and classification": 1.0,
    "detection and classification of": 1.0,
    "and classification of semantic": 1.0,
    "classification of semantic relationship": 1.0,
    "of semantic relationship mentions": 1.0,
    "semantic relationship mentions within": 1.0,
    "relationship mentions within a": 1.0,
    "mentions within a set": 1.0,
    "within a set of": 1.0,
    "a set of artifacts": 0.07142857142857142,
    "set of artifacts ,": 1.0,
    "of artifacts , typically": 1.0,
    "artifacts , typically from": 1.0,
    ", typically from text": 1.0,
    "typically from text or": 1.0,
    "from text or xml": 1.0,
    "text or xml documents": 1.0,
    "or xml documents .": 1.0,
    "<s> the task is": 0.5,
    "the task is very": 0.5,
    "task is very similar": 1.0,
    "very similar to that": 0.3333333333333333,
    "similar to that of": 1.0,
    "to that of information": 1.0,
    "that of information extraction": 1.0,
    "of information extraction -lrb-": 1.0,
    "-lrb- ie -rrb- ,": 0.5,
    "ie -rrb- , but": 1.0,
    "-rrb- , but ie": 0.3333333333333333,
    ", but ie additionally": 1.0,
    "but ie additionally requires": 1.0,
    "ie additionally requires the": 1.0,
    "additionally requires the removal": 1.0,
    "requires the removal of": 1.0,
    "the removal of repeated": 1.0,
    "removal of repeated relations": 1.0,
    "of repeated relations -lrb-": 1.0,
    "repeated relations -lrb- disambiguation": 1.0,
    "relations -lrb- disambiguation -rrb-": 1.0,
    "-lrb- disambiguation -rrb- and": 1.0,
    "disambiguation -rrb- and generally": 1.0,
    "-rrb- and generally refers": 1.0,
    "and generally refers to": 1.0,
    "generally refers to the": 1.0,
    "refers to the extraction": 0.3333333333333333,
    "to the extraction of": 1.0,
    "the extraction of many": 0.3333333333333333,
    "extraction of many different": 1.0,
    "of many different relationships": 0.5,
    "many different relationships .": 1.0,
    "<s> approaches one approach": 1.0,
    "approaches one approach to": 1.0,
    "one approach to this": 1.0,
    "approach to this problem": 1.0,
    "to this problem involves": 1.0,
    "this problem involves the": 0.5,
    "problem involves the use": 1.0,
    "involves the use of": 1.0,
    "the use of domain": 0.06666666666666667,
    "use of domain ontologies": 1.0,
    "of domain ontologies .": 1.0,
    "<s> another approach involves": 0.5,
    "another approach involves visual": 1.0,
    "approach involves visual detection": 1.0,
    "involves visual detection of": 1.0,
    "visual detection of meaningful": 1.0,
    "detection of meaningful relationships": 1.0,
    "of meaningful relationships in": 1.0,
    "meaningful relationships in parametric": 1.0,
    "relationships in parametric values": 1.0,
    "in parametric values of": 1.0,
    "parametric values of objects": 1.0,
    "values of objects listed": 1.0,
    "of objects listed on": 1.0,
    "objects listed on a": 1.0,
    "listed on a data": 1.0,
    "on a data table": 1.0,
    "a data table that": 1.0,
    "data table that shift": 1.0,
    "table that shift positions": 1.0,
    "that shift positions as": 1.0,
    "shift positions as the": 1.0,
    "positions as the table": 1.0,
    "as the table is": 1.0,
    "the table is permuted": 1.0,
    "table is permuted automatically": 1.0,
    "is permuted automatically as": 1.0,
    "permuted automatically as controlled": 1.0,
    "automatically as controlled by": 1.0,
    "as controlled by the": 1.0,
    "controlled by the software": 1.0,
    "by the software user": 1.0,
    "the software user .": 1.0,
    "<s> the poor coverage": 1.0,
    "the poor coverage ,": 1.0,
    "poor coverage , rarity": 1.0,
    "coverage , rarity and": 1.0,
    ", rarity and development": 1.0,
    "rarity and development cost": 1.0,
    "and development cost related": 1.0,
    "development cost related to": 1.0,
    "cost related to structured": 1.0,
    "related to structured resources": 1.0,
    "to structured resources such": 1.0,
    "structured resources such as": 1.0,
    "resources such as semantic": 1.0,
    "such as semantic lexicons": 1.0,
    "as semantic lexicons -lrb-": 1.0,
    "semantic lexicons -lrb- e.g.": 1.0,
    "lexicons -lrb- e.g. wordnet": 1.0,
    "-lrb- e.g. wordnet ,": 1.0,
    "e.g. wordnet , umls": 1.0,
    "wordnet , umls -rrb-": 1.0,
    ", umls -rrb- and": 1.0,
    "umls -rrb- and domain": 1.0,
    "-rrb- and domain ontologies": 1.0,
    "and domain ontologies -lrb-": 1.0,
    "domain ontologies -lrb- e.g.": 1.0,
    "ontologies -lrb- e.g. the": 1.0,
    "-lrb- e.g. the gene": 0.3333333333333333,
    "e.g. the gene ontology": 1.0,
    "the gene ontology -rrb-": 1.0,
    "gene ontology -rrb- has": 1.0,
    "ontology -rrb- has given": 1.0,
    "-rrb- has given rise": 1.0,
    "has given rise to": 1.0,
    "given rise to new": 1.0,
    "rise to new approaches": 1.0,
    "to new approaches based": 1.0,
    "new approaches based on": 1.0,
    "approaches based on broad": 1.0,
    "based on broad ,": 1.0,
    "on broad , dynamic": 1.0,
    "broad , dynamic background": 1.0,
    ", dynamic background knowledge": 1.0,
    "dynamic background knowledge on": 1.0,
    "background knowledge on the": 1.0,
    "knowledge on the web": 0.5,
    "on the web .": 0.5,
    "instance , the archiles": 0.5,
    ", the archiles technique": 1.0,
    "the archiles technique uses": 1.0,
    "archiles technique uses only": 1.0,
    "technique uses only wikipedia": 1.0,
    "uses only wikipedia and": 1.0,
    "only wikipedia and search": 1.0,
    "wikipedia and search engine": 1.0,
    "and search engine page": 1.0,
    "search engine page count": 1.0,
    "engine page count for": 1.0,
    "page count for acquiring": 1.0,
    "count for acquiring coarse-grained": 1.0,
    "for acquiring coarse-grained relations": 1.0,
    "acquiring coarse-grained relations to": 1.0,
    "coarse-grained relations to construct": 1.0,
    "relations to construct lightweight": 1.0,
    "to construct lightweight ontologies": 1.0,
    "construct lightweight ontologies .": 1.0,
    "<s> the relationships can": 1.0,
    "the relationships can be": 1.0,
    "relationships can be represented": 1.0,
    "can be represented using": 1.0,
    "be represented using a": 1.0,
    "represented using a variety": 1.0,
    "using a variety of": 1.0,
    "a variety of formalisms\\/languages": 0.14285714285714285,
    "variety of formalisms\\/languages .": 1.0,
    "<s> one such representation": 1.0,
    "one such representation language": 1.0,
    "such representation language for": 1.0,
    "representation language for data": 1.0,
    "language for data on": 1.0,
    "for data on the": 1.0,
    "data on the web": 1.0,
    "on the web is": 0.5,
    "the web is rdf": 1.0,
    "web is rdf .": 1.0,
    "<s> jump to :": 1.0,
    "jump to : navigation": 1.0,
    "to : navigation ,": 1.0,
    ": navigation , search": 1.0,
    "navigation , search sentence": 1.0,
    ", search sentence boundary": 1.0,
    "search sentence boundary disambiguation": 1.0,
    "sentence boundary disambiguation -lrb-": 0.5,
    "boundary disambiguation -lrb- sbd": 1.0,
    "disambiguation -lrb- sbd -rrb-": 1.0,
    "-lrb- sbd -rrb- ,": 1.0,
    "sbd -rrb- , also": 1.0,
    "-rrb- , also known": 0.5,
    ", also known as": 1.0,
    "known as sentence breaking": 0.5,
    "as sentence breaking ,": 1.0,
    "sentence breaking , is": 1.0,
    "breaking , is the": 1.0,
    ", is the problem": 0.16666666666666666,
    "is the problem in": 0.6666666666666666,
    "the problem in natural": 1.0,
    "problem in natural language": 1.0,
    "in natural language processing": 0.3333333333333333,
    "natural language processing of": 0.07142857142857142,
    "language processing of deciding": 0.5,
    "processing of deciding where": 1.0,
    "of deciding where sentences": 1.0,
    "deciding where sentences begin": 1.0,
    "where sentences begin and": 1.0,
    "sentences begin and end": 1.0,
    "begin and end .": 1.0,
    "<s> often natural language": 1.0,
    "often natural language processing": 1.0,
    "natural language processing tools": 0.03571428571428571,
    "language processing tools require": 1.0,
    "processing tools require their": 1.0,
    "tools require their input": 1.0,
    "require their input to": 1.0,
    "their input to be": 1.0,
    "input to be divided": 1.0,
    "to be divided into": 1.0,
    "be divided into sentences": 1.0,
    "divided into sentences for": 1.0,
    "into sentences for a": 1.0,
    "sentences for a number": 1.0,
    "a number of reasons": 0.045454545454545456,
    "number of reasons .": 1.0,
    "<s> however sentence boundary": 1.0,
    "however sentence boundary identification": 1.0,
    "sentence boundary identification is": 1.0,
    "boundary identification is challenging": 1.0,
    "identification is challenging because": 1.0,
    "is challenging because punctuation": 1.0,
    "challenging because punctuation marks": 1.0,
    "because punctuation marks are": 1.0,
    "punctuation marks are often": 1.0,
    "marks are often ambiguous": 1.0,
    "are often ambiguous .": 1.0,
    "example , a period": 0.2,
    ", a period may": 1.0,
    "a period may denote": 1.0,
    "period may denote an": 1.0,
    "may denote an abbreviation": 1.0,
    "denote an abbreviation ,": 1.0,
    "an abbreviation , decimal": 1.0,
    "abbreviation , decimal point": 1.0,
    ", decimal point ,": 1.0,
    "decimal point , an": 1.0,
    "point , an ellipsis": 1.0,
    ", an ellipsis ,": 1.0,
    "an ellipsis , or": 1.0,
    "ellipsis , or an": 1.0,
    ", or an email": 1.0,
    "or an email address": 1.0,
    "an email address -": 1.0,
    "email address - not": 1.0,
    "address - not the": 1.0,
    "- not the end": 1.0,
    "not the end of": 1.0,
    "the end of a": 1.0,
    "end of a sentence": 1.0,
    "of a sentence .": 0.5,
    "<s> about 47 %": 1.0,
    "about 47 % of": 1.0,
    "47 % of the": 1.0,
    "% of the periods": 0.2,
    "of the periods in": 1.0,
    "the periods in the": 1.0,
    "periods in the wall": 1.0,
    "in the wall street": 1.0,
    "wall street journal corpus": 0.5,
    "street journal corpus denote": 1.0,
    "journal corpus denote abbreviations": 1.0,
    "corpus denote abbreviations .": 1.0,
    "<s> as well ,": 1.0,
    "as well , question": 1.0,
    "well , question marks": 1.0,
    ", question marks and": 1.0,
    "question marks and exclamation": 1.0,
    "marks and exclamation marks": 1.0,
    "and exclamation marks may": 1.0,
    "exclamation marks may appear": 1.0,
    "marks may appear in": 1.0,
    "may appear in embedded": 1.0,
    "appear in embedded quotations": 1.0,
    "in embedded quotations ,": 1.0,
    "embedded quotations , emoticons": 1.0,
    "quotations , emoticons ,": 1.0,
    ", emoticons , computer": 1.0,
    "emoticons , computer code": 1.0,
    ", computer code ,": 1.0,
    "computer code , and": 1.0,
    "code , and slang": 1.0,
    ", and slang .": 1.0,
    "<s> languages like japanese": 1.0,
    "languages like japanese and": 1.0,
    "like japanese and chinese": 1.0,
    "japanese and chinese have": 1.0,
    "and chinese have unambiguous": 1.0,
    "chinese have unambiguous sentence-ending": 1.0,
    "have unambiguous sentence-ending markers": 1.0,
    "unambiguous sentence-ending markers .": 1.0,
    "<s> -lrb- b -rrb-": 1.0,
    "-lrb- b -rrb- if": 1.0,
    "b -rrb- if the": 1.0,
    "-rrb- if the preceding": 0.5,
    "if the preceding token": 1.0,
    "the preceding token is": 1.0,
    "preceding token is on": 1.0,
    "token is on my": 1.0,
    "is on my hand-compiled": 1.0,
    "on my hand-compiled list": 1.0,
    "my hand-compiled list of": 1.0,
    "hand-compiled list of abbreviations": 1.0,
    "list of abbreviations ,": 1.0,
    "of abbreviations , then": 1.0,
    "abbreviations , then it": 1.0,
    ", then it does": 0.5,
    "then it does n't": 1.0,
    "it does n't end": 1.0,
    "does n't end a": 1.0,
    "n't end a sentence": 1.0,
    "end a sentence .": 1.0,
    "<s> -lrb- c -rrb-": 1.0,
    "-lrb- c -rrb- if": 1.0,
    "c -rrb- if the": 1.0,
    "-rrb- if the next": 0.5,
    "if the next token": 1.0,
    "the next token is": 1.0,
    "next token is capitalized": 1.0,
    "token is capitalized ,": 1.0,
    "is capitalized , then": 1.0,
    "capitalized , then it": 1.0,
    ", then it ends": 0.5,
    "then it ends a": 1.0,
    "it ends a sentence": 1.0,
    "ends a sentence .": 1.0,
    "<s> this strategy gets": 1.0,
    "this strategy gets about": 1.0,
    "strategy gets about 95": 1.0,
    "gets about 95 %": 1.0,
    "about 95 % of": 1.0,
    "95 % of sentences": 1.0,
    "% of sentences correct": 1.0,
    "of sentences correct .": 1.0,
    "<s> another approach is": 0.5,
    "another approach is to": 1.0,
    "approach is to automatically": 0.5,
    "is to automatically learn": 1.0,
    "to automatically learn a": 0.5,
    "automatically learn a set": 1.0,
    "learn a set of": 1.0,
    "a set of rules": 0.07142857142857142,
    "set of rules from": 1.0,
    "of rules from a": 1.0,
    "rules from a set": 1.0,
    "set of documents where": 0.3333333333333333,
    "of documents where the": 1.0,
    "documents where the sentence": 1.0,
    "where the sentence breaks": 1.0,
    "the sentence breaks are": 1.0,
    "sentence breaks are pre-marked": 1.0,
    "breaks are pre-marked .": 1.0,
    "<s> solutions have been": 1.0,
    "solutions have been based": 1.0,
    "have been based on": 1.0,
    "been based on a": 1.0,
    "based on a maximum": 0.25,
    "on a maximum entropy": 1.0,
    "a maximum entropy model": 0.5,
    "maximum entropy model .": 1.0,
    "<s> the satz architecture": 1.0,
    "the satz architecture uses": 1.0,
    "satz architecture uses a": 1.0,
    "architecture uses a neural": 1.0,
    "uses a neural network": 1.0,
    "a neural network to": 1.0,
    "neural network to disambiguate": 1.0,
    "network to disambiguate sentence": 1.0,
    "to disambiguate sentence boundaries": 1.0,
    "disambiguate sentence boundaries and": 1.0,
    "sentence boundaries and achieves": 1.0,
    "boundaries and achieves 98.5": 1.0,
    "and achieves 98.5 %": 1.0,
    "achieves 98.5 % accuracy": 1.0,
    "98.5 % accuracy .": 1.0,
    "<s> sentiment analysis or": 0.2,
    "sentiment analysis or opinion": 1.0,
    "analysis or opinion mining": 1.0,
    "or opinion mining refers": 1.0,
    "opinion mining refers to": 1.0,
    "mining refers to the": 1.0,
    "refers to the application": 0.3333333333333333,
    "to the application of": 1.0,
    "the application of natural": 1.0,
    "application of natural language": 1.0,
    "language processing , computational": 0.16666666666666666,
    "processing , computational linguistics": 1.0,
    ", computational linguistics ,": 1.0,
    "computational linguistics , and": 0.3333333333333333,
    "linguistics , and text": 1.0,
    ", and text analytics": 1.0,
    "and text analytics to": 1.0,
    "text analytics to identify": 1.0,
    "analytics to identify and": 1.0,
    "to identify and extract": 1.0,
    "identify and extract subjective": 1.0,
    "and extract subjective information": 1.0,
    "extract subjective information in": 0.5,
    "subjective information in source": 1.0,
    "information in source materials": 1.0,
    "in source materials .": 1.0,
    "generally speaking , sentiment": 0.5,
    "speaking , sentiment analysis": 1.0,
    ", sentiment analysis aims": 1.0,
    "sentiment analysis aims to": 1.0,
    "analysis aims to determine": 1.0,
    "aims to determine the": 1.0,
    "to determine the attitude": 0.25,
    "determine the attitude of": 1.0,
    "the attitude of a": 1.0,
    "attitude of a speaker": 1.0,
    "of a speaker or": 0.5,
    "a speaker or a": 1.0,
    "speaker or a writer": 1.0,
    "or a writer with": 1.0,
    "a writer with respect": 1.0,
    "writer with respect to": 1.0,
    "with respect to some": 0.14285714285714285,
    "respect to some topic": 1.0,
    "to some topic or": 1.0,
    "some topic or the": 1.0,
    "topic or the overall": 1.0,
    "or the overall contextual": 1.0,
    "the overall contextual polarity": 1.0,
    "overall contextual polarity of": 1.0,
    "contextual polarity of a": 1.0,
    "polarity of a document": 1.0,
    "of a document .": 0.5,
    "<s> the attitude may": 1.0,
    "the attitude may be": 1.0,
    "attitude may be his": 1.0,
    "may be his or": 1.0,
    "be his or her": 1.0,
    "his or her judgement": 1.0,
    "or her judgement or": 1.0,
    "her judgement or evaluation": 1.0,
    "judgement or evaluation -lrb-": 1.0,
    "or evaluation -lrb- see": 1.0,
    "evaluation -lrb- see appraisal": 1.0,
    "-lrb- see appraisal theory": 1.0,
    "see appraisal theory -rrb-": 1.0,
    "appraisal theory -rrb- ,": 1.0,
    "theory -rrb- , affective": 1.0,
    "-rrb- , affective state": 1.0,
    ", affective state -lrb-": 1.0,
    "affective state -lrb- that": 1.0,
    "state -lrb- that is": 1.0,
    "-lrb- that is to": 0.5,
    "that is to say": 1.0,
    "is to say ,": 1.0,
    "to say , the": 1.0,
    "say , the emotional": 1.0,
    ", the emotional state": 0.5,
    "the emotional state of": 1.0,
    "emotional state of the": 1.0,
    "state of the author": 0.25,
    "of the author when": 1.0,
    "the author when writing": 1.0,
    "author when writing -rrb-": 1.0,
    "when writing -rrb- ,": 1.0,
    "writing -rrb- , or": 1.0,
    "-rrb- , or the": 0.3333333333333333,
    ", or the intended": 0.5,
    "or the intended emotional": 1.0,
    "the intended emotional communication": 1.0,
    "intended emotional communication -lrb-": 1.0,
    "emotional communication -lrb- that": 1.0,
    "communication -lrb- that is": 1.0,
    ", the emotional effect": 0.5,
    "the emotional effect the": 1.0,
    "emotional effect the author": 1.0,
    "effect the author wishes": 1.0,
    "the author wishes to": 1.0,
    "author wishes to have": 1.0,
    "wishes to have on": 1.0,
    "to have on the": 1.0,
    "have on the reader": 1.0,
    "on the reader -rrb-": 1.0,
    "the reader -rrb- .": 1.0,
    "<s> advanced , ``": 1.0,
    "advanced , `` beyond": 1.0,
    ", `` beyond polarity": 1.0,
    "`` beyond polarity ''": 1.0,
    "beyond polarity '' sentiment": 1.0,
    "polarity '' sentiment classification": 1.0,
    "'' sentiment classification looks": 1.0,
    "sentiment classification looks ,": 1.0,
    "classification looks , for": 1.0,
    "looks , for instance": 1.0,
    ", for instance ,": 0.5,
    "for instance , at": 0.1111111111111111,
    "instance , at emotional": 1.0,
    ", at emotional states": 1.0,
    "at emotional states such": 1.0,
    "emotional states such as": 1.0,
    "states such as ``": 1.0,
    "such as `` angry": 0.125,
    "as `` angry ,": 1.0,
    "`` angry , ''": 1.0,
    "angry , '' ``": 1.0,
    ", '' `` sad": 1.0,
    "'' `` sad ,": 1.0,
    "`` sad , ''": 1.0,
    "sad , '' and": 1.0,
    ", '' and ``": 1.0,
    "'' and `` happy": 0.1111111111111111,
    "and `` happy .": 1.0,
    "`` happy . ''": 1.0,
    "<s> early work in": 1.0,
    "early work in that": 1.0,
    "work in that area": 1.0,
    "in that area includes": 1.0,
    "that area includes turney": 1.0,
    "area includes turney and": 1.0,
    "includes turney and pang": 1.0,
    "turney and pang who": 1.0,
    "and pang who applied": 1.0,
    "pang who applied different": 1.0,
    "who applied different methods": 1.0,
    "applied different methods for": 1.0,
    "different methods for detecting": 1.0,
    "methods for detecting the": 1.0,
    "for detecting the polarity": 1.0,
    "detecting the polarity of": 1.0,
    "the polarity of product": 1.0,
    "polarity of product reviews": 1.0,
    "of product reviews and": 1.0,
    "product reviews and movie": 1.0,
    "reviews and movie reviews": 1.0,
    "and movie reviews respectively": 1.0,
    "movie reviews respectively .": 1.0,
    "<s> this work is": 0.5,
    "this work is at": 0.5,
    "work is at the": 1.0,
    "is at the document": 1.0,
    "at the document level": 1.0,
    "the document level .": 1.0,
    "<s> one can also": 1.0,
    "one can also classify": 1.0,
    "can also classify a": 1.0,
    "also classify a document": 1.0,
    "classify a document 's": 1.0,
    "a document 's polarity": 1.0,
    "document 's polarity on": 1.0,
    "'s polarity on a": 1.0,
    "polarity on a multi-way": 1.0,
    "on a multi-way scale": 1.0,
    "a multi-way scale ,": 1.0,
    "multi-way scale , which": 1.0,
    "scale , which was": 1.0,
    ", which was attempted": 0.25,
    "which was attempted by": 1.0,
    "was attempted by pang": 1.0,
    "attempted by pang and": 1.0,
    "by pang and snyder": 1.0,
    "pang and snyder -lrb-": 1.0,
    "and snyder -lrb- among": 1.0,
    "snyder -lrb- among others": 1.0,
    "-lrb- among others -rrb-": 1.0,
    "among others -rrb- :": 1.0,
    "others -rrb- : expanded": 1.0,
    "-rrb- : expanded the": 1.0,
    ": expanded the basic": 1.0,
    "expanded the basic task": 1.0,
    "the basic task of": 1.0,
    "basic task of classifying": 1.0,
    "task of classifying a": 1.0,
    "of classifying a movie": 1.0,
    "classifying a movie review": 1.0,
    "a movie review as": 1.0,
    "movie review as either": 1.0,
    "review as either positive": 1.0,
    "as either positive or": 1.0,
    "either positive or negative": 1.0,
    "positive or negative to": 0.5,
    "or negative to predicting": 1.0,
    "negative to predicting star": 1.0,
    "to predicting star ratings": 1.0,
    "predicting star ratings on": 1.0,
    "star ratings on either": 1.0,
    "ratings on either a": 1.0,
    "on either a 3": 1.0,
    "either a 3 or": 1.0,
    "a 3 or a": 1.0,
    "3 or a 4": 1.0,
    "or a 4 star": 1.0,
    "a 4 star scale": 1.0,
    "4 star scale ,": 1.0,
    "star scale , while": 1.0,
    "scale , while snyder": 1.0,
    ", while snyder performed": 1.0,
    "while snyder performed an": 1.0,
    "snyder performed an in-depth": 1.0,
    "performed an in-depth analysis": 1.0,
    "an in-depth analysis of": 1.0,
    "in-depth analysis of restaurant": 1.0,
    "analysis of restaurant reviews": 1.0,
    "of restaurant reviews ,": 1.0,
    "restaurant reviews , predicting": 1.0,
    "reviews , predicting ratings": 1.0,
    ", predicting ratings for": 1.0,
    "predicting ratings for various": 1.0,
    "ratings for various aspects": 1.0,
    "for various aspects of": 1.0,
    "various aspects of the": 1.0,
    "aspects of the given": 1.0,
    "of the given restaurant": 0.5,
    "the given restaurant ,": 1.0,
    "given restaurant , such": 1.0,
    "restaurant , such as": 1.0,
    "such as the food": 0.07142857142857142,
    "as the food and": 1.0,
    "the food and atmosphere": 1.0,
    "food and atmosphere -lrb-": 1.0,
    "and atmosphere -lrb- on": 1.0,
    "atmosphere -lrb- on a": 1.0,
    "-lrb- on a five-star": 1.0,
    "on a five-star scale": 1.0,
    "a five-star scale -rrb-": 1.0,
    "five-star scale -rrb- .": 1.0,
    "<s> a different method": 0.5,
    "a different method for": 1.0,
    "different method for determining": 1.0,
    "method for determining sentiment": 1.0,
    "for determining sentiment is": 1.0,
    "determining sentiment is the": 1.0,
    "sentiment is the use": 1.0,
    "is the use of": 1.0,
    "the use of a": 0.06666666666666667,
    "use of a scaling": 0.25,
    "of a scaling system": 1.0,
    "a scaling system whereby": 1.0,
    "scaling system whereby words": 1.0,
    "system whereby words commonly": 1.0,
    "whereby words commonly associated": 1.0,
    "words commonly associated with": 1.0,
    "commonly associated with having": 1.0,
    "associated with having a": 1.0,
    "with having a negative": 1.0,
    "having a negative ,": 1.0,
    "a negative , neutral": 1.0,
    "negative , neutral or": 1.0,
    ", neutral or positive": 1.0,
    "neutral or positive sentiment": 1.0,
    "or positive sentiment with": 1.0,
    "positive sentiment with them": 1.0,
    "sentiment with them are": 1.0,
    "with them are given": 1.0,
    "them are given an": 1.0,
    "are given an associated": 1.0,
    "given an associated number": 1.0,
    "an associated number on": 1.0,
    "associated number on a": 1.0,
    "number on a -5": 1.0,
    "on a -5 to": 1.0,
    "a -5 to +5": 1.0,
    "-5 to +5 scale": 1.0,
    "to +5 scale -lrb-": 1.0,
    "+5 scale -lrb- most": 1.0,
    "scale -lrb- most negative": 1.0,
    "-lrb- most negative up": 1.0,
    "most negative up to": 1.0,
    "negative up to most": 1.0,
    "up to most positive": 1.0,
    "to most positive -rrb-": 1.0,
    "most positive -rrb- and": 1.0,
    "positive -rrb- and when": 1.0,
    "-rrb- and when a": 1.0,
    "and when a piece": 1.0,
    "when a piece of": 1.0,
    "a piece of unstructured": 0.5,
    "piece of unstructured text": 1.0,
    "of unstructured text is": 1.0,
    "unstructured text is analyzed": 1.0,
    "text is analyzed using": 1.0,
    "is analyzed using natural": 1.0,
    "analyzed using natural language": 1.0,
    "using natural language processing": 1.0,
    "language processing , the": 0.16666666666666666,
    "processing , the subsequent": 1.0,
    ", the subsequent concepts": 1.0,
    "the subsequent concepts are": 1.0,
    "subsequent concepts are analyzed": 1.0,
    "concepts are analyzed for": 1.0,
    "are analyzed for an": 1.0,
    "analyzed for an understanding": 1.0,
    "for an understanding of": 1.0,
    "an understanding of these": 0.5,
    "understanding of these words": 1.0,
    "of these words and": 1.0,
    "these words and how": 1.0,
    "words and how they": 1.0,
    "and how they relate": 0.5,
    "how they relate to": 1.0,
    "they relate to the": 1.0,
    "relate to the concept": 1.0,
    "to the concept -lrb-": 0.5,
    "the concept -lrb- citation": 1.0,
    "concept -lrb- citation needed": 1.0,
    "<s> each concept is": 1.0,
    "each concept is then": 1.0,
    "concept is then given": 1.0,
    "is then given a": 1.0,
    "then given a score": 1.0,
    "given a score based": 1.0,
    "a score based on": 1.0,
    "score based on the": 1.0,
    "based on the way": 0.09090909090909091,
    "on the way sentiment": 1.0,
    "the way sentiment words": 1.0,
    "way sentiment words relate": 1.0,
    "sentiment words relate to": 1.0,
    "words relate to the": 1.0,
    "to the concept ,": 0.5,
    "the concept , and": 1.0,
    "concept , and their": 1.0,
    ", and their associated": 1.0,
    "and their associated score": 1.0,
    "their associated score .": 1.0,
    "<s> this allows movement": 0.5,
    "this allows movement to": 1.0,
    "allows movement to a": 1.0,
    "movement to a more": 1.0,
    "to a more sophisticated": 1.0,
    "a more sophisticated understanding": 1.0,
    "more sophisticated understanding of": 1.0,
    "sophisticated understanding of sentiment": 1.0,
    "understanding of sentiment based": 1.0,
    "of sentiment based on": 1.0,
    "sentiment based on an": 1.0,
    "based on an 11": 1.0,
    "on an 11 point": 1.0,
    "an 11 point scale": 1.0,
    "11 point scale .": 1.0,
    "<s> alternatively , texts": 0.5,
    "alternatively , texts can": 1.0,
    ", texts can be": 1.0,
    "texts can be given": 1.0,
    "can be given a": 1.0,
    "be given a positive": 1.0,
    "given a positive and": 1.0,
    "a positive and negative": 1.0,
    "positive and negative sentiment": 0.5,
    "and negative sentiment strength": 1.0,
    "negative sentiment strength score": 1.0,
    "sentiment strength score if": 1.0,
    "strength score if the": 1.0,
    "score if the goal": 1.0,
    "if the goal is": 1.0,
    "goal is to determine": 0.3333333333333333,
    "is to determine the": 1.0,
    "to determine the sentiment": 0.25,
    "determine the sentiment in": 1.0,
    "the sentiment in a": 1.0,
    "sentiment in a text": 1.0,
    "in a text rather": 0.25,
    "a text rather than": 1.0,
    "text rather than the": 1.0,
    "rather than the overall": 1.0,
    "than the overall polarity": 1.0,
    "the overall polarity and": 1.0,
    "overall polarity and strength": 1.0,
    "polarity and strength of": 1.0,
    "and strength of the": 1.0,
    "strength of the text": 1.0,
    "<s> another research direction": 1.0,
    "another research direction is": 1.0,
    "research direction is subjectivity\\/objectivity": 1.0,
    "direction is subjectivity\\/objectivity identification": 1.0,
    "is subjectivity\\/objectivity identification .": 1.0,
    "<s> this task is": 0.5,
    "this task is commonly": 0.5,
    "task is commonly defined": 1.0,
    "is commonly defined as": 1.0,
    "commonly defined as classifying": 1.0,
    "defined as classifying a": 1.0,
    "as classifying a given": 1.0,
    "classifying a given text": 1.0,
    "a given text -lrb-": 1.0,
    "given text -lrb- usually": 1.0,
    "text -lrb- usually a": 1.0,
    "-lrb- usually a sentence": 1.0,
    "usually a sentence -rrb-": 1.0,
    "a sentence -rrb- into": 1.0,
    "sentence -rrb- into one": 1.0,
    "-rrb- into one of": 1.0,
    "into one of two": 1.0,
    "one of two classes": 1.0,
    "of two classes :": 1.0,
    "two classes : objective": 1.0,
    "classes : objective or": 1.0,
    ": objective or subjective": 1.0,
    "objective or subjective .": 1.0,
    "<s> this problem can": 0.25,
    "this problem can sometimes": 1.0,
    "problem can sometimes be": 1.0,
    "can sometimes be more": 1.0,
    "sometimes be more difficult": 1.0,
    "be more difficult than": 1.0,
    "more difficult than polarity": 0.3333333333333333,
    "difficult than polarity classification": 1.0,
    "than polarity classification :": 1.0,
    "polarity classification : the": 1.0,
    "classification : the subjectivity": 1.0,
    ": the subjectivity of": 1.0,
    "the subjectivity of words": 1.0,
    "subjectivity of words and": 1.0,
    "words and phrases may": 0.5,
    "and phrases may depend": 1.0,
    "phrases may depend on": 1.0,
    "may depend on their": 1.0,
    "depend on their context": 1.0,
    "on their context and": 1.0,
    "their context and an": 1.0,
    "context and an objective": 1.0,
    "and an objective document": 1.0,
    "an objective document may": 1.0,
    "objective document may contain": 1.0,
    "document may contain subjective": 0.5,
    "may contain subjective sentences": 1.0,
    "contain subjective sentences -lrb-": 1.0,
    "subjective sentences -lrb- e.g.": 1.0,
    "sentences -lrb- e.g. ,": 0.5,
    "-lrb- e.g. , a": 0.10526315789473684,
    "e.g. , a news": 0.5,
    ", a news article": 1.0,
    "a news article quoting": 1.0,
    "news article quoting people": 1.0,
    "article quoting people 's": 1.0,
    "quoting people 's opinions": 1.0,
    "people 's opinions -rrb-": 1.0,
    "'s opinions -rrb- .": 1.0,
    "<s> moreover , as": 0.25,
    "moreover , as mentioned": 1.0,
    ", as mentioned by": 1.0,
    "as mentioned by su": 1.0,
    "mentioned by su ,": 1.0,
    "by su , results": 1.0,
    "su , results are": 1.0,
    ", results are largely": 1.0,
    "results are largely dependent": 1.0,
    "are largely dependent on": 1.0,
    "largely dependent on the": 1.0,
    "dependent on the definition": 1.0,
    "on the definition of": 1.0,
    "the definition of subjectivity": 0.3333333333333333,
    "definition of subjectivity used": 1.0,
    "of subjectivity used when": 1.0,
    "subjectivity used when annotating": 1.0,
    "used when annotating texts": 1.0,
    "when annotating texts .": 1.0,
    "<s> however , pang": 0.03125,
    "however , pang showed": 1.0,
    ", pang showed that": 1.0,
    "pang showed that removing": 1.0,
    "showed that removing objective": 1.0,
    "that removing objective sentences": 1.0,
    "removing objective sentences from": 1.0,
    "objective sentences from a": 1.0,
    "sentences from a document": 1.0,
    "from a document before": 1.0,
    "a document before classifying": 1.0,
    "document before classifying its": 1.0,
    "before classifying its polarity": 1.0,
    "classifying its polarity helped": 1.0,
    "its polarity helped improve": 1.0,
    "polarity helped improve performance": 1.0,
    "helped improve performance .": 1.0,
    "<s> the more fine-grained": 1.0,
    "the more fine-grained analysis": 1.0,
    "more fine-grained analysis model": 1.0,
    "fine-grained analysis model is": 1.0,
    "analysis model is called": 1.0,
    "model is called the": 1.0,
    "is called the feature\\/aspect-based": 1.0,
    "called the feature\\/aspect-based sentiment": 1.0,
    "the feature\\/aspect-based sentiment analysis": 1.0,
    "feature\\/aspect-based sentiment analysis .": 1.0,
    "<s> it refers to": 1.0,
    "it refers to determining": 1.0,
    "refers to determining the": 1.0,
    "to determining the opinions": 1.0,
    "determining the opinions or": 1.0,
    "the opinions or sentiments": 1.0,
    "opinions or sentiments expressed": 1.0,
    "or sentiments expressed on": 1.0,
    "sentiments expressed on different": 1.0,
    "expressed on different features": 1.0,
    "on different features or": 1.0,
    "different features or aspects": 1.0,
    "features or aspects of": 1.0,
    "or aspects of entities": 1.0,
    "aspects of entities ,": 1.0,
    "of entities , e.g.": 1.0,
    "entities , e.g. ,": 1.0,
    ", e.g. , of": 0.14285714285714285,
    "e.g. , of a": 1.0,
    ", of a cell": 1.0,
    "of a cell phone": 1.0,
    "a cell phone ,": 1.0,
    "cell phone , a": 0.5,
    "phone , a digital": 1.0,
    ", a digital camera": 1.0,
    "a digital camera ,": 1.0,
    "digital camera , or": 1.0,
    "camera , or a": 1.0,
    ", or a bank": 0.5,
    "or a bank .": 1.0,
    "<s> a feature or": 1.0,
    "a feature or aspect": 1.0,
    "feature or aspect is": 1.0,
    "or aspect is an": 1.0,
    "aspect is an attribute": 1.0,
    "is an attribute or": 1.0,
    "an attribute or component": 1.0,
    "attribute or component of": 1.0,
    "or component of an": 1.0,
    "component of an entity": 1.0,
    "of an entity ,": 1.0,
    "an entity , e.g.": 1.0,
    "entity , e.g. ,": 1.0,
    "e.g. , the screen": 0.5,
    ", the screen of": 1.0,
    "the screen of a": 1.0,
    "screen of a cell": 1.0,
    "cell phone , or": 0.5,
    "phone , or the": 1.0,
    ", or the picture": 0.5,
    "or the picture quality": 1.0,
    "the picture quality of": 1.0,
    "picture quality of a": 1.0,
    "quality of a camera": 0.3333333333333333,
    "of a camera .": 1.0,
    "<s> this problem involves": 0.25,
    "this problem involves several": 0.5,
    "problem involves several sub-problems": 1.0,
    "involves several sub-problems ,": 1.0,
    "several sub-problems , e.g.": 1.0,
    "sub-problems , e.g. ,": 1.0,
    ", e.g. , identifying": 0.14285714285714285,
    "e.g. , identifying relevant": 1.0,
    ", identifying relevant entities": 1.0,
    "identifying relevant entities ,": 1.0,
    "relevant entities , extracting": 1.0,
    "entities , extracting their": 1.0,
    ", extracting their features\\/aspects": 1.0,
    "extracting their features\\/aspects ,": 1.0,
    "their features\\/aspects , and": 1.0,
    "features\\/aspects , and determining": 1.0,
    ", and determining whether": 1.0,
    "and determining whether an": 1.0,
    "determining whether an opinion": 1.0,
    "whether an opinion expressed": 1.0,
    "an opinion expressed on": 1.0,
    "opinion expressed on each": 1.0,
    "expressed on each feature\\/aspect": 1.0,
    "on each feature\\/aspect is": 1.0,
    "each feature\\/aspect is positive": 1.0,
    "feature\\/aspect is positive ,": 1.0,
    "is positive , negative": 1.0,
    "positive , negative or": 1.0,
    ", negative or neutral": 1.0,
    "negative or neutral .": 1.0,
    "<s> more detailed discussions": 1.0,
    "more detailed discussions about": 1.0,
    "detailed discussions about this": 1.0,
    "discussions about this level": 1.0,
    "about this level of": 1.0,
    "this level of sentiment": 1.0,
    "level of sentiment analysis": 1.0,
    "of sentiment analysis can": 0.3333333333333333,
    "sentiment analysis can be": 1.0,
    "analysis can be found": 1.0,
    "can be found in": 0.3333333333333333,
    "be found in liu": 1.0,
    "found in liu 's": 1.0,
    "in liu 's nlp": 1.0,
    "liu 's nlp handbook": 1.0,
    "'s nlp handbook chapter": 1.0,
    "nlp handbook chapter ,": 1.0,
    "handbook chapter , ``": 1.0,
    "chapter , `` sentiment": 1.0,
    ", `` sentiment analysis": 1.0,
    "`` sentiment analysis and": 1.0,
    "sentiment analysis and subjectivity": 0.5,
    "analysis and subjectivity ''": 1.0,
    "and subjectivity '' .": 1.0,
    "<s> methods computers can": 1.0,
    "methods computers can perform": 1.0,
    "computers can perform automated": 1.0,
    "can perform automated sentiment": 1.0,
    "perform automated sentiment analysis": 1.0,
    "automated sentiment analysis of": 1.0,
    "sentiment analysis of digital": 1.0,
    "analysis of digital texts": 1.0,
    "of digital texts ,": 1.0,
    "digital texts , using": 1.0,
    "texts , using elements": 1.0,
    ", using elements from": 1.0,
    "using elements from machine": 1.0,
    "elements from machine learning": 1.0,
    "from machine learning such": 0.5,
    "machine learning such as": 1.0,
    "learning such as latent": 1.0,
    "such as latent semantic": 1.0,
    "as latent semantic analysis": 1.0,
    "latent semantic analysis ,": 1.0,
    "semantic analysis , support": 1.0,
    "analysis , support vector": 1.0,
    ", support vector machines": 1.0,
    "support vector machines ,": 1.0,
    "vector machines , ``": 1.0,
    "machines , `` bag": 1.0,
    ", `` bag of": 1.0,
    "`` bag of words": 1.0,
    "bag of words ''": 1.0,
    "of words '' and": 1.0,
    "words '' and semantic": 1.0,
    "'' and semantic orientation": 1.0,
    "and semantic orientation --": 1.0,
    "semantic orientation -- pointwise": 1.0,
    "orientation -- pointwise mutual": 1.0,
    "-- pointwise mutual information": 1.0,
    "pointwise mutual information -lrb-": 1.0,
    "mutual information -lrb- see": 0.5,
    "information -lrb- see peter": 1.0,
    "-lrb- see peter turney": 1.0,
    "see peter turney 's": 1.0,
    "peter turney 's work": 1.0,
    "turney 's work in": 1.0,
    "'s work in this": 1.0,
    "work in this area": 1.0,
    "in this area -rrb-": 0.3333333333333333,
    "this area -rrb- .": 1.0,
    "<s> more sophisticated methods": 0.5,
    "more sophisticated methods try": 1.0,
    "sophisticated methods try to": 1.0,
    "methods try to detect": 1.0,
    "try to detect the": 1.0,
    "to detect the holder": 1.0,
    "detect the holder of": 1.0,
    "the holder of a": 1.0,
    "holder of a sentiment": 1.0,
    "of a sentiment -lrb-": 0.5,
    "a sentiment -lrb- i.e.": 1.0,
    "sentiment -lrb- i.e. the": 1.0,
    "-lrb- i.e. the person": 0.3333333333333333,
    "i.e. the person who": 1.0,
    "the person who maintains": 1.0,
    "person who maintains that": 1.0,
    "who maintains that affective": 1.0,
    "maintains that affective state": 1.0,
    "that affective state -rrb-": 1.0,
    "affective state -rrb- and": 1.0,
    "state -rrb- and the": 1.0,
    "-rrb- and the target": 0.2,
    "and the target -lrb-": 1.0,
    "the target -lrb- i.e.": 1.0,
    "target -lrb- i.e. the": 1.0,
    "-lrb- i.e. the entity": 0.3333333333333333,
    "i.e. the entity about": 1.0,
    "the entity about which": 1.0,
    "entity about which the": 1.0,
    "about which the affect": 1.0,
    "which the affect is": 1.0,
    "the affect is felt": 1.0,
    "affect is felt -rrb-": 1.0,
    "is felt -rrb- .": 1.0,
    "<s> to mine the": 1.0,
    "to mine the opinion": 1.0,
    "mine the opinion in": 1.0,
    "the opinion in context": 1.0,
    "opinion in context and": 1.0,
    "in context and get": 1.0,
    "context and get the": 1.0,
    "and get the feature": 1.0,
    "get the feature which": 1.0,
    "the feature which has": 1.0,
    "feature which has been": 1.0,
    "which has been opinionated": 0.3333333333333333,
    "has been opinionated ,": 1.0,
    "been opinionated , the": 1.0,
    "opinionated , the grammatical": 1.0,
    ", the grammatical relationships": 1.0,
    "the grammatical relationships of": 1.0,
    "grammatical relationships of words": 1.0,
    "relationships of words are": 1.0,
    "of words are used": 1.0,
    "words are used .": 0.5,
    "<s> grammatical dependency relations": 1.0,
    "grammatical dependency relations are": 1.0,
    "dependency relations are obtained": 1.0,
    "relations are obtained by": 1.0,
    "are obtained by deep": 0.5,
    "obtained by deep parsing": 1.0,
    "by deep parsing of": 1.0,
    "deep parsing of the": 1.0,
    "parsing of the text": 1.0,
    "<s> open source software": 1.0,
    "open source software tools": 1.0,
    "source software tools deploy": 1.0,
    "software tools deploy machine": 1.0,
    "tools deploy machine learning": 1.0,
    "deploy machine learning ,": 1.0,
    "machine learning , statistics": 0.3333333333333333,
    "learning , statistics ,": 1.0,
    ", statistics , and": 1.0,
    "statistics , and natural": 1.0,
    ", and natural language": 1.0,
    "processing techniques to automate": 0.5,
    "techniques to automate sentiment": 1.0,
    "to automate sentiment analysis": 1.0,
    "automate sentiment analysis on": 1.0,
    "sentiment analysis on large": 1.0,
    "analysis on large collections": 1.0,
    "on large collections of": 1.0,
    "large collections of texts": 1.0,
    "collections of texts ,": 1.0,
    "of texts , including": 1.0,
    "texts , including web": 1.0,
    ", including web pages": 1.0,
    "including web pages ,": 1.0,
    "web pages , online": 1.0,
    "pages , online news": 1.0,
    ", online news ,": 1.0,
    "online news , internet": 1.0,
    "news , internet discussion": 1.0,
    ", internet discussion groups": 1.0,
    "internet discussion groups ,": 1.0,
    "discussion groups , online": 1.0,
    "groups , online reviews": 1.0,
    ", online reviews ,": 1.0,
    "online reviews , web": 1.0,
    "reviews , web blogs": 1.0,
    ", web blogs ,": 1.0,
    "web blogs , and": 1.0,
    "blogs , and social": 1.0,
    ", and social media": 1.0,
    "and social media .": 1.0,
    "<s> evaluation the accuracy": 1.0,
    "evaluation the accuracy of": 1.0,
    "the accuracy of a": 0.5,
    "accuracy of a sentiment": 1.0,
    "of a sentiment analysis": 0.5,
    "a sentiment analysis system": 1.0,
    "sentiment analysis system is": 1.0,
    "analysis system is ,": 1.0,
    "system is , in": 1.0,
    "is , in principle": 1.0,
    ", in principle ,": 1.0,
    "in principle , how": 1.0,
    "principle , how well": 1.0,
    ", how well it": 1.0,
    "how well it agrees": 0.5,
    "well it agrees with": 1.0,
    "it agrees with human": 1.0,
    "agrees with human judgments": 1.0,
    "with human judgments .": 1.0,
    "this is usually measured": 0.5,
    "is usually measured by": 1.0,
    "usually measured by precision": 1.0,
    "measured by precision and": 1.0,
    "by precision and recall": 1.0,
    "<s> however , human": 0.03125,
    "however , human raters": 1.0,
    ", human raters typically": 1.0,
    "human raters typically agree": 1.0,
    "raters typically agree about": 1.0,
    "typically agree about 70": 1.0,
    "agree about 70 %": 1.0,
    "about 70 % -lrb-": 0.5,
    "70 % -lrb- citation": 1.0,
    "% -lrb- citation needed": 1.0,
    "citation needed -rrb- of": 0.07692307692307693,
    "needed -rrb- of the": 1.0,
    "-rrb- of the time": 0.3333333333333333,
    "of the time -lrb-": 0.25,
    "the time -lrb- see": 1.0,
    "time -lrb- see inter-rater": 1.0,
    "-lrb- see inter-rater reliability": 1.0,
    "see inter-rater reliability -rrb-": 1.0,
    "inter-rater reliability -rrb- .": 1.0,
    "thus , a 70": 0.5,
    ", a 70 %": 1.0,
    "a 70 % accurate": 1.0,
    "70 % accurate program": 1.0,
    "% accurate program is": 1.0,
    "accurate program is doing": 1.0,
    "program is doing as": 1.0,
    "is doing as well": 1.0,
    "doing as well as": 1.0,
    "as well as humans": 0.07692307692307693,
    "well as humans ,": 1.0,
    "as humans , even": 1.0,
    "humans , even though": 1.0,
    ", even though such": 1.0,
    "even though such accuracy": 1.0,
    "though such accuracy may": 1.0,
    "such accuracy may not": 1.0,
    "accuracy may not sound": 1.0,
    "may not sound impressive": 1.0,
    "not sound impressive .": 1.0,
    "<s> if a program": 1.0,
    "if a program were": 1.0,
    "a program were ``": 1.0,
    "program were `` right": 1.0,
    "were `` right ''": 1.0,
    "`` right '' 100": 1.0,
    "right '' 100 %": 1.0,
    "'' 100 % of": 1.0,
    "100 % of the": 1.0,
    "the time , humans": 0.2,
    "time , humans would": 1.0,
    ", humans would still": 1.0,
    "humans would still disagree": 1.0,
    "would still disagree with": 1.0,
    "still disagree with it": 1.0,
    "disagree with it about": 1.0,
    "with it about 30": 1.0,
    "it about 30 %": 1.0,
    "about 30 % of": 1.0,
    "30 % of the": 1.0,
    "the time , since": 0.2,
    "time , since they": 1.0,
    ", since they disagree": 1.0,
    "since they disagree that": 1.0,
    "they disagree that much": 1.0,
    "disagree that much about": 1.0,
    "that much about any": 1.0,
    "much about any answer": 1.0,
    "about any answer .": 1.0,
    "<s> more sophisticated measures": 0.5,
    "more sophisticated measures can": 1.0,
    "sophisticated measures can be": 1.0,
    "measures can be applied": 0.5,
    "can be applied ,": 0.5,
    "be applied , but": 1.0,
    "applied , but evaluation": 1.0,
    ", but evaluation of": 1.0,
    "but evaluation of sentiment": 1.0,
    "evaluation of sentiment analysis": 1.0,
    "of sentiment analysis systems": 0.3333333333333333,
    "sentiment analysis systems remains": 1.0,
    "analysis systems remains a": 1.0,
    "systems remains a complex": 1.0,
    "remains a complex matter": 1.0,
    "a complex matter .": 1.0,
    "<s> for sentiment analysis": 1.0,
    "for sentiment analysis tasks": 1.0,
    "sentiment analysis tasks returning": 1.0,
    "analysis tasks returning a": 1.0,
    "tasks returning a scale": 1.0,
    "returning a scale rather": 1.0,
    "a scale rather than": 1.0,
    "scale rather than a": 1.0,
    "rather than a binary": 0.3333333333333333,
    "than a binary judgement": 1.0,
    "a binary judgement ,": 1.0,
    "binary judgement , correlation": 1.0,
    "judgement , correlation is": 1.0,
    ", correlation is a": 1.0,
    "correlation is a better": 1.0,
    "is a better measure": 1.0,
    "a better measure than": 1.0,
    "better measure than precision": 1.0,
    "measure than precision because": 1.0,
    "than precision because it": 1.0,
    "precision because it takes": 1.0,
    "because it takes into": 1.0,
    "it takes into account": 1.0,
    "takes into account how": 1.0,
    "into account how close": 1.0,
    "account how close the": 1.0,
    "how close the predicted": 1.0,
    "close the predicted value": 1.0,
    "the predicted value is": 1.0,
    "predicted value is to": 1.0,
    "value is to the": 1.0,
    "is to the target": 1.0,
    "to the target value": 1.0,
    "the target value .": 1.0,
    "<s> sentiment analysis was": 0.2,
    "sentiment analysis was used": 1.0,
    "analysis was used to": 1.0,
    "was used to test": 1.0,
    "used to test the": 1.0,
    "to test the relationship": 1.0,
    "test the relationship between": 1.0,
    "the relationship between internet": 1.0,
    "relationship between internet financial": 1.0,
    "between internet financial message": 1.0,
    "internet financial message boards": 1.0,
    "financial message boards and": 1.0,
    "message boards and the": 1.0,
    "boards and the behavior": 1.0,
    "and the behavior of": 1.0,
    "the behavior of the": 1.0,
    "behavior of the stock": 1.0,
    "of the stock market": 1.0,
    "the stock market to": 1.0,
    "stock market to find": 1.0,
    "market to find a": 1.0,
    "to find a strong": 1.0,
    "find a strong correlation": 1.0,
    "a strong correlation between": 1.0,
    "strong correlation between posts": 1.0,
    "correlation between posts and": 1.0,
    "between posts and volume": 1.0,
    "posts and volume of": 1.0,
    "and volume of stock": 1.0,
    "volume of stock .": 1.0,
    "<s> sentiment analysis and": 0.2,
    "sentiment analysis and web": 0.5,
    "analysis and web 2.0": 1.0,
    "and web 2.0 the": 1.0,
    "web 2.0 the rise": 1.0,
    "2.0 the rise of": 1.0,
    "the rise of social": 1.0,
    "rise of social media": 1.0,
    "of social media such": 1.0,
    "social media such as": 1.0,
    "media such as blogs": 1.0,
    "such as blogs and": 1.0,
    "as blogs and social": 1.0,
    "blogs and social networks": 1.0,
    "and social networks has": 1.0,
    "social networks has fueled": 1.0,
    "networks has fueled interest": 1.0,
    "has fueled interest in": 1.0,
    "fueled interest in sentiment": 1.0,
    "interest in sentiment analysis": 1.0,
    "in sentiment analysis .": 1.0,
    "<s> with the proliferation": 0.5,
    "with the proliferation of": 1.0,
    "the proliferation of reviews": 1.0,
    "proliferation of reviews ,": 1.0,
    "of reviews , ratings": 1.0,
    "reviews , ratings ,": 1.0,
    ", ratings , recommendations": 1.0,
    "ratings , recommendations and": 1.0,
    ", recommendations and other": 1.0,
    "recommendations and other forms": 1.0,
    "and other forms of": 1.0,
    "other forms of online": 1.0,
    "forms of online expression": 1.0,
    "of online expression ,": 1.0,
    "online expression , online": 1.0,
    "expression , online opinion": 1.0,
    ", online opinion has": 1.0,
    "online opinion has turned": 1.0,
    "opinion has turned into": 1.0,
    "has turned into a": 1.0,
    "turned into a kind": 0.5,
    "into a kind of": 1.0,
    "a kind of virtual": 1.0,
    "kind of virtual currency": 1.0,
    "of virtual currency for": 1.0,
    "virtual currency for businesses": 1.0,
    "currency for businesses looking": 1.0,
    "for businesses looking to": 1.0,
    "businesses looking to market": 1.0,
    "looking to market their": 1.0,
    "to market their products": 1.0,
    "market their products ,": 1.0,
    "their products , identify": 1.0,
    "products , identify new": 1.0,
    ", identify new opportunities": 1.0,
    "identify new opportunities and": 1.0,
    "new opportunities and manage": 1.0,
    "opportunities and manage their": 1.0,
    "and manage their reputations": 1.0,
    "manage their reputations .": 1.0,
    "<s> as businesses look": 1.0,
    "as businesses look to": 1.0,
    "businesses look to automate": 1.0,
    "look to automate the": 1.0,
    "to automate the process": 1.0,
    "automate the process of": 1.0,
    "the process of filtering": 0.09090909090909091,
    "process of filtering out": 1.0,
    "of filtering out the": 1.0,
    "filtering out the noise": 1.0,
    "out the noise ,": 1.0,
    "the noise , understanding": 1.0,
    "noise , understanding the": 1.0,
    ", understanding the conversations": 1.0,
    "understanding the conversations ,": 1.0,
    "the conversations , identifying": 1.0,
    "conversations , identifying the": 1.0,
    ", identifying the relevant": 0.5,
    "identifying the relevant content": 1.0,
    "the relevant content and": 1.0,
    "relevant content and actioning": 1.0,
    "content and actioning it": 1.0,
    "and actioning it appropriately": 1.0,
    "actioning it appropriately ,": 1.0,
    "it appropriately , many": 1.0,
    "appropriately , many are": 1.0,
    ", many are now": 1.0,
    "many are now looking": 1.0,
    "are now looking to": 1.0,
    "now looking to the": 1.0,
    "looking to the field": 1.0,
    "the field of sentiment": 0.1111111111111111,
    "field of sentiment analysis": 1.0,
    "of sentiment analysis .": 0.3333333333333333,
    "<s> if web 2.0": 1.0,
    "if web 2.0 was": 1.0,
    "web 2.0 was all": 1.0,
    "2.0 was all about": 1.0,
    "was all about democratizing": 1.0,
    "all about democratizing publishing": 1.0,
    "about democratizing publishing ,": 1.0,
    "democratizing publishing , then": 1.0,
    "publishing , then the": 1.0,
    ", then the next": 0.5,
    "then the next stage": 1.0,
    "the next stage of": 0.5,
    "next stage of the": 1.0,
    "stage of the web": 1.0,
    "of the web may": 1.0,
    "the web may well": 1.0,
    "web may well be": 1.0,
    "may well be based": 1.0,
    "well be based on": 1.0,
    "be based on democratizing": 1.0,
    "based on democratizing data": 1.0,
    "on democratizing data mining": 1.0,
    "democratizing data mining of": 1.0,
    "data mining of all": 1.0,
    "mining of all the": 1.0,
    "of all the content": 0.5,
    "all the content that": 1.0,
    "the content that is": 1.0,
    "content that is getting": 1.0,
    "that is getting published": 1.0,
    "is getting published .": 1.0,
    "<s> one step towards": 1.0,
    "one step towards this": 1.0,
    "step towards this aim": 1.0,
    "towards this aim is": 1.0,
    "this aim is accomplished": 1.0,
    "aim is accomplished in": 1.0,
    "is accomplished in research": 1.0,
    "accomplished in research .": 1.0,
    "<s> several research teams": 1.0,
    "several research teams in": 1.0,
    "research teams in universities": 1.0,
    "teams in universities around": 1.0,
    "in universities around the": 1.0,
    "universities around the world": 1.0,
    "around the world currently": 1.0,
    "the world currently focus": 1.0,
    "world currently focus on": 1.0,
    "currently focus on understanding": 1.0,
    "focus on understanding the": 1.0,
    "on understanding the dynamics": 1.0,
    "understanding the dynamics of": 1.0,
    "the dynamics of sentiment": 1.0,
    "dynamics of sentiment in": 1.0,
    "of sentiment in e-communities": 1.0,
    "sentiment in e-communities through": 1.0,
    "in e-communities through sentiment": 1.0,
    "e-communities through sentiment analysis": 1.0,
    "through sentiment analysis .": 1.0,
    "<s> the cyberemotions project": 1.0,
    "the cyberemotions project ,": 1.0,
    "cyberemotions project , for": 1.0,
    "project , for instance": 1.0,
    "for instance , recently": 0.1111111111111111,
    "instance , recently identified": 1.0,
    ", recently identified the": 1.0,
    "recently identified the role": 1.0,
    "identified the role of": 1.0,
    "the role of negative": 1.0,
    "role of negative emotions": 1.0,
    "of negative emotions in": 1.0,
    "negative emotions in driving": 1.0,
    "emotions in driving social": 1.0,
    "in driving social networks": 1.0,
    "driving social networks discussions": 1.0,
    "social networks discussions .": 1.0,
    "<s> sentiment analysis could": 0.2,
    "sentiment analysis could therefore": 1.0,
    "analysis could therefore help": 1.0,
    "could therefore help understand": 1.0,
    "therefore help understand why": 1.0,
    "help understand why certain": 1.0,
    "understand why certain e-communities": 1.0,
    "why certain e-communities die": 1.0,
    "certain e-communities die or": 1.0,
    "e-communities die or fade": 1.0,
    "die or fade away": 1.0,
    "or fade away -lrb-": 1.0,
    "fade away -lrb- e.g.": 1.0,
    "away -lrb- e.g. ,": 1.0,
    "-lrb- e.g. , myspace": 0.05263157894736842,
    "e.g. , myspace -rrb-": 1.0,
    ", myspace -rrb- while": 1.0,
    "myspace -rrb- while others": 1.0,
    "-rrb- while others seem": 1.0,
    "while others seem to": 1.0,
    "others seem to grow": 1.0,
    "seem to grow without": 1.0,
    "to grow without limits": 1.0,
    "grow without limits -lrb-": 1.0,
    "without limits -lrb- e.g.": 1.0,
    "limits -lrb- e.g. ,": 1.0,
    "-lrb- e.g. , facebook": 0.05263157894736842,
    "e.g. , facebook -rrb-": 1.0,
    ", facebook -rrb- .": 1.0,
    "<s> the problem is": 0.6666666666666666,
    "the problem is that": 0.5,
    "problem is that most": 1.0,
    "is that most sentiment": 1.0,
    "that most sentiment analysis": 1.0,
    "most sentiment analysis algorithms": 1.0,
    "sentiment analysis algorithms use": 1.0,
    "analysis algorithms use simple": 1.0,
    "algorithms use simple terms": 1.0,
    "use simple terms to": 1.0,
    "simple terms to express": 1.0,
    "terms to express sentiment": 1.0,
    "to express sentiment about": 1.0,
    "express sentiment about a": 1.0,
    "sentiment about a product": 1.0,
    "about a product or": 1.0,
    "a product or service": 1.0,
    "product or service .": 1.0,
    "<s> however , cultural": 0.03125,
    "however , cultural factors": 1.0,
    ", cultural factors ,": 1.0,
    "cultural factors , linguistic": 1.0,
    "factors , linguistic nuances": 1.0,
    ", linguistic nuances and": 1.0,
    "linguistic nuances and differing": 1.0,
    "nuances and differing contexts": 1.0,
    "and differing contexts make": 1.0,
    "differing contexts make it": 1.0,
    "contexts make it extremely": 1.0,
    "make it extremely difficult": 1.0,
    "it extremely difficult to": 1.0,
    "extremely difficult to turn": 1.0,
    "difficult to turn a": 1.0,
    "to turn a string": 1.0,
    "turn a string of": 1.0,
    "a string of written": 1.0,
    "string of written text": 0.5,
    "of written text into": 1.0,
    "written text into a": 0.5,
    "text into a simple": 1.0,
    "into a simple pro": 1.0,
    "a simple pro or": 1.0,
    "simple pro or con": 1.0,
    "pro or con sentiment": 1.0,
    "or con sentiment .": 1.0,
    "<s> the fact that": 1.0,
    "the fact that humans": 0.2,
    "fact that humans often": 1.0,
    "that humans often disagree": 1.0,
    "humans often disagree on": 1.0,
    "often disagree on the": 1.0,
    "disagree on the sentiment": 1.0,
    "on the sentiment of": 1.0,
    "the sentiment of text": 1.0,
    "sentiment of text illustrates": 1.0,
    "of text illustrates how": 1.0,
    "text illustrates how big": 1.0,
    "illustrates how big a": 1.0,
    "how big a task": 1.0,
    "big a task it": 1.0,
    "a task it is": 1.0,
    "task it is for": 1.0,
    "it is for computers": 1.0,
    "is for computers to": 1.0,
    "for computers to get": 1.0,
    "computers to get this": 1.0,
    "to get this right": 1.0,
    "get this right .": 1.0,
    "<s> the shorter the": 1.0,
    "the shorter the string": 1.0,
    "shorter the string of": 1.0,
    "the string of text": 1.0,
    "string of text ,": 1.0,
    "of text , the": 0.1,
    "text , the harder": 1.0,
    ", the harder it": 1.0,
    "the harder it becomes": 1.0,
    "harder it becomes .": 1.0,
    "<s> n computer science": 1.0,
    "n computer science ,": 1.0,
    "computer science , speech": 0.3333333333333333,
    "science , speech recognition": 1.0,
    ", speech recognition is": 0.2,
    "speech recognition is the": 0.125,
    "recognition is the translation": 1.0,
    "is the translation of": 1.0,
    "the translation of spoken": 0.3333333333333333,
    "translation of spoken words": 1.0,
    "of spoken words into": 1.0,
    "spoken words into text": 1.0,
    "words into text .": 1.0,
    "<s> it is also": 0.05263157894736842,
    "it is also known": 0.5,
    "is also known as": 1.0,
    "also known as ``": 0.16666666666666666,
    "known as `` automatic": 1.0,
    "as `` automatic speech": 1.0,
    "`` automatic speech recognition": 1.0,
    "automatic speech recognition ''": 0.3333333333333333,
    "speech recognition '' ,": 0.5,
    "recognition '' , ``": 1.0,
    "'' , `` asr": 0.09090909090909091,
    ", `` asr ''": 1.0,
    "`` asr '' ,": 1.0,
    "asr '' , ``": 1.0,
    "'' , `` computer": 0.09090909090909091,
    ", `` computer speech": 1.0,
    "`` computer speech recognition": 0.5,
    "computer speech recognition ''": 1.0,
    "'' , `` speech": 0.09090909090909091,
    ", `` speech to": 1.0,
    "`` speech to text": 1.0,
    "speech to text ''": 1.0,
    "to text '' ,": 1.0,
    "text '' , or": 1.0,
    "'' , or just": 1.0,
    ", or just ``": 1.0,
    "or just `` stt": 1.0,
    "just `` stt ''": 1.0,
    "`` stt '' .": 1.0,
    "<s> speech recognition is": 0.42857142857142855,
    "speech recognition is technology": 0.125,
    "recognition is technology that": 1.0,
    "is technology that can": 1.0,
    "technology that can translate": 1.0,
    "that can translate spoken": 1.0,
    "can translate spoken words": 1.0,
    "translate spoken words into": 1.0,
    "<s> some sr systems": 1.0,
    "some sr systems use": 1.0,
    "sr systems use ``": 1.0,
    "systems use `` training": 1.0,
    "use `` training ''": 1.0,
    "`` training '' where": 1.0,
    "training '' where an": 1.0,
    "'' where an individual": 1.0,
    "where an individual speaker": 1.0,
    "an individual speaker reads": 1.0,
    "individual speaker reads sections": 1.0,
    "speaker reads sections of": 1.0,
    "reads sections of text": 1.0,
    "sections of text into": 1.0,
    "of text into the": 0.5,
    "text into the sr": 1.0,
    "into the sr system": 1.0,
    "the sr system .": 1.0,
    "<s> these systems analyze": 0.25,
    "these systems analyze the": 1.0,
    "systems analyze the person": 1.0,
    "analyze the person 's": 1.0,
    "the person 's specific": 0.5,
    "person 's specific voice": 1.0,
    "'s specific voice and": 1.0,
    "specific voice and use": 1.0,
    "voice and use it": 1.0,
    "and use it to": 1.0,
    "use it to fine": 0.5,
    "it to fine tune": 1.0,
    "to fine tune the": 1.0,
    "fine tune the recognition": 1.0,
    "tune the recognition of": 1.0,
    "the recognition of that": 0.5,
    "recognition of that person": 1.0,
    "of that person 's": 1.0,
    "that person 's speech": 1.0,
    "person 's speech ,": 1.0,
    "'s speech , resulting": 1.0,
    "speech , resulting in": 1.0,
    ", resulting in more": 1.0,
    "resulting in more accurate": 1.0,
    "in more accurate transcription": 1.0,
    "more accurate transcription .": 1.0,
    "<s> systems that do": 0.25,
    "systems that do not": 1.0,
    "that do not use": 1.0,
    "do not use training": 1.0,
    "not use training are": 1.0,
    "use training are called": 1.0,
    "training are called ``": 1.0,
    "are called `` speaker": 1.0,
    "called `` speaker independent": 0.5,
    "`` speaker independent ''": 1.0,
    "speaker independent '' systems": 1.0,
    "independent '' systems .": 1.0,
    "<s> systems that use": 0.25,
    "systems that use training": 0.5,
    "that use training are": 1.0,
    "called `` speaker dependent": 0.5,
    "`` speaker dependent ''": 1.0,
    "speaker dependent '' systems": 1.0,
    "dependent '' systems .": 1.0,
    "<s> speech recognition applications": 0.14285714285714285,
    "speech recognition applications include": 1.0,
    "recognition applications include voice": 1.0,
    "applications include voice user": 1.0,
    "include voice user interfaces": 1.0,
    "voice user interfaces such": 1.0,
    "user interfaces such as": 1.0,
    "interfaces such as voice": 1.0,
    "such as voice dialing": 1.0,
    "as voice dialing -lrb-": 1.0,
    "voice dialing -lrb- e.g.": 1.0,
    "dialing -lrb- e.g. ,": 1.0,
    "e.g. , `` call": 0.3333333333333333,
    ", `` call home": 1.0,
    "`` call home ''": 1.0,
    "call home '' -rrb-": 1.0,
    "home '' -rrb- ,": 1.0,
    "'' -rrb- , call": 0.25,
    "-rrb- , call routing": 1.0,
    ", call routing -lrb-": 1.0,
    "call routing -lrb- e.g.": 1.0,
    "routing -lrb- e.g. ,": 1.0,
    "e.g. , `` i": 0.3333333333333333,
    ", `` i would": 1.0,
    "`` i would like": 1.0,
    "i would like to": 1.0,
    "would like to make": 0.5,
    "like to make a": 1.0,
    "to make a collect": 0.5,
    "make a collect call": 1.0,
    "a collect call ''": 1.0,
    "collect call '' -rrb-": 1.0,
    "call '' -rrb- ,": 1.0,
    "'' -rrb- , domotic": 0.25,
    "-rrb- , domotic appliance": 1.0,
    ", domotic appliance control": 1.0,
    "domotic appliance control ,": 1.0,
    "appliance control , search": 1.0,
    "control , search -lrb-": 1.0,
    ", search -lrb- e.g.": 1.0,
    "search -lrb- e.g. ,": 1.0,
    "-lrb- e.g. , find": 0.05263157894736842,
    "e.g. , find a": 1.0,
    ", find a podcast": 1.0,
    "find a podcast where": 1.0,
    "a podcast where particular": 1.0,
    "podcast where particular words": 1.0,
    "where particular words were": 1.0,
    "particular words were spoken": 1.0,
    "words were spoken -rrb-": 1.0,
    "were spoken -rrb- ,": 1.0,
    "spoken -rrb- , simple": 1.0,
    "-rrb- , simple data": 1.0,
    ", simple data entry": 1.0,
    "simple data entry -lrb-": 1.0,
    "data entry -lrb- e.g.": 1.0,
    "entry -lrb- e.g. ,": 1.0,
    "-lrb- e.g. , entering": 0.05263157894736842,
    "e.g. , entering a": 1.0,
    ", entering a credit": 1.0,
    "entering a credit card": 1.0,
    "a credit card number": 0.5,
    "credit card number -rrb-": 1.0,
    "card number -rrb- ,": 1.0,
    "number -rrb- , preparation": 1.0,
    "-rrb- , preparation of": 1.0,
    ", preparation of structured": 1.0,
    "preparation of structured documents": 1.0,
    "of structured documents -lrb-": 1.0,
    "structured documents -lrb- e.g.": 1.0,
    "documents -lrb- e.g. ,": 1.0,
    "e.g. , a radiology": 0.5,
    ", a radiology report": 1.0,
    "a radiology report -rrb-": 1.0,
    "radiology report -rrb- ,": 1.0,
    "report -rrb- , speech-to-text": 1.0,
    "-rrb- , speech-to-text processing": 1.0,
    ", speech-to-text processing -lrb-": 1.0,
    "speech-to-text processing -lrb- e.g.": 1.0,
    "processing -lrb- e.g. ,": 1.0,
    "-lrb- e.g. , word": 0.05263157894736842,
    "e.g. , word processors": 1.0,
    ", word processors or": 1.0,
    "word processors or emails": 1.0,
    "processors or emails -rrb-": 1.0,
    "or emails -rrb- ,": 1.0,
    "emails -rrb- , and": 1.0,
    "-rrb- , and aircraft": 0.09090909090909091,
    ", and aircraft -lrb-": 1.0,
    "and aircraft -lrb- usually": 1.0,
    "aircraft -lrb- usually termed": 1.0,
    "-lrb- usually termed direct": 1.0,
    "usually termed direct voice": 1.0,
    "termed direct voice input": 1.0,
    "direct voice input -rrb-": 1.0,
    "voice input -rrb- .": 1.0,
    "<s> the term voice": 0.25,
    "the term voice recognition": 1.0,
    "term voice recognition refers": 1.0,
    "voice recognition refers to": 1.0,
    "recognition refers to finding": 1.0,
    "refers to finding the": 1.0,
    "to finding the identity": 1.0,
    "finding the identity of": 1.0,
    "the identity of ``": 0.25,
    "identity of `` who": 1.0,
    "of `` who ''": 1.0,
    "`` who '' is": 1.0,
    "who '' is speaking": 1.0,
    "'' is speaking ,": 1.0,
    "is speaking , rather": 1.0,
    "speaking , rather than": 1.0,
    ", rather than what": 0.5,
    "rather than what they": 1.0,
    "than what they are": 1.0,
    "what they are saying": 1.0,
    "they are saying .": 1.0,
    "<s> recognizing the speaker": 1.0,
    "recognizing the speaker can": 1.0,
    "the speaker can simplify": 1.0,
    "speaker can simplify the": 1.0,
    "can simplify the task": 1.0,
    "simplify the task of": 1.0,
    "the task of translating": 0.16666666666666666,
    "task of translating speech": 1.0,
    "of translating speech in": 1.0,
    "translating speech in systems": 1.0,
    "speech in systems that": 1.0,
    "in systems that have": 1.0,
    "systems that have been": 1.0,
    "that have been trained": 0.3333333333333333,
    "have been trained on": 1.0,
    "been trained on specific": 1.0,
    "trained on specific person": 1.0,
    "on specific person 's": 1.0,
    "specific person 's voices": 1.0,
    "person 's voices or": 1.0,
    "'s voices or it": 1.0,
    "voices or it can": 1.0,
    "or it can be": 1.0,
    "it can be used": 0.5,
    "be used to authenticate": 0.16666666666666666,
    "used to authenticate or": 1.0,
    "to authenticate or verify": 1.0,
    "authenticate or verify the": 1.0,
    "or verify the identity": 1.0,
    "verify the identity of": 1.0,
    "the identity of a": 0.25,
    "identity of a speaker": 1.0,
    "of a speaker as": 0.5,
    "a speaker as part": 1.0,
    "speaker as part of": 1.0,
    "part of a security": 0.3333333333333333,
    "of a security process": 1.0,
    "a security process .": 1.0,
    "<s> front-end speech recognition": 1.0,
    "front-end speech recognition is": 1.0,
    "speech recognition is where": 0.25,
    "recognition is where the": 1.0,
    "is where the provider": 1.0,
    "where the provider dictates": 1.0,
    "the provider dictates into": 1.0,
    "provider dictates into a": 1.0,
    "dictates into a speech-recognition": 0.5,
    "into a speech-recognition engine": 1.0,
    "a speech-recognition engine ,": 0.5,
    "speech-recognition engine , the": 1.0,
    "engine , the recognized": 1.0,
    ", the recognized words": 1.0,
    "the recognized words are": 1.0,
    "recognized words are displayed": 1.0,
    "words are displayed as": 1.0,
    "are displayed as they": 1.0,
    "displayed as they are": 1.0,
    "as they are spoken": 0.5,
    "they are spoken ,": 1.0,
    "are spoken , and": 1.0,
    "spoken , and the": 1.0,
    ", and the dictator": 0.1,
    "and the dictator is": 1.0,
    "the dictator is responsible": 1.0,
    "dictator is responsible for": 1.0,
    "is responsible for editing": 1.0,
    "responsible for editing and": 1.0,
    "for editing and signing": 1.0,
    "editing and signing off": 1.0,
    "and signing off on": 1.0,
    "signing off on the": 1.0,
    "off on the document": 1.0,
    "on the document .": 1.0,
    "<s> back-end or deferred": 1.0,
    "back-end or deferred speech": 1.0,
    "or deferred speech recognition": 1.0,
    "deferred speech recognition is": 1.0,
    "dictates into a digital": 0.5,
    "into a digital dictation": 1.0,
    "a digital dictation system": 1.0,
    "digital dictation system ,": 1.0,
    "dictation system , the": 1.0,
    "system , the voice": 0.3333333333333333,
    ", the voice is": 1.0,
    "the voice is routed": 1.0,
    "voice is routed through": 1.0,
    "is routed through a": 1.0,
    "routed through a speech-recognition": 1.0,
    "through a speech-recognition machine": 1.0,
    "a speech-recognition machine and": 1.0,
    "speech-recognition machine and the": 1.0,
    "machine and the recognized": 1.0,
    "and the recognized draft": 1.0,
    "the recognized draft document": 1.0,
    "recognized draft document is": 1.0,
    "draft document is routed": 1.0,
    "document is routed along": 1.0,
    "is routed along with": 1.0,
    "routed along with the": 1.0,
    "along with the original": 1.0,
    "with the original voice": 1.0,
    "the original voice file": 1.0,
    "original voice file to": 1.0,
    "voice file to the": 1.0,
    "file to the editor": 1.0,
    "to the editor ,": 1.0,
    "the editor , where": 1.0,
    "editor , where the": 1.0,
    ", where the draft": 0.2,
    "where the draft is": 1.0,
    "the draft is edited": 1.0,
    "draft is edited and": 1.0,
    "is edited and report": 1.0,
    "edited and report finalized": 1.0,
    "and report finalized .": 1.0,
    "<s> deferred speech recognition": 1.0,
    "speech recognition is widely": 0.125,
    "recognition is widely used": 1.0,
    "is widely used in": 0.5,
    "used in the industry": 0.16666666666666666,
    "in the industry currently": 1.0,
    "the industry currently .": 1.0,
    "<s> many electronic medical": 1.0,
    "many electronic medical records": 1.0,
    "electronic medical records -lrb-": 0.5,
    "medical records -lrb- emr": 1.0,
    "records -lrb- emr -rrb-": 1.0,
    "-lrb- emr -rrb- applications": 1.0,
    "emr -rrb- applications can": 1.0,
    "-rrb- applications can be": 1.0,
    "applications can be more": 1.0,
    "can be more effective": 1.0,
    "be more effective and": 1.0,
    "more effective and may": 1.0,
    "effective and may be": 1.0,
    "and may be performed": 1.0,
    "may be performed more": 1.0,
    "be performed more easily": 1.0,
    "performed more easily when": 1.0,
    "more easily when deployed": 1.0,
    "easily when deployed in": 1.0,
    "when deployed in conjunction": 1.0,
    "deployed in conjunction with": 1.0,
    "in conjunction with a": 0.5,
    "conjunction with a speech-recognition": 1.0,
    "with a speech-recognition engine": 1.0,
    "a speech-recognition engine .": 0.5,
    "<s> searches , queries": 1.0,
    "searches , queries ,": 1.0,
    ", queries , and": 1.0,
    "queries , and form": 1.0,
    ", and form filling": 1.0,
    "and form filling may": 1.0,
    "form filling may all": 1.0,
    "filling may all be": 1.0,
    "may all be faster": 1.0,
    "all be faster to": 1.0,
    "be faster to perform": 1.0,
    "faster to perform by": 1.0,
    "to perform by voice": 1.0,
    "perform by voice than": 1.0,
    "by voice than by": 1.0,
    "voice than by using": 1.0,
    "than by using a": 1.0,
    "by using a keyboard": 1.0,
    "using a keyboard .": 1.0,
    "one of the major": 0.08333333333333333,
    "of the major issues": 1.0,
    "the major issues relating": 1.0,
    "major issues relating to": 1.0,
    "issues relating to the": 1.0,
    "relating to the use": 1.0,
    "the use of speech": 0.13333333333333333,
    "use of speech recognition": 1.0,
    "of speech recognition in": 0.14285714285714285,
    "speech recognition in healthcare": 0.3333333333333333,
    "recognition in healthcare is": 1.0,
    "in healthcare is that": 1.0,
    "healthcare is that the": 1.0,
    "is that the american": 0.3333333333333333,
    "that the american recovery": 1.0,
    "the american recovery and": 1.0,
    "american recovery and reinvestment": 1.0,
    "recovery and reinvestment act": 1.0,
    "and reinvestment act of": 1.0,
    "reinvestment act of 2009": 1.0,
    "act of 2009 -lrb-": 1.0,
    "of 2009 -lrb- arra": 1.0,
    "2009 -lrb- arra -rrb-": 1.0,
    "-lrb- arra -rrb- provides": 1.0,
    "arra -rrb- provides for": 1.0,
    "-rrb- provides for substantial": 1.0,
    "provides for substantial financial": 1.0,
    "for substantial financial benefits": 1.0,
    "substantial financial benefits to": 1.0,
    "financial benefits to physicians": 1.0,
    "benefits to physicians who": 1.0,
    "to physicians who utilize": 1.0,
    "physicians who utilize an": 1.0,
    "who utilize an emr": 1.0,
    "utilize an emr according": 1.0,
    "an emr according to": 1.0,
    "emr according to ``": 1.0,
    "according to `` meaningful": 1.0,
    "to `` meaningful use": 1.0,
    "`` meaningful use ''": 1.0,
    "meaningful use '' standards": 1.0,
    "use '' standards .": 1.0,
    "<s> these standards require": 1.0,
    "these standards require that": 1.0,
    "standards require that a": 1.0,
    "require that a substantial": 1.0,
    "that a substantial amount": 1.0,
    "a substantial amount of": 1.0,
    "substantial amount of data": 1.0,
    "amount of data be": 1.0,
    "of data be maintained": 1.0,
    "data be maintained by": 1.0,
    "be maintained by the": 1.0,
    "maintained by the emr": 1.0,
    "by the emr -lrb-": 1.0,
    "the emr -lrb- now": 1.0,
    "emr -lrb- now more": 1.0,
    "-lrb- now more commonly": 1.0,
    "now more commonly referred": 1.0,
    "more commonly referred to": 1.0,
    "commonly referred to as": 1.0,
    "to as an electronic": 0.5,
    "as an electronic health": 1.0,
    "an electronic health record": 1.0,
    "electronic health record or": 1.0,
    "health record or ehr": 1.0,
    "record or ehr -rrb-": 1.0,
    "or ehr -rrb- .": 1.0,
    "<s> unfortunately , in": 1.0,
    "unfortunately , in many": 1.0,
    ", in many instances": 1.0,
    "in many instances ,": 1.0,
    "many instances , the": 1.0,
    "instances , the use": 1.0,
    ", the use of": 1.0,
    "of speech recognition within": 0.07142857142857142,
    "speech recognition within an": 1.0,
    "recognition within an ehr": 1.0,
    "within an ehr will": 1.0,
    "an ehr will not": 1.0,
    "ehr will not lead": 1.0,
    "will not lead to": 1.0,
    "not lead to data": 1.0,
    "lead to data maintained": 1.0,
    "to data maintained within": 1.0,
    "data maintained within a": 1.0,
    "maintained within a database": 1.0,
    "within a database ,": 1.0,
    "a database , but": 1.0,
    "database , but rather": 1.0,
    ", but rather to": 0.5,
    "but rather to narrative": 1.0,
    "rather to narrative text": 1.0,
    "to narrative text .": 1.0,
    "<s> for this reason": 0.6666666666666666,
    "for this reason ,": 1.0,
    "this reason , substantial": 0.5,
    "reason , substantial resources": 1.0,
    ", substantial resources are": 1.0,
    "substantial resources are being": 1.0,
    "resources are being expended": 1.0,
    "are being expended to": 1.0,
    "being expended to allow": 1.0,
    "expended to allow for": 1.0,
    "to allow for the": 1.0,
    "allow for the use": 1.0,
    "for the use of": 1.0,
    "the use of front-end": 0.06666666666666667,
    "use of front-end sr": 1.0,
    "of front-end sr while": 1.0,
    "front-end sr while capturing": 1.0,
    "sr while capturing data": 1.0,
    "while capturing data within": 1.0,
    "capturing data within the": 1.0,
    "data within the ehr": 1.0,
    "within the ehr .": 1.0,
    "<s> military high-performance fighter": 1.0,
    "military high-performance fighter aircraft": 1.0,
    "high-performance fighter aircraft substantial": 1.0,
    "fighter aircraft substantial efforts": 1.0,
    "aircraft substantial efforts have": 1.0,
    "substantial efforts have been": 1.0,
    "efforts have been devoted": 0.5,
    "have been devoted in": 1.0,
    "been devoted in the": 1.0,
    "devoted in the last": 1.0,
    "in the last decade": 0.6666666666666666,
    "the last decade to": 0.5,
    "last decade to the": 1.0,
    "decade to the test": 1.0,
    "to the test and": 0.5,
    "the test and evaluation": 1.0,
    "test and evaluation of": 0.5,
    "and evaluation of speech": 1.0,
    "evaluation of speech recognition": 1.0,
    "speech recognition in fighter": 0.3333333333333333,
    "recognition in fighter aircraft": 1.0,
    "in fighter aircraft .": 0.5,
    "<s> of particular note": 1.0,
    "of particular note is": 1.0,
    "particular note is the": 1.0,
    "note is the u.s.": 1.0,
    "is the u.s. program": 1.0,
    "the u.s. program in": 1.0,
    "u.s. program in speech": 1.0,
    "program in speech recognition": 1.0,
    "in speech recognition for": 0.14285714285714285,
    "speech recognition for the": 1.0,
    "recognition for the advanced": 1.0,
    "for the advanced fighter": 1.0,
    "the advanced fighter technology": 1.0,
    "advanced fighter technology integration": 1.0,
    "fighter technology integration -lrb-": 1.0,
    "technology integration -lrb- afti": 1.0,
    "integration -lrb- afti -rrb-": 1.0,
    "-lrb- afti -rrb- \\/": 1.0,
    "afti -rrb- \\/ f-16": 1.0,
    "-rrb- \\/ f-16 aircraft": 1.0,
    "\\/ f-16 aircraft -lrb-": 1.0,
    "f-16 aircraft -lrb- f-16": 1.0,
    "aircraft -lrb- f-16 vista": 1.0,
    "-lrb- f-16 vista -rrb-": 1.0,
    "f-16 vista -rrb- ,": 1.0,
    "vista -rrb- , and": 1.0,
    "-rrb- , and a": 0.09090909090909091,
    ", and a program": 0.16666666666666666,
    "and a program in": 1.0,
    "a program in france": 1.0,
    "program in france installing": 1.0,
    "in france installing speech": 1.0,
    "france installing speech recognition": 1.0,
    "installing speech recognition systems": 1.0,
    "speech recognition systems on": 0.1111111111111111,
    "recognition systems on mirage": 1.0,
    "systems on mirage aircraft": 1.0,
    "on mirage aircraft ,": 1.0,
    "mirage aircraft , and": 1.0,
    "aircraft , and also": 1.0,
    ", and also programs": 1.0,
    "and also programs in": 1.0,
    "also programs in the": 1.0,
    "programs in the uk": 1.0,
    "in the uk dealing": 0.3333333333333333,
    "the uk dealing with": 1.0,
    "uk dealing with a": 1.0,
    "dealing with a variety": 1.0,
    "with a variety of": 1.0,
    "a variety of aircraft": 0.14285714285714285,
    "variety of aircraft platforms": 1.0,
    "of aircraft platforms .": 1.0,
    "<s> in these programs": 1.0,
    "in these programs ,": 1.0,
    "these programs , speech": 1.0,
    "programs , speech recognizers": 1.0,
    ", speech recognizers have": 1.0,
    "speech recognizers have been": 1.0,
    "recognizers have been operated": 1.0,
    "have been operated successfully": 1.0,
    "been operated successfully in": 1.0,
    "operated successfully in fighter": 1.0,
    "successfully in fighter aircraft": 1.0,
    "in fighter aircraft ,": 0.5,
    "fighter aircraft , with": 1.0,
    "aircraft , with applications": 1.0,
    ", with applications including": 1.0,
    "with applications including :": 1.0,
    "applications including : setting": 1.0,
    "including : setting radio": 1.0,
    ": setting radio frequencies": 1.0,
    "setting radio frequencies ,": 1.0,
    "radio frequencies , commanding": 1.0,
    "frequencies , commanding an": 1.0,
    ", commanding an autopilot": 1.0,
    "commanding an autopilot system": 1.0,
    "an autopilot system ,": 1.0,
    "autopilot system , setting": 1.0,
    "system , setting steer-point": 1.0,
    ", setting steer-point coordinates": 1.0,
    "setting steer-point coordinates and": 1.0,
    "steer-point coordinates and weapons": 1.0,
    "coordinates and weapons release": 1.0,
    "and weapons release parameters": 1.0,
    "weapons release parameters ,": 1.0,
    "release parameters , and": 1.0,
    "parameters , and controlling": 1.0,
    ", and controlling flight": 1.0,
    "and controlling flight displays": 1.0,
    "controlling flight displays .": 1.0,
    "<s> working with swedish": 1.0,
    "working with swedish pilots": 1.0,
    "with swedish pilots flying": 1.0,
    "swedish pilots flying in": 1.0,
    "pilots flying in the": 1.0,
    "flying in the jas-39": 1.0,
    "in the jas-39 gripen": 1.0,
    "the jas-39 gripen cockpit": 1.0,
    "jas-39 gripen cockpit ,": 1.0,
    "gripen cockpit , englund": 1.0,
    "cockpit , englund -lrb-": 1.0,
    ", englund -lrb- 2004": 1.0,
    "englund -lrb- 2004 -rrb-": 1.0,
    "-lrb- 2004 -rrb- found": 1.0,
    "2004 -rrb- found recognition": 1.0,
    "-rrb- found recognition deteriorated": 1.0,
    "found recognition deteriorated with": 1.0,
    "recognition deteriorated with increasing": 1.0,
    "deteriorated with increasing g-loads": 1.0,
    "with increasing g-loads .": 1.0,
    "<s> it was also": 0.5,
    "it was also concluded": 1.0,
    "was also concluded that": 1.0,
    "also concluded that adaptation": 1.0,
    "concluded that adaptation greatly": 1.0,
    "that adaptation greatly improved": 1.0,
    "adaptation greatly improved the": 1.0,
    "greatly improved the results": 1.0,
    "improved the results in": 1.0,
    "the results in all": 1.0,
    "results in all cases": 1.0,
    "in all cases and": 1.0,
    "all cases and introducing": 1.0,
    "cases and introducing models": 1.0,
    "and introducing models for": 1.0,
    "introducing models for breathing": 1.0,
    "models for breathing was": 1.0,
    "for breathing was shown": 1.0,
    "breathing was shown to": 1.0,
    "was shown to improve": 1.0,
    "shown to improve recognition": 1.0,
    "to improve recognition scores": 0.5,
    "improve recognition scores significantly": 1.0,
    "recognition scores significantly .": 1.0,
    "<s> contrary to what": 0.5,
    "contrary to what might": 1.0,
    "to what might be": 1.0,
    "what might be expected": 1.0,
    "might be expected ,": 1.0,
    "be expected , no": 1.0,
    "expected , no effects": 1.0,
    ", no effects of": 1.0,
    "no effects of the": 1.0,
    "effects of the broken": 1.0,
    "of the broken english": 1.0,
    "the broken english of": 1.0,
    "broken english of the": 1.0,
    "english of the speakers": 1.0,
    "of the speakers were": 1.0,
    "the speakers were found": 1.0,
    "speakers were found .": 1.0,
    "<s> it was evident": 0.5,
    "it was evident that": 1.0,
    "was evident that spontaneous": 1.0,
    "evident that spontaneous speech": 1.0,
    "that spontaneous speech caused": 1.0,
    "spontaneous speech caused problems": 1.0,
    "speech caused problems for": 1.0,
    "caused problems for the": 1.0,
    "problems for the recognizer": 1.0,
    "for the recognizer ,": 1.0,
    "the recognizer , as": 1.0,
    "recognizer , as could": 1.0,
    ", as could be": 1.0,
    "as could be expected": 1.0,
    "could be expected .": 1.0,
    "<s> a restricted vocabulary": 1.0,
    "a restricted vocabulary ,": 1.0,
    "restricted vocabulary , and": 1.0,
    "vocabulary , and above": 1.0,
    ", and above all": 1.0,
    "and above all ,": 1.0,
    "above all , a": 1.0,
    "all , a proper": 1.0,
    ", a proper syntax": 1.0,
    "a proper syntax ,": 1.0,
    "proper syntax , could": 1.0,
    "syntax , could thus": 1.0,
    ", could thus be": 1.0,
    "could thus be expected": 1.0,
    "thus be expected to": 1.0,
    "be expected to improve": 1.0,
    "expected to improve recognition": 1.0,
    "to improve recognition accuracy": 0.5,
    "improve recognition accuracy substantially": 1.0,
    "recognition accuracy substantially .": 1.0,
    "<s> the eurofighter typhoon": 1.0,
    "the eurofighter typhoon currently": 1.0,
    "eurofighter typhoon currently in": 1.0,
    "typhoon currently in service": 1.0,
    "currently in service with": 1.0,
    "in service with the": 1.0,
    "service with the uk": 1.0,
    "with the uk raf": 1.0,
    "the uk raf employs": 1.0,
    "uk raf employs a": 1.0,
    "raf employs a speaker-dependent": 1.0,
    "employs a speaker-dependent system": 1.0,
    "a speaker-dependent system ,": 1.0,
    "speaker-dependent system , i.e.": 1.0,
    "system , i.e. it": 1.0,
    ", i.e. it requires": 1.0,
    "i.e. it requires each": 1.0,
    "it requires each pilot": 1.0,
    "requires each pilot to": 1.0,
    "each pilot to create": 1.0,
    "pilot to create a": 1.0,
    "to create a template": 0.2,
    "create a template .": 1.0,
    "<s> the system is": 0.3333333333333333,
    "the system is not": 0.25,
    "system is not used": 1.0,
    "is not used for": 0.5,
    "not used for any": 1.0,
    "used for any safety": 1.0,
    "for any safety critical": 1.0,
    "any safety critical or": 1.0,
    "safety critical or weapon": 1.0,
    "critical or weapon critical": 1.0,
    "or weapon critical tasks": 1.0,
    "weapon critical tasks ,": 1.0,
    "critical tasks , such": 1.0,
    "tasks , such as": 1.0,
    ", such as weapon": 0.030303030303030304,
    "such as weapon release": 1.0,
    "as weapon release or": 1.0,
    "weapon release or lowering": 1.0,
    "release or lowering of": 1.0,
    "or lowering of the": 1.0,
    "lowering of the undercarriage": 1.0,
    "of the undercarriage ,": 1.0,
    "the undercarriage , but": 1.0,
    "undercarriage , but is": 1.0,
    ", but is used": 0.5,
    "but is used for": 1.0,
    "is used for a": 1.0,
    "used for a wide": 0.5,
    "for a wide range": 1.0,
    "wide range of other": 0.5,
    "range of other cockpit": 1.0,
    "of other cockpit functions": 1.0,
    "other cockpit functions .": 1.0,
    "<s> voice commands are": 1.0,
    "voice commands are confirmed": 1.0,
    "commands are confirmed by": 1.0,
    "are confirmed by visual": 1.0,
    "confirmed by visual and\\/or": 1.0,
    "by visual and\\/or aural": 1.0,
    "visual and\\/or aural feedback": 1.0,
    "and\\/or aural feedback .": 1.0,
    "the system is seen": 0.25,
    "system is seen as": 1.0,
    "is seen as a": 1.0,
    "seen as a major": 0.5,
    "as a major design": 1.0,
    "a major design feature": 1.0,
    "major design feature in": 1.0,
    "design feature in the": 1.0,
    "feature in the reduction": 1.0,
    "in the reduction of": 1.0,
    "the reduction of pilot": 1.0,
    "reduction of pilot workload": 1.0,
    "of pilot workload ,": 1.0,
    "pilot workload , and": 1.0,
    "workload , and even": 1.0,
    ", and even allows": 0.16666666666666666,
    "and even allows the": 1.0,
    "even allows the pilot": 1.0,
    "allows the pilot to": 1.0,
    "the pilot to assign": 1.0,
    "pilot to assign targets": 1.0,
    "to assign targets to": 1.0,
    "assign targets to himself": 1.0,
    "targets to himself with": 1.0,
    "to himself with two": 1.0,
    "himself with two simple": 1.0,
    "with two simple voice": 1.0,
    "two simple voice commands": 1.0,
    "simple voice commands or": 1.0,
    "voice commands or to": 1.0,
    "commands or to any": 1.0,
    "or to any of": 1.0,
    "to any of his": 1.0,
    "any of his wingmen": 1.0,
    "of his wingmen with": 1.0,
    "his wingmen with only": 1.0,
    "wingmen with only five": 1.0,
    "with only five commands": 1.0,
    "only five commands .": 1.0,
    "<s> speaker independent systems": 1.0,
    "speaker independent systems are": 1.0,
    "independent systems are also": 1.0,
    "systems are also being": 1.0,
    "are also being developed": 1.0,
    "also being developed and": 1.0,
    "being developed and are": 1.0,
    "developed and are in": 1.0,
    "and are in testing": 1.0,
    "are in testing for": 1.0,
    "in testing for the": 1.0,
    "testing for the f35": 1.0,
    "for the f35 lightning": 1.0,
    "the f35 lightning ii": 1.0,
    "f35 lightning ii -lrb-": 1.0,
    "lightning ii -lrb- jsf": 1.0,
    "ii -lrb- jsf -rrb-": 1.0,
    "-lrb- jsf -rrb- and": 1.0,
    "jsf -rrb- and the": 1.0,
    "-rrb- and the alenia": 0.2,
    "and the alenia aermacchi": 1.0,
    "the alenia aermacchi m-346": 1.0,
    "alenia aermacchi m-346 master": 1.0,
    "aermacchi m-346 master lead-in": 1.0,
    "m-346 master lead-in fighter": 1.0,
    "master lead-in fighter trainer": 1.0,
    "lead-in fighter trainer .": 1.0,
    "<s> these systems have": 0.25,
    "these systems have produced": 1.0,
    "systems have produced word": 1.0,
    "have produced word accuracies": 1.0,
    "produced word accuracies in": 1.0,
    "word accuracies in excess": 1.0,
    "accuracies in excess of": 1.0,
    "in excess of 98": 0.5,
    "excess of 98 %": 1.0,
    "of 98 % .": 1.0,
    "<s> helicopters the problems": 1.0,
    "helicopters the problems of": 1.0,
    "the problems of achieving": 1.0,
    "problems of achieving high": 1.0,
    "of achieving high recognition": 1.0,
    "achieving high recognition accuracy": 1.0,
    "high recognition accuracy under": 1.0,
    "recognition accuracy under stress": 1.0,
    "accuracy under stress and": 1.0,
    "under stress and noise": 1.0,
    "stress and noise pertain": 1.0,
    "and noise pertain strongly": 1.0,
    "noise pertain strongly to": 1.0,
    "pertain strongly to the": 1.0,
    "strongly to the helicopter": 1.0,
    "to the helicopter environment": 1.0,
    "the helicopter environment as": 0.5,
    "helicopter environment as well": 1.0,
    "environment as well as": 1.0,
    "as well as to": 0.07692307692307693,
    "well as to the": 1.0,
    "as to the jet": 1.0,
    "to the jet fighter": 1.0,
    "the jet fighter environment": 1.0,
    "jet fighter environment .": 1.0,
    "<s> the acoustic noise": 1.0,
    "the acoustic noise problem": 1.0,
    "acoustic noise problem is": 1.0,
    "noise problem is actually": 1.0,
    "problem is actually more": 1.0,
    "is actually more severe": 1.0,
    "actually more severe in": 1.0,
    "more severe in the": 1.0,
    "severe in the helicopter": 1.0,
    "in the helicopter environment": 1.0,
    "the helicopter environment ,": 0.5,
    "helicopter environment , not": 1.0,
    "environment , not only": 1.0,
    ", not only because": 0.5,
    "not only because of": 1.0,
    "only because of the": 1.0,
    "because of the high": 0.25,
    "of the high noise": 1.0,
    "the high noise levels": 1.0,
    "high noise levels but": 1.0,
    "noise levels but also": 1.0,
    "levels but also because": 1.0,
    "but also because the": 1.0,
    "also because the helicopter": 1.0,
    "because the helicopter pilot": 1.0,
    "the helicopter pilot ,": 1.0,
    "helicopter pilot , in": 1.0,
    "pilot , in general": 1.0,
    ", in general ,": 1.0,
    "in general , does": 0.16666666666666666,
    "general , does not": 1.0,
    ", does not wear": 1.0,
    "does not wear a": 1.0,
    "not wear a facemask": 1.0,
    "wear a facemask ,": 1.0,
    "a facemask , which": 1.0,
    "facemask , which would": 1.0,
    ", which would reduce": 0.5,
    "which would reduce acoustic": 1.0,
    "would reduce acoustic noise": 1.0,
    "reduce acoustic noise in": 1.0,
    "acoustic noise in the": 1.0,
    "noise in the microphone": 1.0,
    "in the microphone .": 1.0,
    "<s> substantial test and": 1.0,
    "substantial test and evaluation": 1.0,
    "test and evaluation programs": 0.5,
    "and evaluation programs have": 1.0,
    "evaluation programs have been": 1.0,
    "programs have been carried": 1.0,
    "have been carried out": 1.0,
    "been carried out in": 1.0,
    "carried out in the": 1.0,
    "out in the past": 1.0,
    "in the past decade": 1.0,
    "the past decade in": 1.0,
    "past decade in speech": 1.0,
    "decade in speech recognition": 1.0,
    "in speech recognition systems": 0.14285714285714285,
    "speech recognition systems applications": 0.1111111111111111,
    "recognition systems applications in": 1.0,
    "systems applications in helicopters": 1.0,
    "applications in helicopters ,": 1.0,
    "in helicopters , notably": 1.0,
    "helicopters , notably by": 1.0,
    ", notably by the": 1.0,
    "notably by the u.s.": 1.0,
    "by the u.s. army": 0.5,
    "the u.s. army avionics": 1.0,
    "u.s. army avionics research": 1.0,
    "army avionics research and": 1.0,
    "avionics research and development": 1.0,
    "research and development activity": 0.5,
    "and development activity -lrb-": 1.0,
    "development activity -lrb- avrada": 1.0,
    "activity -lrb- avrada -rrb-": 1.0,
    "-lrb- avrada -rrb- and": 1.0,
    "avrada -rrb- and by": 1.0,
    "-rrb- and by the": 1.0,
    "and by the royal": 1.0,
    "by the royal aerospace": 1.0,
    "the royal aerospace establishment": 1.0,
    "royal aerospace establishment -lrb-": 1.0,
    "aerospace establishment -lrb- rae": 1.0,
    "establishment -lrb- rae -rrb-": 1.0,
    "-lrb- rae -rrb- in": 1.0,
    "rae -rrb- in the": 1.0,
    "-rrb- in the uk": 0.3333333333333333,
    "<s> work in france": 1.0,
    "work in france has": 1.0,
    "in france has included": 1.0,
    "france has included speech": 1.0,
    "has included speech recognition": 1.0,
    "included speech recognition in": 1.0,
    "speech recognition in the": 0.3333333333333333,
    "recognition in the puma": 1.0,
    "in the puma helicopter": 1.0,
    "the puma helicopter .": 1.0,
    "<s> there has also": 1.0,
    "there has also been": 1.0,
    "has also been much": 0.3333333333333333,
    "also been much useful": 1.0,
    "been much useful work": 1.0,
    "much useful work in": 1.0,
    "useful work in canada": 1.0,
    "work in canada .": 1.0,
    "<s> results have been": 1.0,
    "results have been encouraging": 1.0,
    "have been encouraging ,": 1.0,
    "been encouraging , and": 1.0,
    "encouraging , and voice": 1.0,
    ", and voice applications": 1.0,
    "and voice applications have": 1.0,
    "voice applications have included": 1.0,
    "applications have included :": 1.0,
    "have included : control": 1.0,
    "included : control of": 1.0,
    ": control of communication": 1.0,
    "control of communication radios": 1.0,
    "of communication radios ,": 1.0,
    "communication radios , setting": 1.0,
    "radios , setting of": 1.0,
    ", setting of navigation": 1.0,
    "setting of navigation systems": 1.0,
    "of navigation systems ,": 1.0,
    "navigation systems , and": 1.0,
    "systems , and control": 1.0,
    ", and control of": 1.0,
    "and control of an": 0.5,
    "control of an automated": 1.0,
    "of an automated target": 1.0,
    "an automated target handover": 1.0,
    "automated target handover system": 1.0,
    "target handover system .": 1.0,
    "<s> as in fighter": 0.3333333333333333,
    "as in fighter applications": 1.0,
    "in fighter applications ,": 1.0,
    "fighter applications , the": 1.0,
    "applications , the overriding": 1.0,
    ", the overriding issue": 1.0,
    "the overriding issue for": 1.0,
    "overriding issue for voice": 1.0,
    "issue for voice in": 1.0,
    "for voice in helicopters": 1.0,
    "voice in helicopters is": 1.0,
    "in helicopters is the": 1.0,
    "helicopters is the impact": 1.0,
    "is the impact on": 1.0,
    "the impact on pilot": 1.0,
    "impact on pilot effectiveness": 1.0,
    "on pilot effectiveness .": 1.0,
    "<s> encouraging results are": 1.0,
    "encouraging results are reported": 1.0,
    "results are reported for": 1.0,
    "are reported for the": 1.0,
    "reported for the avrada": 1.0,
    "for the avrada tests": 1.0,
    "the avrada tests ,": 1.0,
    "avrada tests , although": 1.0,
    "tests , although these": 1.0,
    ", although these represent": 1.0,
    "although these represent only": 1.0,
    "these represent only a": 1.0,
    "represent only a feasibility": 1.0,
    "only a feasibility demonstration": 1.0,
    "a feasibility demonstration in": 1.0,
    "feasibility demonstration in a": 1.0,
    "demonstration in a test": 1.0,
    "in a test environment": 1.0,
    "a test environment .": 1.0,
    "<s> much remains to": 1.0,
    "much remains to be": 1.0,
    "remains to be done": 1.0,
    "to be done both": 0.3333333333333333,
    "be done both in": 1.0,
    "done both in speech": 1.0,
    "both in speech recognition": 1.0,
    "in speech recognition and": 0.14285714285714285,
    "speech recognition and in": 0.16666666666666666,
    "recognition and in overall": 1.0,
    "and in overall speech": 1.0,
    "in overall speech recognition": 1.0,
    "overall speech recognition technology": 1.0,
    "speech recognition technology ,": 1.0,
    "recognition technology , in": 1.0,
    "technology , in order": 1.0,
    "in order to consistently": 0.125,
    "order to consistently achieve": 1.0,
    "to consistently achieve performance": 1.0,
    "consistently achieve performance improvements": 1.0,
    "achieve performance improvements in": 1.0,
    "performance improvements in operational": 1.0,
    "improvements in operational settings": 1.0,
    "in operational settings .": 1.0,
    "<s> battle management question": 1.0,
    "battle management question book-new": 1.0,
    "management question book-new .": 1.0,
    "<s> svg this unreferenced": 1.0,
    "svg this unreferenced section": 1.0,
    "this unreferenced section requires": 1.0,
    "unreferenced section requires citations": 1.0,
    "section requires citations to": 1.0,
    "requires citations to ensure": 1.0,
    "citations to ensure verifiability": 1.0,
    "to ensure verifiability .": 1.0,
    "in general , battle": 0.16666666666666666,
    "general , battle management": 1.0,
    ", battle management command": 1.0,
    "battle management command centres": 1.0,
    "management command centres require": 1.0,
    "command centres require rapid": 1.0,
    "centres require rapid access": 1.0,
    "require rapid access to": 1.0,
    "rapid access to and": 1.0,
    "access to and control": 1.0,
    "to and control of": 1.0,
    "and control of large": 0.5,
    "control of large ,": 1.0,
    "of large , rapidly": 1.0,
    "large , rapidly changing": 1.0,
    ", rapidly changing information": 1.0,
    "rapidly changing information databases": 1.0,
    "changing information databases .": 1.0,
    "<s> commanders and system": 1.0,
    "commanders and system operators": 1.0,
    "and system operators need": 1.0,
    "system operators need to": 1.0,
    "operators need to query": 1.0,
    "need to query these": 1.0,
    "to query these databases": 1.0,
    "query these databases as": 1.0,
    "these databases as conveniently": 1.0,
    "databases as conveniently as": 1.0,
    "as conveniently as possible": 1.0,
    "conveniently as possible ,": 1.0,
    "as possible , in": 1.0,
    "possible , in an": 1.0,
    ", in an eyes-busy": 1.0,
    "in an eyes-busy environment": 1.0,
    "an eyes-busy environment where": 1.0,
    "eyes-busy environment where much": 1.0,
    "environment where much of": 1.0,
    "where much of the": 1.0,
    "much of the information": 1.0,
    "of the information is": 0.5,
    "the information is presented": 1.0,
    "information is presented in": 1.0,
    "is presented in a": 1.0,
    "presented in a display": 0.5,
    "in a display format": 1.0,
    "a display format .": 1.0,
    "<s> human-machine interaction by": 1.0,
    "human-machine interaction by voice": 1.0,
    "interaction by voice has": 1.0,
    "by voice has the": 1.0,
    "voice has the potential": 1.0,
    "has the potential to": 1.0,
    "the potential to be": 0.5,
    "potential to be very": 1.0,
    "to be very useful": 1.0,
    "be very useful in": 1.0,
    "very useful in these": 1.0,
    "useful in these environments": 1.0,
    "in these environments .": 1.0,
    "a number of efforts": 0.045454545454545456,
    "number of efforts have": 1.0,
    "of efforts have been": 1.0,
    "efforts have been undertaken": 0.5,
    "have been undertaken to": 1.0,
    "been undertaken to interface": 1.0,
    "undertaken to interface commercially": 1.0,
    "to interface commercially available": 1.0,
    "interface commercially available isolated-word": 1.0,
    "commercially available isolated-word recognizers": 1.0,
    "available isolated-word recognizers into": 1.0,
    "isolated-word recognizers into battle": 1.0,
    "recognizers into battle management": 1.0,
    "into battle management environments": 1.0,
    "battle management environments .": 1.0,
    "<s> in one feasibility": 1.0,
    "in one feasibility study": 1.0,
    "one feasibility study ,": 1.0,
    "feasibility study , speech": 1.0,
    "study , speech recognition": 1.0,
    ", speech recognition equipment": 0.2,
    "speech recognition equipment was": 1.0,
    "recognition equipment was tested": 1.0,
    "equipment was tested in": 1.0,
    "was tested in conjunction": 1.0,
    "tested in conjunction with": 1.0,
    "in conjunction with an": 0.5,
    "conjunction with an integrated": 1.0,
    "with an integrated information": 1.0,
    "an integrated information display": 1.0,
    "integrated information display for": 1.0,
    "information display for naval": 1.0,
    "display for naval battle": 1.0,
    "for naval battle management": 1.0,
    "naval battle management applications": 1.0,
    "battle management applications .": 1.0,
    "<s> users were very": 1.0,
    "users were very optimistic": 1.0,
    "were very optimistic about": 1.0,
    "very optimistic about the": 1.0,
    "optimistic about the potential": 1.0,
    "about the potential of": 1.0,
    "the potential of the": 1.0,
    "potential of the system": 1.0,
    "the system , although": 0.5,
    "system , although capabilities": 1.0,
    ", although capabilities were": 1.0,
    "although capabilities were limited": 1.0,
    "capabilities were limited .": 1.0,
    "<s> speech understanding programs": 1.0,
    "speech understanding programs sponsored": 1.0,
    "understanding programs sponsored by": 1.0,
    "programs sponsored by the": 1.0,
    "sponsored by the defense": 1.0,
    "by the defense advanced": 1.0,
    "the defense advanced research": 1.0,
    "defense advanced research projects": 1.0,
    "advanced research projects agency": 1.0,
    "research projects agency -lrb-": 1.0,
    "projects agency -lrb- darpa": 1.0,
    "agency -lrb- darpa -rrb-": 1.0,
    "-lrb- darpa -rrb- in": 1.0,
    "darpa -rrb- in the": 1.0,
    "-rrb- in the u.s.": 0.3333333333333333,
    "in the u.s. has": 1.0,
    "the u.s. has focused": 1.0,
    "u.s. has focused on": 1.0,
    "has focused on this": 0.25,
    "focused on this problem": 1.0,
    "on this problem of": 1.0,
    "this problem of natural": 1.0,
    "problem of natural speech": 0.5,
    "of natural speech interface": 1.0,
    "natural speech interface .": 1.0,
    "<s> speech recognition efforts": 0.14285714285714285,
    "speech recognition efforts have": 1.0,
    "recognition efforts have focused": 1.0,
    "have focused on a": 0.5,
    "focused on a database": 1.0,
    "on a database of": 1.0,
    "a database of continuous": 0.5,
    "database of continuous speech": 1.0,
    "of continuous speech recognition": 1.0,
    "continuous speech recognition -lrb-": 1.0,
    "speech recognition -lrb- csr": 0.25,
    "recognition -lrb- csr -rrb-": 1.0,
    "-lrb- csr -rrb- ,": 0.5,
    "csr -rrb- , large-vocabulary": 1.0,
    "-rrb- , large-vocabulary speech": 1.0,
    ", large-vocabulary speech designed": 1.0,
    "large-vocabulary speech designed to": 1.0,
    "speech designed to be": 1.0,
    "designed to be representative": 1.0,
    "to be representative of": 1.0,
    "be representative of the": 1.0,
    "representative of the naval": 1.0,
    "of the naval resource": 1.0,
    "the naval resource management": 1.0,
    "naval resource management task": 0.5,
    "resource management task .": 1.0,
    "<s> significant advances in": 1.0,
    "significant advances in the": 1.0,
    "advances in the state-of-the-art": 1.0,
    "in the state-of-the-art in": 1.0,
    "the state-of-the-art in csr": 1.0,
    "state-of-the-art in csr have": 1.0,
    "in csr have been": 1.0,
    "csr have been achieved": 1.0,
    "have been achieved ,": 0.5,
    "been achieved , and": 1.0,
    "achieved , and current": 1.0,
    ", and current efforts": 1.0,
    "and current efforts are": 1.0,
    "current efforts are focused": 1.0,
    "efforts are focused on": 1.0,
    "are focused on integrating": 1.0,
    "focused on integrating speech": 1.0,
    "on integrating speech recognition": 1.0,
    "integrating speech recognition and": 1.0,
    "speech recognition and natural": 0.16666666666666666,
    "recognition and natural language": 1.0,
    "natural language processing to": 0.03571428571428571,
    "language processing to allow": 1.0,
    "processing to allow spoken": 1.0,
    "to allow spoken language": 1.0,
    "allow spoken language interaction": 1.0,
    "spoken language interaction with": 1.0,
    "language interaction with a": 1.0,
    "interaction with a naval": 1.0,
    "with a naval resource": 1.0,
    "a naval resource management": 1.0,
    "naval resource management system": 0.5,
    "resource management system .": 1.0,
    "<s> training air traffic": 1.0,
    "training air traffic controllers": 1.0,
    "air traffic controllers training": 0.3333333333333333,
    "traffic controllers training for": 1.0,
    "controllers training for air": 1.0,
    "training for air traffic": 1.0,
    "for air traffic controllers": 1.0,
    "air traffic controllers -lrb-": 0.3333333333333333,
    "traffic controllers -lrb- atc": 1.0,
    "controllers -lrb- atc -rrb-": 1.0,
    "-lrb- atc -rrb- represents": 1.0,
    "atc -rrb- represents an": 1.0,
    "-rrb- represents an excellent": 1.0,
    "represents an excellent application": 1.0,
    "an excellent application for": 1.0,
    "excellent application for speech": 1.0,
    "application for speech recognition": 1.0,
    "for speech recognition systems": 0.2,
    "speech recognition systems .": 0.1111111111111111,
    "<s> many atc training": 1.0,
    "many atc training systems": 1.0,
    "atc training systems currently": 1.0,
    "training systems currently require": 1.0,
    "systems currently require a": 1.0,
    "currently require a person": 1.0,
    "require a person to": 1.0,
    "a person to act": 1.0,
    "person to act as": 1.0,
    "to act as a": 0.5,
    "act as a ``": 1.0,
    "as a `` pseudo-pilot": 1.0,
    "a `` pseudo-pilot ''": 1.0,
    "`` pseudo-pilot '' ,": 1.0,
    "pseudo-pilot '' , engaging": 1.0,
    "'' , engaging in": 1.0,
    ", engaging in a": 1.0,
    "engaging in a voice": 1.0,
    "in a voice dialog": 1.0,
    "a voice dialog with": 1.0,
    "voice dialog with the": 1.0,
    "dialog with the trainee": 1.0,
    "with the trainee controller": 1.0,
    "the trainee controller ,": 1.0,
    "trainee controller , which": 1.0,
    "controller , which simulates": 1.0,
    ", which simulates the": 1.0,
    "which simulates the dialog": 1.0,
    "simulates the dialog that": 1.0,
    "the dialog that the": 1.0,
    "dialog that the controller": 1.0,
    "that the controller would": 1.0,
    "the controller would have": 1.0,
    "controller would have to": 1.0,
    "would have to conduct": 1.0,
    "have to conduct with": 1.0,
    "to conduct with pilots": 1.0,
    "conduct with pilots in": 1.0,
    "with pilots in a": 1.0,
    "pilots in a real": 1.0,
    "in a real atc": 1.0,
    "a real atc situation": 1.0,
    "real atc situation .": 1.0,
    "<s> speech recognition and": 0.14285714285714285,
    "speech recognition and synthesis": 0.16666666666666666,
    "recognition and synthesis techniques": 1.0,
    "and synthesis techniques offer": 1.0,
    "synthesis techniques offer the": 1.0,
    "techniques offer the potential": 1.0,
    "offer the potential to": 1.0,
    "the potential to eliminate": 0.5,
    "potential to eliminate the": 1.0,
    "to eliminate the need": 1.0,
    "eliminate the need for": 1.0,
    "the need for a": 0.5,
    "need for a person": 1.0,
    "for a person to": 1.0,
    "to act as pseudo-pilot": 0.5,
    "act as pseudo-pilot ,": 1.0,
    "as pseudo-pilot , thus": 1.0,
    "pseudo-pilot , thus reducing": 1.0,
    ", thus reducing training": 1.0,
    "thus reducing training and": 1.0,
    "reducing training and support": 1.0,
    "training and support personnel": 1.0,
    "and support personnel .": 1.0,
    "in theory , air": 0.5,
    "theory , air controller": 1.0,
    ", air controller tasks": 1.0,
    "air controller tasks are": 1.0,
    "controller tasks are also": 1.0,
    "tasks are also characterized": 1.0,
    "are also characterized by": 1.0,
    "also characterized by highly": 1.0,
    "characterized by highly structured": 1.0,
    "by highly structured speech": 1.0,
    "highly structured speech as": 1.0,
    "structured speech as the": 1.0,
    "speech as the primary": 1.0,
    "as the primary output": 1.0,
    "the primary output of": 1.0,
    "primary output of the": 1.0,
    "output of the controller": 0.5,
    "of the controller ,": 1.0,
    "the controller , hence": 1.0,
    "controller , hence reducing": 1.0,
    ", hence reducing the": 1.0,
    "hence reducing the difficulty": 1.0,
    "reducing the difficulty of": 1.0,
    "the difficulty of the": 0.3333333333333333,
    "difficulty of the speech": 1.0,
    "of the speech recognition": 0.25,
    "the speech recognition task": 1.0,
    "speech recognition task should": 1.0,
    "recognition task should be": 1.0,
    "task should be possible": 1.0,
    "should be possible .": 1.0,
    "<s> in practice ,": 1.0,
    "in practice , this": 1.0,
    "practice , this is": 1.0,
    ", this is rarely": 0.5,
    "this is rarely the": 1.0,
    "is rarely the case": 1.0,
    "rarely the case .": 1.0,
    "<s> the faa document": 1.0,
    "the faa document 7110.65": 1.0,
    "faa document 7110.65 details": 1.0,
    "document 7110.65 details the": 1.0,
    "7110.65 details the phrases": 1.0,
    "details the phrases that": 1.0,
    "the phrases that should": 1.0,
    "phrases that should be": 1.0,
    "that should be used": 1.0,
    "should be used by": 0.5,
    "be used by air": 1.0,
    "used by air traffic": 1.0,
    "by air traffic controllers": 1.0,
    "air traffic controllers .": 0.3333333333333333,
    "<s> while this document": 1.0,
    "while this document gives": 1.0,
    "this document gives less": 1.0,
    "document gives less than": 1.0,
    "gives less than 150": 1.0,
    "less than 150 examples": 1.0,
    "than 150 examples of": 1.0,
    "150 examples of such": 1.0,
    "examples of such phrases": 0.5,
    "of such phrases ,": 1.0,
    "such phrases , the": 1.0,
    "phrases , the number": 1.0,
    "the number of phrases": 0.2,
    "number of phrases supported": 1.0,
    "of phrases supported by": 1.0,
    "phrases supported by one": 1.0,
    "supported by one of": 1.0,
    "by one of the": 1.0,
    "one of the simulation": 0.08333333333333333,
    "of the simulation vendors": 1.0,
    "the simulation vendors speech": 1.0,
    "simulation vendors speech recognition": 1.0,
    "vendors speech recognition systems": 1.0,
    "speech recognition systems is": 0.2222222222222222,
    "recognition systems is in": 0.5,
    "systems is in excess": 1.0,
    "is in excess of": 1.0,
    "in excess of 500,000": 0.5,
    "excess of 500,000 .": 1.0,
    "<s> the usaf ,": 1.0,
    "the usaf , usmc": 1.0,
    "usaf , usmc ,": 1.0,
    ", usmc , us": 1.0,
    "usmc , us army": 1.0,
    ", us army ,": 1.0,
    "us army , us": 1.0,
    "army , us navy": 1.0,
    ", us navy ,": 1.0,
    "us navy , and": 1.0,
    "navy , and faa": 1.0,
    ", and faa as": 1.0,
    "and faa as well": 1.0,
    "faa as well as": 1.0,
    "as well as a": 0.07692307692307693,
    "well as a number": 1.0,
    "as a number of": 1.0,
    "a number of international": 0.045454545454545456,
    "number of international atc": 1.0,
    "of international atc training": 1.0,
    "international atc training organizations": 1.0,
    "atc training organizations such": 1.0,
    "training organizations such as": 1.0,
    "organizations such as the": 1.0,
    "such as the royal": 0.07142857142857142,
    "as the royal australian": 1.0,
    "the royal australian air": 1.0,
    "royal australian air force": 1.0,
    "australian air force and": 1.0,
    "air force and civil": 1.0,
    "force and civil aviation": 1.0,
    "and civil aviation authorities": 1.0,
    "civil aviation authorities in": 1.0,
    "aviation authorities in italy": 1.0,
    "authorities in italy ,": 1.0,
    "in italy , brazil": 0.5,
    "italy , brazil ,": 1.0,
    ", brazil , and": 1.0,
    "brazil , and canada": 1.0,
    ", and canada are": 1.0,
    "and canada are currently": 1.0,
    "canada are currently using": 1.0,
    "are currently using atc": 1.0,
    "currently using atc simulators": 1.0,
    "using atc simulators with": 1.0,
    "atc simulators with speech": 1.0,
    "simulators with speech recognition": 1.0,
    "with speech recognition from": 0.5,
    "speech recognition from a": 0.5,
    "recognition from a number": 1.0,
    "from a number of": 1.0,
    "a number of different": 0.045454545454545456,
    "number of different vendors": 1.0,
    "of different vendors .": 1.0,
    "<s> telephony and other": 1.0,
    "telephony and other domains": 1.0,
    "and other domains asr": 1.0,
    "other domains asr in": 1.0,
    "domains asr in the": 1.0,
    "asr in the field": 0.6666666666666666,
    "the field of telephony": 0.1111111111111111,
    "field of telephony is": 1.0,
    "of telephony is now": 1.0,
    "telephony is now commonplace": 1.0,
    "is now commonplace and": 1.0,
    "now commonplace and in": 1.0,
    "commonplace and in the": 1.0,
    "and in the field": 1.0,
    "the field of computer": 0.1111111111111111,
    "field of computer gaming": 0.5,
    "of computer gaming and": 1.0,
    "computer gaming and simulation": 1.0,
    "gaming and simulation is": 1.0,
    "and simulation is becoming": 1.0,
    "simulation is becoming more": 1.0,
    "is becoming more widespread": 1.0,
    "becoming more widespread .": 1.0,
    "<s> despite the high": 1.0,
    "despite the high level": 1.0,
    "the high level of": 1.0,
    "high level of integration": 0.3333333333333333,
    "level of integration with": 1.0,
    "of integration with word": 1.0,
    "integration with word processing": 1.0,
    "with word processing in": 1.0,
    "word processing in general": 1.0,
    "processing in general personal": 1.0,
    "in general personal computing": 1.0,
    "general personal computing .": 1.0,
    "<s> however , asr": 0.03125,
    "however , asr in": 1.0,
    ", asr in the": 1.0,
    "the field of document": 0.1111111111111111,
    "field of document production": 1.0,
    "of document production has": 1.0,
    "document production has not": 1.0,
    "production has not seen": 1.0,
    "has not seen the": 1.0,
    "not seen the expected": 1.0,
    "seen the expected -lrb-": 1.0,
    "the expected -lrb- by": 1.0,
    "expected -lrb- by whom": 1.0,
    "-lrb- by whom ?": 1.0,
    "by whom ? -rrb-": 1.0,
    "<s> increases in use": 1.0,
    "increases in use .": 1.0,
    "<s> the improvement of": 1.0,
    "the improvement of mobile": 0.5,
    "improvement of mobile processor": 1.0,
    "of mobile processor speeds": 1.0,
    "mobile processor speeds made": 1.0,
    "processor speeds made feasible": 1.0,
    "speeds made feasible the": 1.0,
    "made feasible the speech-enabled": 1.0,
    "feasible the speech-enabled symbian": 1.0,
    "the speech-enabled symbian and": 1.0,
    "speech-enabled symbian and windows": 1.0,
    "symbian and windows mobile": 1.0,
    "and windows mobile smartphones": 1.0,
    "windows mobile smartphones .": 1.0,
    "<s> speech is used": 0.5,
    "speech is used mostly": 1.0,
    "is used mostly as": 1.0,
    "used mostly as a": 1.0,
    "mostly as a part": 1.0,
    "as a part of": 1.0,
    "a part of user": 0.5,
    "part of user interface": 1.0,
    "of user interface ,": 1.0,
    "user interface , for": 1.0,
    "interface , for creating": 1.0,
    ", for creating pre-defined": 1.0,
    "for creating pre-defined or": 1.0,
    "creating pre-defined or custom": 1.0,
    "pre-defined or custom speech": 1.0,
    "or custom speech commands": 1.0,
    "custom speech commands .": 1.0,
    "<s> leading software vendors": 1.0,
    "leading software vendors in": 1.0,
    "software vendors in this": 1.0,
    "vendors in this field": 1.0,
    "in this field are": 0.5,
    "this field are :": 1.0,
    "field are : microsoft": 1.0,
    "are : microsoft corporation": 1.0,
    ": microsoft corporation -lrb-": 1.0,
    "microsoft corporation -lrb- microsoft": 1.0,
    "corporation -lrb- microsoft voice": 1.0,
    "-lrb- microsoft voice command": 1.0,
    "microsoft voice command -rrb-": 1.0,
    "voice command -rrb- ,": 1.0,
    "command -rrb- , digital": 1.0,
    "-rrb- , digital syphon": 1.0,
    ", digital syphon -lrb-": 1.0,
    "digital syphon -lrb- sonic": 1.0,
    "syphon -lrb- sonic extractor": 1.0,
    "-lrb- sonic extractor -rrb-": 1.0,
    "sonic extractor -rrb- ,": 1.0,
    "extractor -rrb- , nuance": 1.0,
    "-rrb- , nuance communications": 1.0,
    ", nuance communications -lrb-": 1.0,
    "nuance communications -lrb- nuance": 0.5,
    "communications -lrb- nuance voice": 1.0,
    "-lrb- nuance voice control": 1.0,
    "nuance voice control -rrb-": 1.0,
    "voice control -rrb- ,": 1.0,
    "control -rrb- , speech": 1.0,
    "-rrb- , speech technology": 0.5,
    ", speech technology center": 1.0,
    "speech technology center ,": 1.0,
    "technology center , vito": 1.0,
    "center , vito technology": 1.0,
    ", vito technology -lrb-": 1.0,
    "vito technology -lrb- vito": 1.0,
    "technology -lrb- vito voice2go": 1.0,
    "-lrb- vito voice2go -rrb-": 1.0,
    "vito voice2go -rrb- ,": 1.0,
    "voice2go -rrb- , speereo": 1.0,
    "-rrb- , speereo software": 1.0,
    ", speereo software -lrb-": 1.0,
    "speereo software -lrb- speereo": 1.0,
    "software -lrb- speereo voice": 1.0,
    "-lrb- speereo voice translator": 1.0,
    "speereo voice translator -rrb-": 1.0,
    "voice translator -rrb- ,": 1.0,
    "translator -rrb- , verbyx": 1.0,
    "-rrb- , verbyx vrx": 1.0,
    ", verbyx vrx and": 1.0,
    "verbyx vrx and svox": 1.0,
    "vrx and svox .": 1.0,
    "<s> further applications aerospace": 1.0,
    "further applications aerospace -lrb-": 1.0,
    "applications aerospace -lrb- e.g.": 1.0,
    "aerospace -lrb- e.g. space": 1.0,
    "-lrb- e.g. space exploration": 1.0,
    "e.g. space exploration ,": 1.0,
    "space exploration , spacecraft": 1.0,
    "exploration , spacecraft ,": 1.0,
    ", spacecraft , etc.": 1.0,
    "spacecraft , etc. -rrb-": 1.0,
    ", etc. -rrb- nasa": 0.1111111111111111,
    "etc. -rrb- nasa 's": 1.0,
    "-rrb- nasa 's mars": 1.0,
    "nasa 's mars polar": 1.0,
    "'s mars polar lander": 1.0,
    "mars polar lander used": 1.0,
    "polar lander used speech": 1.0,
    "lander used speech recognition": 1.0,
    "used speech recognition from": 1.0,
    "speech recognition from technology": 0.5,
    "recognition from technology sensory": 1.0,
    "from technology sensory ,": 1.0,
    "technology sensory , inc.": 1.0,
    "sensory , inc. in": 1.0,
    ", inc. in the": 1.0,
    "inc. in the mars": 1.0,
    "in the mars microphone": 1.0,
    "the mars microphone on": 1.0,
    "mars microphone on the": 1.0,
    "microphone on the lander": 1.0,
    "on the lander automatic": 1.0,
    "the lander automatic translation": 1.0,
    "lander automatic translation automotive": 1.0,
    "automatic translation automotive speech": 1.0,
    "translation automotive speech recognition": 1.0,
    "automotive speech recognition -lrb-": 1.0,
    "speech recognition -lrb- e.g.": 0.25,
    "recognition -lrb- e.g. ,": 1.0,
    "-lrb- e.g. , onstar": 0.05263157894736842,
    "e.g. , onstar ,": 1.0,
    ", onstar , ford": 1.0,
    "onstar , ford sync": 1.0,
    ", ford sync -rrb-": 1.0,
    "ford sync -rrb- court": 1.0,
    "sync -rrb- court reporting": 1.0,
    "-rrb- court reporting -lrb-": 1.0,
    "court reporting -lrb- realtime": 1.0,
    "reporting -lrb- realtime speech": 1.0,
    "-lrb- realtime speech writing": 1.0,
    "realtime speech writing -rrb-": 1.0,
    "speech writing -rrb- hands-free": 1.0,
    "writing -rrb- hands-free computing": 1.0,
    "-rrb- hands-free computing :": 1.0,
    "hands-free computing : speech": 1.0,
    "computing : speech recognition": 1.0,
    ": speech recognition computer": 1.0,
    "speech recognition computer user": 1.0,
    "recognition computer user interface": 1.0,
    "computer user interface home": 1.0,
    "user interface home automation": 1.0,
    "interface home automation interactive": 1.0,
    "home automation interactive voice": 1.0,
    "automation interactive voice response": 1.0,
    "interactive voice response mobile": 1.0,
    "voice response mobile telephony": 1.0,
    "response mobile telephony ,": 1.0,
    "mobile telephony , including": 1.0,
    "telephony , including mobile": 1.0,
    ", including mobile email": 1.0,
    "including mobile email multimodal": 1.0,
    "mobile email multimodal interaction": 1.0,
    "email multimodal interaction pronunciation": 1.0,
    "multimodal interaction pronunciation evaluation": 1.0,
    "interaction pronunciation evaluation in": 1.0,
    "pronunciation evaluation in computer-aided": 1.0,
    "evaluation in computer-aided language": 1.0,
    "in computer-aided language learning": 1.0,
    "computer-aided language learning applications": 1.0,
    "language learning applications robotics": 1.0,
    "learning applications robotics speech-to-text": 1.0,
    "applications robotics speech-to-text reporter": 1.0,
    "robotics speech-to-text reporter -lrb-": 1.0,
    "speech-to-text reporter -lrb- transcription": 1.0,
    "reporter -lrb- transcription of": 1.0,
    "-lrb- transcription of speech": 1.0,
    "transcription of speech into": 1.0,
    "of speech into text": 1.0,
    "speech into text ,": 1.0,
    "into text , video": 1.0,
    "text , video captioning": 1.0,
    ", video captioning ,": 1.0,
    "video captioning , court": 1.0,
    "captioning , court reporting": 1.0,
    ", court reporting -rrb-": 1.0,
    "court reporting -rrb- telematics": 1.0,
    "reporting -rrb- telematics -lrb-": 1.0,
    "-rrb- telematics -lrb- e.g.": 1.0,
    "telematics -lrb- e.g. ,": 1.0,
    "-lrb- e.g. , vehicle": 0.05263157894736842,
    "e.g. , vehicle navigation": 1.0,
    ", vehicle navigation systems": 1.0,
    "vehicle navigation systems -rrb-": 1.0,
    "navigation systems -rrb- transcription": 1.0,
    "systems -rrb- transcription -lrb-": 1.0,
    "-rrb- transcription -lrb- digital": 1.0,
    "transcription -lrb- digital speech-to-text": 1.0,
    "-lrb- digital speech-to-text -rrb-": 1.0,
    "digital speech-to-text -rrb- video": 1.0,
    "speech-to-text -rrb- video games": 1.0,
    "-rrb- video games ,": 1.0,
    "video games , with": 1.0,
    "games , with tom": 1.0,
    ", with tom clancy": 1.0,
    "with tom clancy 's": 1.0,
    "tom clancy 's endwar": 1.0,
    "clancy 's endwar and": 1.0,
    "'s endwar and lifeline": 1.0,
    "endwar and lifeline as": 1.0,
    "and lifeline as working": 1.0,
    "lifeline as working examples": 1.0,
    "as working examples performance": 1.0,
    "working examples performance the": 1.0,
    "examples performance the performance": 1.0,
    "performance the performance of": 1.0,
    "the performance of speech": 1.0,
    "performance of speech recognition": 1.0,
    "of speech recognition systems": 0.07142857142857142,
    "recognition systems is usually": 0.5,
    "systems is usually evaluated": 1.0,
    "is usually evaluated in": 1.0,
    "usually evaluated in terms": 1.0,
    "evaluated in terms of": 1.0,
    "in terms of accuracy": 0.14285714285714285,
    "terms of accuracy and": 1.0,
    "of accuracy and speed": 1.0,
    "accuracy and speed .": 1.0,
    "<s> accuracy is usually": 1.0,
    "accuracy is usually rated": 1.0,
    "is usually rated with": 1.0,
    "usually rated with word": 1.0,
    "rated with word error": 1.0,
    "with word error rate": 1.0,
    "word error rate -lrb-": 1.0,
    "error rate -lrb- wer": 0.5,
    "rate -lrb- wer -rrb-": 1.0,
    "-lrb- wer -rrb- ,": 1.0,
    "wer -rrb- , whereas": 1.0,
    "-rrb- , whereas speed": 1.0,
    ", whereas speed is": 1.0,
    "whereas speed is measured": 1.0,
    "speed is measured with": 1.0,
    "is measured with the": 1.0,
    "measured with the real": 1.0,
    "with the real time": 1.0,
    "the real time factor": 1.0,
    "real time factor .": 1.0,
    "<s> other measures of": 1.0,
    "other measures of accuracy": 1.0,
    "measures of accuracy include": 1.0,
    "of accuracy include single": 1.0,
    "accuracy include single word": 1.0,
    "include single word error": 1.0,
    "single word error rate": 1.0,
    "error rate -lrb- swer": 0.5,
    "rate -lrb- swer -rrb-": 1.0,
    "-lrb- swer -rrb- and": 1.0,
    "swer -rrb- and command": 1.0,
    "-rrb- and command success": 1.0,
    "and command success rate": 1.0,
    "command success rate -lrb-": 1.0,
    "success rate -lrb- csr": 1.0,
    "rate -lrb- csr -rrb-": 1.0,
    "-lrb- csr -rrb- .": 0.5,
    "<s> however , speech": 0.03125,
    "however , speech recognition": 1.0,
    ", speech recognition -lrb-": 0.2,
    "speech recognition -lrb- by": 0.25,
    "recognition -lrb- by a": 1.0,
    "-lrb- by a machine": 1.0,
    "by a machine -rrb-": 0.5,
    "a machine -rrb- is": 1.0,
    "machine -rrb- is a": 1.0,
    "-rrb- is a very": 0.25,
    "is a very complex": 0.3333333333333333,
    "a very complex problem": 1.0,
    "very complex problem .": 1.0,
    "<s> vocalizations vary in": 1.0,
    "vocalizations vary in terms": 1.0,
    "vary in terms of": 1.0,
    "in terms of accent": 0.14285714285714285,
    "terms of accent ,": 1.0,
    "of accent , pronunciation": 1.0,
    "accent , pronunciation ,": 1.0,
    ", pronunciation , articulation": 1.0,
    "pronunciation , articulation ,": 1.0,
    ", articulation , roughness": 1.0,
    "articulation , roughness ,": 1.0,
    ", roughness , nasality": 1.0,
    "roughness , nasality ,": 1.0,
    ", nasality , pitch": 1.0,
    "nasality , pitch ,": 1.0,
    ", pitch , volume": 1.0,
    "pitch , volume ,": 1.0,
    ", volume , and": 1.0,
    "volume , and speed": 1.0,
    ", and speed .": 1.0,
    "<s> speech is distorted": 0.5,
    "speech is distorted by": 1.0,
    "is distorted by a": 1.0,
    "distorted by a background": 1.0,
    "by a background noise": 1.0,
    "a background noise and": 1.0,
    "background noise and echoes": 1.0,
    "noise and echoes ,": 1.0,
    "and echoes , electrical": 1.0,
    "echoes , electrical characteristics": 1.0,
    ", electrical characteristics .": 1.0,
    "<s> accuracy of speech": 0.5,
    "accuracy of speech recognition": 0.6666666666666666,
    "of speech recognition vary": 0.07142857142857142,
    "speech recognition vary with": 1.0,
    "recognition vary with the": 1.0,
    "vary with the following": 1.0,
    "with the following :": 1.0,
    "the following : vocabulary": 1.0,
    "following : vocabulary size": 1.0,
    ": vocabulary size and": 1.0,
    "vocabulary size and confusability": 1.0,
    "size and confusability speaker": 1.0,
    "and confusability speaker dependence": 1.0,
    "confusability speaker dependence vs.": 1.0,
    "speaker dependence vs. independence": 1.0,
    "dependence vs. independence isolated": 0.5,
    "vs. independence isolated ,": 1.0,
    "independence isolated , discontinuous": 1.0,
    "isolated , discontinuous ,": 0.5,
    ", discontinuous , or": 1.0,
    "discontinuous , or continuous": 1.0,
    ", or continuous speech": 1.0,
    "or continuous speech task": 0.5,
    "continuous speech task and": 1.0,
    "speech task and language": 1.0,
    "task and language constraints": 1.0,
    "and language constraints read": 0.5,
    "language constraints read vs.": 1.0,
    "constraints read vs. spontaneous": 1.0,
    "read vs. spontaneous speech": 1.0,
    "vs. spontaneous speech adverse": 0.5,
    "spontaneous speech adverse conditions": 1.0,
    "speech adverse conditions accuracy": 1.0,
    "adverse conditions accuracy of": 1.0,
    "conditions accuracy of speech": 1.0,
    "of speech recognition as": 0.07142857142857142,
    "speech recognition as mentioned": 1.0,
    "recognition as mentioned earlier": 1.0,
    "as mentioned earlier in": 0.5,
    "mentioned earlier in this": 1.0,
    "earlier in this article": 1.0,
    "in this article accuracy": 0.5,
    "this article accuracy of": 1.0,
    "article accuracy of speech": 1.0,
    "accuracy of speech recogniton": 0.3333333333333333,
    "of speech recogniton vary": 1.0,
    "speech recogniton vary in": 1.0,
    "recogniton vary in following": 1.0,
    "vary in following :": 1.0,
    "in following : error": 1.0,
    "following : error rates": 1.0,
    ": error rates increase": 1.0,
    "error rates increase as": 1.0,
    "rates increase as the": 1.0,
    "increase as the vocabulary": 1.0,
    "as the vocabulary size": 1.0,
    "the vocabulary size grows": 1.0,
    "vocabulary size grows :": 1.0,
    "size grows : e.g.": 1.0,
    "grows : e.g. the": 1.0,
    ": e.g. the 10": 0.5,
    "e.g. the 10 digits": 1.0,
    "the 10 digits ``": 1.0,
    "10 digits `` zero": 1.0,
    "digits `` zero ''": 1.0,
    "`` zero '' to": 1.0,
    "zero '' to ``": 1.0,
    "'' to `` nine": 1.0,
    "to `` nine ''": 1.0,
    "`` nine '' can": 1.0,
    "nine '' can be": 1.0,
    "'' can be recognized": 0.2,
    "can be recognized essentially": 1.0,
    "be recognized essentially perfectly": 1.0,
    "recognized essentially perfectly ,": 1.0,
    "essentially perfectly , but": 1.0,
    "perfectly , but vocabulary": 1.0,
    ", but vocabulary sizes": 1.0,
    "but vocabulary sizes of": 1.0,
    "vocabulary sizes of 200": 1.0,
    "sizes of 200 ,": 1.0,
    "of 200 , 5000": 1.0,
    "200 , 5000 or": 1.0,
    ", 5000 or 100000": 1.0,
    "5000 or 100000 may": 1.0,
    "or 100000 may have": 1.0,
    "100000 may have error": 1.0,
    "may have error rates": 1.0,
    "have error rates of": 1.0,
    "error rates of 3": 1.0,
    "rates of 3 %": 1.0,
    "of 3 % ,": 1.0,
    "3 % , 7": 1.0,
    "% , 7 %": 1.0,
    ", 7 % or": 1.0,
    "7 % or 45": 1.0,
    "% or 45 %": 1.0,
    "or 45 % .": 1.0,
    "<s> vocabulary is hard": 1.0,
    "vocabulary is hard to": 1.0,
    "is hard to recognize": 0.5,
    "hard to recognize if": 1.0,
    "to recognize if it": 1.0,
    "recognize if it contains": 1.0,
    "if it contains confusable": 1.0,
    "it contains confusable words": 1.0,
    "contains confusable words :": 1.0,
    "confusable words : e.g.": 1.0,
    "words : e.g. the": 1.0,
    ": e.g. the 26": 0.5,
    "e.g. the 26 letters": 1.0,
    "the 26 letters of": 1.0,
    "26 letters of the": 1.0,
    "the english alphabet are": 0.5,
    "english alphabet are difficult": 1.0,
    "alphabet are difficult to": 1.0,
    "are difficult to discriminate": 1.0,
    "difficult to discriminate because": 1.0,
    "to discriminate because they": 1.0,
    "discriminate because they are": 1.0,
    "because they are confusable": 1.0,
    "they are confusable words": 1.0,
    "are confusable words -lrb-": 1.0,
    "confusable words -lrb- most": 1.0,
    "words -lrb- most notoriously": 1.0,
    "-lrb- most notoriously ,": 1.0,
    "most notoriously , the": 1.0,
    "notoriously , the e-set": 1.0,
    ", the e-set :": 1.0,
    "the e-set : ``": 1.0,
    "e-set : `` b": 1.0,
    ": `` b ,": 1.0,
    "`` b , c": 1.0,
    "b , c ,": 1.0,
    ", c , d": 1.0,
    "c , d ,": 1.0,
    ", d , e": 1.0,
    "d , e ,": 1.0,
    ", e , g": 1.0,
    "e , g ,": 1.0,
    ", g , p": 1.0,
    "g , p ,": 1.0,
    ", p , t": 1.0,
    "p , t ,": 1.0,
    ", t , v": 1.0,
    "t , v ,": 1.0,
    ", v , z": 1.0,
    "v , z ''": 1.0,
    ", z '' -rrb-": 1.0,
    "z '' -rrb- ;": 1.0,
    "'' -rrb- ; an": 0.5,
    "-rrb- ; an 8": 1.0,
    "; an 8 %": 1.0,
    "an 8 % error": 1.0,
    "8 % error rate": 1.0,
    "% error rate is": 1.0,
    "error rate is considered": 1.0,
    "rate is considered good": 1.0,
    "is considered good for": 1.0,
    "considered good for this": 1.0,
    "good for this vocabulary": 1.0,
    "for this vocabulary .": 1.0,
    "<s> speaker dependence vs.": 1.0,
    "dependence vs. independence :": 0.5,
    "vs. independence : a": 1.0,
    "independence : a speaker": 1.0,
    ": a speaker dependent": 1.0,
    "a speaker dependent system": 1.0,
    "speaker dependent system is": 1.0,
    "dependent system is intended": 1.0,
    "system is intended for": 1.0,
    "is intended for use": 1.0,
    "intended for use by": 1.0,
    "for use by a": 0.5,
    "use by a single": 1.0,
    "by a single speaker": 1.0,
    "a single speaker .": 1.0,
    "<s> a speaker independent": 1.0,
    "a speaker independent system": 1.0,
    "speaker independent system is": 1.0,
    "independent system is intended": 1.0,
    "for use by any": 0.5,
    "use by any speaker": 1.0,
    "by any speaker ,": 1.0,
    "any speaker , more": 1.0,
    "speaker , more difficult": 1.0,
    ", more difficult .": 1.0,
    "<s> isolated , discontinuous": 1.0,
    "isolated , discontinuous or": 0.5,
    ", discontinuous or continuous": 1.0,
    "discontinuous or continuous speech": 1.0,
    "or continuous speech with": 0.5,
    "continuous speech with isolated": 1.0,
    "speech with isolated speech": 1.0,
    "with isolated speech single": 0.5,
    "isolated speech single words": 1.0,
    "speech single words are": 1.0,
    "single words are used": 1.0,
    "words are used ,": 0.5,
    "are used , therefore": 1.0,
    "used , therefore it": 1.0,
    ", therefore it becomes": 1.0,
    "therefore it becomes easier": 0.6666666666666666,
    "it becomes easier to": 1.0,
    "becomes easier to recognize": 1.0,
    "easier to recognize the": 1.0,
    "to recognize the speech": 1.0,
    "recognize the speech .": 0.5,
    "<s> with discontinuous speech": 1.0,
    "with discontinuous speech full": 1.0,
    "discontinuous speech full sentenced": 1.0,
    "speech full sentenced separated": 1.0,
    "full sentenced separated by": 1.0,
    "sentenced separated by silence": 1.0,
    "separated by silence are": 1.0,
    "by silence are used": 1.0,
    "silence are used ,": 1.0,
    "recognize the speech as": 0.25,
    "the speech as well": 1.0,
    "speech as well as": 1.0,
    "as well as with": 0.07692307692307693,
    "well as with isolated": 1.0,
    "as with isolated speech": 1.0,
    "with isolated speech .": 0.5,
    "<s> with continuous speech": 1.0,
    "with continuous speech naturally": 1.0,
    "continuous speech naturally spoken": 1.0,
    "speech naturally spoken sentences": 1.0,
    "naturally spoken sentences are": 1.0,
    "spoken sentences are used": 1.0,
    "sentences are used ,": 1.0,
    "therefore it becomes harder": 0.3333333333333333,
    "it becomes harder to": 1.0,
    "becomes harder to recognize": 1.0,
    "harder to recognize the": 1.0,
    "recognize the speech ,": 0.25,
    "the speech , different": 1.0,
    "speech , different from": 1.0,
    ", different from both": 1.0,
    "different from both isloated": 1.0,
    "from both isloated and": 1.0,
    "both isloated and discontinuous": 1.0,
    "isloated and discontinuous speech": 1.0,
    "and discontinuous speech .": 1.0,
    "<s> task and language": 1.0,
    "and language constraints e.g.": 0.5,
    "language constraints e.g. querying": 1.0,
    "constraints e.g. querying application": 1.0,
    "e.g. querying application may": 1.0,
    "querying application may dismiss": 1.0,
    "application may dismiss the": 1.0,
    "may dismiss the hypothesis": 1.0,
    "dismiss the hypothesis ``": 1.0,
    "the hypothesis `` the": 1.0,
    "hypothesis `` the apple": 1.0,
    "`` the apple is": 1.0,
    "the apple is red": 0.5,
    "apple is red .": 1.0,
    "is red . ''": 1.0,
    "<s> e.g. constraints may": 1.0,
    "e.g. constraints may be": 1.0,
    "constraints may be semantic": 1.0,
    "may be semantic ;": 1.0,
    "be semantic ; rejecting": 1.0,
    "semantic ; rejecting ``": 1.0,
    "; rejecting `` the": 0.5,
    "rejecting `` the apple": 1.0,
    "the apple is angry": 0.5,
    "apple is angry .": 1.0,
    "is angry . ''": 1.0,
    "<s> e.g. syntactic ;": 1.0,
    "e.g. syntactic ; rejecting": 1.0,
    "syntactic ; rejecting ``": 1.0,
    "; rejecting `` red": 0.5,
    "rejecting `` red is": 1.0,
    "`` red is apple": 1.0,
    "red is apple the": 1.0,
    "is apple the .": 1.0,
    "apple the . ''": 1.0,
    "<s> constraints are often": 1.0,
    "constraints are often represented": 1.0,
    "are often represented by": 1.0,
    "often represented by a": 1.0,
    "represented by a grammar": 1.0,
    "by a grammar .": 0.5,
    "<s> read vs. spontaneous": 1.0,
    "vs. spontaneous speech when": 0.5,
    "spontaneous speech when a": 1.0,
    "speech when a person": 1.0,
    "when a person reads": 0.5,
    "a person reads it": 1.0,
    "person reads it 's": 1.0,
    "reads it 's usually": 1.0,
    "it 's usually in": 1.0,
    "'s usually in a": 1.0,
    "usually in a context": 1.0,
    "in a context that": 1.0,
    "a context that has": 1.0,
    "context that has been": 1.0,
    "that has been previously": 0.25,
    "has been previously prepared": 1.0,
    "been previously prepared ,": 1.0,
    "previously prepared , but": 1.0,
    "prepared , but when": 1.0,
    ", but when a": 1.0,
    "but when a person": 1.0,
    "when a person uses": 0.5,
    "a person uses spontaneous": 1.0,
    "person uses spontaneous speech": 1.0,
    "uses spontaneous speech ,": 1.0,
    "spontaneous speech , it": 1.0,
    "speech , it is": 1.0,
    ", it is difficult": 0.07692307692307693,
    "is difficult to recognize": 0.3333333333333333,
    "difficult to recognize the": 1.0,
    "<s> because of the": 1.0,
    "because of the disfluences": 0.25,
    "of the disfluences -lrb-": 1.0,
    "the disfluences -lrb- like": 1.0,
    "disfluences -lrb- like ``": 1.0,
    "-lrb- like `` uh": 1.0,
    "like `` uh ''": 1.0,
    "`` uh '' and": 1.0,
    "uh '' and ``": 1.0,
    "'' and `` um": 0.1111111111111111,
    "and `` um ''": 1.0,
    "`` um '' ,": 1.0,
    "um '' , false": 1.0,
    "'' , false starts": 1.0,
    ", false starts ,": 1.0,
    "false starts , incomplete": 1.0,
    "starts , incomplete sentences": 1.0,
    ", incomplete sentences ,": 1.0,
    "incomplete sentences , stutering": 1.0,
    "sentences , stutering ,": 1.0,
    ", stutering , coughing": 1.0,
    "stutering , coughing ,": 1.0,
    ", coughing , and": 1.0,
    "coughing , and laughter": 1.0,
    ", and laughter -rrb-": 1.0,
    "and laughter -rrb- and": 1.0,
    "laughter -rrb- and limited": 1.0,
    "-rrb- and limited vocabulary": 1.0,
    "and limited vocabulary .": 1.0,
    "<s> adverse conditions environmental": 1.0,
    "adverse conditions environmental noise": 1.0,
    "conditions environmental noise -lrb-": 1.0,
    "environmental noise -lrb- e.g.": 1.0,
    "noise -lrb- e.g. noise": 1.0,
    "-lrb- e.g. noise in": 1.0,
    "e.g. noise in a": 1.0,
    "noise in a car": 1.0,
    "in a car or": 1.0,
    "a car or a": 1.0,
    "car or a factory": 1.0,
    "or a factory -rrb-": 1.0,
    "a factory -rrb- acoustical": 1.0,
    "factory -rrb- acoustical distortions": 1.0,
    "-rrb- acoustical distortions -lrb-": 1.0,
    "acoustical distortions -lrb- e.g.": 1.0,
    "distortions -lrb- e.g. echoes": 1.0,
    "-lrb- e.g. echoes ,": 1.0,
    "e.g. echoes , room": 1.0,
    "echoes , room acoustics": 1.0,
    ", room acoustics -rrb-": 1.0,
    "room acoustics -rrb- speech": 1.0,
    "acoustics -rrb- speech recognition": 1.0,
    "-rrb- speech recognition is": 1.0,
    "speech recognition is a": 0.125,
    "recognition is a multileveled": 1.0,
    "is a multileveled pattern": 1.0,
    "a multileveled pattern recognition": 1.0,
    "multileveled pattern recognition task": 1.0,
    "pattern recognition task .": 1.0,
    "<s> acoustical signals are": 1.0,
    "acoustical signals are structured": 1.0,
    "signals are structured into": 1.0,
    "are structured into a": 1.0,
    "structured into a hierarchy": 1.0,
    "into a hierarchy of": 1.0,
    "a hierarchy of units": 1.0,
    "hierarchy of units ;": 1.0,
    "of units ; e.g.": 1.0,
    "units ; e.g. phonemes": 1.0,
    "; e.g. phonemes ,": 1.0,
    "e.g. phonemes , words": 1.0,
    "phonemes , words ,": 1.0,
    ", words , phrases": 1.0,
    ", phrases , and": 0.5,
    "phrases , and sentences": 1.0,
    ", and sentences ;": 1.0,
    "and sentences ; each": 1.0,
    "sentences ; each level": 1.0,
    "; each level provides": 1.0,
    "each level provides additional": 1.0,
    "level provides additional constraints": 1.0,
    "provides additional constraints ;": 1.0,
    "additional constraints ; e.g.": 1.0,
    "constraints ; e.g. known": 1.0,
    "; e.g. known word": 1.0,
    "e.g. known word pronunciations": 1.0,
    "known word pronunciations or": 1.0,
    "word pronunciations or legal": 1.0,
    "pronunciations or legal word": 1.0,
    "or legal word sequences": 1.0,
    "legal word sequences ,": 1.0,
    "word sequences , which": 1.0,
    "sequences , which can": 1.0,
    ", which can compensate": 0.5,
    "which can compensate for": 1.0,
    "can compensate for errors": 1.0,
    "compensate for errors or": 1.0,
    "for errors or uncertainties": 1.0,
    "errors or uncertainties at": 1.0,
    "or uncertainties at lower": 1.0,
    "uncertainties at lower level": 1.0,
    "at lower level ;": 1.0,
    "lower level ; this": 1.0,
    "level ; this hierarchy": 1.0,
    "; this hierarchy of": 1.0,
    "this hierarchy of constraints": 1.0,
    "hierarchy of constraints are": 1.0,
    "of constraints are exploited": 1.0,
    "constraints are exploited ;": 1.0,
    "are exploited ; by": 1.0,
    "exploited ; by combining": 1.0,
    "; by combining decisions": 1.0,
    "by combining decisions probabilistically": 1.0,
    "combining decisions probabilistically at": 1.0,
    "decisions probabilistically at all": 1.0,
    "probabilistically at all lower": 1.0,
    "at all lower levels": 1.0,
    "all lower levels ,": 1.0,
    "lower levels , and": 1.0,
    "levels , and making": 1.0,
    ", and making more": 0.5,
    "and making more deterministic": 1.0,
    "making more deterministic decisions": 1.0,
    "more deterministic decisions only": 1.0,
    "deterministic decisions only at": 1.0,
    "decisions only at the": 1.0,
    "only at the highest": 1.0,
    "at the highest level": 1.0,
    "the highest level ;": 1.0,
    "highest level ; speech": 1.0,
    "level ; speech recogniton": 1.0,
    "; speech recogniton by": 1.0,
    "speech recogniton by a": 1.0,
    "recogniton by a machine": 1.0,
    "by a machine is": 0.5,
    "a machine is a": 1.0,
    "machine is a process": 1.0,
    "is a process broken": 1.0,
    "a process broken into": 1.0,
    "process broken into several": 1.0,
    "broken into several phases": 1.0,
    "into several phases .": 1.0,
    "<s> computationally , it": 1.0,
    "computationally , it is": 1.0,
    "it is a problem": 0.16666666666666666,
    "is a problem in": 1.0,
    "a problem in which": 1.0,
    "problem in which a": 1.0,
    "in which a sound": 0.5,
    "which a sound pattern": 1.0,
    "a sound pattern has": 1.0,
    "sound pattern has to": 1.0,
    "pattern has to be": 1.0,
    "has to be recognized": 0.25,
    "to be recognized or": 1.0,
    "be recognized or classified": 1.0,
    "recognized or classified into": 1.0,
    "or classified into a": 1.0,
    "classified into a category": 1.0,
    "into a category that": 1.0,
    "a category that represents": 1.0,
    "category that represents a": 1.0,
    "that represents a meaning": 1.0,
    "represents a meaning to": 1.0,
    "a meaning to a": 0.5,
    "meaning to a human": 1.0,
    "to a human .": 0.5,
    "<s> every acoustic signal": 1.0,
    "every acoustic signal can": 1.0,
    "acoustic signal can be": 1.0,
    "signal can be broken": 0.5,
    "can be broken in": 1.0,
    "be broken in smaller": 1.0,
    "broken in smaller more": 1.0,
    "in smaller more basic": 1.0,
    "smaller more basic sub-signals": 1.0,
    "more basic sub-signals .": 1.0,
    "<s> as the more": 1.0,
    "as the more complex": 1.0,
    "the more complex sound": 1.0,
    "more complex sound signal": 0.5,
    "complex sound signal is": 1.0,
    "sound signal is broken": 1.0,
    "signal is broken into": 1.0,
    "is broken into the": 1.0,
    "broken into the smaller": 1.0,
    "into the smaller sub-sounds": 1.0,
    "the smaller sub-sounds ,": 1.0,
    "smaller sub-sounds , different": 1.0,
    "sub-sounds , different levels": 1.0,
    ", different levels are": 1.0,
    "different levels are created": 1.0,
    "levels are created ,": 1.0,
    "are created , where": 0.5,
    "created , where at": 1.0,
    ", where at the": 1.0,
    "where at the top": 1.0,
    "at the top level": 1.0,
    "the top level we": 1.0,
    "top level we have": 1.0,
    "level we have complex": 1.0,
    "we have complex sounds": 1.0,
    "have complex sounds ,": 1.0,
    "complex sounds , which": 1.0,
    "sounds , which are": 1.0,
    ", which are made": 0.2,
    "which are made of": 1.0,
    "are made of simpler": 1.0,
    "made of simpler sounds": 1.0,
    "of simpler sounds on": 1.0,
    "simpler sounds on lower": 1.0,
    "sounds on lower level": 1.0,
    "on lower level ,": 1.0,
    "lower level , and": 1.0,
    "level , and going": 1.0,
    ", and going to": 1.0,
    "and going to lower": 1.0,
    "going to lower levels": 1.0,
    "to lower levels even": 1.0,
    "lower levels even more": 1.0,
    "levels even more ,": 1.0,
    "even more , we": 1.0,
    "more , we create": 1.0,
    ", we create more": 1.0,
    "we create more basic": 1.0,
    "create more basic and": 1.0,
    "more basic and shorter": 1.0,
    "basic and shorter and": 1.0,
    "and shorter and simpler": 1.0,
    "shorter and simpler sounds": 1.0,
    "and simpler sounds .": 1.0,
    "<s> the lowest level": 1.0,
    "the lowest level ,": 1.0,
    "lowest level , where": 1.0,
    "level , where the": 1.0,
    ", where the sounds": 0.2,
    "where the sounds are": 1.0,
    "the sounds are the": 1.0,
    "sounds are the most": 1.0,
    "are the most fundamental": 1.0,
    "the most fundamental ,": 1.0,
    "most fundamental , a": 1.0,
    "fundamental , a machine": 1.0,
    "a machine would check": 0.5,
    "machine would check for": 1.0,
    "would check for simple": 1.0,
    "check for simple and": 1.0,
    "for simple and more": 1.0,
    "simple and more probabilistic": 1.0,
    "and more probabilistic rules": 1.0,
    "more probabilistic rules of": 1.0,
    "probabilistic rules of what": 1.0,
    "rules of what sound": 1.0,
    "of what sound should": 1.0,
    "what sound should represent": 1.0,
    "sound should represent .": 1.0,
    "<s> once these sounds": 1.0,
    "once these sounds are": 1.0,
    "these sounds are put": 1.0,
    "sounds are put together": 1.0,
    "are put together into": 1.0,
    "put together into more": 1.0,
    "together into more complex": 1.0,
    "into more complex sound": 1.0,
    "more complex sound on": 0.5,
    "complex sound on upper": 1.0,
    "sound on upper level": 1.0,
    "on upper level ,": 1.0,
    "upper level , a": 1.0,
    "level , a new": 1.0,
    ", a new set": 1.0,
    "a new set of": 1.0,
    "new set of more": 1.0,
    "set of more deterministic": 0.5,
    "of more deterministic rules": 1.0,
    "more deterministic rules should": 1.0,
    "deterministic rules should predict": 1.0,
    "rules should predict what": 1.0,
    "should predict what new": 1.0,
    "predict what new complex": 1.0,
    "what new complex sound": 1.0,
    "new complex sound should": 1.0,
    "complex sound should represent": 1.0,
    "<s> the most upper": 0.3333333333333333,
    "the most upper level": 1.0,
    "most upper level of": 1.0,
    "upper level of a": 1.0,
    "level of a deterministic": 1.0,
    "of a deterministic rule": 1.0,
    "a deterministic rule should": 1.0,
    "deterministic rule should figure": 1.0,
    "rule should figure out": 1.0,
    "should figure out the": 1.0,
    "figure out the meaning": 1.0,
    "out the meaning of": 1.0,
    "the meaning of complex": 0.16666666666666666,
    "meaning of complex expressions": 1.0,
    "of complex expressions .": 1.0,
    "in order to expand": 0.125,
    "order to expand our": 1.0,
    "to expand our knowledge": 1.0,
    "expand our knowledge about": 1.0,
    "our knowledge about speech": 1.0,
    "knowledge about speech recognition": 1.0,
    "about speech recognition we": 0.5,
    "speech recognition we need": 1.0,
    "recognition we need to": 1.0,
    "we need to take": 0.3333333333333333,
    "to take into a": 0.5,
    "take into a consideration": 1.0,
    "into a consideration neural": 1.0,
    "a consideration neural networks": 1.0,
    "consideration neural networks .": 1.0,
    "<s> there are four": 0.2,
    "there are four steps": 1.0,
    "are four steps of": 1.0,
    "four steps of neural": 1.0,
    "steps of neural network": 1.0,
    "of neural network approaches": 1.0,
    "neural network approaches :": 0.5,
    "network approaches : digitize": 1.0,
    "approaches : digitize the": 1.0,
    ": digitize the speech": 1.0,
    "digitize the speech that": 1.0,
    "the speech that we": 1.0,
    "speech that we want": 1.0,
    "that we want to": 1.0,
    "we want to recognize": 0.5,
    "want to recognize for": 1.0,
    "to recognize for telephone": 1.0,
    "recognize for telephone speech": 1.0,
    "for telephone speech the": 1.0,
    "telephone speech the sampling": 1.0,
    "speech the sampling rate": 1.0,
    "the sampling rate is": 1.0,
    "sampling rate is 8000": 1.0,
    "rate is 8000 samples": 1.0,
    "is 8000 samples per": 1.0,
    "8000 samples per second": 1.0,
    "samples per second ;": 1.0,
    "per second ; compute": 1.0,
    "second ; compute features": 1.0,
    "; compute features of": 1.0,
    "compute features of spectral-domain": 1.0,
    "features of spectral-domain of": 1.0,
    "of spectral-domain of the": 1.0,
    "spectral-domain of the speech": 1.0,
    "of the speech -lrb-": 0.5,
    "the speech -lrb- with": 0.5,
    "speech -lrb- with fourier": 1.0,
    "-lrb- with fourier transform": 1.0,
    "with fourier transform -rrb-": 1.0,
    "fourier transform -rrb- ;": 1.0,
    "transform -rrb- ; computed": 1.0,
    "-rrb- ; computed every": 1.0,
    "; computed every 10msec": 1.0,
    "computed every 10msec ,": 1.0,
    "every 10msec , with": 1.0,
    "10msec , with one": 1.0,
    ", with one 10msec": 1.0,
    "with one 10msec section": 1.0,
    "one 10msec section called": 1.0,
    "10msec section called a": 1.0,
    "section called a frame": 1.0,
    "called a frame ;": 1.0,
    "a frame ; analysis": 1.0,
    "frame ; analysis of": 1.0,
    "; analysis of four": 1.0,
    "analysis of four step": 1.0,
    "of four step neural": 1.0,
    "four step neural network": 1.0,
    "step neural network approaches": 1.0,
    "neural network approaches can": 0.5,
    "network approaches can be": 1.0,
    "approaches can be explained": 1.0,
    "can be explained by": 1.0,
    "be explained by further": 1.0,
    "explained by further information": 1.0,
    "by further information .": 1.0,
    "<s> sound is produced": 1.0,
    "sound is produced by": 1.0,
    "is produced by air": 1.0,
    "produced by air -lrb-": 1.0,
    "by air -lrb- or": 1.0,
    "air -lrb- or some": 1.0,
    "-lrb- or some other": 1.0,
    "or some other medium": 0.5,
    "some other medium -rrb-": 1.0,
    "other medium -rrb- vibration": 1.0,
    "medium -rrb- vibration ,": 1.0,
    "-rrb- vibration , which": 1.0,
    "vibration , which we": 1.0,
    ", which we register": 1.0,
    "which we register by": 1.0,
    "we register by ears": 1.0,
    "register by ears ,": 1.0,
    "by ears , but": 1.0,
    "ears , but machines": 1.0,
    ", but machines by": 1.0,
    "but machines by receivers": 1.0,
    "machines by receivers .": 1.0,
    "<s> basic sound creates": 1.0,
    "basic sound creates a": 1.0,
    "sound creates a wave": 1.0,
    "creates a wave which": 1.0,
    "a wave which has": 1.0,
    "wave which has 2": 1.0,
    "which has 2 descriptions": 1.0,
    "has 2 descriptions ;": 1.0,
    "2 descriptions ; amplitude": 1.0,
    "descriptions ; amplitude -lrb-": 1.0,
    "; amplitude -lrb- how": 1.0,
    "amplitude -lrb- how strong": 1.0,
    "-lrb- how strong is": 1.0,
    "how strong is it": 1.0,
    "strong is it -rrb-": 1.0,
    "is it -rrb- ,": 1.0,
    "it -rrb- , and": 1.0,
    "-rrb- , and frequency": 0.09090909090909091,
    ", and frequency -lrb-": 1.0,
    "and frequency -lrb- how": 1.0,
    "frequency -lrb- how often": 1.0,
    "-lrb- how often it": 1.0,
    "how often it vibrates": 1.0,
    "often it vibrates per": 1.0,
    "it vibrates per second": 1.0,
    "vibrates per second -rrb-": 1.0,
    "per second -rrb- .": 1.0,
    "<s> digitized sound graph": 1.0,
    "digitized sound graph this": 1.0,
    "sound graph this is": 1.0,
    "graph this is the": 1.0,
    "this is the same": 0.3333333333333333,
    "is the same as": 1.0,
    "same as the wave": 0.5,
    "as the wave in": 1.0,
    "the wave in the": 1.0,
    "wave in the water": 1.0,
    "in the water .": 1.0,
    "<s> big wave is": 1.0,
    "big wave is strong": 1.0,
    "wave is strong and": 1.0,
    "is strong and smaller": 1.0,
    "strong and smaller ones": 1.0,
    "and smaller ones are": 1.0,
    "smaller ones are usually": 1.0,
    "ones are usually faster": 1.0,
    "are usually faster but": 1.0,
    "usually faster but weaker": 1.0,
    "faster but weaker .": 1.0,
    "<s> that is how": 0.3333333333333333,
    "that is how air": 1.0,
    "is how air is": 1.0,
    "how air is distorted": 1.0,
    "air is distorted ,": 1.0,
    "is distorted , but": 1.0,
    "distorted , but we": 1.0,
    ", but we do": 1.0,
    "but we do n't": 1.0,
    "we do n't see": 1.0,
    "do n't see it": 1.0,
    "n't see it easily": 1.0,
    "see it easily ,": 1.0,
    "it easily , in": 1.0,
    "easily , in order": 1.0,
    ", in order for": 0.3333333333333333,
    "in order for sound": 1.0,
    "order for sound to": 1.0,
    "for sound to travel": 1.0,
    "sound to travel .": 1.0,
    "<s> these waves can": 1.0,
    "these waves can be": 1.0,
    "waves can be digitalized": 1.0,
    "can be digitalized :": 1.0,
    "be digitalized : sample": 1.0,
    "digitalized : sample a": 1.0,
    ": sample a strength": 1.0,
    "sample a strength at": 1.0,
    "a strength at short": 1.0,
    "strength at short intervals": 1.0,
    "at short intervals like": 1.0,
    "short intervals like in": 1.0,
    "intervals like in picture": 1.0,
    "like in picture above": 1.0,
    "in picture above to": 1.0,
    "picture above to get": 1.0,
    "above to get bunch": 1.0,
    "to get bunch of": 1.0,
    "get bunch of numbers": 1.0,
    "bunch of numbers that": 0.5,
    "of numbers that approximate": 1.0,
    "numbers that approximate at": 1.0,
    "that approximate at each": 1.0,
    "approximate at each time": 1.0,
    "at each time step": 1.0,
    "each time step the": 1.0,
    "time step the strength": 1.0,
    "step the strength of": 1.0,
    "the strength of a": 0.5,
    "strength of a wave": 1.0,
    "of a wave .": 0.5,
    "<s> collection of these": 1.0,
    "collection of these numbers": 1.0,
    "of these numbers represent": 1.0,
    "these numbers represent analog": 1.0,
    "numbers represent analog wave": 1.0,
    "represent analog wave .": 1.0,
    "<s> this new wave": 1.0,
    "this new wave is": 1.0,
    "new wave is digital": 1.0,
    "wave is digital .": 1.0,
    "<s> sound waves are": 1.0,
    "sound waves are complicated": 1.0,
    "waves are complicated because": 1.0,
    "are complicated because they": 1.0,
    "complicated because they superimpose": 1.0,
    "because they superimpose one": 1.0,
    "they superimpose one on": 1.0,
    "superimpose one on top": 1.0,
    "one on top of": 1.0,
    "on top of each": 1.0,
    "top of each other": 1.0,
    "of each other .": 1.0,
    "<s> like the waves": 1.0,
    "like the waves would": 1.0,
    "the waves would .": 1.0,
    "<s> this way they": 1.0,
    "this way they create": 1.0,
    "way they create odd": 1.0,
    "they create odd looking": 1.0,
    "create odd looking waves": 1.0,
    "odd looking waves .": 1.0,
    "example , if there": 0.16666666666666666,
    ", if there are": 1.0,
    "if there are two": 0.5,
    "there are two waves": 0.5,
    "are two waves that": 1.0,
    "two waves that interact": 1.0,
    "waves that interact with": 1.0,
    "that interact with each": 1.0,
    "interact with each other": 1.0,
    "with each other we": 1.0,
    "each other we can": 1.0,
    "other we can add": 1.0,
    "we can add them": 1.0,
    "can add them which": 1.0,
    "add them which creates": 1.0,
    "them which creates new": 1.0,
    "which creates new odd": 1.0,
    "creates new odd looking": 1.0,
    "new odd looking wave": 1.0,
    "odd looking wave as": 1.0,
    "looking wave as is": 1.0,
    "wave as is shown": 1.0,
    "as is shown in": 1.0,
    "is shown in the": 1.0,
    "shown in the picture": 1.0,
    "in the picture on": 1.0,
    "the picture on the": 1.0,
    "picture on the right": 1.0,
    "on the right .": 1.0,
    "<s> neural network classifies": 1.0,
    "neural network classifies features": 1.0,
    "network classifies features into": 1.0,
    "classifies features into phonetic-based": 1.0,
    "features into phonetic-based categories": 1.0,
    "into phonetic-based categories ;": 1.0,
    "phonetic-based categories ; given": 1.0,
    "categories ; given basic": 1.0,
    "; given basic sound": 1.0,
    "given basic sound blocks": 1.0,
    "basic sound blocks ,": 1.0,
    "sound blocks , that": 1.0,
    "blocks , that machine": 1.0,
    ", that machine digitized": 1.0,
    "that machine digitized ,": 1.0,
    "machine digitized , we": 1.0,
    "digitized , we have": 1.0,
    ", we have a": 1.0,
    "we have a bunch": 1.0,
    "have a bunch of": 1.0,
    "a bunch of numbers": 1.0,
    "bunch of numbers which": 0.5,
    "of numbers which describe": 1.0,
    "numbers which describe a": 1.0,
    "which describe a wave": 1.0,
    "describe a wave and": 1.0,
    "a wave and waves": 1.0,
    "wave and waves describe": 1.0,
    "and waves describe words": 1.0,
    "waves describe words .": 1.0,
    "<s> each frame has": 1.0,
    "each frame has a": 1.0,
    "frame has a unit": 1.0,
    "has a unit block": 1.0,
    "a unit block of": 1.0,
    "unit block of sound": 1.0,
    "block of sound ,": 1.0,
    "of sound , which": 1.0,
    "sound , which are": 1.0,
    ", which are broken": 0.2,
    "which are broken into": 1.0,
    "are broken into basic": 1.0,
    "broken into basic sound": 1.0,
    "into basic sound waves": 1.0,
    "basic sound waves and": 1.0,
    "sound waves and represented": 1.0,
    "waves and represented by": 1.0,
    "and represented by numbers": 1.0,
    "represented by numbers after": 1.0,
    "by numbers after fourier": 1.0,
    "numbers after fourier transform": 1.0,
    "after fourier transform ,": 1.0,
    "fourier transform , can": 1.0,
    "transform , can be": 1.0,
    ", can be statistically": 0.5,
    "can be statistically evaluated": 1.0,
    "be statistically evaluated to": 1.0,
    "statistically evaluated to set": 0.5,
    "evaluated to set to": 1.0,
    "to set to which": 1.0,
    "set to which class": 1.0,
    "to which class of": 1.0,
    "which class of sounds": 1.0,
    "class of sounds it": 1.0,
    "of sounds it belongs": 1.0,
    "sounds it belongs to": 1.0,
    "it belongs to .": 1.0,
    "<s> the nodes in": 1.0,
    "the nodes in the": 1.0,
    "nodes in the figure": 1.0,
    "in the figure on": 1.0,
    "the figure on a": 1.0,
    "figure on a slide": 1.0,
    "on a slide represent": 1.0,
    "a slide represent a": 1.0,
    "slide represent a feature": 1.0,
    "represent a feature of": 1.0,
    "a feature of a": 1.0,
    "feature of a sound": 0.5,
    "of a sound in": 0.5,
    "a sound in which": 1.0,
    "sound in which a": 1.0,
    "in which a feature": 0.5,
    "which a feature of": 1.0,
    "feature of a wave": 0.5,
    "of a wave from": 0.5,
    "a wave from first": 1.0,
    "wave from first layer": 1.0,
    "from first layer of": 1.0,
    "first layer of nodes": 1.0,
    "layer of nodes to": 0.3333333333333333,
    "of nodes to a": 1.0,
    "nodes to a second": 1.0,
    "to a second layer": 1.0,
    "a second layer of": 1.0,
    "second layer of nodes": 1.0,
    "layer of nodes based": 0.3333333333333333,
    "of nodes based on": 1.0,
    "nodes based on some": 1.0,
    "based on some statistical": 0.25,
    "on some statistical analysis": 1.0,
    "some statistical analysis .": 1.0,
    "<s> this analysis depends": 1.0,
    "this analysis depends on": 1.0,
    "analysis depends on programer": 1.0,
    "depends on programer 's": 1.0,
    "on programer 's instructions": 1.0,
    "programer 's instructions .": 1.0,
    "<s> at this point": 1.0,
    "at this point ,": 1.0,
    "this point , a": 1.0,
    "point , a second": 1.0,
    ", a second layer": 1.0,
    "layer of nodes represents": 0.3333333333333333,
    "of nodes represents a": 1.0,
    "nodes represents a higher": 1.0,
    "represents a higher level": 1.0,
    "a higher level features": 1.0,
    "higher level features of": 1.0,
    "level features of a": 1.0,
    "features of a sound": 1.0,
    "of a sound input": 0.5,
    "a sound input which": 1.0,
    "sound input which is": 1.0,
    "input which is again": 1.0,
    "which is again statistically": 1.0,
    "is again statistically evaluated": 1.0,
    "again statistically evaluated to": 1.0,
    "statistically evaluated to see": 0.5,
    "evaluated to see what": 1.0,
    "to see what class": 1.0,
    "see what class they": 1.0,
    "what class they belong": 1.0,
    "class they belong to": 1.0,
    "they belong to .": 1.0,
    "<s> last level of": 1.0,
    "last level of nodes": 1.0,
    "level of nodes should": 1.0,
    "of nodes should be": 1.0,
    "nodes should be output": 1.0,
    "should be output nodes": 1.0,
    "be output nodes that": 1.0,
    "output nodes that tell": 1.0,
    "nodes that tell us": 1.0,
    "that tell us with": 1.0,
    "tell us with high": 1.0,
    "us with high probability": 1.0,
    "with high probability what": 1.0,
    "high probability what original": 1.0,
    "probability what original sound": 1.0,
    "what original sound really": 1.0,
    "original sound really was": 1.0,
    "sound really was .": 1.0,
    "<s> search to match": 1.0,
    "search to match the": 1.0,
    "to match the neural-network": 1.0,
    "match the neural-network output": 1.0,
    "the neural-network output scores": 1.0,
    "neural-network output scores for": 1.0,
    "output scores for the": 1.0,
    "scores for the best": 1.0,
    "for the best word": 1.0,
    "the best word ,": 1.0,
    "best word , to": 1.0,
    "word , to determine": 1.0,
    ", to determine the": 0.5,
    "to determine the word": 0.25,
    "determine the word that": 1.0,
    "the word that was": 1.0,
    "word that was most": 1.0,
    "that was most likely": 1.0,
    "was most likely uttered": 1.0,
    "most likely uttered ;": 1.0,
    "likely uttered ; a": 1.0,
    "uttered ; a machine": 1.0,
    "; a machine speech": 1.0,
    "a machine speech recognition": 1.0,
    "machine speech recognition using": 1.0,
    "speech recognition using neural": 1.0,
    "recognition using neural network": 1.0,
    "using neural network is": 1.0,
    "neural network is still": 1.0,
    "network is still just": 1.0,
    "is still just a": 1.0,
    "still just a fancy": 1.0,
    "just a fancy statistics": 1.0,
    "a fancy statistics .": 1.0,
    "<s> artificial neural network": 1.0,
    "artificial neural network has": 1.0,
    "neural network has specialized": 1.0,
    "network has specialized output": 1.0,
    "has specialized output nodes": 1.0,
    "specialized output nodes for": 1.0,
    "output nodes for results": 1.0,
    "nodes for results ,": 1.0,
    "for results , unlike": 1.0,
    "results , unlike brain": 1.0,
    ", unlike brain .": 1.0,
    "<s> our brain recognizes": 0.5,
    "our brain recognizes the": 1.0,
    "brain recognizes the meaning": 1.0,
    "recognizes the meaning of": 1.0,
    "the meaning of words": 0.16666666666666666,
    "meaning of words in": 1.0,
    "of words in fundamentally": 0.25,
    "words in fundamentally different": 1.0,
    "in fundamentally different way": 1.0,
    "fundamentally different way .": 1.0,
    "<s> our brain is": 0.5,
    "our brain is entirely": 1.0,
    "brain is entirely committed": 1.0,
    "is entirely committed into": 1.0,
    "entirely committed into the": 1.0,
    "committed into the perception": 1.0,
    "into the perception of": 1.0,
    "the perception of sound": 1.0,
    "perception of sound .": 1.0,
    "<s> when we hear": 1.0,
    "when we hear sound": 1.0,
    "we hear sound ,": 1.0,
    "hear sound , our": 1.0,
    "sound , our life": 1.0,
    ", our life experience": 1.0,
    "our life experience is": 1.0,
    "life experience is brought": 1.0,
    "experience is brought together": 1.0,
    "is brought together to": 1.0,
    "brought together to action": 1.0,
    "together to action of": 1.0,
    "to action of listening": 1.0,
    "action of listening to": 1.0,
    "of listening to set": 1.0,
    "listening to set a": 1.0,
    "to set a sound": 0.5,
    "set a sound into": 1.0,
    "a sound into a": 1.0,
    "sound into a appropriate": 1.0,
    "into a appropriate perspective": 1.0,
    "a appropriate perspective so": 1.0,
    "appropriate perspective so it": 1.0,
    "perspective so it is": 1.0,
    "so it is meaningful": 1.0,
    "it is meaningful .": 1.0,
    "<s> brain has a": 1.0,
    "brain has a purpose": 1.0,
    "has a purpose when": 1.0,
    "a purpose when it": 1.0,
    "purpose when it listens": 1.0,
    "when it listens for": 1.0,
    "it listens for a": 1.0,
    "listens for a sound": 1.0,
    "for a sound that": 1.0,
    "a sound that is": 1.0,
    "sound that is steered": 1.0,
    "that is steered toward": 1.0,
    "is steered toward actions": 1.0,
    "steered toward actions .": 1.0,
    "<s> in 1982 ,": 1.0,
    "in 1982 , kurzweil": 1.0,
    "1982 , kurzweil applied": 1.0,
    ", kurzweil applied intelligence": 1.0,
    "kurzweil applied intelligence and": 1.0,
    "applied intelligence and dragon": 1.0,
    "intelligence and dragon systems": 1.0,
    "and dragon systems released": 1.0,
    "dragon systems released speech": 0.5,
    "systems released speech recognition": 1.0,
    "released speech recognition products": 1.0,
    "speech recognition products .": 1.0,
    "<s> by 1985 ,": 1.0,
    "by 1985 , kurzweil": 1.0,
    "1985 , kurzweil 's": 1.0,
    ", kurzweil 's software": 1.0,
    "kurzweil 's software had": 1.0,
    "'s software had a": 1.0,
    "software had a vocabulary": 1.0,
    "had a vocabulary of": 1.0,
    "a vocabulary of 1,000": 1.0,
    "vocabulary of 1,000 words": 1.0,
    "of 1,000 words --": 1.0,
    "1,000 words -- if": 1.0,
    "words -- if uttered": 1.0,
    "-- if uttered one": 1.0,
    "if uttered one word": 1.0,
    "uttered one word at": 1.0,
    "one word at a": 1.0,
    "word at a time": 1.0,
    "years later , in": 0.3333333333333333,
    "later , in 1987": 0.5,
    ", in 1987 ,": 1.0,
    "in 1987 , its": 0.5,
    "1987 , its lexicon": 1.0,
    ", its lexicon reached": 1.0,
    "its lexicon reached 20,000": 1.0,
    "lexicon reached 20,000 words": 1.0,
    "reached 20,000 words ,": 1.0,
    "20,000 words , entering": 1.0,
    "words , entering the": 1.0,
    ", entering the realm": 1.0,
    "entering the realm of": 1.0,
    "the realm of human": 1.0,
    "realm of human vocabularies": 1.0,
    "of human vocabularies ,": 1.0,
    "human vocabularies , which": 1.0,
    "vocabularies , which range": 1.0,
    ", which range from": 1.0,
    "which range from 10,000": 1.0,
    "range from 10,000 to": 1.0,
    "from 10,000 to 150,000": 1.0,
    "10,000 to 150,000 words": 1.0,
    "to 150,000 words .": 1.0,
    "<s> but recognition accuracy": 1.0,
    "but recognition accuracy was": 1.0,
    "recognition accuracy was only": 1.0,
    "accuracy was only 10": 1.0,
    "was only 10 %": 1.0,
    "only 10 % in": 1.0,
    "10 % in 1993": 1.0,
    "% in 1993 .": 1.0,
    "years later , the": 0.3333333333333333,
    "later , the error": 0.5,
    ", the error rate": 1.0,
    "the error rate crossed": 1.0,
    "error rate crossed below": 1.0,
    "rate crossed below 50": 1.0,
    "crossed below 50 %": 1.0,
    "below 50 % .": 1.0,
    "<s> dragon systems released": 1.0,
    "dragon systems released ``": 0.5,
    "systems released `` naturally": 1.0,
    "released `` naturally speaking": 1.0,
    "`` naturally speaking ''": 1.0,
    "naturally speaking '' in": 1.0,
    "speaking '' in 1997": 1.0,
    "'' in 1997 ,": 1.0,
    "in 1997 , which": 1.0,
    "1997 , which recognized": 1.0,
    ", which recognized normal": 1.0,
    "which recognized normal human": 1.0,
    "recognized normal human speech": 1.0,
    "normal human speech .": 1.0,
    "<s> progress mainly came": 1.0,
    "progress mainly came from": 1.0,
    "mainly came from improved": 1.0,
    "came from improved computer": 1.0,
    "from improved computer performance": 1.0,
    "improved computer performance and": 1.0,
    "computer performance and larger": 1.0,
    "performance and larger source": 1.0,
    "and larger source text": 1.0,
    "larger source text databases": 1.0,
    "source text databases .": 1.0,
    "brown corpus was the": 0.5,
    "corpus was the first": 1.0,
    "was the first major": 1.0,
    "the first major database": 0.5,
    "first major database available": 1.0,
    "major database available ,": 1.0,
    "database available , containing": 1.0,
    "available , containing several": 1.0,
    ", containing several million": 1.0,
    "containing several million words": 1.0,
    "several million words .": 1.0,
    "<s> in 2006 ,": 1.0,
    "in 2006 , google": 1.0,
    "2006 , google published": 1.0,
    ", google published a": 1.0,
    "google published a trillion-word": 1.0,
    "published a trillion-word corpus": 1.0,
    "a trillion-word corpus ,": 1.0,
    "trillion-word corpus , while": 1.0,
    "corpus , while carnegie": 1.0,
    ", while carnegie mellon": 1.0,
    "while carnegie mellon university": 1.0,
    "carnegie mellon university researchers": 0.5,
    "mellon university researchers found": 1.0,
    "university researchers found no": 1.0,
    "researchers found no significant": 1.0,
    "found no significant increase": 1.0,
    "no significant increase in": 1.0,
    "significant increase in recognition": 1.0,
    "increase in recognition accuracy": 1.0,
    "<s> algorithms both acoustic": 1.0,
    "algorithms both acoustic modeling": 1.0,
    "both acoustic modeling and": 1.0,
    "acoustic modeling and language": 1.0,
    "modeling and language modeling": 1.0,
    "and language modeling are": 1.0,
    "language modeling are important": 1.0,
    "modeling are important parts": 1.0,
    "are important parts of": 1.0,
    "important parts of modern": 1.0,
    "parts of modern statistically-based": 1.0,
    "of modern statistically-based speech": 1.0,
    "modern statistically-based speech recognition": 1.0,
    "statistically-based speech recognition algorithms": 1.0,
    "speech recognition algorithms .": 1.0,
    "<s> hidden markov models": 0.6666666666666666,
    "-lrb- hmms -rrb- are": 0.5,
    "hmms -rrb- are widely": 1.0,
    "-rrb- are widely used": 1.0,
    "are widely used in": 1.0,
    "widely used in many": 0.3333333333333333,
    "used in many systems": 0.3333333333333333,
    "in many systems .": 1.0,
    "<s> language modeling has": 1.0,
    "language modeling has many": 1.0,
    "modeling has many other": 1.0,
    "has many other applications": 1.0,
    "many other applications such": 1.0,
    "other applications such as": 1.0,
    "applications such as smart": 1.0,
    "such as smart keyboard": 1.0,
    "as smart keyboard and": 1.0,
    "smart keyboard and document": 1.0,
    "keyboard and document classification": 1.0,
    "and document classification .": 1.0,
    "hidden markov models main": 0.14285714285714285,
    "markov models main article": 1.0,
    "models main article :": 1.0,
    "main article : hidden": 0.08333333333333333,
    "article : hidden markov": 1.0,
    ": hidden markov model": 1.0,
    "hidden markov model modern": 0.16666666666666666,
    "markov model modern general-purpose": 1.0,
    "model modern general-purpose speech": 1.0,
    "modern general-purpose speech recognition": 1.0,
    "general-purpose speech recognition systems": 1.0,
    "speech recognition systems are": 0.1111111111111111,
    "recognition systems are based": 0.5,
    "are based on hidden": 0.2,
    "based on hidden markov": 1.0,
    "on hidden markov models": 1.0,
    "hidden markov models .": 0.14285714285714285,
    "<s> these are statistical": 0.5,
    "these are statistical models": 1.0,
    "are statistical models that": 1.0,
    "statistical models that output": 1.0,
    "models that output a": 1.0,
    "that output a sequence": 1.0,
    "output a sequence of": 1.0,
    "a sequence of symbols": 0.16666666666666666,
    "sequence of symbols or": 1.0,
    "of symbols or quantities": 1.0,
    "symbols or quantities .": 1.0,
    "<s> hmms are used": 1.0,
    "hmms are used in": 1.0,
    "are used in speech": 0.5,
    "used in speech recognition": 1.0,
    "in speech recognition because": 0.14285714285714285,
    "speech recognition because a": 1.0,
    "recognition because a speech": 1.0,
    "because a speech signal": 1.0,
    "a speech signal can": 1.0,
    "speech signal can be": 1.0,
    "signal can be viewed": 0.5,
    "be viewed as a": 0.25,
    "viewed as a piecewise": 1.0,
    "as a piecewise stationary": 1.0,
    "a piecewise stationary signal": 1.0,
    "piecewise stationary signal or": 1.0,
    "stationary signal or a": 1.0,
    "signal or a short-time": 1.0,
    "or a short-time stationary": 1.0,
    "a short-time stationary signal": 1.0,
    "short-time stationary signal .": 1.0,
    "<s> in a short": 0.5,
    "in a short time-scales": 1.0,
    "a short time-scales -lrb-": 1.0,
    "short time-scales -lrb- e.g.": 1.0,
    "time-scales -lrb- e.g. ,": 1.0,
    "-lrb- e.g. , 10": 0.05263157894736842,
    "e.g. , 10 milliseconds": 1.0,
    ", 10 milliseconds -rrb-": 1.0,
    "10 milliseconds -rrb- ,": 1.0,
    "milliseconds -rrb- , speech": 1.0,
    "-rrb- , speech can": 0.5,
    ", speech can be": 1.0,
    "speech can be approximated": 0.5,
    "can be approximated as": 1.0,
    "be approximated as a": 1.0,
    "approximated as a stationary": 1.0,
    "as a stationary process": 1.0,
    "a stationary process .": 1.0,
    "<s> speech can be": 1.0,
    "speech can be thought": 0.5,
    "can be thought of": 1.0,
    "be thought of as": 1.0,
    "thought of as a": 0.5,
    "of as a markov": 1.0,
    "as a markov model": 1.0,
    "a markov model for": 1.0,
    "markov model for many": 0.5,
    "model for many stochastic": 1.0,
    "for many stochastic purposes": 1.0,
    "many stochastic purposes .": 1.0,
    "<s> another reason why": 1.0,
    "another reason why hmms": 1.0,
    "reason why hmms are": 1.0,
    "why hmms are popular": 1.0,
    "hmms are popular is": 1.0,
    "are popular is because": 1.0,
    "popular is because they": 1.0,
    "is because they can": 1.0,
    "because they can be": 1.0,
    "they can be trained": 0.25,
    "can be trained automatically": 1.0,
    "be trained automatically and": 1.0,
    "trained automatically and are": 1.0,
    "automatically and are simple": 1.0,
    "and are simple and": 1.0,
    "are simple and computationally": 1.0,
    "simple and computationally feasible": 1.0,
    "and computationally feasible to": 1.0,
    "computationally feasible to use": 1.0,
    "feasible to use .": 1.0,
    "<s> in speech recognition": 1.0,
    "in speech recognition ,": 0.14285714285714285,
    "speech recognition , the": 0.2,
    "recognition , the hidden": 1.0,
    ", the hidden markov": 1.0,
    "the hidden markov model": 1.0,
    "hidden markov model would": 0.16666666666666666,
    "markov model would output": 1.0,
    "model would output a": 1.0,
    "would output a sequence": 1.0,
    "a sequence of n-dimensional": 0.16666666666666666,
    "sequence of n-dimensional real-valued": 1.0,
    "of n-dimensional real-valued vectors": 1.0,
    "n-dimensional real-valued vectors -lrb-": 1.0,
    "real-valued vectors -lrb- with": 1.0,
    "vectors -lrb- with n": 1.0,
    "-lrb- with n being": 1.0,
    "with n being a": 1.0,
    "n being a small": 1.0,
    "being a small integer": 1.0,
    "a small integer ,": 1.0,
    "small integer , such": 1.0,
    "integer , such as": 1.0,
    ", such as 10": 0.030303030303030304,
    "such as 10 -rrb-": 1.0,
    "as 10 -rrb- ,": 1.0,
    "10 -rrb- , outputting": 1.0,
    "-rrb- , outputting one": 1.0,
    ", outputting one of": 1.0,
    "outputting one of these": 1.0,
    "one of these every": 1.0,
    "of these every 10": 1.0,
    "these every 10 milliseconds": 1.0,
    "every 10 milliseconds .": 1.0,
    "<s> the vectors would": 1.0,
    "the vectors would consist": 1.0,
    "vectors would consist of": 1.0,
    "would consist of cepstral": 1.0,
    "consist of cepstral coefficients": 1.0,
    "of cepstral coefficients ,": 1.0,
    "cepstral coefficients , which": 1.0,
    "coefficients , which are": 1.0,
    ", which are obtained": 0.2,
    "which are obtained by": 1.0,
    "are obtained by taking": 0.5,
    "obtained by taking a": 1.0,
    "by taking a fourier": 1.0,
    "taking a fourier transform": 1.0,
    "a fourier transform of": 1.0,
    "fourier transform of a": 1.0,
    "transform of a short": 1.0,
    "of a short time": 1.0,
    "a short time window": 1.0,
    "short time window of": 1.0,
    "time window of speech": 1.0,
    "window of speech and": 1.0,
    "of speech and decorrelating": 1.0,
    "speech and decorrelating the": 1.0,
    "and decorrelating the spectrum": 1.0,
    "decorrelating the spectrum using": 1.0,
    "the spectrum using a": 1.0,
    "spectrum using a cosine": 1.0,
    "using a cosine transform": 1.0,
    "a cosine transform ,": 1.0,
    "cosine transform , then": 1.0,
    "transform , then taking": 1.0,
    ", then taking the": 1.0,
    "then taking the first": 1.0,
    "taking the first -lrb-": 1.0,
    "the first -lrb- most": 1.0,
    "first -lrb- most significant": 1.0,
    "-lrb- most significant -rrb-": 1.0,
    "most significant -rrb- coefficients": 1.0,
    "significant -rrb- coefficients .": 1.0,
    "<s> the hidden markov": 1.0,
    "hidden markov model will": 0.16666666666666666,
    "markov model will tend": 1.0,
    "model will tend to": 1.0,
    "will tend to have": 1.0,
    "tend to have in": 1.0,
    "to have in each": 1.0,
    "have in each state": 1.0,
    "in each state a": 1.0,
    "each state a statistical": 1.0,
    "state a statistical distribution": 1.0,
    "a statistical distribution that": 1.0,
    "statistical distribution that is": 1.0,
    "distribution that is a": 1.0,
    "that is a mixture": 1.0,
    "is a mixture of": 1.0,
    "a mixture of diagonal": 1.0,
    "mixture of diagonal covariance": 1.0,
    "of diagonal covariance gaussians": 1.0,
    "diagonal covariance gaussians ,": 1.0,
    "covariance gaussians , which": 1.0,
    "gaussians , which will": 1.0,
    ", which will give": 1.0,
    "which will give a": 1.0,
    "will give a likelihood": 1.0,
    "give a likelihood for": 1.0,
    "a likelihood for each": 1.0,
    "likelihood for each observed": 1.0,
    "for each observed vector": 1.0,
    "each observed vector .": 1.0,
    "<s> each word ,": 1.0,
    "each word , or": 1.0,
    "word , or -lrb-": 1.0,
    ", or -lrb- for": 1.0,
    "or -lrb- for more": 1.0,
    "-lrb- for more general": 1.0,
    "for more general speech": 0.5,
    "more general speech recognition": 1.0,
    "general speech recognition systems": 1.0,
    "speech recognition systems -rrb-": 0.1111111111111111,
    "recognition systems -rrb- ,": 1.0,
    "systems -rrb- , each": 1.0,
    "-rrb- , each phoneme": 1.0,
    ", each phoneme ,": 1.0,
    "each phoneme , will": 1.0,
    "phoneme , will have": 1.0,
    ", will have a": 1.0,
    "will have a different": 0.5,
    "have a different output": 1.0,
    "a different output distribution": 1.0,
    "different output distribution ;": 1.0,
    "output distribution ; a": 1.0,
    "distribution ; a hidden": 1.0,
    "; a hidden markov": 1.0,
    "a hidden markov model": 1.0,
    "hidden markov model for": 0.16666666666666666,
    "markov model for a": 0.5,
    "model for a sequence": 1.0,
    "for a sequence of": 1.0,
    "a sequence of words": 0.16666666666666666,
    "sequence of words or": 1.0,
    "of words or phonemes": 1.0,
    "words or phonemes is": 1.0,
    "or phonemes is made": 1.0,
    "phonemes is made by": 1.0,
    "is made by concatenating": 1.0,
    "made by concatenating the": 1.0,
    "by concatenating the individual": 1.0,
    "concatenating the individual trained": 1.0,
    "the individual trained hidden": 1.0,
    "individual trained hidden markov": 1.0,
    "trained hidden markov models": 1.0,
    "hidden markov models for": 0.14285714285714285,
    "markov models for the": 1.0,
    "models for the separate": 1.0,
    "for the separate words": 1.0,
    "the separate words and": 1.0,
    "separate words and phonemes": 1.0,
    "words and phonemes .": 1.0,
    "<s> described above are": 1.0,
    "described above are the": 1.0,
    "above are the core": 1.0,
    "are the core elements": 1.0,
    "the core elements of": 1.0,
    "core elements of the": 1.0,
    "elements of the most": 1.0,
    "of the most common": 0.16666666666666666,
    "the most common ,": 0.16666666666666666,
    "most common , hmm-based": 1.0,
    "common , hmm-based approach": 1.0,
    ", hmm-based approach to": 1.0,
    "hmm-based approach to speech": 1.0,
    "approach to speech recognition": 1.0,
    "to speech recognition .": 0.5,
    "<s> modern speech recognition": 1.0,
    "modern speech recognition systems": 1.0,
    "speech recognition systems use": 0.1111111111111111,
    "recognition systems use various": 1.0,
    "systems use various combinations": 1.0,
    "use various combinations of": 1.0,
    "various combinations of a": 1.0,
    "combinations of a number": 1.0,
    "a number of standard": 0.045454545454545456,
    "number of standard techniques": 1.0,
    "of standard techniques in": 1.0,
    "standard techniques in order": 1.0,
    "techniques in order to": 1.0,
    "in order to improve": 0.125,
    "order to improve results": 1.0,
    "to improve results over": 1.0,
    "improve results over the": 1.0,
    "results over the basic": 1.0,
    "over the basic approach": 1.0,
    "the basic approach described": 1.0,
    "basic approach described above": 1.0,
    "approach described above .": 1.0,
    "<s> a typical large-vocabulary": 0.5,
    "a typical large-vocabulary system": 1.0,
    "typical large-vocabulary system would": 1.0,
    "large-vocabulary system would need": 1.0,
    "system would need context": 1.0,
    "would need context dependency": 1.0,
    "need context dependency for": 1.0,
    "context dependency for the": 1.0,
    "dependency for the phonemes": 1.0,
    "for the phonemes -lrb-": 1.0,
    "the phonemes -lrb- so": 1.0,
    "phonemes -lrb- so phonemes": 1.0,
    "-lrb- so phonemes with": 1.0,
    "so phonemes with different": 1.0,
    "phonemes with different left": 1.0,
    "with different left and": 1.0,
    "different left and right": 1.0,
    "left and right context": 0.5,
    "and right context have": 1.0,
    "right context have different": 1.0,
    "context have different realizations": 1.0,
    "have different realizations as": 1.0,
    "different realizations as hmm": 1.0,
    "realizations as hmm states": 1.0,
    "as hmm states -rrb-": 1.0,
    "hmm states -rrb- ;": 1.0,
    "states -rrb- ; it": 1.0,
    "-rrb- ; it would": 1.0,
    "; it would use": 1.0,
    "it would use cepstral": 1.0,
    "would use cepstral normalization": 1.0,
    "use cepstral normalization to": 1.0,
    "cepstral normalization to normalize": 1.0,
    "normalization to normalize for": 1.0,
    "to normalize for different": 1.0,
    "normalize for different speaker": 1.0,
    "for different speaker and": 1.0,
    "different speaker and recording": 1.0,
    "speaker and recording conditions": 1.0,
    "and recording conditions ;": 1.0,
    "recording conditions ; for": 1.0,
    "conditions ; for further": 1.0,
    "; for further speaker": 1.0,
    "for further speaker normalization": 1.0,
    "further speaker normalization it": 1.0,
    "speaker normalization it might": 1.0,
    "normalization it might use": 1.0,
    "it might use vocal": 1.0,
    "might use vocal tract": 1.0,
    "use vocal tract length": 1.0,
    "vocal tract length normalization": 1.0,
    "tract length normalization -lrb-": 1.0,
    "length normalization -lrb- vtln": 1.0,
    "normalization -lrb- vtln -rrb-": 1.0,
    "-lrb- vtln -rrb- for": 1.0,
    "vtln -rrb- for male-female": 1.0,
    "-rrb- for male-female normalization": 1.0,
    "for male-female normalization and": 1.0,
    "male-female normalization and maximum": 1.0,
    "normalization and maximum likelihood": 1.0,
    "and maximum likelihood linear": 1.0,
    "maximum likelihood linear regression": 0.5,
    "likelihood linear regression -lrb-": 1.0,
    "linear regression -lrb- mllr": 1.0,
    "regression -lrb- mllr -rrb-": 1.0,
    "-lrb- mllr -rrb- for": 1.0,
    "mllr -rrb- for more": 1.0,
    "-rrb- for more general": 1.0,
    "for more general speaker": 0.5,
    "more general speaker adaptation": 1.0,
    "general speaker adaptation .": 1.0,
    "<s> the features would": 1.0,
    "the features would have": 1.0,
    "features would have so-called": 1.0,
    "would have so-called delta": 1.0,
    "have so-called delta and": 1.0,
    "so-called delta and delta-delta": 1.0,
    "delta and delta-delta coefficients": 1.0,
    "and delta-delta coefficients to": 0.5,
    "delta-delta coefficients to capture": 1.0,
    "coefficients to capture speech": 1.0,
    "to capture speech dynamics": 1.0,
    "capture speech dynamics and": 1.0,
    "speech dynamics and in": 1.0,
    "dynamics and in addition": 1.0,
    "and in addition might": 1.0,
    "in addition might use": 1.0,
    "addition might use heteroscedastic": 1.0,
    "might use heteroscedastic linear": 1.0,
    "use heteroscedastic linear discriminant": 1.0,
    "heteroscedastic linear discriminant analysis": 1.0,
    "linear discriminant analysis -lrb-": 0.5,
    "discriminant analysis -lrb- hlda": 1.0,
    "analysis -lrb- hlda -rrb-": 1.0,
    "-lrb- hlda -rrb- ;": 1.0,
    "hlda -rrb- ; or": 1.0,
    "-rrb- ; or might": 1.0,
    "; or might skip": 1.0,
    "or might skip the": 1.0,
    "might skip the delta": 1.0,
    "skip the delta and": 1.0,
    "the delta and delta-delta": 1.0,
    "and delta-delta coefficients and": 0.5,
    "delta-delta coefficients and use": 1.0,
    "coefficients and use splicing": 1.0,
    "and use splicing and": 1.0,
    "use splicing and an": 1.0,
    "splicing and an lda-based": 1.0,
    "and an lda-based projection": 1.0,
    "an lda-based projection followed": 1.0,
    "lda-based projection followed perhaps": 1.0,
    "projection followed perhaps by": 1.0,
    "followed perhaps by heteroscedastic": 1.0,
    "perhaps by heteroscedastic linear": 1.0,
    "by heteroscedastic linear discriminant": 1.0,
    "linear discriminant analysis or": 0.5,
    "discriminant analysis or a": 1.0,
    "analysis or a global": 1.0,
    "or a global semitied": 1.0,
    "a global semitied covariance": 1.0,
    "global semitied covariance transform": 1.0,
    "semitied covariance transform -lrb-": 1.0,
    "covariance transform -lrb- also": 1.0,
    "transform -lrb- also known": 1.0,
    "also known as maximum": 0.16666666666666666,
    "known as maximum likelihood": 1.0,
    "as maximum likelihood linear": 1.0,
    "maximum likelihood linear transform": 0.5,
    "likelihood linear transform ,": 1.0,
    "linear transform , or": 1.0,
    "transform , or mllt": 1.0,
    ", or mllt -rrb-": 1.0,
    "or mllt -rrb- .": 1.0,
    "<s> many systems use": 1.0,
    "many systems use so-called": 1.0,
    "systems use so-called discriminative": 1.0,
    "use so-called discriminative training": 1.0,
    "so-called discriminative training techniques": 1.0,
    "discriminative training techniques that": 1.0,
    "training techniques that dispense": 1.0,
    "techniques that dispense with": 1.0,
    "that dispense with a": 1.0,
    "dispense with a purely": 1.0,
    "with a purely statistical": 1.0,
    "a purely statistical approach": 1.0,
    "purely statistical approach to": 1.0,
    "statistical approach to hmm": 1.0,
    "approach to hmm parameter": 1.0,
    "to hmm parameter estimation": 1.0,
    "hmm parameter estimation and": 1.0,
    "parameter estimation and instead": 1.0,
    "estimation and instead optimize": 1.0,
    "and instead optimize some": 1.0,
    "instead optimize some classification-related": 1.0,
    "optimize some classification-related measure": 1.0,
    "some classification-related measure of": 1.0,
    "classification-related measure of the": 1.0,
    "measure of the training": 1.0,
    "of the training data": 1.0,
    "the training data .": 0.3333333333333333,
    "<s> examples are maximum": 0.5,
    "examples are maximum mutual": 1.0,
    "are maximum mutual information": 1.0,
    "maximum mutual information -lrb-": 1.0,
    "mutual information -lrb- mmi": 0.5,
    "information -lrb- mmi -rrb-": 1.0,
    "-lrb- mmi -rrb- ,": 1.0,
    "mmi -rrb- , minimum": 1.0,
    "-rrb- , minimum classification": 1.0,
    ", minimum classification error": 1.0,
    "minimum classification error -lrb-": 1.0,
    "classification error -lrb- mce": 1.0,
    "error -lrb- mce -rrb-": 1.0,
    "-lrb- mce -rrb- and": 1.0,
    "mce -rrb- and minimum": 1.0,
    "-rrb- and minimum phone": 1.0,
    "and minimum phone error": 1.0,
    "minimum phone error -lrb-": 1.0,
    "phone error -lrb- mpe": 1.0,
    "error -lrb- mpe -rrb-": 1.0,
    "-lrb- mpe -rrb- .": 1.0,
    "<s> decoding of the": 1.0,
    "decoding of the speech": 1.0,
    "the speech -lrb- the": 0.5,
    "speech -lrb- the term": 1.0,
    "-lrb- the term for": 1.0,
    "the term for what": 1.0,
    "term for what happens": 1.0,
    "for what happens when": 1.0,
    "what happens when the": 1.0,
    "happens when the system": 1.0,
    "when the system is": 1.0,
    "the system is presented": 0.25,
    "system is presented with": 1.0,
    "is presented with a": 1.0,
    "presented with a new": 1.0,
    "with a new utterance": 1.0,
    "a new utterance and": 1.0,
    "new utterance and must": 1.0,
    "utterance and must compute": 1.0,
    "and must compute the": 1.0,
    "must compute the most": 1.0,
    "compute the most likely": 1.0,
    "the most likely source": 0.5,
    "most likely source sentence": 1.0,
    "likely source sentence -rrb-": 1.0,
    "source sentence -rrb- would": 1.0,
    "sentence -rrb- would probably": 1.0,
    "-rrb- would probably use": 1.0,
    "would probably use the": 1.0,
    "probably use the viterbi": 1.0,
    "use the viterbi algorithm": 1.0,
    "the viterbi algorithm to": 0.25,
    "viterbi algorithm to find": 1.0,
    "algorithm to find the": 1.0,
    "to find the best": 0.3333333333333333,
    "find the best path": 1.0,
    "the best path ,": 1.0,
    "best path , and": 1.0,
    "path , and here": 1.0,
    ", and here there": 1.0,
    "and here there is": 1.0,
    "here there is a": 1.0,
    "there is a choice": 0.25,
    "is a choice between": 1.0,
    "a choice between dynamically": 1.0,
    "choice between dynamically creating": 1.0,
    "between dynamically creating a": 1.0,
    "dynamically creating a combination": 1.0,
    "creating a combination hidden": 1.0,
    "a combination hidden markov": 1.0,
    "combination hidden markov model": 1.0,
    "hidden markov model ,": 0.16666666666666666,
    "markov model , which": 1.0,
    "model , which includes": 1.0,
    ", which includes both": 0.5,
    "which includes both the": 1.0,
    "includes both the acoustic": 1.0,
    "both the acoustic and": 1.0,
    "the acoustic and language": 1.0,
    "acoustic and language model": 1.0,
    "and language model information": 1.0,
    "language model information ,": 1.0,
    "model information , and": 1.0,
    "information , and combining": 0.5,
    ", and combining it": 1.0,
    "and combining it statically": 1.0,
    "combining it statically beforehand": 1.0,
    "it statically beforehand -lrb-": 1.0,
    "statically beforehand -lrb- the": 1.0,
    "beforehand -lrb- the finite": 1.0,
    "-lrb- the finite state": 1.0,
    "the finite state transducer": 1.0,
    "finite state transducer ,": 0.5,
    "state transducer , or": 1.0,
    "transducer , or fst": 1.0,
    ", or fst ,": 1.0,
    "or fst , approach": 1.0,
    "fst , approach -rrb-": 1.0,
    ", approach -rrb- .": 1.0,
    "<s> a possible improvement": 1.0,
    "a possible improvement to": 1.0,
    "possible improvement to decoding": 1.0,
    "improvement to decoding is": 1.0,
    "to decoding is to": 1.0,
    "decoding is to keep": 1.0,
    "is to keep a": 1.0,
    "to keep a set": 1.0,
    "keep a set of": 1.0,
    "a set of good": 0.07142857142857142,
    "set of good candidates": 1.0,
    "of good candidates instead": 1.0,
    "good candidates instead of": 1.0,
    "candidates instead of just": 1.0,
    "instead of just keeping": 1.0,
    "of just keeping the": 1.0,
    "just keeping the best": 1.0,
    "keeping the best candidate": 1.0,
    "the best candidate ,": 1.0,
    "best candidate , and": 1.0,
    "candidate , and to": 1.0,
    ", and to use": 0.25,
    "and to use a": 0.5,
    "to use a better": 1.0,
    "use a better scoring": 1.0,
    "a better scoring function": 1.0,
    "better scoring function -lrb-": 1.0,
    "scoring function -lrb- rescoring": 1.0,
    "function -lrb- rescoring -rrb-": 1.0,
    "-lrb- rescoring -rrb- to": 1.0,
    "rescoring -rrb- to rate": 1.0,
    "-rrb- to rate these": 1.0,
    "to rate these good": 1.0,
    "rate these good candidates": 1.0,
    "these good candidates so": 1.0,
    "good candidates so that": 1.0,
    "candidates so that we": 1.0,
    "so that we may": 1.0,
    "that we may pick": 1.0,
    "we may pick the": 1.0,
    "may pick the best": 1.0,
    "pick the best one": 1.0,
    "the best one according": 1.0,
    "best one according to": 1.0,
    "one according to this": 1.0,
    "according to this refined": 1.0,
    "to this refined score": 1.0,
    "this refined score .": 1.0,
    "<s> the set of": 1.0,
    "the set of candidates": 0.3333333333333333,
    "set of candidates can": 1.0,
    "of candidates can be": 1.0,
    "candidates can be kept": 1.0,
    "can be kept either": 1.0,
    "be kept either as": 1.0,
    "kept either as a": 1.0,
    "either as a list": 1.0,
    "as a list -lrb-": 1.0,
    "a list -lrb- the": 1.0,
    "list -lrb- the n-best": 1.0,
    "-lrb- the n-best list": 1.0,
    "the n-best list approach": 1.0,
    "n-best list approach -rrb-": 1.0,
    "list approach -rrb- or": 1.0,
    "approach -rrb- or as": 1.0,
    "-rrb- or as a": 1.0,
    "or as a subset": 1.0,
    "as a subset of": 1.0,
    "a subset of the": 0.3333333333333333,
    "subset of the models": 1.0,
    "of the models -lrb-": 1.0,
    "the models -lrb- a": 1.0,
    "models -lrb- a lattice": 1.0,
    "-lrb- a lattice -rrb-": 1.0,
    "a lattice -rrb- .": 1.0,
    "<s> rescoring is usually": 1.0,
    "rescoring is usually done": 1.0,
    "is usually done by": 0.5,
    "usually done by trying": 1.0,
    "done by trying to": 1.0,
    "by trying to minimize": 1.0,
    "trying to minimize the": 1.0,
    "to minimize the bayes": 1.0,
    "minimize the bayes risk": 1.0,
    "the bayes risk -lrb-": 1.0,
    "bayes risk -lrb- or": 1.0,
    "risk -lrb- or an": 1.0,
    "-lrb- or an approximation": 1.0,
    "or an approximation thereof": 1.0,
    "an approximation thereof -rrb-": 1.0,
    "approximation thereof -rrb- :": 1.0,
    "thereof -rrb- : instead": 1.0,
    "-rrb- : instead of": 1.0,
    ": instead of taking": 1.0,
    "instead of taking the": 1.0,
    "of taking the source": 1.0,
    "taking the source sentence": 1.0,
    "the source sentence with": 1.0,
    "source sentence with maximal": 1.0,
    "sentence with maximal probability": 1.0,
    "with maximal probability ,": 1.0,
    "maximal probability , we": 1.0,
    "probability , we try": 1.0,
    ", we try to": 1.0,
    "we try to take": 1.0,
    "try to take the": 1.0,
    "to take the sentence": 1.0,
    "take the sentence that": 1.0,
    "the sentence that minimizes": 1.0,
    "sentence that minimizes the": 1.0,
    "that minimizes the expectancy": 0.5,
    "minimizes the expectancy of": 1.0,
    "the expectancy of a": 1.0,
    "expectancy of a given": 1.0,
    "of a given loss": 0.5,
    "a given loss function": 1.0,
    "given loss function with": 1.0,
    "loss function with regards": 1.0,
    "function with regards to": 1.0,
    "with regards to all": 1.0,
    "regards to all possible": 1.0,
    "to all possible transcriptions": 1.0,
    "all possible transcriptions -lrb-": 1.0,
    "possible transcriptions -lrb- i.e.": 1.0,
    "transcriptions -lrb- i.e. ,": 1.0,
    "-lrb- i.e. , we": 0.14285714285714285,
    "i.e. , we take": 1.0,
    ", we take the": 1.0,
    "we take the sentence": 1.0,
    "that minimizes the average": 0.5,
    "minimizes the average distance": 1.0,
    "the average distance to": 1.0,
    "average distance to other": 1.0,
    "distance to other possible": 1.0,
    "to other possible sentences": 1.0,
    "other possible sentences weighted": 1.0,
    "possible sentences weighted by": 1.0,
    "sentences weighted by their": 1.0,
    "weighted by their estimated": 1.0,
    "by their estimated probability": 1.0,
    "their estimated probability -rrb-": 1.0,
    "estimated probability -rrb- .": 1.0,
    "<s> the loss function": 1.0,
    "the loss function is": 1.0,
    "loss function is usually": 1.0,
    "function is usually the": 1.0,
    "is usually the levenshtein": 1.0,
    "usually the levenshtein distance": 1.0,
    "the levenshtein distance ,": 1.0,
    "levenshtein distance , though": 1.0,
    "distance , though it": 1.0,
    ", though it can": 1.0,
    "though it can be": 1.0,
    "it can be different": 0.5,
    "can be different distances": 1.0,
    "be different distances for": 1.0,
    "different distances for specific": 1.0,
    "distances for specific tasks": 1.0,
    "for specific tasks ;": 1.0,
    "specific tasks ; the": 1.0,
    "tasks ; the set": 1.0,
    "; the set of": 1.0,
    "the set of possible": 0.3333333333333333,
    "set of possible transcriptions": 1.0,
    "of possible transcriptions is": 1.0,
    "possible transcriptions is ,": 1.0,
    "transcriptions is , of": 1.0,
    "is , of course": 1.0,
    ", of course ,": 1.0,
    "of course , pruned": 1.0,
    "course , pruned to": 1.0,
    ", pruned to maintain": 1.0,
    "pruned to maintain tractability": 1.0,
    "to maintain tractability .": 1.0,
    "<s> efficient algorithms have": 1.0,
    "efficient algorithms have been": 1.0,
    "algorithms have been devised": 0.5,
    "have been devised to": 1.0,
    "been devised to rescore": 1.0,
    "devised to rescore lattices": 1.0,
    "to rescore lattices represented": 1.0,
    "rescore lattices represented as": 1.0,
    "lattices represented as weighted": 1.0,
    "represented as weighted finite": 1.0,
    "as weighted finite state": 1.0,
    "weighted finite state transducers": 1.0,
    "finite state transducers with": 1.0,
    "state transducers with edit": 1.0,
    "transducers with edit distances": 1.0,
    "with edit distances represented": 1.0,
    "edit distances represented themselves": 1.0,
    "distances represented themselves as": 1.0,
    "represented themselves as a": 1.0,
    "themselves as a finite": 1.0,
    "as a finite state": 1.0,
    "a finite state transducer": 1.0,
    "finite state transducer verifying": 0.5,
    "state transducer verifying certain": 1.0,
    "transducer verifying certain assumptions": 1.0,
    "verifying certain assumptions .": 1.0,
    "<s> dynamic time warping": 1.0,
    "dynamic time warping -lrb-": 0.25,
    "time warping -lrb- dtw": 1.0,
    "warping -lrb- dtw -rrb-": 1.0,
    "-lrb- dtw -rrb- -": 1.0,
    "dtw -rrb- - based": 1.0,
    "-rrb- - based speech": 1.0,
    "- based speech recognition": 1.0,
    "based speech recognition main": 1.0,
    "speech recognition main article": 1.0,
    "recognition main article :": 1.0,
    "main article : dynamic": 0.08333333333333333,
    "article : dynamic time": 1.0,
    ": dynamic time warping": 1.0,
    "dynamic time warping dynamic": 0.25,
    "time warping dynamic time": 1.0,
    "warping dynamic time warping": 1.0,
    "dynamic time warping is": 0.5,
    "time warping is an": 1.0,
    "warping is an approach": 0.5,
    "is an approach that": 1.0,
    "an approach that was": 1.0,
    "approach that was historically": 1.0,
    "that was historically used": 1.0,
    "was historically used for": 1.0,
    "historically used for speech": 1.0,
    "used for speech recognition": 1.0,
    "for speech recognition but": 0.2,
    "speech recognition but has": 1.0,
    "recognition but has now": 1.0,
    "but has now largely": 1.0,
    "has now largely been": 1.0,
    "now largely been displaced": 1.0,
    "largely been displaced by": 1.0,
    "been displaced by the": 1.0,
    "displaced by the more": 1.0,
    "by the more successful": 1.0,
    "the more successful hmm-based": 0.5,
    "more successful hmm-based approach": 1.0,
    "successful hmm-based approach .": 1.0,
    "warping is an algorithm": 0.5,
    "is an algorithm for": 0.5,
    "an algorithm for measuring": 1.0,
    "algorithm for measuring similarity": 1.0,
    "for measuring similarity between": 1.0,
    "measuring similarity between two": 1.0,
    "similarity between two sequences": 1.0,
    "between two sequences that": 1.0,
    "two sequences that may": 1.0,
    "sequences that may vary": 1.0,
    "that may vary in": 1.0,
    "may vary in time": 1.0,
    "vary in time or": 1.0,
    "in time or speed": 1.0,
    "time or speed .": 1.0,
    "for instance , similarities": 0.1111111111111111,
    "instance , similarities in": 1.0,
    ", similarities in walking": 1.0,
    "similarities in walking patterns": 1.0,
    "in walking patterns would": 1.0,
    "walking patterns would be": 1.0,
    "patterns would be detected": 1.0,
    "would be detected ,": 1.0,
    "be detected , even": 1.0,
    "detected , even if": 1.0,
    ", even if in": 0.5,
    "even if in one": 1.0,
    "if in one video": 1.0,
    "in one video the": 1.0,
    "one video the person": 1.0,
    "video the person was": 1.0,
    "the person was walking": 1.0,
    "person was walking slowly": 1.0,
    "was walking slowly and": 1.0,
    "walking slowly and if": 1.0,
    "slowly and if in": 1.0,
    "and if in another": 1.0,
    "if in another he": 1.0,
    "in another he or": 1.0,
    "another he or she": 1.0,
    "he or she were": 1.0,
    "or she were walking": 1.0,
    "she were walking more": 1.0,
    "were walking more quickly": 1.0,
    "walking more quickly ,": 1.0,
    "more quickly , or": 1.0,
    "quickly , or even": 1.0,
    ", or even if": 0.5,
    "or even if there": 1.0,
    "even if there were": 1.0,
    "if there were accelerations": 1.0,
    "there were accelerations and": 1.0,
    "were accelerations and decelerations": 1.0,
    "accelerations and decelerations during": 1.0,
    "and decelerations during the": 1.0,
    "decelerations during the course": 1.0,
    "during the course of": 1.0,
    "the course of one": 1.0,
    "course of one observation": 1.0,
    "of one observation .": 1.0,
    "<s> dtw has been": 1.0,
    "dtw has been applied": 1.0,
    "been applied to video": 0.2,
    "applied to video ,": 1.0,
    "to video , audio": 1.0,
    "video , audio ,": 1.0,
    ", audio , and": 0.5,
    "audio , and graphics": 1.0,
    ", and graphics --": 1.0,
    "and graphics -- indeed": 1.0,
    "graphics -- indeed ,": 1.0,
    "-- indeed , any": 1.0,
    "indeed , any data": 1.0,
    ", any data that": 1.0,
    "any data that can": 1.0,
    "data that can be": 1.0,
    "that can be turned": 0.2,
    "can be turned into": 1.0,
    "be turned into a": 1.0,
    "turned into a linear": 0.5,
    "into a linear representation": 1.0,
    "a linear representation can": 1.0,
    "linear representation can be": 1.0,
    "representation can be analyzed": 1.0,
    "can be analyzed with": 1.0,
    "be analyzed with dtw": 1.0,
    "analyzed with dtw .": 1.0,
    "<s> a well-known application": 1.0,
    "a well-known application has": 1.0,
    "well-known application has been": 1.0,
    "application has been automatic": 1.0,
    "has been automatic speech": 1.0,
    "been automatic speech recognition": 1.0,
    "automatic speech recognition ,": 0.3333333333333333,
    "speech recognition , to": 0.2,
    "recognition , to cope": 1.0,
    ", to cope with": 1.0,
    "to cope with different": 1.0,
    "cope with different speaking": 1.0,
    "with different speaking speeds": 1.0,
    "different speaking speeds .": 1.0,
    "in general , it": 0.16666666666666666,
    "general , it is": 1.0,
    "it is a method": 0.16666666666666666,
    "is a method that": 1.0,
    "a method that allows": 1.0,
    "method that allows a": 1.0,
    "that allows a computer": 1.0,
    "allows a computer to": 1.0,
    "a computer to find": 0.5,
    "computer to find an": 1.0,
    "to find an optimal": 1.0,
    "find an optimal match": 1.0,
    "an optimal match between": 1.0,
    "optimal match between two": 1.0,
    "match between two given": 1.0,
    "between two given sequences": 1.0,
    "two given sequences -lrb-": 1.0,
    "given sequences -lrb- e.g.": 1.0,
    "sequences -lrb- e.g. ,": 1.0,
    "-lrb- e.g. , time": 0.05263157894736842,
    "e.g. , time series": 1.0,
    ", time series -rrb-": 1.0,
    "time series -rrb- with": 1.0,
    "series -rrb- with certain": 1.0,
    "-rrb- with certain restrictions": 1.0,
    "with certain restrictions .": 1.0,
    "that is , the": 0.2,
    "is , the sequences": 1.0,
    ", the sequences are": 1.0,
    "the sequences are ``": 1.0,
    "sequences are `` warped": 1.0,
    "are `` warped ''": 1.0,
    "`` warped '' non-linearly": 1.0,
    "warped '' non-linearly to": 1.0,
    "'' non-linearly to match": 1.0,
    "non-linearly to match each": 1.0,
    "to match each other": 1.0,
    "match each other .": 1.0,
    "<s> this sequence alignment": 1.0,
    "this sequence alignment method": 1.0,
    "sequence alignment method is": 1.0,
    "alignment method is often": 1.0,
    "method is often used": 1.0,
    "is often used in": 1.0,
    "often used in the": 1.0,
    "used in the context": 0.16666666666666666,
    "the context of hidden": 0.2,
    "context of hidden markov": 1.0,
    "hidden markov models ...": 0.14285714285714285,
    "markov models ... .": 1.0,
    "<s> neural networks main": 1.0,
    "neural networks main article": 1.0,
    "networks main article :": 1.0,
    "main article : neural": 0.08333333333333333,
    "article : neural networks": 1.0,
    ": neural networks neural": 1.0,
    "neural networks neural networks": 1.0,
    "networks neural networks emerged": 1.0,
    "neural networks emerged as": 1.0,
    "networks emerged as an": 1.0,
    "emerged as an attractive": 1.0,
    "as an attractive acoustic": 1.0,
    "an attractive acoustic modeling": 1.0,
    "attractive acoustic modeling approach": 1.0,
    "acoustic modeling approach in": 1.0,
    "modeling approach in asr": 1.0,
    "approach in asr in": 1.0,
    "in asr in the": 1.0,
    "asr in the late": 0.3333333333333333,
    "the late 1980s .": 0.25,
    "<s> since then ,": 1.0,
    "since then , neural": 1.0,
    "then , neural networks": 1.0,
    ", neural networks have": 0.25,
    "neural networks have been": 1.0,
    "networks have been used": 1.0,
    "have been used in": 0.3333333333333333,
    "been used in many": 1.0,
    "used in many aspects": 0.3333333333333333,
    "in many aspects of": 1.0,
    "many aspects of speech": 1.0,
    "aspects of speech recognition": 1.0,
    "of speech recognition such": 0.07142857142857142,
    "speech recognition such as": 1.0,
    "recognition such as phoneme": 1.0,
    "such as phoneme classification": 1.0,
    "as phoneme classification ,": 1.0,
    "phoneme classification , isolated": 1.0,
    "classification , isolated word": 1.0,
    ", isolated word recognition": 1.0,
    "isolated word recognition ,": 1.0,
    "word recognition , and": 1.0,
    "recognition , and speaker": 0.3333333333333333,
    ", and speaker adaptation": 1.0,
    "and speaker adaptation .": 1.0,
    "<s> in contrast to": 0.2,
    "in contrast to hmms": 1.0,
    "contrast to hmms ,": 1.0,
    "to hmms , neural": 1.0,
    "hmms , neural networks": 1.0,
    ", neural networks make": 0.25,
    "neural networks make no": 1.0,
    "networks make no assumptions": 1.0,
    "make no assumptions about": 1.0,
    "no assumptions about feature": 1.0,
    "assumptions about feature statistical": 1.0,
    "about feature statistical properties": 1.0,
    "feature statistical properties and": 1.0,
    "statistical properties and have": 1.0,
    "properties and have several": 1.0,
    "and have several qualities": 1.0,
    "have several qualities making": 1.0,
    "several qualities making them": 1.0,
    "qualities making them attractive": 1.0,
    "making them attractive recognition": 1.0,
    "them attractive recognition models": 1.0,
    "attractive recognition models for": 1.0,
    "recognition models for speech": 1.0,
    "models for speech recognition": 1.0,
    "for speech recognition .": 0.4,
    "<s> when used to": 1.0,
    "when used to estimate": 1.0,
    "used to estimate the": 1.0,
    "to estimate the probabilities": 0.5,
    "estimate the probabilities of": 1.0,
    "the probabilities of a": 0.3333333333333333,
    "probabilities of a speech": 1.0,
    "of a speech feature": 1.0,
    "a speech feature segment": 1.0,
    "speech feature segment ,": 1.0,
    "feature segment , neural": 1.0,
    "segment , neural networks": 1.0,
    ", neural networks allow": 0.25,
    "neural networks allow discriminative": 1.0,
    "networks allow discriminative training": 1.0,
    "allow discriminative training in": 1.0,
    "discriminative training in a": 1.0,
    "training in a natural": 1.0,
    "in a natural and": 1.0,
    "a natural and efficient": 1.0,
    "natural and efficient manner": 1.0,
    "and efficient manner .": 1.0,
    "<s> few assumptions on": 1.0,
    "few assumptions on the": 1.0,
    "assumptions on the statistics": 1.0,
    "on the statistics of": 1.0,
    "the statistics of input": 1.0,
    "statistics of input features": 1.0,
    "of input features are": 1.0,
    "input features are made": 1.0,
    "features are made with": 1.0,
    "are made with neural": 1.0,
    "made with neural networks": 1.0,
    "with neural networks .": 1.0,
    "however , in spite": 0.25,
    ", in spite of": 1.0,
    "in spite of their": 1.0,
    "spite of their effectiveness": 1.0,
    "of their effectiveness in": 1.0,
    "their effectiveness in classifying": 1.0,
    "effectiveness in classifying short-time": 1.0,
    "in classifying short-time units": 1.0,
    "classifying short-time units such": 1.0,
    "short-time units such as": 1.0,
    "units such as individual": 1.0,
    "such as individual phones": 1.0,
    "as individual phones and": 1.0,
    "individual phones and isolated": 1.0,
    "phones and isolated words": 1.0,
    "and isolated words ,": 1.0,
    "isolated words , neural": 1.0,
    "words , neural networks": 1.0,
    ", neural networks are": 0.25,
    "neural networks are rarely": 1.0,
    "networks are rarely successful": 1.0,
    "are rarely successful for": 1.0,
    "rarely successful for continuous": 1.0,
    "successful for continuous recognition": 1.0,
    "for continuous recognition tasks": 1.0,
    "continuous recognition tasks ,": 1.0,
    "recognition tasks , largely": 1.0,
    "tasks , largely because": 1.0,
    ", largely because of": 1.0,
    "largely because of their": 1.0,
    "because of their lack": 1.0,
    "of their lack of": 1.0,
    "their lack of ability": 1.0,
    "lack of ability to": 1.0,
    "of ability to model": 1.0,
    "ability to model temporal": 1.0,
    "to model temporal dependencies": 1.0,
    "model temporal dependencies .": 1.0,
    "<s> thus , one": 0.09090909090909091,
    "thus , one alternative": 1.0,
    ", one alternative approach": 1.0,
    "one alternative approach is": 1.0,
    "alternative approach is to": 1.0,
    "approach is to use": 0.5,
    "is to use neural": 1.0,
    "to use neural networks": 1.0,
    "use neural networks as": 1.0,
    "neural networks as a": 1.0,
    "networks as a pre-processing": 1.0,
    "as a pre-processing e.g.": 1.0,
    "a pre-processing e.g. feature": 1.0,
    "pre-processing e.g. feature transformation": 1.0,
    "e.g. feature transformation ,": 1.0,
    "feature transformation , dimensionality": 1.0,
    "transformation , dimensionality reduction": 1.0,
    ", dimensionality reduction ,": 1.0,
    "dimensionality reduction , for": 1.0,
    "reduction , for the": 1.0,
    ", for the hmm": 0.5,
    "for the hmm based": 1.0,
    "the hmm based recognition": 1.0,
    "hmm based recognition .": 1.0,
    "<s> further information popular": 1.0,
    "further information popular speech": 1.0,
    "information popular speech recognition": 1.0,
    "popular speech recognition conferences": 1.0,
    "speech recognition conferences held": 1.0,
    "recognition conferences held each": 1.0,
    "conferences held each year": 1.0,
    "held each year or": 1.0,
    "each year or two": 1.0,
    "year or two include": 1.0,
    "or two include speechtek": 1.0,
    "two include speechtek and": 1.0,
    "include speechtek and speechtek": 1.0,
    "speechtek and speechtek europe": 1.0,
    "and speechtek europe ,": 1.0,
    "speechtek europe , icassp": 1.0,
    "europe , icassp ,": 1.0,
    ", icassp , eurospeech\\/icslp": 1.0,
    "icassp , eurospeech\\/icslp -lrb-": 1.0,
    ", eurospeech\\/icslp -lrb- now": 1.0,
    "eurospeech\\/icslp -lrb- now named": 1.0,
    "-lrb- now named interspeech": 0.5,
    "now named interspeech -rrb-": 1.0,
    "named interspeech -rrb- and": 1.0,
    "interspeech -rrb- and the": 1.0,
    "-rrb- and the ieee": 0.2,
    "and the ieee asru": 1.0,
    "the ieee asru .": 1.0,
    "<s> conferences in the": 1.0,
    "conferences in the field": 1.0,
    "language processing , such": 0.16666666666666666,
    "processing , such as": 1.0,
    ", such as acl": 0.030303030303030304,
    "such as acl ,": 1.0,
    "as acl , naacl": 1.0,
    "acl , naacl ,": 1.0,
    ", naacl , emnlp": 1.0,
    "naacl , emnlp ,": 1.0,
    ", emnlp , and": 1.0,
    "emnlp , and hlt": 1.0,
    ", and hlt ,": 1.0,
    "and hlt , are": 1.0,
    "hlt , are beginning": 1.0,
    ", are beginning to": 1.0,
    "are beginning to include": 1.0,
    "beginning to include papers": 1.0,
    "to include papers on": 1.0,
    "include papers on speech": 1.0,
    "papers on speech processing": 1.0,
    "on speech processing .": 1.0,
    "<s> important journals include": 1.0,
    "important journals include the": 1.0,
    "journals include the ieee": 1.0,
    "include the ieee transactions": 1.0,
    "the ieee transactions on": 1.0,
    "ieee transactions on speech": 0.5,
    "transactions on speech and": 1.0,
    "on speech and audio": 1.0,
    "speech and audio processing": 1.0,
    "and audio processing -lrb-": 1.0,
    "audio processing -lrb- now": 1.0,
    "processing -lrb- now named": 1.0,
    "-lrb- now named ieee": 0.5,
    "now named ieee transactions": 1.0,
    "named ieee transactions on": 1.0,
    "ieee transactions on audio": 0.5,
    "transactions on audio ,": 1.0,
    "on audio , speech": 1.0,
    "audio , speech and": 1.0,
    ", speech and language": 1.0,
    "speech and language processing": 0.6666666666666666,
    "and language processing -rrb-": 0.5,
    "language processing -rrb- ,": 1.0,
    "processing -rrb- , computer": 1.0,
    "-rrb- , computer speech": 1.0,
    ", computer speech and": 1.0,
    "computer speech and language": 1.0,
    "speech and language ,": 0.3333333333333333,
    "and language , and": 1.0,
    "language , and speech": 1.0,
    ", and speech communication": 1.0,
    "and speech communication .": 1.0,
    "<s> books like ``": 1.0,
    "books like `` fundamentals": 1.0,
    "like `` fundamentals of": 1.0,
    "`` fundamentals of speech": 0.5,
    "fundamentals of speech recognition": 1.0,
    "of speech recognition ''": 0.07142857142857142,
    "speech recognition '' by": 0.5,
    "recognition '' by lawrence": 0.3333333333333333,
    "'' by lawrence rabiner": 1.0,
    "by lawrence rabiner can": 1.0,
    "lawrence rabiner can be": 1.0,
    "rabiner can be useful": 1.0,
    "can be useful to": 0.5,
    "be useful to acquire": 0.5,
    "useful to acquire basic": 1.0,
    "to acquire basic knowledge": 1.0,
    "acquire basic knowledge but": 1.0,
    "basic knowledge but may": 1.0,
    "knowledge but may not": 1.0,
    "but may not be": 1.0,
    "may not be fully": 0.5,
    "not be fully up": 1.0,
    "be fully up to": 1.0,
    "fully up to date": 1.0,
    "up to date -lrb-": 0.5,
    "to date -lrb- 1993": 1.0,
    "date -lrb- 1993 -rrb-": 1.0,
    "-lrb- 1993 -rrb- .": 1.0,
    "<s> a very recent": 1.0,
    "a very recent book": 1.0,
    "very recent book -lrb-": 1.0,
    "recent book -lrb- dec.": 1.0,
    "book -lrb- dec. 2011": 1.0,
    "-lrb- dec. 2011 -rrb-": 1.0,
    "dec. 2011 -rrb- ,": 1.0,
    "2011 -rrb- , ``": 1.0,
    "-rrb- , `` fundamentals": 1.0,
    ", `` fundamentals of": 1.0,
    "`` fundamentals of speaker": 0.5,
    "fundamentals of speaker recognition": 1.0,
    "of speaker recognition ''": 1.0,
    "speaker recognition '' by": 1.0,
    "recognition '' by homayoon": 0.3333333333333333,
    "'' by homayoon beigi": 1.0,
    "by homayoon beigi covers": 1.0,
    "homayoon beigi covers the": 1.0,
    "beigi covers the more": 1.0,
    "covers the more recent": 1.0,
    "the more recent developments": 1.0,
    "more recent developments in": 1.0,
    "recent developments in some": 1.0,
    "developments in some detail": 1.0,
    "in some detail .": 1.0,
    "<s> although the title": 0.3333333333333333,
    "although the title concentrates": 1.0,
    "the title concentrates on": 1.0,
    "title concentrates on speaker": 1.0,
    "concentrates on speaker recognition": 1.0,
    "on speaker recognition ,": 1.0,
    "speaker recognition , but": 1.0,
    "recognition , but a": 1.0,
    ", but a large": 1.0,
    "but a large portion": 1.0,
    "a large portion of": 1.0,
    "large portion of the": 1.0,
    "portion of the book": 0.5,
    "of the book applies": 1.0,
    "the book applies directly": 1.0,
    "book applies directly to": 1.0,
    "applies directly to speech": 1.0,
    "directly to speech recognition": 1.0,
    "to speech recognition ,": 0.5,
    "speech recognition , with": 0.2,
    "recognition , with a": 1.0,
    ", with a lot": 1.0,
    "with a lot of": 1.0,
    "a lot of valuable": 1.0,
    "lot of valuable detailed": 1.0,
    "of valuable detailed background": 1.0,
    "valuable detailed background material": 1.0,
    "detailed background material .": 1.0,
    "<s> another good source": 1.0,
    "another good source can": 1.0,
    "good source can be": 1.0,
    "source can be ``": 1.0,
    "can be `` statistical": 1.0,
    "be `` statistical methods": 1.0,
    "`` statistical methods for": 1.0,
    "statistical methods for speech": 1.0,
    "methods for speech recognition": 1.0,
    "for speech recognition ''": 0.2,
    "recognition '' by frederick": 0.3333333333333333,
    "'' by frederick jelinek": 1.0,
    "by frederick jelinek and": 1.0,
    "frederick jelinek and ``": 1.0,
    "jelinek and `` spoken": 1.0,
    "and `` spoken language": 1.0,
    "`` spoken language processing": 1.0,
    "spoken language processing -lrb-": 1.0,
    "language processing -lrb- 2001": 0.2,
    "processing -lrb- 2001 -rrb-": 1.0,
    "-lrb- 2001 -rrb- ''": 1.0,
    "2001 -rrb- '' by": 1.0,
    "-rrb- '' by xuedong": 0.5,
    "'' by xuedong huang": 1.0,
    "by xuedong huang etc.": 1.0,
    "xuedong huang etc. .": 1.0,
    "<s> more up to": 1.0,
    "more up to date": 1.0,
    "up to date is": 0.5,
    "to date is ``": 1.0,
    "date is `` computer": 1.0,
    "is `` computer speech": 1.0,
    "`` computer speech ''": 0.5,
    "computer speech '' ,": 1.0,
    "speech '' , by": 1.0,
    "'' , by manfred": 1.0,
    ", by manfred r.": 1.0,
    "by manfred r. schroeder": 1.0,
    "manfred r. schroeder ,": 1.0,
    "r. schroeder , second": 1.0,
    "schroeder , second edition": 1.0,
    ", second edition published": 1.0,
    "second edition published in": 1.0,
    "edition published in 2004": 1.0,
    "published in 2004 .": 1.0,
    "<s> the recently updated": 1.0,
    "the recently updated textbook": 1.0,
    "recently updated textbook of": 1.0,
    "updated textbook of ``": 1.0,
    "textbook of `` speech": 1.0,
    "of `` speech and": 1.0,
    "`` speech and language": 1.0,
    "and language processing -lrb-": 0.5,
    "language processing -lrb- 2008": 0.2,
    "processing -lrb- 2008 -rrb-": 1.0,
    "-lrb- 2008 -rrb- ''": 1.0,
    "2008 -rrb- '' by": 1.0,
    "-rrb- '' by jurafsky": 0.5,
    "'' by jurafsky and": 1.0,
    "by jurafsky and martin": 1.0,
    "jurafsky and martin presents": 1.0,
    "and martin presents the": 1.0,
    "martin presents the basics": 1.0,
    "presents the basics and": 1.0,
    "the basics and the": 1.0,
    "basics and the state": 1.0,
    "and the state of": 1.0,
    "of the art for": 0.5,
    "the art for asr": 1.0,
    "art for asr .": 1.0,
    "<s> a good insight": 1.0,
    "a good insight into": 1.0,
    "good insight into the": 1.0,
    "insight into the techniques": 1.0,
    "into the techniques used": 1.0,
    "the techniques used in": 1.0,
    "techniques used in the": 1.0,
    "used in the best": 0.16666666666666666,
    "in the best modern": 1.0,
    "the best modern systems": 1.0,
    "best modern systems can": 1.0,
    "modern systems can be": 1.0,
    "systems can be gained": 0.5,
    "can be gained by": 1.0,
    "be gained by paying": 1.0,
    "gained by paying attention": 1.0,
    "by paying attention to": 1.0,
    "paying attention to government": 1.0,
    "attention to government sponsored": 1.0,
    "to government sponsored evaluations": 1.0,
    "government sponsored evaluations such": 1.0,
    "sponsored evaluations such as": 1.0,
    "evaluations such as those": 1.0,
    "such as those organised": 0.2,
    "as those organised by": 1.0,
    "those organised by darpa": 1.0,
    "organised by darpa -lrb-": 1.0,
    "by darpa -lrb- the": 1.0,
    "darpa -lrb- the largest": 1.0,
    "-lrb- the largest speech": 1.0,
    "the largest speech recognition-related": 1.0,
    "largest speech recognition-related project": 1.0,
    "speech recognition-related project ongoing": 1.0,
    "recognition-related project ongoing as": 1.0,
    "project ongoing as of": 1.0,
    "ongoing as of 2007": 1.0,
    "as of 2007 is": 1.0,
    "of 2007 is the": 1.0,
    "2007 is the gale": 1.0,
    "is the gale project": 1.0,
    "the gale project ,": 1.0,
    "gale project , which": 1.0,
    "project , which involves": 0.3333333333333333,
    ", which involves both": 1.0,
    "which involves both speech": 1.0,
    "involves both speech recognition": 1.0,
    "both speech recognition and": 1.0,
    "speech recognition and translation": 0.16666666666666666,
    "recognition and translation components": 1.0,
    "and translation components -rrb-": 1.0,
    "translation components -rrb- .": 1.0,
    "<s> in terms of": 1.0,
    "in terms of freely": 0.14285714285714285,
    "terms of freely available": 1.0,
    "of freely available resources": 1.0,
    "freely available resources ,": 1.0,
    "available resources , carnegie": 1.0,
    "resources , carnegie mellon": 1.0,
    ", carnegie mellon university": 1.0,
    "carnegie mellon university 's": 0.5,
    "mellon university 's sphinx": 1.0,
    "university 's sphinx toolkit": 1.0,
    "'s sphinx toolkit is": 1.0,
    "sphinx toolkit is one": 1.0,
    "toolkit is one place": 1.0,
    "is one place to": 1.0,
    "one place to start": 1.0,
    "place to start to": 1.0,
    "to start to both": 1.0,
    "start to both learn": 1.0,
    "to both learn about": 1.0,
    "both learn about speech": 1.0,
    "learn about speech recognition": 1.0,
    "about speech recognition and": 0.5,
    "speech recognition and to": 0.16666666666666666,
    "recognition and to start": 1.0,
    "and to start experimenting": 1.0,
    "to start experimenting .": 1.0,
    "<s> another resource -lrb-": 1.0,
    "another resource -lrb- free": 1.0,
    "resource -lrb- free as": 1.0,
    "-lrb- free as in": 1.0,
    "free as in free": 1.0,
    "as in free beer": 0.5,
    "in free beer ,": 1.0,
    "free beer , not": 1.0,
    "beer , not as": 1.0,
    ", not as in": 1.0,
    "not as in free": 1.0,
    "as in free speech": 0.5,
    "in free speech -rrb-": 1.0,
    "free speech -rrb- is": 1.0,
    "speech -rrb- is the": 1.0,
    "-rrb- is the htk": 0.3333333333333333,
    "is the htk book": 1.0,
    "the htk book -lrb-": 1.0,
    "htk book -lrb- and": 1.0,
    "book -lrb- and the": 1.0,
    "-lrb- and the accompanying": 0.5,
    "and the accompanying htk": 1.0,
    "the accompanying htk toolkit": 1.0,
    "accompanying htk toolkit -rrb-": 1.0,
    "htk toolkit -rrb- .": 1.0,
    "<s> the at&t libraries": 1.0,
    "the at&t libraries grm": 1.0,
    "at&t libraries grm library": 1.0,
    "libraries grm library ,": 1.0,
    "grm library , and": 1.0,
    "library , and dcd": 1.0,
    ", and dcd library": 1.0,
    "and dcd library are": 1.0,
    "dcd library are also": 1.0,
    "library are also general": 1.0,
    "are also general software": 1.0,
    "also general software libraries": 1.0,
    "general software libraries for": 1.0,
    "software libraries for large-vocabulary": 1.0,
    "libraries for large-vocabulary speech": 1.0,
    "for large-vocabulary speech recognition": 1.0,
    "large-vocabulary speech recognition .": 1.0,
    "<s> for more software": 0.5,
    "for more software resources": 1.0,
    "more software resources ,": 1.0,
    "software resources , see": 1.0,
    "resources , see list": 1.0,
    ", see list of": 1.0,
    "see list of speech": 1.0,
    "list of speech recognition": 1.0,
    "of speech recognition software": 0.07142857142857142,
    "speech recognition software .": 0.5,
    "<s> a useful review": 1.0,
    "a useful review of": 1.0,
    "useful review of the": 1.0,
    "review of the area": 1.0,
    "of the area of": 1.0,
    "the area of robustness": 1.0,
    "area of robustness in": 1.0,
    "of robustness in asr": 1.0,
    "robustness in asr is": 1.0,
    "in asr is provided": 1.0,
    "asr is provided by": 1.0,
    "is provided by junqua": 1.0,
    "provided by junqua and": 1.0,
    "by junqua and haton": 1.0,
    "junqua and haton -lrb-": 1.0,
    "and haton -lrb- 1995": 1.0,
    "haton -lrb- 1995 -rrb-": 1.0,
    "-lrb- 1995 -rrb- .": 1.0,
    "<s> people with disabilities": 1.0,
    "people with disabilities people": 0.5,
    "with disabilities people with": 1.0,
    "disabilities people with disabilities": 1.0,
    "people with disabilities can": 0.5,
    "with disabilities can benefit": 1.0,
    "disabilities can benefit from": 1.0,
    "can benefit from speech": 0.5,
    "benefit from speech recognition": 1.0,
    "from speech recognition programs": 1.0,
    "speech recognition programs .": 1.0,
    "<s> for individuals that": 1.0,
    "for individuals that are": 1.0,
    "individuals that are deaf": 1.0,
    "that are deaf or": 1.0,
    "are deaf or hard": 1.0,
    "deaf or hard of": 1.0,
    "or hard of hearing": 1.0,
    "hard of hearing ,": 1.0,
    "of hearing , speech": 1.0,
    "hearing , speech recognition": 1.0,
    ", speech recognition software": 0.2,
    "speech recognition software is": 0.5,
    "recognition software is used": 1.0,
    "software is used to": 1.0,
    "is used to automatically": 0.14285714285714285,
    "used to automatically generate": 1.0,
    "to automatically generate a": 1.0,
    "automatically generate a closed-captioning": 1.0,
    "generate a closed-captioning of": 1.0,
    "a closed-captioning of conversations": 1.0,
    "closed-captioning of conversations such": 1.0,
    "of conversations such as": 1.0,
    "conversations such as discussions": 1.0,
    "such as discussions in": 1.0,
    "as discussions in conference": 1.0,
    "discussions in conference rooms": 1.0,
    "in conference rooms ,": 1.0,
    "conference rooms , classroom": 1.0,
    "rooms , classroom lectures": 1.0,
    ", classroom lectures ,": 1.0,
    "classroom lectures , and\\/or": 1.0,
    "lectures , and\\/or religious": 1.0,
    ", and\\/or religious services": 1.0,
    "and\\/or religious services .": 1.0,
    "speech recognition is also": 0.125,
    "recognition is also very": 0.5,
    "is also very useful": 0.5,
    "also very useful for": 1.0,
    "very useful for people": 1.0,
    "useful for people who": 1.0,
    "for people who have": 1.0,
    "people who have difficulty": 1.0,
    "who have difficulty using": 1.0,
    "have difficulty using their": 1.0,
    "difficulty using their hands": 1.0,
    "using their hands ,": 1.0,
    "their hands , ranging": 1.0,
    "hands , ranging from": 1.0,
    ", ranging from mild": 0.5,
    "ranging from mild repetitive": 1.0,
    "from mild repetitive stress": 1.0,
    "mild repetitive stress injuries": 1.0,
    "repetitive stress injuries to": 1.0,
    "stress injuries to involved": 1.0,
    "injuries to involved disabilities": 1.0,
    "to involved disabilities that": 1.0,
    "involved disabilities that preclude": 1.0,
    "disabilities that preclude using": 1.0,
    "that preclude using conventional": 1.0,
    "preclude using conventional computer": 1.0,
    "using conventional computer input": 1.0,
    "conventional computer input devices": 1.0,
    "computer input devices .": 1.0,
    "in fact , people": 0.25,
    "fact , people who": 1.0,
    ", people who used": 1.0,
    "people who used the": 1.0,
    "who used the keyboard": 1.0,
    "used the keyboard a": 1.0,
    "the keyboard a lot": 1.0,
    "keyboard a lot and": 1.0,
    "a lot and developed": 1.0,
    "lot and developed rsi": 1.0,
    "and developed rsi became": 1.0,
    "developed rsi became an": 1.0,
    "rsi became an urgent": 1.0,
    "became an urgent early": 1.0,
    "an urgent early market": 1.0,
    "urgent early market for": 1.0,
    "early market for speech": 1.0,
    "market for speech recognition": 1.0,
    "speech recognition is used": 0.125,
    "recognition is used in": 1.0,
    "is used in deaf": 0.5,
    "used in deaf telephony": 1.0,
    "in deaf telephony ,": 1.0,
    "deaf telephony , such": 1.0,
    "telephony , such as": 1.0,
    ", such as voicemail": 0.030303030303030304,
    "such as voicemail to": 1.0,
    "as voicemail to text": 1.0,
    "voicemail to text ,": 1.0,
    "to text , relay": 1.0,
    "text , relay services": 1.0,
    ", relay services ,": 1.0,
    "relay services , and": 1.0,
    "services , and captioned": 1.0,
    ", and captioned telephone": 1.0,
    "and captioned telephone .": 1.0,
    "<s> individuals with learning": 1.0,
    "individuals with learning disabilities": 1.0,
    "with learning disabilities who": 1.0,
    "learning disabilities who have": 1.0,
    "disabilities who have problems": 1.0,
    "who have problems with": 1.0,
    "have problems with thought-to-paper": 1.0,
    "problems with thought-to-paper communication": 1.0,
    "with thought-to-paper communication -lrb-": 1.0,
    "thought-to-paper communication -lrb- essentially": 1.0,
    "communication -lrb- essentially they": 1.0,
    "-lrb- essentially they think": 1.0,
    "essentially they think of": 1.0,
    "they think of an": 1.0,
    "think of an idea": 1.0,
    "of an idea but": 1.0,
    "an idea but it": 1.0,
    "idea but it is": 1.0,
    "but it is processed": 1.0,
    "it is processed incorrectly": 1.0,
    "is processed incorrectly causing": 1.0,
    "processed incorrectly causing it": 1.0,
    "incorrectly causing it to": 1.0,
    "causing it to end": 1.0,
    "it to end up": 1.0,
    "to end up differently": 1.0,
    "end up differently on": 1.0,
    "up differently on paper": 1.0,
    "differently on paper -rrb-": 1.0,
    "on paper -rrb- can": 1.0,
    "paper -rrb- can benefit": 1.0,
    "-rrb- can benefit from": 1.0,
    "can benefit from the": 0.5,
    "benefit from the software": 1.0,
    "from the software -lrb-": 1.0,
    "the software -lrb- citation": 1.0,
    "software -lrb- citation needed": 1.0,
    "<s> -lrb- icon -rrb-": 1.0,
    "-lrb- icon -rrb- this": 1.0,
    "icon -rrb- this section": 1.0,
    "-rrb- this section requires": 1.0,
    "this section requires expansion": 1.0,
    "section requires expansion .": 1.0,
    "<s> current research and": 1.0,
    "current research and funding": 0.5,
    "research and funding measuring": 1.0,
    "and funding measuring progress": 1.0,
    "funding measuring progress in": 1.0,
    "measuring progress in speech": 1.0,
    "progress in speech recognition": 1.0,
    "in speech recognition performance": 0.2857142857142857,
    "speech recognition performance is": 0.3333333333333333,
    "recognition performance is difficult": 1.0,
    "performance is difficult and": 1.0,
    "is difficult and controversial": 1.0,
    "difficult and controversial .": 1.0,
    "<s> some speech recognition": 1.0,
    "some speech recognition tasks": 1.0,
    "speech recognition tasks are": 1.0,
    "recognition tasks are much": 1.0,
    "tasks are much more": 1.0,
    "are much more difficult": 1.0,
    "more difficult than others": 0.3333333333333333,
    "difficult than others .": 1.0,
    "<s> word error rates": 1.0,
    "word error rates on": 1.0,
    "error rates on some": 1.0,
    "rates on some tasks": 1.0,
    "on some tasks are": 1.0,
    "some tasks are less": 1.0,
    "tasks are less than": 1.0,
    "are less than 1": 1.0,
    "less than 1 %": 1.0,
    "than 1 % .": 1.0,
    "<s> on others they": 1.0,
    "on others they can": 1.0,
    "others they can be": 1.0,
    "they can be as": 0.25,
    "can be as high": 0.5,
    "be as high as": 1.0,
    "as high as 50": 1.0,
    "high as 50 %": 1.0,
    "as 50 % .": 1.0,
    "<s> sometimes it even": 1.0,
    "sometimes it even appears": 1.0,
    "it even appears that": 1.0,
    "even appears that performance": 1.0,
    "appears that performance is": 1.0,
    "that performance is going": 1.0,
    "performance is going backward": 1.0,
    "is going backward ,": 1.0,
    "going backward , as": 1.0,
    "backward , as researchers": 1.0,
    ", as researchers undertake": 1.0,
    "as researchers undertake harder": 1.0,
    "researchers undertake harder tasks": 1.0,
    "undertake harder tasks that": 1.0,
    "harder tasks that have": 1.0,
    "tasks that have higher": 1.0,
    "that have higher error": 1.0,
    "have higher error rates": 1.0,
    "higher error rates .": 1.0,
    "<s> because progress is": 1.0,
    "because progress is slow": 1.0,
    "progress is slow and": 1.0,
    "is slow and is": 1.0,
    "slow and is difficult": 1.0,
    "and is difficult to": 1.0,
    "is difficult to measure": 0.3333333333333333,
    "difficult to measure ,": 1.0,
    "to measure , there": 1.0,
    "measure , there is": 1.0,
    ", there is some": 0.16666666666666666,
    "there is some perception": 1.0,
    "is some perception that": 1.0,
    "some perception that performance": 1.0,
    "perception that performance has": 1.0,
    "that performance has plateaued": 1.0,
    "performance has plateaued and": 1.0,
    "has plateaued and that": 1.0,
    "plateaued and that funding": 1.0,
    "and that funding has": 1.0,
    "that funding has dried": 1.0,
    "funding has dried up": 1.0,
    "has dried up or": 1.0,
    "dried up or shifted": 1.0,
    "up or shifted priorities": 1.0,
    "or shifted priorities .": 1.0,
    "<s> such perceptions are": 1.0,
    "such perceptions are not": 1.0,
    "perceptions are not new": 1.0,
    "are not new .": 1.0,
    "<s> in 1969 ,": 0.5,
    "in 1969 , john": 1.0,
    "1969 , john pierce": 1.0,
    ", john pierce wrote": 1.0,
    "john pierce wrote an": 1.0,
    "pierce wrote an open": 1.0,
    "wrote an open letter": 1.0,
    "an open letter that": 1.0,
    "open letter that did": 1.0,
    "letter that did cause": 1.0,
    "that did cause much": 1.0,
    "did cause much funding": 1.0,
    "cause much funding to": 1.0,
    "much funding to dry": 1.0,
    "funding to dry up": 1.0,
    "to dry up for": 1.0,
    "dry up for several": 1.0,
    "up for several years": 1.0,
    "for several years .": 0.5,
    "<s> in 1993 there": 1.0,
    "in 1993 there was": 1.0,
    "1993 there was a": 1.0,
    "there was a strong": 0.5,
    "was a strong feeling": 1.0,
    "a strong feeling that": 1.0,
    "strong feeling that performance": 1.0,
    "feeling that performance had": 1.0,
    "that performance had plateaued": 1.0,
    "performance had plateaued and": 1.0,
    "had plateaued and there": 1.0,
    "plateaued and there were": 1.0,
    "and there were workshops": 1.0,
    "there were workshops dedicated": 1.0,
    "were workshops dedicated to": 1.0,
    "workshops dedicated to the": 1.0,
    "dedicated to the issue": 1.0,
    "to the issue .": 1.0,
    ", in the 1990s": 0.125,
    "in the 1990s ,": 0.5,
    "the 1990s , funding": 1.0,
    "1990s , funding continued": 1.0,
    ", funding continued more": 1.0,
    "funding continued more or": 1.0,
    "continued more or less": 1.0,
    "more or less uninterrupted": 0.3333333333333333,
    "or less uninterrupted and": 1.0,
    "less uninterrupted and performance": 1.0,
    "uninterrupted and performance continued": 1.0,
    "and performance continued ,": 1.0,
    "performance continued , slowly": 1.0,
    "continued , slowly but": 1.0,
    ", slowly but steadily": 1.0,
    "slowly but steadily ,": 1.0,
    "but steadily , to": 1.0,
    "steadily , to improve": 1.0,
    ", to improve .": 0.5,
    "<s> for the past": 1.0,
    "for the past thirty": 1.0,
    "the past thirty years": 1.0,
    "past thirty years ,": 1.0,
    "thirty years , speech": 1.0,
    "years , speech recognition": 1.0,
    ", speech recognition research": 0.2,
    "speech recognition research has": 1.0,
    "recognition research has been": 1.0,
    "research has been characterized": 1.0,
    "has been characterized by": 1.0,
    "been characterized by the": 1.0,
    "characterized by the steady": 1.0,
    "by the steady accumulation": 1.0,
    "the steady accumulation of": 1.0,
    "steady accumulation of small": 1.0,
    "accumulation of small incremental": 1.0,
    "of small incremental improvements": 1.0,
    "small incremental improvements .": 1.0,
    "has also been a": 0.3333333333333333,
    "also been a trend": 1.0,
    "been a trend to": 1.0,
    "a trend to change": 1.0,
    "trend to change focus": 1.0,
    "to change focus to": 1.0,
    "change focus to more": 1.0,
    "focus to more difficult": 1.0,
    "to more difficult tasks": 1.0,
    "more difficult tasks due": 0.5,
    "difficult tasks due both": 1.0,
    "tasks due both to": 1.0,
    "due both to progress": 0.5,
    "both to progress in": 1.0,
    "to progress in speech": 1.0,
    "speech recognition performance and": 0.3333333333333333,
    "recognition performance and to": 1.0,
    "performance and to the": 1.0,
    "and to the availability": 1.0,
    "to the availability of": 1.0,
    "the availability of faster": 1.0,
    "availability of faster computers": 1.0,
    "of faster computers .": 1.0,
    "in particular , this": 0.3333333333333333,
    "particular , this shifting": 1.0,
    ", this shifting to": 1.0,
    "this shifting to more": 1.0,
    "shifting to more difficult": 1.0,
    "more difficult tasks has": 0.5,
    "difficult tasks has characterized": 1.0,
    "tasks has characterized darpa": 1.0,
    "has characterized darpa funding": 1.0,
    "characterized darpa funding of": 1.0,
    "darpa funding of speech": 1.0,
    "funding of speech recognition": 1.0,
    "of speech recognition since": 0.07142857142857142,
    "speech recognition since the": 1.0,
    "recognition since the 1980s": 1.0,
    "since the 1980s .": 1.0,
    "<s> in the last": 0.08333333333333333,
    "the last decade ,": 0.5,
    "last decade , it": 1.0,
    "decade , it has": 1.0,
    ", it has continued": 1.0,
    "it has continued with": 1.0,
    "has continued with the": 1.0,
    "continued with the ears": 1.0,
    "with the ears project": 1.0,
    "the ears project ,": 1.0,
    "ears project , which": 1.0,
    "project , which undertook": 0.3333333333333333,
    ", which undertook recognition": 1.0,
    "which undertook recognition of": 1.0,
    "undertook recognition of mandarin": 1.0,
    "recognition of mandarin and": 1.0,
    "of mandarin and arabic": 1.0,
    "mandarin and arabic in": 0.5,
    "and arabic in addition": 1.0,
    "arabic in addition to": 1.0,
    "in addition to english": 0.3333333333333333,
    "addition to english ,": 1.0,
    "to english , and": 1.0,
    "english , and the": 1.0,
    ", and the gale": 0.1,
    "and the gale project": 1.0,
    "project , which focused": 0.3333333333333333,
    ", which focused solely": 1.0,
    "which focused solely on": 1.0,
    "focused solely on mandarin": 1.0,
    "solely on mandarin and": 1.0,
    "on mandarin and arabic": 1.0,
    "mandarin and arabic and": 0.5,
    "and arabic and required": 1.0,
    "arabic and required translation": 1.0,
    "and required translation simultaneously": 1.0,
    "required translation simultaneously with": 1.0,
    "translation simultaneously with speech": 1.0,
    "simultaneously with speech recognition": 1.0,
    "with speech recognition .": 0.5,
    "<s> commercial research and": 1.0,
    "commercial research and other": 1.0,
    "research and other academic": 1.0,
    "and other academic research": 1.0,
    "other academic research also": 1.0,
    "academic research also continue": 1.0,
    "research also continue to": 1.0,
    "also continue to focus": 1.0,
    "continue to focus on": 1.0,
    "to focus on increasingly": 1.0,
    "focus on increasingly difficult": 1.0,
    "on increasingly difficult problems": 1.0,
    "increasingly difficult problems .": 1.0,
    "<s> one key area": 1.0,
    "one key area is": 1.0,
    "key area is to": 1.0,
    "area is to improve": 1.0,
    "is to improve robustness": 1.0,
    "to improve robustness of": 1.0,
    "improve robustness of speech": 1.0,
    "robustness of speech recognition": 1.0,
    "of speech recognition performance": 0.07142857142857142,
    "speech recognition performance ,": 0.3333333333333333,
    "recognition performance , not": 1.0,
    "performance , not just": 1.0,
    ", not just robustness": 1.0,
    "not just robustness against": 1.0,
    "just robustness against noise": 1.0,
    "robustness against noise but": 1.0,
    "against noise but robustness": 1.0,
    "noise but robustness against": 1.0,
    "but robustness against any": 1.0,
    "robustness against any condition": 1.0,
    "against any condition that": 1.0,
    "any condition that causes": 1.0,
    "condition that causes a": 1.0,
    "that causes a major": 1.0,
    "causes a major degradation": 1.0,
    "a major degradation in": 1.0,
    "major degradation in performance": 1.0,
    "degradation in performance .": 1.0,
    "<s> another key area": 1.0,
    "another key area of": 1.0,
    "key area of research": 1.0,
    "area of research is": 0.6666666666666666,
    "of research is focused": 0.5,
    "research is focused on": 1.0,
    "is focused on an": 1.0,
    "focused on an opportunity": 1.0,
    "on an opportunity rather": 1.0,
    "an opportunity rather than": 1.0,
    "opportunity rather than a": 1.0,
    "rather than a problem": 0.3333333333333333,
    "than a problem .": 1.0,
    "<s> this research attempts": 1.0,
    "this research attempts to": 1.0,
    "research attempts to take": 0.5,
    "attempts to take advantage": 1.0,
    "the fact that in": 0.2,
    "fact that in many": 1.0,
    "that in many applications": 1.0,
    "in many applications there": 1.0,
    "many applications there is": 1.0,
    "applications there is a": 1.0,
    "there is a large": 0.25,
    "is a large quantity": 1.0,
    "a large quantity of": 1.0,
    "large quantity of speech": 1.0,
    "quantity of speech data": 1.0,
    "of speech data available": 1.0,
    "speech data available ,": 1.0,
    "data available , up": 1.0,
    "available , up to": 1.0,
    ", up to millions": 1.0,
    "up to millions of": 1.0,
    "to millions of hours": 1.0,
    "millions of hours .": 1.0,
    "<s> it is too": 0.05263157894736842,
    "it is too expensive": 1.0,
    "is too expensive to": 1.0,
    "too expensive to have": 1.0,
    "expensive to have humans": 1.0,
    "to have humans transcribe": 1.0,
    "have humans transcribe such": 1.0,
    "humans transcribe such large": 1.0,
    "transcribe such large quantities": 1.0,
    "such large quantities of": 1.0,
    "large quantities of speech": 0.5,
    "quantities of speech ,": 1.0,
    "of speech , so": 0.16666666666666666,
    "speech , so the": 1.0,
    ", so the research": 0.25,
    "so the research focus": 1.0,
    "the research focus is": 1.0,
    "research focus is on": 1.0,
    "focus is on developing": 1.0,
    "is on developing new": 1.0,
    "on developing new methods": 1.0,
    "developing new methods of": 1.0,
    "new methods of machine": 1.0,
    "methods of machine learning": 1.0,
    "of machine learning that": 0.2,
    "machine learning that can": 1.0,
    "learning that can effectively": 1.0,
    "that can effectively utilize": 1.0,
    "can effectively utilize large": 1.0,
    "effectively utilize large quantities": 1.0,
    "utilize large quantities of": 1.0,
    "large quantities of unlabeled": 0.5,
    "quantities of unlabeled data": 1.0,
    "of unlabeled data .": 1.0,
    "<s> another area of": 1.0,
    "another area of research": 1.0,
    "of research is better": 0.5,
    "research is better understanding": 1.0,
    "is better understanding of": 1.0,
    "better understanding of human": 1.0,
    "understanding of human capabilities": 1.0,
    "of human capabilities and": 1.0,
    "human capabilities and to": 1.0,
    "capabilities and to use": 1.0,
    "and to use this": 0.5,
    "to use this understanding": 1.0,
    "use this understanding to": 1.0,
    "this understanding to improve": 1.0,
    "understanding to improve machine": 1.0,
    "to improve machine recognition": 1.0,
    "improve machine recognition performance": 1.0,
    "machine recognition performance .": 1.0,
    "<s> speech segmentation is": 0.6666666666666666,
    "speech segmentation is the": 0.3333333333333333,
    "segmentation is the process": 0.5,
    "the process of identifying": 0.09090909090909091,
    "process of identifying the": 1.0,
    "of identifying the boundaries": 1.0,
    "identifying the boundaries between": 1.0,
    "the boundaries between words": 0.5,
    "boundaries between words ,": 1.0,
    "between words , syllables": 1.0,
    "words , syllables ,": 1.0,
    ", syllables , or": 1.0,
    "syllables , or phonemes": 1.0,
    ", or phonemes in": 1.0,
    "or phonemes in spoken": 1.0,
    "phonemes in spoken natural": 1.0,
    "in spoken natural languages": 1.0,
    "spoken natural languages .": 1.0,
    "<s> the term applies": 0.5,
    "the term applies both": 1.0,
    "term applies both to": 1.0,
    "applies both to the": 0.5,
    "both to the mental": 0.5,
    "to the mental processes": 1.0,
    "the mental processes used": 1.0,
    "mental processes used by": 1.0,
    "processes used by humans": 1.0,
    "used by humans ,": 0.5,
    "by humans , and": 1.0,
    "humans , and to": 1.0,
    ", and to artificial": 0.5,
    "and to artificial processes": 1.0,
    "to artificial processes of": 0.5,
    "artificial processes of natural": 1.0,
    "processes of natural language": 1.0,
    "speech segmentation is an": 0.3333333333333333,
    "segmentation is an important": 1.0,
    "is an important subproblem": 1.0,
    "an important subproblem of": 1.0,
    "important subproblem of speech": 1.0,
    "subproblem of speech recognition": 1.0,
    "of speech recognition ,": 0.07142857142857142,
    "speech recognition , and": 0.2,
    "recognition , and can": 0.3333333333333333,
    ", and can not": 0.2,
    "and can not be": 1.0,
    "can not be adequately": 0.25,
    "not be adequately solved": 1.0,
    "be adequately solved in": 1.0,
    "adequately solved in isolation": 1.0,
    "solved in isolation .": 1.0,
    "<s> as in most": 0.3333333333333333,
    "as in most natural": 1.0,
    "most natural language processing": 0.5,
    "natural language processing problems": 0.03571428571428571,
    "language processing problems ,": 1.0,
    "processing problems , one": 1.0,
    "problems , one must": 1.0,
    ", one must take": 1.0,
    "one must take into": 1.0,
    "must take into account": 1.0,
    "take into account context": 0.5,
    "into account context ,": 1.0,
    "account context , grammar": 1.0,
    "context , grammar ,": 1.0,
    ", grammar , and": 1.0,
    "grammar , and semantics": 0.5,
    ", and semantics ,": 1.0,
    "and semantics , and": 1.0,
    "semantics , and even": 0.5,
    ", and even so": 0.16666666666666666,
    "and even so the": 1.0,
    "even so the result": 1.0,
    "so the result is": 1.0,
    "the result is often": 0.5,
    "result is often a": 1.0,
    "is often a probabilistic": 1.0,
    "often a probabilistic division": 1.0,
    "a probabilistic division rather": 1.0,
    "probabilistic division rather than": 1.0,
    "division rather than a": 1.0,
    "rather than a categorical": 0.3333333333333333,
    "than a categorical .": 1.0,
    "<s> a comprehensive survey": 1.0,
    "a comprehensive survey of": 1.0,
    "comprehensive survey of speech": 1.0,
    "survey of speech segmentation": 1.0,
    "of speech segmentation problems": 1.0,
    "speech segmentation problems and": 1.0,
    "segmentation problems and techniques": 1.0,
    "problems and techniques can": 1.0,
    "and techniques can be": 1.0,
    "techniques can be seen": 1.0,
    "can be seen in": 0.3333333333333333,
    "be seen in .": 1.0,
    "<s> some writing systems": 1.0,
    "some writing systems indicate": 0.5,
    "writing systems indicate speech": 1.0,
    "systems indicate speech segmentation": 1.0,
    "indicate speech segmentation between": 1.0,
    "speech segmentation between words": 1.0,
    "segmentation between words by": 1.0,
    "between words by a": 1.0,
    "words by a word": 1.0,
    "by a word divider": 1.0,
    "a word divider ,": 1.0,
    "word divider , such": 1.0,
    "divider , such as": 1.0,
    "such as the space": 0.07142857142857142,
    "as the space .": 1.0,
    "difficulty of this problem": 0.5,
    "of this problem is": 1.0,
    "this problem is compounded": 0.5,
    "problem is compounded by": 1.0,
    "is compounded by the": 1.0,
    "compounded by the phenomenon": 1.0,
    "by the phenomenon of": 1.0,
    "the phenomenon of co-articulation": 0.3333333333333333,
    "phenomenon of co-articulation of": 1.0,
    "of co-articulation of speech": 1.0,
    "co-articulation of speech sounds": 1.0,
    "of speech sounds ,": 1.0,
    "speech sounds , where": 1.0,
    "sounds , where one": 1.0,
    ", where one may": 1.0,
    "where one may be": 1.0,
    "one may be modified": 1.0,
    "may be modified in": 1.0,
    "be modified in various": 1.0,
    "modified in various ways": 1.0,
    "in various ways by": 0.5,
    "various ways by the": 1.0,
    "ways by the adjacent": 1.0,
    "by the adjacent sounds": 1.0,
    "the adjacent sounds :": 1.0,
    "adjacent sounds : it": 1.0,
    "sounds : it may": 1.0,
    ": it may blend": 1.0,
    "it may blend smoothly": 1.0,
    "may blend smoothly with": 1.0,
    "blend smoothly with them": 1.0,
    "smoothly with them ,": 1.0,
    "with them , fuse": 0.5,
    "them , fuse with": 1.0,
    ", fuse with them": 1.0,
    "fuse with them ,": 1.0,
    "with them , split": 0.5,
    "them , split ,": 1.0,
    ", split , or": 1.0,
    "split , or even": 1.0,
    ", or even disappear": 0.5,
    "or even disappear .": 1.0,
    "<s> this phenomenon may": 0.5,
    "this phenomenon may happen": 1.0,
    "phenomenon may happen between": 1.0,
    "may happen between adjacent": 1.0,
    "happen between adjacent words": 1.0,
    "between adjacent words just": 0.5,
    "adjacent words just as": 1.0,
    "words just as easily": 1.0,
    "just as easily as": 0.5,
    "as easily as within": 1.0,
    "easily as within a": 1.0,
    "as within a single": 1.0,
    "within a single word": 1.0,
    "a single word .": 1.0,
    "<s> the notion that": 0.5,
    "the notion that speech": 1.0,
    "notion that speech is": 1.0,
    "that speech is produced": 1.0,
    "speech is produced like": 1.0,
    "is produced like writing": 1.0,
    "produced like writing ,": 1.0,
    "like writing , as": 1.0,
    "writing , as a": 1.0,
    ", as a sequence": 1.0,
    "as a sequence of": 1.0,
    "a sequence of distinct": 0.16666666666666666,
    "sequence of distinct vowels": 1.0,
    "of distinct vowels and": 1.0,
    "distinct vowels and consonants": 1.0,
    "vowels and consonants ,": 1.0,
    "and consonants , is": 1.0,
    "consonants , is a": 1.0,
    ", is a relic": 0.25,
    "is a relic of": 1.0,
    "a relic of our": 1.0,
    "relic of our alphabetic": 1.0,
    "of our alphabetic heritage": 1.0,
    "our alphabetic heritage -lrb-": 1.0,
    "alphabetic heritage -lrb- citation": 1.0,
    "heritage -lrb- citation needed": 1.0,
    "in fact , the": 0.25,
    "fact , the way": 1.0,
    ", the way we": 1.0,
    "the way we produce": 1.0,
    "way we produce vowels": 0.5,
    "we produce vowels depends": 1.0,
    "produce vowels depends on": 1.0,
    "vowels depends on the": 1.0,
    "depends on the surrounding": 0.4,
    "on the surrounding consonants": 0.5,
    "the surrounding consonants and": 1.0,
    "surrounding consonants and the": 1.0,
    "consonants and the way": 1.0,
    "and the way we": 1.0,
    "way we produce consonants": 0.5,
    "we produce consonants depends": 1.0,
    "produce consonants depends on": 1.0,
    "consonants depends on the": 1.0,
    "on the surrounding vowels": 0.5,
    "the surrounding vowels .": 1.0,
    "example , when we": 0.5,
    ", when we say": 1.0,
    "when we say `": 1.0,
    "we say ` kit": 0.5,
    "say ` kit '": 1.0,
    "` kit ' ,": 1.0,
    "kit ' , the": 0.5,
    "' , the -lrb-": 1.0,
    ", the -lrb- k": 1.0,
    "the -lrb- k -rrb-": 1.0,
    "-lrb- k -rrb- is": 1.0,
    "k -rrb- is farther": 1.0,
    "-rrb- is farther forward": 1.0,
    "is farther forward than": 1.0,
    "farther forward than when": 1.0,
    "forward than when we": 1.0,
    "than when we say": 1.0,
    "we say ` caught": 0.5,
    "say ` caught '": 1.0,
    "` caught ' .": 1.0,
    "<s> but also the": 1.0,
    "but also the vowel": 0.5,
    "also the vowel in": 1.0,
    "the vowel in `": 1.0,
    "vowel in ` kick": 0.5,
    "in ` kick '": 1.0,
    "` kick ' is": 1.0,
    "kick ' is phonetically": 1.0,
    "' is phonetically different": 1.0,
    "is phonetically different from": 1.0,
    "phonetically different from the": 1.0,
    "different from the vowel": 1.0,
    "from the vowel in": 1.0,
    "vowel in ` kit": 0.5,
    "in ` kit '": 1.0,
    "kit ' , though": 0.5,
    "' , though we": 1.0,
    ", though we normally": 1.0,
    "though we normally do": 1.0,
    "we normally do not": 1.0,
    "normally do not hear": 1.0,
    "do not hear this": 1.0,
    "not hear this .": 1.0,
    "in addition , there": 0.5,
    "addition , there are": 1.0,
    ", there are language-specific": 0.3333333333333333,
    "there are language-specific changes": 1.0,
    "are language-specific changes which": 1.0,
    "language-specific changes which occur": 1.0,
    "changes which occur on": 1.0,
    "which occur on casual": 1.0,
    "occur on casual speech": 1.0,
    "on casual speech which": 1.0,
    "casual speech which makes": 1.0,
    "speech which makes it": 1.0,
    "which makes it quite": 0.5,
    "makes it quite different": 1.0,
    "it quite different from": 1.0,
    "quite different from spelling": 0.5,
    "different from spelling .": 1.0,
    "example , in english": 0.3333333333333333,
    ", in english ,": 1.0,
    "in english , the": 1.0,
    "english , the phrase": 1.0,
    ", the phrase `": 1.0,
    "the phrase ` hit": 1.0,
    "phrase ` hit you": 1.0,
    "` hit you '": 1.0,
    "hit you ' could": 1.0,
    "you ' could often": 1.0,
    "' could often be": 1.0,
    "could often be more": 1.0,
    "often be more appropriately": 1.0,
    "be more appropriately spelled": 1.0,
    "more appropriately spelled `": 1.0,
    "appropriately spelled ` hitcha": 1.0,
    "spelled ` hitcha '": 1.0,
    "` hitcha ' .": 1.0,
    "<s> therefore , even": 0.5,
    "therefore , even with": 1.0,
    ", even with the": 1.0,
    "even with the best": 1.0,
    "with the best algorithms": 1.0,
    "the best algorithms ,": 1.0,
    "best algorithms , the": 1.0,
    "algorithms , the result": 0.5,
    ", the result of": 1.0,
    "the result of phonetic": 0.5,
    "result of phonetic segmentation": 1.0,
    "of phonetic segmentation will": 1.0,
    "phonetic segmentation will usually": 1.0,
    "segmentation will usually be": 1.0,
    "will usually be very": 1.0,
    "usually be very distant": 1.0,
    "be very distant from": 1.0,
    "very distant from the": 1.0,
    "distant from the standard": 1.0,
    "from the standard written": 1.0,
    "the standard written language": 1.0,
    "standard written language .": 1.0,
    "this reason , the": 0.5,
    "reason , the lexical": 1.0,
    ", the lexical and": 1.0,
    "the lexical and syntactic": 1.0,
    "lexical and syntactic parsing": 0.5,
    "and syntactic parsing of": 1.0,
    "syntactic parsing of spoken": 1.0,
    "parsing of spoken text": 1.0,
    "of spoken text normally": 1.0,
    "spoken text normally requires": 1.0,
    "text normally requires specialized": 1.0,
    "normally requires specialized algorithms": 1.0,
    "requires specialized algorithms ,": 1.0,
    "specialized algorithms , distinct": 1.0,
    "algorithms , distinct from": 1.0,
    ", distinct from those": 1.0,
    "distinct from those used": 1.0,
    "from those used for": 1.0,
    "those used for parsing": 1.0,
    "used for parsing written": 1.0,
    "for parsing written text": 1.0,
    "parsing written text .": 1.0,
    "<s> statistical models can": 1.0,
    "statistical models can be": 1.0,
    "models can be used": 1.0,
    "be used to segment": 0.16666666666666666,
    "used to segment and": 1.0,
    "to segment and align": 1.0,
    "segment and align recorded": 1.0,
    "and align recorded speech": 1.0,
    "align recorded speech to": 1.0,
    "recorded speech to words": 1.0,
    "speech to words or": 1.0,
    "to words or phones": 1.0,
    "words or phones .": 1.0,
    "<s> applications include automatic": 1.0,
    "applications include automatic lip-synch": 1.0,
    "include automatic lip-synch timing": 1.0,
    "automatic lip-synch timing for": 1.0,
    "lip-synch timing for cartoon": 1.0,
    "timing for cartoon animation": 1.0,
    "for cartoon animation ,": 1.0,
    "cartoon animation , follow-the-bouncing-ball": 1.0,
    "animation , follow-the-bouncing-ball video": 1.0,
    ", follow-the-bouncing-ball video sub-titling": 1.0,
    "follow-the-bouncing-ball video sub-titling ,": 1.0,
    "video sub-titling , and": 1.0,
    "sub-titling , and linguistic": 1.0,
    ", and linguistic research": 1.0,
    "and linguistic research .": 1.0,
    "<s> automatic segmentation and": 0.5,
    "automatic segmentation and alignment": 1.0,
    "segmentation and alignment software": 1.0,
    "and alignment software is": 1.0,
    "alignment software is commercially": 1.0,
    "software is commercially available": 1.0,
    "is commercially available .": 1.0,
    "<s> lexical segmentation in": 1.0,
    "lexical segmentation in all": 1.0,
    "segmentation in all natural": 1.0,
    "in all natural languages": 1.0,
    "all natural languages ,": 1.0,
    "natural languages , the": 0.5,
    "languages , the meaning": 0.3333333333333333,
    ", the meaning of": 1.0,
    "the meaning of a": 0.16666666666666666,
    "meaning of a complex": 1.0,
    "of a complex spoken": 0.5,
    "a complex spoken sentence": 1.0,
    "complex spoken sentence -lrb-": 1.0,
    "spoken sentence -lrb- which": 1.0,
    "sentence -lrb- which often": 1.0,
    "-lrb- which often has": 1.0,
    "which often has never": 1.0,
    "often has never been": 1.0,
    "has never been heard": 0.5,
    "never been heard or": 1.0,
    "been heard or uttered": 1.0,
    "heard or uttered before": 1.0,
    "or uttered before -rrb-": 1.0,
    "uttered before -rrb- can": 1.0,
    "before -rrb- can be": 1.0,
    "-rrb- can be understood": 1.0,
    "can be understood only": 1.0,
    "be understood only by": 1.0,
    "understood only by decomposing": 1.0,
    "only by decomposing it": 1.0,
    "by decomposing it into": 1.0,
    "decomposing it into smaller": 1.0,
    "it into smaller lexical": 1.0,
    "into smaller lexical segments": 1.0,
    "smaller lexical segments -lrb-": 1.0,
    "lexical segments -lrb- roughly": 1.0,
    "segments -lrb- roughly ,": 1.0,
    "-lrb- roughly , the": 1.0,
    "roughly , the words": 0.5,
    ", the words of": 1.0,
    "the words of the": 1.0,
    "words of the language": 0.5,
    "of the language -rrb-": 0.3333333333333333,
    "the language -rrb- ,": 0.5,
    "language -rrb- , associating": 1.0,
    "-rrb- , associating a": 1.0,
    ", associating a meaning": 1.0,
    "associating a meaning to": 1.0,
    "a meaning to each": 0.5,
    "meaning to each segment": 1.0,
    "to each segment ,": 1.0,
    "each segment , and": 1.0,
    "segment , and then": 1.0,
    ", and then combining": 0.25,
    "and then combining those": 1.0,
    "then combining those meanings": 1.0,
    "combining those meanings according": 1.0,
    "those meanings according to": 1.0,
    "meanings according to the": 1.0,
    "according to the grammar": 0.3333333333333333,
    "to the grammar rules": 0.5,
    "the grammar rules of": 1.0,
    "grammar rules of the": 1.0,
    "rules of the language": 1.0,
    "of the language .": 0.16666666666666666,
    "<s> the recognition of": 1.0,
    "the recognition of each": 0.5,
    "recognition of each lexical": 1.0,
    "of each lexical segment": 1.0,
    "each lexical segment in": 1.0,
    "lexical segment in turn": 1.0,
    "segment in turn requires": 1.0,
    "in turn requires its": 1.0,
    "turn requires its decomposition": 1.0,
    "requires its decomposition into": 1.0,
    "its decomposition into a": 1.0,
    "decomposition into a sequence": 1.0,
    "into a sequence of": 1.0,
    "a sequence of discrete": 0.16666666666666666,
    "sequence of discrete phonetic": 1.0,
    "of discrete phonetic segments": 1.0,
    "discrete phonetic segments and": 1.0,
    "phonetic segments and mapping": 1.0,
    "segments and mapping each": 1.0,
    "and mapping each segment": 1.0,
    "mapping each segment to": 1.0,
    "each segment to one": 1.0,
    "segment to one element": 1.0,
    "to one element of": 1.0,
    "one element of a": 1.0,
    "element of a finite": 1.0,
    "of a finite set": 1.0,
    "a finite set of": 1.0,
    "finite set of elementary": 1.0,
    "set of elementary sounds": 1.0,
    "of elementary sounds -lrb-": 1.0,
    "elementary sounds -lrb- roughly": 1.0,
    "sounds -lrb- roughly ,": 1.0,
    "roughly , the phonemes": 0.5,
    ", the phonemes of": 1.0,
    "the phonemes of the": 1.0,
    "phonemes of the language": 1.0,
    "the language -rrb- ;": 0.5,
    "language -rrb- ; the": 1.0,
    "-rrb- ; the meaning": 1.0,
    "; the meaning then": 1.0,
    "the meaning then can": 1.0,
    "meaning then can be": 1.0,
    "then can be found": 1.0,
    "can be found by": 0.3333333333333333,
    "be found by standard": 1.0,
    "found by standard table": 1.0,
    "by standard table lookup": 1.0,
    "standard table lookup algorithms": 1.0,
    "table lookup algorithms .": 1.0,
    "<s> for most spoken": 1.0,
    "for most spoken languages": 1.0,
    "languages , the boundaries": 0.3333333333333333,
    ", the boundaries between": 1.0,
    "the boundaries between lexical": 0.5,
    "boundaries between lexical units": 1.0,
    "between lexical units are": 1.0,
    "lexical units are surprisingly": 1.0,
    "units are surprisingly difficult": 1.0,
    "are surprisingly difficult to": 1.0,
    "surprisingly difficult to identify": 1.0,
    "difficult to identify .": 1.0,
    "<s> one might expect": 1.0,
    "one might expect that": 1.0,
    "might expect that the": 1.0,
    "expect that the inter-word": 1.0,
    "that the inter-word spaces": 1.0,
    "the inter-word spaces used": 1.0,
    "inter-word spaces used by": 1.0,
    "spaces used by many": 1.0,
    "used by many written": 1.0,
    "by many written languages": 1.0,
    "many written languages ,": 1.0,
    "written languages , like": 1.0,
    "languages , like english": 1.0,
    ", like english or": 1.0,
    "like english or spanish": 1.0,
    "english or spanish ,": 1.0,
    "or spanish , would": 1.0,
    "spanish , would correspond": 1.0,
    ", would correspond to": 1.0,
    "would correspond to pauses": 1.0,
    "correspond to pauses in": 1.0,
    "to pauses in their": 1.0,
    "pauses in their spoken": 1.0,
    "in their spoken version": 1.0,
    "their spoken version ;": 1.0,
    "spoken version ; but": 1.0,
    "version ; but that": 1.0,
    "; but that is": 1.0,
    "but that is true": 1.0,
    "that is true only": 1.0,
    "is true only in": 1.0,
    "true only in very": 1.0,
    "only in very slow": 0.5,
    "in very slow speech": 1.0,
    "very slow speech ,": 1.0,
    "slow speech , when": 1.0,
    "speech , when the": 0.5,
    ", when the speaker": 0.3333333333333333,
    "when the speaker deliberately": 1.0,
    "the speaker deliberately inserts": 1.0,
    "speaker deliberately inserts those": 1.0,
    "deliberately inserts those pauses": 1.0,
    "inserts those pauses .": 1.0,
    "<s> in normal speech": 1.0,
    "in normal speech ,": 1.0,
    "normal speech , one": 1.0,
    "speech , one typically": 1.0,
    ", one typically finds": 1.0,
    "one typically finds many": 1.0,
    "typically finds many consecutive": 1.0,
    "finds many consecutive words": 1.0,
    "many consecutive words being": 1.0,
    "consecutive words being said": 1.0,
    "words being said with": 1.0,
    "being said with no": 1.0,
    "said with no pauses": 1.0,
    "with no pauses between": 1.0,
    "no pauses between them": 1.0,
    "pauses between them ,": 1.0,
    "between them , and": 1.0,
    "them , and often": 1.0,
    ", and often the": 0.5,
    "and often the final": 1.0,
    "often the final sounds": 1.0,
    "the final sounds of": 1.0,
    "final sounds of one": 1.0,
    "sounds of one word": 1.0,
    "of one word blend": 1.0,
    "one word blend smoothly": 1.0,
    "word blend smoothly or": 1.0,
    "blend smoothly or fuse": 1.0,
    "smoothly or fuse with": 1.0,
    "or fuse with the": 1.0,
    "fuse with the initial": 1.0,
    "with the initial sounds": 1.0,
    "the initial sounds of": 1.0,
    "initial sounds of the": 1.0,
    "sounds of the next": 1.0,
    "of the next word": 1.0,
    "the next word .": 0.5,
    "<s> moreover , an": 0.25,
    "moreover , an utterance": 1.0,
    ", an utterance can": 1.0,
    "an utterance can have": 1.0,
    "utterance can have different": 1.0,
    "can have different meanings": 1.0,
    "have different meanings depending": 1.0,
    "different meanings depending on": 1.0,
    "meanings depending on how": 1.0,
    "depending on how it": 1.0,
    "on how it is": 0.5,
    "how it is split": 1.0,
    "it is split into": 1.0,
    "is split into words": 0.5,
    "split into words .": 1.0,
    "<s> a popular example": 1.0,
    "a popular example ,": 1.0,
    "popular example , often": 1.0,
    "example , often quoted": 1.0,
    ", often quoted in": 1.0,
    "often quoted in the": 1.0,
    "quoted in the field": 1.0,
    "in the field ,": 0.08333333333333333,
    "the field , is": 1.0,
    "field , is the": 1.0,
    ", is the phrase": 0.16666666666666666,
    "is the phrase how": 1.0,
    "the phrase how to": 1.0,
    "phrase how to wreck": 1.0,
    "how to wreck a": 1.0,
    "to wreck a nice": 1.0,
    "wreck a nice beach": 1.0,
    "a nice beach ,": 1.0,
    "nice beach , which": 1.0,
    "beach , which sounds": 1.0,
    ", which sounds very": 1.0,
    "which sounds very similar": 1.0,
    "sounds very similar to": 1.0,
    "very similar to how": 0.3333333333333333,
    "similar to how to": 1.0,
    "to how to recognize": 1.0,
    "how to recognize speech": 1.0,
    "to recognize speech .": 1.0,
    "<s> as this example": 1.0,
    "as this example shows": 1.0,
    "this example shows ,": 1.0,
    "example shows , proper": 1.0,
    "shows , proper lexical": 1.0,
    ", proper lexical segmentation": 1.0,
    "proper lexical segmentation depends": 1.0,
    "lexical segmentation depends on": 1.0,
    "segmentation depends on context": 1.0,
    "depends on context and": 1.0,
    "on context and semantics": 1.0,
    "context and semantics which": 1.0,
    "and semantics which draws": 1.0,
    "semantics which draws on": 1.0,
    "which draws on the": 1.0,
    "draws on the whole": 1.0,
    "on the whole of": 1.0,
    "the whole of human": 1.0,
    "whole of human knowledge": 1.0,
    "of human knowledge and": 1.0,
    "human knowledge and experience": 1.0,
    "knowledge and experience ,": 1.0,
    "and experience , and": 1.0,
    "experience , and would": 1.0,
    ", and would thus": 1.0,
    "and would thus require": 1.0,
    "would thus require advanced": 1.0,
    "thus require advanced pattern": 1.0,
    "require advanced pattern recognition": 1.0,
    "advanced pattern recognition and": 1.0,
    "pattern recognition and artificial": 1.0,
    "recognition and artificial intelligence": 1.0,
    "and artificial intelligence technologies": 1.0,
    "artificial intelligence technologies to": 1.0,
    "intelligence technologies to be": 1.0,
    "technologies to be implemented": 1.0,
    "to be implemented on": 1.0,
    "be implemented on a": 1.0,
    "implemented on a computer": 1.0,
    "on a computer .": 1.0,
    "<s> this problem overlaps": 0.25,
    "this problem overlaps to": 1.0,
    "problem overlaps to some": 1.0,
    "overlaps to some extent": 1.0,
    "to some extent with": 1.0,
    "some extent with the": 1.0,
    "extent with the problem": 1.0,
    "with the problem of": 1.0,
    "the problem of text": 0.16666666666666666,
    "problem of text segmentation": 1.0,
    "of text segmentation that": 1.0,
    "text segmentation that occurs": 1.0,
    "segmentation that occurs in": 1.0,
    "that occurs in some": 1.0,
    "occurs in some languages": 1.0,
    "in some languages which": 1.0,
    "some languages which are": 1.0,
    "languages which are traditionally": 1.0,
    "which are traditionally written": 1.0,
    "are traditionally written without": 1.0,
    "traditionally written without inter-word": 1.0,
    "written without inter-word spaces": 1.0,
    "without inter-word spaces ,": 1.0,
    "inter-word spaces , like": 1.0,
    "spaces , like chinese": 1.0,
    ", like chinese and": 1.0,
    "like chinese and japanese": 1.0,
    "chinese and japanese .": 1.0,
    "<s> however , even": 0.03125,
    "however , even for": 1.0,
    ", even for those": 1.0,
    "even for those languages": 1.0,
    "for those languages ,": 1.0,
    "those languages , text": 1.0,
    "languages , text segmentation": 1.0,
    ", text segmentation is": 1.0,
    "text segmentation is often": 0.3333333333333333,
    "segmentation is often much": 1.0,
    "is often much easier": 1.0,
    "often much easier than": 1.0,
    "much easier than speech": 1.0,
    "easier than speech segmentation": 1.0,
    "than speech segmentation ,": 1.0,
    "speech segmentation , because": 0.5,
    "segmentation , because the": 1.0,
    ", because the written": 0.5,
    "because the written language": 1.0,
    "the written language usually": 1.0,
    "written language usually has": 1.0,
    "language usually has little": 1.0,
    "usually has little interference": 1.0,
    "has little interference between": 1.0,
    "little interference between adjacent": 1.0,
    "interference between adjacent words": 1.0,
    "between adjacent words ,": 0.5,
    "adjacent words , and": 1.0,
    "words , and often": 0.3333333333333333,
    ", and often contains": 0.5,
    "and often contains additional": 1.0,
    "often contains additional clues": 1.0,
    "contains additional clues not": 1.0,
    "additional clues not present": 1.0,
    "clues not present in": 1.0,
    "not present in speech": 0.3333333333333333,
    "present in speech -lrb-": 1.0,
    "in speech -lrb- such": 1.0,
    "speech -lrb- such as": 1.0,
    "-lrb- such as the": 0.125,
    "such as the use": 0.07142857142857142,
    "as the use of": 1.0,
    "the use of chinese": 0.06666666666666667,
    "use of chinese characters": 1.0,
    "of chinese characters for": 1.0,
    "chinese characters for word": 1.0,
    "characters for word stems": 1.0,
    "for word stems in": 1.0,
    "word stems in japanese": 1.0,
    "stems in japanese -rrb-": 1.0,
    "in japanese -rrb- .": 1.0,
    "<s> text segmentation is": 1.0,
    "text segmentation is the": 0.3333333333333333,
    "the process of dividing": 0.18181818181818182,
    "process of dividing written": 0.5,
    "of dividing written text": 1.0,
    "dividing written text into": 1.0,
    "written text into meaningful": 0.5,
    "text into meaningful units": 1.0,
    "into meaningful units ,": 1.0,
    "meaningful units , such": 1.0,
    "units , such as": 1.0,
    ", such as words": 0.030303030303030304,
    "such as words ,": 1.0,
    "as words , sentences": 1.0,
    "words , sentences ,": 1.0,
    ", sentences , or": 1.0,
    "sentences , or topics": 1.0,
    ", or topics .": 1.0,
    "applies both to mental": 0.5,
    "both to mental processes": 1.0,
    "to mental processes used": 1.0,
    "used by humans when": 0.5,
    "by humans when reading": 1.0,
    "humans when reading text": 1.0,
    "when reading text ,": 1.0,
    "reading text , and": 1.0,
    "text , and to": 0.3333333333333333,
    "to artificial processes implemented": 0.5,
    "artificial processes implemented in": 1.0,
    "processes implemented in computers": 1.0,
    "implemented in computers ,": 1.0,
    "in computers , which": 1.0,
    "computers , which are": 1.0,
    ", which are the": 0.2,
    "which are the subject": 1.0,
    "are the subject of": 1.0,
    "the subject of natural": 0.5,
    "subject of natural language": 1.0,
    "the problem is non-trivial": 0.5,
    "problem is non-trivial ,": 1.0,
    "is non-trivial , because": 1.0,
    "non-trivial , because while": 1.0,
    ", because while some": 1.0,
    "because while some written": 1.0,
    "while some written languages": 1.0,
    "some written languages have": 0.5,
    "written languages have explicit": 1.0,
    "languages have explicit word": 1.0,
    "have explicit word boundary": 1.0,
    "explicit word boundary markers": 1.0,
    "word boundary markers ,": 1.0,
    "boundary markers , such": 1.0,
    "markers , such as": 1.0,
    "such as the word": 0.07142857142857142,
    "as the word spaces": 1.0,
    "the word spaces of": 1.0,
    "word spaces of written": 1.0,
    "spaces of written english": 1.0,
    "of written english and": 1.0,
    "written english and the": 1.0,
    "english and the distinctive": 1.0,
    "and the distinctive initial": 1.0,
    "the distinctive initial ,": 1.0,
    "distinctive initial , medial": 1.0,
    "initial , medial and": 1.0,
    ", medial and final": 1.0,
    "medial and final letter": 1.0,
    "and final letter shapes": 1.0,
    "final letter shapes of": 1.0,
    "letter shapes of arabic": 1.0,
    "shapes of arabic ,": 1.0,
    "of arabic , such": 1.0,
    "arabic , such signals": 1.0,
    ", such signals are": 1.0,
    "such signals are sometimes": 1.0,
    "signals are sometimes ambiguous": 1.0,
    "are sometimes ambiguous and": 1.0,
    "sometimes ambiguous and not": 1.0,
    "ambiguous and not present": 1.0,
    "and not present in": 1.0,
    "not present in all": 0.3333333333333333,
    "present in all written": 1.0,
    "in all written languages": 0.5,
    "all written languages .": 0.5,
    "<s> compare speech segmentation": 1.0,
    "compare speech segmentation ,": 1.0,
    "speech segmentation , the": 0.5,
    "segmentation , the process": 1.0,
    ", the process of": 1.0,
    "process of dividing speech": 0.5,
    "of dividing speech into": 1.0,
    "dividing speech into linguistically": 1.0,
    "speech into linguistically meaningful": 1.0,
    "into linguistically meaningful portions": 1.0,
    "linguistically meaningful portions .": 1.0,
    "<s> in english and": 1.0,
    "in english and many": 0.5,
    "english and many other": 1.0,
    "and many other languages": 1.0,
    "many other languages using": 0.3333333333333333,
    "other languages using some": 1.0,
    "languages using some form": 1.0,
    "using some form of": 1.0,
    "some form of the": 0.25,
    "form of the latin": 1.0,
    "of the latin alphabet": 1.0,
    "the latin alphabet ,": 1.0,
    "latin alphabet , the": 1.0,
    "alphabet , the space": 1.0,
    ", the space is": 1.0,
    "the space is a": 1.0,
    "space is a good": 1.0,
    "is a good approximation": 1.0,
    "a good approximation of": 1.0,
    "good approximation of a": 1.0,
    "approximation of a word": 1.0,
    "of a word delimiter": 0.3333333333333333,
    "a word delimiter .": 1.0,
    "<s> -lrb- some examples": 1.0,
    "-lrb- some examples where": 1.0,
    "some examples where the": 1.0,
    "examples where the space": 1.0,
    "where the space character": 1.0,
    "the space character alone": 1.0,
    "space character alone may": 1.0,
    "character alone may not": 1.0,
    "alone may not be": 1.0,
    "may not be sufficient": 0.5,
    "not be sufficient include": 1.0,
    "be sufficient include contractions": 1.0,
    "sufficient include contractions like": 1.0,
    "include contractions like ca": 1.0,
    "contractions like ca n't": 1.0,
    "like ca n't for": 1.0,
    "ca n't for can": 1.0,
    "n't for can not": 1.0,
    "for can not .": 1.0,
    "can not . -rrb-": 1.0,
    "<s> however the equivalent": 1.0,
    "however the equivalent to": 1.0,
    "the equivalent to this": 1.0,
    "equivalent to this character": 1.0,
    "to this character is": 1.0,
    "this character is not": 1.0,
    "character is not found": 1.0,
    "is not found in": 1.0,
    "not found in all": 1.0,
    "found in all written": 1.0,
    "in all written scripts": 0.5,
    "all written scripts ,": 1.0,
    "written scripts , and": 1.0,
    "scripts , and without": 1.0,
    ", and without it": 0.5,
    "and without it word": 1.0,
    "without it word segmentation": 1.0,
    "it word segmentation is": 1.0,
    "word segmentation is a": 1.0,
    "segmentation is a difficult": 0.3333333333333333,
    "is a difficult problem": 1.0,
    "a difficult problem .": 1.0,
    "<s> languages which do": 1.0,
    "languages which do not": 1.0,
    "which do not have": 1.0,
    "do not have a": 0.5,
    "not have a trivial": 1.0,
    "have a trivial word": 1.0,
    "a trivial word segmentation": 1.0,
    "trivial word segmentation process": 1.0,
    "word segmentation process include": 1.0,
    "segmentation process include chinese": 1.0,
    "process include chinese ,": 1.0,
    "include chinese , japanese": 1.0,
    "chinese , japanese ,": 0.5,
    ", japanese , where": 1.0,
    "japanese , where sentences": 1.0,
    ", where sentences but": 1.0,
    "where sentences but not": 1.0,
    "sentences but not words": 1.0,
    "but not words are": 1.0,
    "not words are delimited": 1.0,
    "words are delimited ,": 0.6666666666666666,
    "are delimited , thai": 0.5,
    "delimited , thai and": 1.0,
    ", thai and lao": 1.0,
    "thai and lao ,": 1.0,
    "and lao , where": 1.0,
    "lao , where phrases": 1.0,
    ", where phrases and": 1.0,
    "where phrases and sentences": 1.0,
    "phrases and sentences but": 1.0,
    "and sentences but not": 1.0,
    "are delimited , and": 0.5,
    "delimited , and vietnamese": 1.0,
    ", and vietnamese ,": 1.0,
    "and vietnamese , where": 1.0,
    "vietnamese , where syllables": 1.0,
    ", where syllables but": 1.0,
    "where syllables but not": 1.0,
    "syllables but not words": 1.0,
    "words are delimited .": 0.3333333333333333,
    "<s> in some writing": 0.3333333333333333,
    "in some writing systems": 1.0,
    "some writing systems however": 0.5,
    "writing systems however ,": 1.0,
    "systems however , such": 1.0,
    "however , such as": 0.5,
    "such as the ge'ez": 0.07142857142857142,
    "as the ge'ez script": 1.0,
    "the ge'ez script used": 1.0,
    "ge'ez script used for": 1.0,
    "script used for amharic": 1.0,
    "used for amharic and": 1.0,
    "for amharic and tigrinya": 1.0,
    "amharic and tigrinya among": 1.0,
    "and tigrinya among other": 1.0,
    "tigrinya among other languages": 1.0,
    "among other languages ,": 1.0,
    "other languages , words": 0.5,
    "languages , words are": 1.0,
    ", words are explicitly": 1.0,
    "words are explicitly delimited": 1.0,
    "are explicitly delimited -lrb-": 1.0,
    "explicitly delimited -lrb- at": 1.0,
    "delimited -lrb- at least": 1.0,
    "-lrb- at least historically": 1.0,
    "at least historically -rrb-": 1.0,
    "least historically -rrb- with": 1.0,
    "historically -rrb- with a": 1.0,
    "-rrb- with a non-whitespace": 1.0,
    "with a non-whitespace character": 1.0,
    "a non-whitespace character .": 1.0,
    "<s> the unicode consortium": 1.0,
    "the unicode consortium has": 1.0,
    "unicode consortium has published": 1.0,
    "consortium has published a": 1.0,
    "has published a standard": 1.0,
    "published a standard annex": 1.0,
    "a standard annex on": 1.0,
    "standard annex on text": 1.0,
    "annex on text segmentation": 1.0,
    "on text segmentation ,": 1.0,
    "text segmentation , exploring": 1.0,
    "segmentation , exploring the": 1.0,
    ", exploring the issues": 1.0,
    "exploring the issues of": 1.0,
    "the issues of segmentation": 1.0,
    "issues of segmentation in": 1.0,
    "of segmentation in multiscript": 1.0,
    "segmentation in multiscript texts": 1.0,
    "in multiscript texts .": 1.0,
    "<s> word splitting is": 0.5,
    "word splitting is the": 1.0,
    "splitting is the process": 1.0,
    "the process of parsing": 0.09090909090909091,
    "process of parsing concatenated": 1.0,
    "of parsing concatenated text": 1.0,
    "parsing concatenated text -lrb-": 1.0,
    "concatenated text -lrb- i.e.": 1.0,
    "text -lrb- i.e. text": 1.0,
    "-lrb- i.e. text that": 1.0,
    "i.e. text that contains": 1.0,
    "text that contains no": 1.0,
    "that contains no spaces": 1.0,
    "contains no spaces or": 1.0,
    "no spaces or other": 1.0,
    "spaces or other word": 1.0,
    "or other word separators": 1.0,
    "other word separators -rrb-": 1.0,
    "word separators -rrb- to": 1.0,
    "separators -rrb- to infer": 1.0,
    "-rrb- to infer where": 1.0,
    "to infer where word": 1.0,
    "infer where word breaks": 1.0,
    "where word breaks exist": 1.0,
    "word breaks exist .": 1.0,
    "<s> word splitting may": 0.5,
    "word splitting may also": 1.0,
    "splitting may also refer": 1.0,
    "may also refer to": 1.0,
    "also refer to the": 1.0,
    "refer to the process": 0.5,
    "to the process of": 1.0,
    "the process of hyphenation": 0.09090909090909091,
    "process of hyphenation .": 1.0,
    "<s> sentence segmentation sentence": 1.0,
    "sentence segmentation sentence segmentation": 1.0,
    "segmentation sentence segmentation is": 1.0,
    "sentence segmentation is the": 1.0,
    "segmentation is the problem": 0.5,
    "is the problem of": 0.3333333333333333,
    "the problem of dividing": 0.16666666666666666,
    "problem of dividing a": 1.0,
    "of dividing a string": 1.0,
    "dividing a string of": 1.0,
    "string of written language": 0.5,
    "of written language into": 1.0,
    "written language into its": 1.0,
    "language into its component": 1.0,
    "into its component sentences": 1.0,
    "its component sentences .": 1.0,
    "in english and some": 0.5,
    "english and some other": 1.0,
    "and some other languages": 1.0,
    "some other languages ,": 1.0,
    "other languages , using": 0.5,
    "languages , using punctuation": 1.0,
    ", using punctuation ,": 1.0,
    "using punctuation , particularly": 1.0,
    "punctuation , particularly the": 1.0,
    ", particularly the full": 1.0,
    "particularly the full stop": 1.0,
    "the full stop character": 1.0,
    "full stop character is": 0.5,
    "stop character is a": 1.0,
    "character is a reasonable": 1.0,
    "is a reasonable approximation": 1.0,
    "a reasonable approximation .": 1.0,
    "<s> however even in": 1.0,
    "however even in english": 1.0,
    "even in english this": 1.0,
    "in english this problem": 1.0,
    "english this problem is": 1.0,
    "this problem is not": 0.5,
    "problem is not trivial": 1.0,
    "is not trivial due": 1.0,
    "not trivial due to": 1.0,
    "trivial due to the": 1.0,
    "due to the use": 0.5,
    "the use of the": 0.06666666666666667,
    "use of the full": 1.0,
    "of the full stop": 1.0,
    "full stop character for": 0.5,
    "stop character for abbreviations": 1.0,
    "character for abbreviations ,": 1.0,
    "for abbreviations , which": 1.0,
    "abbreviations , which may": 1.0,
    ", which may or": 1.0,
    "which may or may": 1.0,
    "may or may not": 1.0,
    "or may not also": 1.0,
    "may not also terminate": 1.0,
    "not also terminate a": 1.0,
    "also terminate a sentence": 1.0,
    "terminate a sentence .": 1.0,
    "<s> for example mr.": 0.02857142857142857,
    "for example mr. is": 1.0,
    "example mr. is not": 1.0,
    "mr. is not its": 1.0,
    "is not its own": 1.0,
    "not its own sentence": 1.0,
    "its own sentence in": 1.0,
    "own sentence in ``": 1.0,
    "sentence in `` mr.": 1.0,
    "in `` mr. smith": 1.0,
    "`` mr. smith went": 1.0,
    "mr. smith went to": 1.0,
    "smith went to the": 1.0,
    "went to the shops": 1.0,
    "to the shops in": 1.0,
    "the shops in jones": 1.0,
    "shops in jones street": 1.0,
    "in jones street .": 1.0,
    "jones street . ''": 1.0,
    "<s> when processing plain": 1.0,
    "when processing plain text": 1.0,
    "processing plain text ,": 1.0,
    "plain text , tables": 1.0,
    "text , tables of": 1.0,
    ", tables of abbreviations": 1.0,
    "tables of abbreviations that": 1.0,
    "of abbreviations that contain": 1.0,
    "abbreviations that contain periods": 1.0,
    "that contain periods can": 1.0,
    "contain periods can help": 1.0,
    "periods can help prevent": 1.0,
    "can help prevent incorrect": 1.0,
    "help prevent incorrect assignment": 1.0,
    "prevent incorrect assignment of": 1.0,
    "incorrect assignment of sentence": 1.0,
    "assignment of sentence boundaries": 1.0,
    "of sentence boundaries .": 1.0,
    "<s> as with word": 1.0,
    "as with word segmentation": 1.0,
    "with word segmentation ,": 1.0,
    "word segmentation , not": 1.0,
    "segmentation , not all": 1.0,
    ", not all written": 0.5,
    "not all written languages": 1.0,
    "all written languages contain": 0.5,
    "written languages contain punctuation": 1.0,
    "languages contain punctuation characters": 1.0,
    "contain punctuation characters which": 1.0,
    "punctuation characters which are": 1.0,
    "characters which are useful": 1.0,
    "which are useful for": 1.0,
    "are useful for approximating": 1.0,
    "useful for approximating sentence": 1.0,
    "for approximating sentence boundaries": 1.0,
    "approximating sentence boundaries .": 1.0,
    "<s> other segmentation problems": 1.0,
    "other segmentation problems processes": 1.0,
    "segmentation problems processes may": 1.0,
    "problems processes may be": 1.0,
    "processes may be required": 1.0,
    "may be required to": 1.0,
    "be required to segment": 1.0,
    "required to segment text": 1.0,
    "to segment text into": 0.5,
    "segment text into segments": 1.0,
    "text into segments besides": 1.0,
    "into segments besides words": 1.0,
    "segments besides words ,": 1.0,
    "besides words , including": 1.0,
    "words , including morphemes": 1.0,
    ", including morphemes -lrb-": 1.0,
    "including morphemes -lrb- a": 1.0,
    "morphemes -lrb- a task": 1.0,
    "-lrb- a task usually": 1.0,
    "a task usually called": 1.0,
    "task usually called morphological": 1.0,
    "usually called morphological analysis": 1.0,
    "called morphological analysis -rrb-": 1.0,
    "morphological analysis -rrb- ,": 1.0,
    "analysis -rrb- , paragraphs": 1.0,
    "-rrb- , paragraphs ,": 1.0,
    ", paragraphs , topics": 1.0,
    "paragraphs , topics or": 1.0,
    ", topics or discourse": 1.0,
    "topics or discourse turns": 1.0,
    "or discourse turns .": 1.0,
    "<s> a document may": 1.0,
    "a document may contain": 1.0,
    "document may contain multiple": 0.5,
    "may contain multiple topics": 1.0,
    "contain multiple topics ,": 1.0,
    "multiple topics , and": 1.0,
    "topics , and the": 1.0,
    ", and the task": 0.1,
    "and the task of": 1.0,
    "the task of computerized": 0.16666666666666666,
    "task of computerized text": 1.0,
    "of computerized text segmentation": 1.0,
    "computerized text segmentation may": 1.0,
    "text segmentation may be": 1.0,
    "segmentation may be to": 1.0,
    "may be to discover": 1.0,
    "be to discover these": 1.0,
    "to discover these topics": 1.0,
    "discover these topics automatically": 1.0,
    "these topics automatically and": 1.0,
    "topics automatically and segment": 1.0,
    "automatically and segment the": 1.0,
    "and segment the text": 1.0,
    "segment the text accordingly": 1.0,
    "the text accordingly .": 1.0,
    "<s> the topic boundaries": 1.0,
    "the topic boundaries may": 1.0,
    "topic boundaries may be": 1.0,
    "boundaries may be apparent": 1.0,
    "may be apparent from": 1.0,
    "be apparent from section": 1.0,
    "apparent from section titles": 1.0,
    "from section titles and": 1.0,
    "section titles and paragraphs": 1.0,
    "titles and paragraphs .": 1.0,
    "<s> in other cases": 0.5,
    "in other cases one": 1.0,
    "other cases one needs": 1.0,
    "cases one needs to": 1.0,
    "one needs to use": 1.0,
    "needs to use techniques": 1.0,
    "to use techniques similar": 1.0,
    "use techniques similar to": 1.0,
    "techniques similar to those": 1.0,
    "similar to those used": 0.5,
    "to those used in": 1.0,
    "those used in document": 1.0,
    "used in document classification": 1.0,
    "in document classification .": 1.0,
    "<s> many different approaches": 0.5,
    "many different approaches have": 1.0,
    "different approaches have been": 1.0,
    "approaches have been tried": 0.5,
    "have been tried .": 1.0,
    "<s> automatic segmentation approaches": 0.5,
    "automatic segmentation approaches automatic": 1.0,
    "segmentation approaches automatic segmentation": 1.0,
    "approaches automatic segmentation is": 1.0,
    "automatic segmentation is the": 1.0,
    "language processing of implementing": 0.5,
    "processing of implementing a": 1.0,
    "of implementing a computer": 1.0,
    "implementing a computer process": 1.0,
    "a computer process to": 1.0,
    "computer process to segment": 1.0,
    "process to segment text": 1.0,
    "to segment text .": 0.5,
    "<s> when punctuation and": 1.0,
    "when punctuation and similar": 1.0,
    "punctuation and similar clues": 1.0,
    "and similar clues are": 1.0,
    "similar clues are not": 1.0,
    "clues are not consistently": 1.0,
    "are not consistently available": 1.0,
    "not consistently available ,": 1.0,
    "consistently available , the": 1.0,
    "available , the segmentation": 1.0,
    ", the segmentation task": 1.0,
    "the segmentation task often": 1.0,
    "segmentation task often requires": 1.0,
    "task often requires fairly": 1.0,
    "often requires fairly non-trivial": 1.0,
    "requires fairly non-trivial techniques": 1.0,
    "fairly non-trivial techniques ,": 1.0,
    "non-trivial techniques , such": 1.0,
    "techniques , such as": 1.0,
    ", such as statistical": 0.030303030303030304,
    "such as statistical decision-making": 1.0,
    "as statistical decision-making ,": 1.0,
    "statistical decision-making , large": 1.0,
    "decision-making , large dictionaries": 1.0,
    ", large dictionaries ,": 1.0,
    "large dictionaries , as": 1.0,
    "dictionaries , as well": 1.0,
    "as well as consideration": 0.07692307692307693,
    "well as consideration of": 1.0,
    "as consideration of syntactic": 1.0,
    "consideration of syntactic and": 1.0,
    "of syntactic and semantic": 1.0,
    "syntactic and semantic constraints": 0.5,
    "and semantic constraints .": 1.0,
    "<s> effective natural language": 1.0,
    "effective natural language processing": 1.0,
    "language processing systems and": 0.3333333333333333,
    "processing systems and text": 1.0,
    "systems and text segmentation": 1.0,
    "and text segmentation tools": 1.0,
    "text segmentation tools usually": 0.5,
    "segmentation tools usually operate": 1.0,
    "tools usually operate on": 1.0,
    "usually operate on text": 1.0,
    "operate on text in": 1.0,
    "on text in specific": 1.0,
    "text in specific domains": 1.0,
    "in specific domains and": 1.0,
    "specific domains and sources": 1.0,
    "domains and sources .": 1.0,
    "an example , processing": 0.5,
    "example , processing text": 1.0,
    ", processing text used": 1.0,
    "processing text used in": 1.0,
    "text used in medical": 1.0,
    "used in medical records": 1.0,
    "in medical records is": 1.0,
    "medical records is a": 1.0,
    "records is a very": 1.0,
    "is a very different": 0.3333333333333333,
    "a very different problem": 1.0,
    "very different problem than": 1.0,
    "different problem than processing": 1.0,
    "problem than processing news": 1.0,
    "than processing news articles": 1.0,
    "processing news articles or": 1.0,
    "news articles or real": 1.0,
    "articles or real estate": 1.0,
    "or real estate advertisements": 1.0,
    "real estate advertisements .": 1.0,
    "the process of developing": 0.09090909090909091,
    "process of developing text": 1.0,
    "of developing text segmentation": 1.0,
    "developing text segmentation tools": 1.0,
    "text segmentation tools starts": 0.5,
    "segmentation tools starts with": 1.0,
    "tools starts with collecting": 1.0,
    "starts with collecting a": 1.0,
    "with collecting a large": 1.0,
    "collecting a large corpus": 1.0,
    "a large corpus of": 1.0,
    "large corpus of text": 1.0,
    "corpus of text in": 0.5,
    "of text in an": 1.0,
    "text in an application": 1.0,
    "in an application domain": 1.0,
    "an application domain .": 1.0,
    "<s> there are two": 0.2,
    "there are two general": 0.5,
    "are two general approaches": 1.0,
    "two general approaches :": 1.0,
    "general approaches : manual": 1.0,
    "approaches : manual analysis": 1.0,
    ": manual analysis of": 1.0,
    "manual analysis of text": 1.0,
    "analysis of text and": 1.0,
    "of text and writing": 1.0,
    "text and writing custom": 1.0,
    "and writing custom software": 1.0,
    "writing custom software annotate": 1.0,
    "custom software annotate the": 1.0,
    "software annotate the sample": 1.0,
    "annotate the sample corpus": 1.0,
    "the sample corpus with": 1.0,
    "sample corpus with boundary": 1.0,
    "corpus with boundary information": 1.0,
    "with boundary information and": 1.0,
    "boundary information and use": 1.0,
    "information and use machine": 1.0,
    "and use machine learning": 1.0,
    "use machine learning some": 1.0,
    "machine learning some text": 1.0,
    "learning some text segmentation": 1.0,
    "some text segmentation systems": 1.0,
    "text segmentation systems take": 1.0,
    "segmentation systems take advantage": 1.0,
    "systems take advantage of": 1.0,
    "take advantage of any": 0.25,
    "advantage of any markup": 1.0,
    "of any markup like": 1.0,
    "any markup like html": 1.0,
    "markup like html and": 1.0,
    "like html and know": 1.0,
    "html and know document": 1.0,
    "and know document formats": 1.0,
    "know document formats like": 1.0,
    "document formats like pdf": 1.0,
    "formats like pdf to": 1.0,
    "like pdf to provide": 1.0,
    "pdf to provide additional": 1.0,
    "to provide additional evidence": 1.0,
    "provide additional evidence for": 1.0,
    "additional evidence for sentence": 1.0,
    "evidence for sentence and": 1.0,
    "for sentence and paragraph": 1.0,
    "sentence and paragraph boundaries": 1.0,
    "and paragraph boundaries .": 1.0
}