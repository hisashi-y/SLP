{
    "<s> natural language": 1.0,
    "natural language processing": 0.4057971014492754,
    "language processing -lrb-": 0.1388888888888889,
    "processing -lrb- nlp": 0.42857142857142855,
    "-lrb- nlp -rrb-": 1.0,
    "nlp -rrb- is": 0.25,
    "-rrb- is a": 0.36363636363636365,
    "is a field": 0.05555555555555555,
    "a field of": 1.0,
    "field of computer": 0.16666666666666666,
    "of computer science": 0.25,
    "computer science ,": 0.6,
    "science , artificial": 0.2,
    ", artificial intelligence": 1.0,
    "artificial intelligence -lrb-": 0.125,
    "intelligence -lrb- also": 1.0,
    "-lrb- also called": 0.25,
    "also called machine": 0.3333333333333333,
    "called machine learning": 1.0,
    "machine learning -rrb-": 0.047619047619047616,
    "learning -rrb- ,": 1.0,
    "-rrb- , and": 0.14102564102564102,
    ", and linguistics": 0.005291005291005291,
    "and linguistics concerned": 0.5,
    "linguistics concerned with": 1.0,
    "concerned with the": 0.5,
    "with the interactions": 0.03333333333333333,
    "the interactions between": 1.0,
    "interactions between computers": 1.0,
    "between computers and": 1.0,
    "computers and human": 1.0,
    "and human -lrb-": 1.0,
    "human -lrb- natural": 0.5,
    "-lrb- natural -rrb-": 1.0,
    "natural -rrb- languages": 1.0,
    "-rrb- languages .": 1.0,
    "<s> specifically ,": 1.0,
    "specifically , it": 1.0,
    ", it is": 0.5416666666666666,
    "it is the": 0.06382978723404255,
    "is the process": 0.13333333333333333,
    "the process of": 0.7857142857142857,
    "process of a": 0.08333333333333333,
    "of a computer": 0.03260869565217391,
    "a computer extracting": 0.0625,
    "computer extracting meaningful": 1.0,
    "extracting meaningful information": 1.0,
    "meaningful information from": 1.0,
    "information from natural": 0.3333333333333333,
    "from natural language": 1.0,
    "natural language input": 0.057971014492753624,
    "language input and\\/or": 0.25,
    "input and\\/or producing": 1.0,
    "and\\/or producing natural": 1.0,
    "producing natural language": 1.0,
    "natural language output": 0.014492753623188406,
    "language output .": 1.0,
    "<s> in theory": 0.020618556701030927,
    "in theory ,": 1.0,
    "theory , natural": 0.25,
    ", natural language": 1.0,
    "language processing is": 0.05555555555555555,
    "processing is a": 1.0,
    "is a very": 0.05555555555555555,
    "a very attractive": 0.08333333333333333,
    "very attractive method": 1.0,
    "attractive method of": 1.0,
    "method of human": 0.5,
    "of human --": 0.2,
    "human -- computer": 1.0,
    "-- computer interaction": 1.0,
    "computer interaction .": 1.0,
    "natural language understanding": 0.17391304347826086,
    "language understanding is": 0.13333333333333333,
    "understanding is sometimes": 0.5,
    "is sometimes referred": 0.6666666666666666,
    "sometimes referred to": 1.0,
    "referred to as": 0.5,
    "to as an": 0.5,
    "as an ai-complete": 0.06666666666666667,
    "an ai-complete problem": 1.0,
    "ai-complete problem because": 1.0,
    "problem because it": 1.0,
    "because it seems": 0.3333333333333333,
    "it seems to": 1.0,
    "seems to require": 0.5,
    "to require extensive": 1.0,
    "require extensive knowledge": 0.5,
    "extensive knowledge about": 1.0,
    "knowledge about the": 0.3333333333333333,
    "about the outside": 0.125,
    "the outside world": 1.0,
    "outside world and": 1.0,
    "world and the": 1.0,
    "and the ability": 0.024390243902439025,
    "the ability to": 0.6666666666666666,
    "ability to manipulate": 0.3333333333333333,
    "to manipulate it": 0.5,
    "manipulate it .": 1.0,
    "<s> whether nlp": 0.5,
    "whether nlp is": 1.0,
    "nlp is distinct": 1.0,
    "is distinct from": 1.0,
    "distinct from ,": 0.3333333333333333,
    "from , or": 1.0,
    ", or identical": 0.030303030303030304,
    "or identical to": 1.0,
    "identical to ,": 0.5,
    "to , the": 0.5,
    ", the field": 0.009523809523809525,
    "the field of": 0.5294117647058824,
    "field of computational": 0.08333333333333333,
    "of computational linguistics": 1.0,
    "computational linguistics is": 0.1111111111111111,
    "linguistics is a": 0.3333333333333333,
    "is a matter": 0.018518518518518517,
    "a matter of": 1.0,
    "matter of perspective": 1.0,
    "of perspective .": 1.0,
    "<s> the association": 0.006802721088435374,
    "the association for": 1.0,
    "association for computational": 1.0,
    "for computational linguistics": 1.0,
    "computational linguistics defines": 0.1111111111111111,
    "linguistics defines the": 1.0,
    "defines the latter": 1.0,
    "the latter as": 1.0,
    "latter as focusing": 1.0,
    "as focusing on": 1.0,
    "focusing on the": 1.0,
    "on the theoretical": 0.014925373134328358,
    "the theoretical aspects": 1.0,
    "theoretical aspects of": 1.0,
    "aspects of nlp": 0.16666666666666666,
    "of nlp .": 0.2,
    "<s> on the": 0.4,
    "on the other": 0.07462686567164178,
    "the other hand": 0.625,
    "other hand ,": 1.0,
    "hand , the": 0.14285714285714285,
    ", the open-access": 0.009523809523809525,
    "the open-access journal": 1.0,
    "open-access journal ``": 1.0,
    "journal `` computational": 1.0,
    "`` computational linguistics": 1.0,
    "computational linguistics ''": 0.1111111111111111,
    "linguistics '' ,": 1.0,
    "'' , styles": 0.03333333333333333,
    ", styles itself": 1.0,
    "styles itself as": 1.0,
    "itself as ``": 1.0,
    "as `` the": 0.07142857142857142,
    "`` the longest": 0.125,
    "the longest running": 1.0,
    "longest running publication": 1.0,
    "running publication devoted": 1.0,
    "publication devoted exclusively": 1.0,
    "devoted exclusively to": 1.0,
    "exclusively to the": 1.0,
    "to the design": 0.012987012987012988,
    "the design and": 0.5,
    "design and analysis": 1.0,
    "and analysis of": 1.0,
    "analysis of natural": 0.15384615384615385,
    "of natural language": 0.7391304347826086,
    "language processing systems": 0.08333333333333333,
    "processing systems ''": 0.3333333333333333,
    "systems '' -lrb-": 1.0,
    "'' -lrb- computational": 0.1111111111111111,
    "-lrb- computational linguistics": 1.0,
    "computational linguistics -lrb-": 0.1111111111111111,
    "linguistics -lrb- journal": 0.5,
    "-lrb- journal -rrb-": 1.0,
    "journal -rrb- -rrb-": 1.0,
    "-rrb- -rrb- modern": 0.5,
    "-rrb- modern nlp": 1.0,
    "modern nlp algorithms": 1.0,
    "nlp algorithms are": 0.5,
    "algorithms are grounded": 0.5,
    "are grounded in": 1.0,
    "grounded in machine": 0.6666666666666666,
    "in machine learning": 0.4,
    "machine learning ,": 0.14285714285714285,
    "learning , especially": 0.25,
    ", especially statistical": 0.1111111111111111,
    "especially statistical machine": 1.0,
    "statistical machine learning": 0.2,
    "machine learning .": 0.19047619047619047,
    "<s> research into": 0.5,
    "research into modern": 1.0,
    "into modern statistical": 1.0,
    "modern statistical nlp": 1.0,
    "statistical nlp algorithms": 0.25,
    "nlp algorithms requires": 0.5,
    "algorithms requires an": 1.0,
    "requires an understanding": 1.0,
    "an understanding of": 1.0,
    "understanding of a": 0.2,
    "of a number": 0.021739130434782608,
    "a number of": 0.9565217391304348,
    "number of disparate": 0.027777777777777776,
    "of disparate fields": 1.0,
    "disparate fields ,": 1.0,
    "fields , including": 0.5,
    ", including linguistics": 0.25,
    "including linguistics ,": 1.0,
    "linguistics , computer": 0.125,
    ", computer science": 0.3333333333333333,
    "science , and": 0.2,
    ", and statistics": 0.005291005291005291,
    "and statistics .": 1.0,
    "<s> for a": 0.03508771929824561,
    "for a discussion": 0.03225806451612903,
    "a discussion of": 1.0,
    "discussion of the": 1.0,
    "of the types": 0.005128205128205128,
    "the types of": 1.0,
    "types of algorithms": 0.07142857142857142,
    "of algorithms currently": 1.0,
    "algorithms currently used": 1.0,
    "currently used in": 1.0,
    "used in nlp": 0.043478260869565216,
    "in nlp ,": 0.125,
    "nlp , see": 1.0,
    ", see the": 0.5,
    "see the article": 0.5,
    "the article on": 1.0,
    "article on pattern": 1.0,
    "on pattern recognition": 1.0,
    "pattern recognition .": 0.25,
    "<s> an automated": 0.09090909090909091,
    "an automated online": 0.5,
    "automated online assistant": 1.0,
    "online assistant providing": 1.0,
    "assistant providing customer": 1.0,
    "providing customer service": 1.0,
    "customer service on": 1.0,
    "service on a": 1.0,
    "on a web": 0.041666666666666664,
    "a web page": 1.0,
    "web page ,": 1.0,
    "page , an": 0.25,
    ", an example": 0.1,
    "an example of": 0.375,
    "example of an": 0.2857142857142857,
    "of an application": 0.07692307692307693,
    "an application where": 0.5,
    "application where natural": 1.0,
    "where natural language": 1.0,
    "is a major": 0.018518518518518517,
    "a major component": 0.2,
    "major component .": 1.0,
    "<s> in 1950": 0.020618556701030927,
    "in 1950 ,": 1.0,
    "1950 , alan": 0.5,
    ", alan turing": 1.0,
    "alan turing published": 1.0,
    "turing published his": 1.0,
    "published his famous": 1.0,
    "his famous article": 1.0,
    "famous article ``": 1.0,
    "article `` computing": 1.0,
    "`` computing machinery": 1.0,
    "computing machinery and": 1.0,
    "machinery and intelligence": 1.0,
    "and intelligence ''": 1.0,
    "intelligence '' which": 1.0,
    "'' which proposed": 1.0,
    "which proposed what": 1.0,
    "proposed what is": 1.0,
    "what is now": 0.16666666666666666,
    "is now called": 0.3333333333333333,
    "now called the": 1.0,
    "called the turing": 0.5,
    "the turing test": 1.0,
    "turing test as": 1.0,
    "test as a": 1.0,
    "as a criterion": 0.027777777777777776,
    "a criterion of": 1.0,
    "criterion of intelligence": 1.0,
    "of intelligence .": 1.0,
    "<s> this criterion": 0.019230769230769232,
    "this criterion depends": 1.0,
    "criterion depends on": 1.0,
    "depends on the": 0.7142857142857143,
    "on the ability": 0.014925373134328358,
    "the ability of": 0.3333333333333333,
    "ability of a": 1.0,
    "a computer program": 0.1875,
    "computer program to": 0.2,
    "program to impersonate": 0.5,
    "to impersonate a": 1.0,
    "impersonate a human": 1.0,
    "a human in": 0.09090909090909091,
    "human in a": 1.0,
    "in a real-time": 0.019230769230769232,
    "a real-time written": 1.0,
    "real-time written conversation": 1.0,
    "written conversation with": 1.0,
    "conversation with a": 1.0,
    "with a human": 0.05,
    "a human judge": 0.09090909090909091,
    "human judge ,": 1.0,
    "judge , sufficiently": 1.0,
    ", sufficiently well": 1.0,
    "sufficiently well that": 1.0,
    "well that the": 1.0,
    "that the judge": 0.043478260869565216,
    "the judge is": 1.0,
    "judge is unable": 1.0,
    "is unable to": 1.0,
    "unable to distinguish": 0.5,
    "to distinguish reliably": 0.2,
    "distinguish reliably --": 1.0,
    "reliably -- on": 1.0,
    "-- on the": 1.0,
    "on the basis": 0.029850746268656716,
    "the basis of": 0.75,
    "basis of the": 0.25,
    "of the conversational": 0.005128205128205128,
    "the conversational content": 1.0,
    "conversational content alone": 1.0,
    "content alone --": 1.0,
    "alone -- between": 1.0,
    "-- between the": 1.0,
    "between the program": 0.14285714285714285,
    "the program and": 0.25,
    "program and a": 1.0,
    "and a real": 0.0625,
    "a real human": 0.5,
    "real human .": 1.0,
    "<s> the georgetown": 0.013605442176870748,
    "the georgetown experiment": 1.0,
    "georgetown experiment in": 0.3333333333333333,
    "experiment in 1954": 1.0,
    "in 1954 involved": 0.5,
    "1954 involved fully": 1.0,
    "involved fully automatic": 1.0,
    "fully automatic translation": 0.6666666666666666,
    "automatic translation of": 0.6666666666666666,
    "translation of more": 0.09090909090909091,
    "of more than": 0.25,
    "more than sixty": 0.25,
    "than sixty russian": 1.0,
    "sixty russian sentences": 1.0,
    "russian sentences into": 1.0,
    "sentences into english": 0.6666666666666666,
    "into english .": 1.0,
    "<s> the authors": 0.02040816326530612,
    "the authors claimed": 0.5,
    "authors claimed that": 1.0,
    "claimed that within": 1.0,
    "that within three": 1.0,
    "within three or": 0.5,
    "three or five": 1.0,
    "or five years": 1.0,
    "five years ,": 1.0,
    "years , machine": 0.4,
    ", machine translation": 1.0,
    "machine translation would": 0.045454545454545456,
    "translation would be": 1.0,
    "would be a": 0.3333333333333333,
    "be a solved": 0.15384615384615385,
    "a solved problem": 1.0,
    "solved problem .": 1.0,
    "<s> however ,": 0.8648648648648649,
    "however , real": 0.022727272727272728,
    ", real progress": 1.0,
    "real progress was": 1.0,
    "progress was much": 1.0,
    "was much slower": 1.0,
    "much slower ,": 1.0,
    "slower , and": 0.5,
    ", and after": 0.010582010582010581,
    "and after the": 0.6666666666666666,
    "after the alpac": 0.6666666666666666,
    "the alpac report": 1.0,
    "alpac report in": 0.5,
    "report in 1966": 1.0,
    "in 1966 ,": 1.0,
    "1966 , which": 1.0,
    ", which found": 0.03571428571428571,
    "which found that": 1.0,
    "found that ten": 0.2,
    "that ten years": 1.0,
    "ten years long": 1.0,
    "years long research": 1.0,
    "long research had": 1.0,
    "research had failed": 1.0,
    "had failed to": 1.0,
    "failed to fulfill": 1.0,
    "to fulfill the": 0.5,
    "fulfill the expectations": 1.0,
    "the expectations ,": 1.0,
    "expectations , funding": 1.0,
    ", funding for": 0.3333333333333333,
    "funding for machine": 0.5,
    "for machine translation": 1.0,
    "machine translation was": 0.045454545454545456,
    "translation was dramatically": 0.5,
    "was dramatically reduced": 1.0,
    "dramatically reduced .": 1.0,
    "<s> little further": 1.0,
    "little further research": 1.0,
    "further research in": 1.0,
    "research in machine": 0.14285714285714285,
    "in machine translation": 0.4,
    "translation was conducted": 0.5,
    "was conducted until": 0.5,
    "conducted until the": 1.0,
    "until the late": 1.0,
    "the late 1980s": 0.4444444444444444,
    "late 1980s ,": 0.75,
    "1980s , when": 0.2,
    ", when the": 0.5,
    "when the first": 0.2,
    "the first statistical": 0.09090909090909091,
    "first statistical machine": 1.0,
    "statistical machine translation": 0.8,
    "machine translation systems": 0.022727272727272728,
    "translation systems were": 0.5,
    "systems were developed": 0.3333333333333333,
    "were developed .": 0.4,
    "<s> some notably": 0.0625,
    "some notably successful": 1.0,
    "notably successful nlp": 1.0,
    "successful nlp systems": 1.0,
    "nlp systems developed": 0.3333333333333333,
    "systems developed in": 1.0,
    "developed in the": 1.0,
    "in the 1960s": 0.013071895424836602,
    "the 1960s were": 0.5,
    "1960s were shrdlu": 1.0,
    "were shrdlu ,": 1.0,
    "shrdlu , a": 1.0,
    ", a natural": 0.020833333333333332,
    "a natural language": 0.8,
    "natural language system": 0.014492753623188406,
    "language system working": 1.0,
    "system working in": 1.0,
    "working in restricted": 0.5,
    "in restricted ``": 1.0,
    "restricted `` blocks": 1.0,
    "`` blocks worlds": 0.5,
    "blocks worlds ''": 1.0,
    "worlds '' with": 1.0,
    "'' with restricted": 0.25,
    "with restricted vocabularies": 1.0,
    "restricted vocabularies ,": 1.0,
    "vocabularies , and": 0.5,
    ", and eliza": 0.005291005291005291,
    "and eliza ,": 0.5,
    "eliza , a": 0.3333333333333333,
    ", a simulation": 0.020833333333333332,
    "a simulation of": 1.0,
    "simulation of a": 1.0,
    "of a rogerian": 0.010869565217391304,
    "a rogerian psychotherapist": 1.0,
    "rogerian psychotherapist ,": 1.0,
    "psychotherapist , written": 1.0,
    ", written by": 1.0,
    "written by joseph": 0.16666666666666666,
    "by joseph weizenbaum": 1.0,
    "joseph weizenbaum between": 0.5,
    "weizenbaum between 1964": 1.0,
    "between 1964 to": 1.0,
    "1964 to 1966": 1.0,
    "to 1966 .": 1.0,
    "<s> using almost": 0.5,
    "using almost no": 1.0,
    "almost no information": 1.0,
    "no information about": 1.0,
    "information about human": 0.5,
    "about human thought": 1.0,
    "human thought or": 1.0,
    "thought or emotion": 1.0,
    "or emotion ,": 1.0,
    "emotion , eliza": 1.0,
    ", eliza sometimes": 0.5,
    "eliza sometimes provided": 1.0,
    "sometimes provided a": 1.0,
    "provided a startlingly": 1.0,
    "a startlingly human-like": 1.0,
    "startlingly human-like interaction": 1.0,
    "human-like interaction .": 1.0,
    "<s> when the": 0.16666666666666666,
    "when the ``": 0.2,
    "the `` patient": 0.14285714285714285,
    "`` patient ''": 1.0,
    "patient '' exceeded": 1.0,
    "'' exceeded the": 1.0,
    "exceeded the very": 1.0,
    "the very small": 1.0,
    "very small knowledge": 0.5,
    "small knowledge base": 1.0,
    "knowledge base ,": 0.5,
    "base , eliza": 0.5,
    ", eliza might": 0.5,
    "eliza might provide": 1.0,
    "might provide a": 1.0,
    "provide a generic": 0.5,
    "a generic response": 1.0,
    "generic response ,": 1.0,
    "response , for": 1.0,
    ", for example": 0.45454545454545453,
    "for example ,": 0.8392857142857143,
    "example , responding": 0.018518518518518517,
    ", responding to": 1.0,
    "responding to ``": 1.0,
    "to `` my": 0.25,
    "`` my head": 1.0,
    "my head hurts": 1.0,
    "head hurts ''": 0.5,
    "hurts '' with": 1.0,
    "'' with ``": 0.25,
    "with `` why": 0.3333333333333333,
    "`` why do": 0.3333333333333333,
    "why do you": 1.0,
    "do you say": 1.0,
    "you say your": 1.0,
    "say your head": 1.0,
    "your head hurts": 1.0,
    "head hurts ?": 0.5,
    "hurts ? ''": 1.0,
    "? '' .": 0.16666666666666666,
    "<s> during the": 0.5,
    "during the 70": 0.16666666666666666,
    "the 70 's": 1.0,
    "70 's many": 1.0,
    "'s many programmers": 1.0,
    "many programmers began": 1.0,
    "programmers began to": 1.0,
    "began to write": 0.25,
    "to write `": 1.0,
    "write ` conceptual": 1.0,
    "` conceptual ontologies": 1.0,
    "conceptual ontologies '": 1.0,
    "ontologies ' ,": 1.0,
    "' , which": 0.16666666666666666,
    ", which structured": 0.017857142857142856,
    "which structured real-world": 1.0,
    "structured real-world information": 1.0,
    "real-world information into": 1.0,
    "information into computer-understandable": 0.5,
    "into computer-understandable data": 1.0,
    "computer-understandable data .": 1.0,
    "<s> examples are": 0.6666666666666666,
    "examples are margie": 0.3333333333333333,
    "are margie -lrb-": 1.0,
    "margie -lrb- schank": 1.0,
    "-lrb- schank ,": 1.0,
    "schank , 1975": 1.0,
    ", 1975 -rrb-": 1.0,
    "1975 -rrb- ,": 1.0,
    "-rrb- , sam": 0.01282051282051282,
    ", sam -lrb-": 1.0,
    "sam -lrb- cullingford": 1.0,
    "-lrb- cullingford ,": 1.0,
    "cullingford , 1978": 1.0,
    ", 1978 -rrb-": 1.0,
    "1978 -rrb- ,": 1.0,
    "-rrb- , pam": 0.01282051282051282,
    ", pam -lrb-": 1.0,
    "pam -lrb- wilensky": 1.0,
    "-lrb- wilensky ,": 1.0,
    "wilensky , 1978": 0.5,
    "-rrb- , talespin": 0.01282051282051282,
    ", talespin -lrb-": 1.0,
    "talespin -lrb- meehan": 1.0,
    "-lrb- meehan ,": 1.0,
    "meehan , 1976": 1.0,
    ", 1976 -rrb-": 0.5,
    "1976 -rrb- ,": 1.0,
    "-rrb- , qualm": 0.01282051282051282,
    ", qualm -lrb-": 1.0,
    "qualm -lrb- lehnert": 1.0,
    "-lrb- lehnert ,": 0.5,
    "lehnert , 1977": 0.5,
    ", 1977 -rrb-": 1.0,
    "1977 -rrb- ,": 1.0,
    "-rrb- , politics": 0.01282051282051282,
    ", politics -lrb-": 1.0,
    "politics -lrb- carbonell": 1.0,
    "-lrb- carbonell ,": 1.0,
    "carbonell , 1979": 1.0,
    ", 1979 -rrb-": 1.0,
    "1979 -rrb- ,": 1.0,
    ", and plot": 0.005291005291005291,
    "and plot units": 1.0,
    "plot units -lrb-": 1.0,
    "units -lrb- lehnert": 1.0,
    "-lrb- lehnert 1981": 0.5,
    "lehnert 1981 -rrb-": 1.0,
    "1981 -rrb- .": 1.0,
    "<s> during this": 0.5,
    "during this time": 1.0,
    "this time ,": 0.6666666666666666,
    "time , many": 0.09090909090909091,
    ", many chatterbots": 0.14285714285714285,
    "many chatterbots were": 1.0,
    "chatterbots were written": 1.0,
    "were written including": 1.0,
    "written including parry": 1.0,
    "including parry ,": 1.0,
    "parry , racter": 1.0,
    ", racter ,": 1.0,
    "racter , and": 1.0,
    ", and jabberwacky": 0.005291005291005291,
    "and jabberwacky .": 1.0,
    "<s> up to": 1.0,
    "up to the": 0.16666666666666666,
    "to the 1980s": 0.012987012987012988,
    "the 1980s ,": 0.5,
    "1980s , most": 0.2,
    ", most nlp": 0.125,
    "most nlp systems": 1.0,
    "nlp systems were": 0.3333333333333333,
    "systems were based": 0.16666666666666666,
    "were based on": 1.0,
    "based on complex": 0.021739130434782608,
    "on complex sets": 1.0,
    "complex sets of": 1.0,
    "sets of hand-written": 0.25,
    "of hand-written rules": 1.0,
    "hand-written rules .": 0.3333333333333333,
    "<s> starting in": 1.0,
    "starting in the": 1.0,
    "in the late": 0.032679738562091505,
    "1980s , however": 0.2,
    ", however ,": 1.0,
    "however , there": 0.06818181818181818,
    ", there was": 0.09090909090909091,
    "there was a": 0.6666666666666666,
    "was a revolution": 0.3333333333333333,
    "a revolution in": 1.0,
    "revolution in nlp": 1.0,
    "in nlp with": 0.125,
    "nlp with the": 1.0,
    "with the introduction": 0.03333333333333333,
    "the introduction of": 1.0,
    "introduction of machine": 1.0,
    "of machine learning": 0.625,
    "machine learning algorithms": 0.14285714285714285,
    "learning algorithms for": 0.2,
    "algorithms for language": 0.25,
    "for language processing": 1.0,
    "language processing .": 0.16666666666666666,
    "<s> this was": 0.019230769230769232,
    "this was due": 1.0,
    "was due both": 1.0,
    "due both to": 1.0,
    "both to the": 0.5,
    "to the steady": 0.012987012987012988,
    "the steady increase": 0.5,
    "steady increase in": 1.0,
    "increase in computational": 0.3333333333333333,
    "in computational power": 0.5,
    "computational power resulting": 0.5,
    "power resulting from": 1.0,
    "resulting from moore": 1.0,
    "from moore 's": 1.0,
    "moore 's law": 1.0,
    "'s law and": 1.0,
    "law and the": 1.0,
    "and the gradual": 0.024390243902439025,
    "the gradual lessening": 1.0,
    "gradual lessening of": 1.0,
    "lessening of the": 1.0,
    "of the dominance": 0.005128205128205128,
    "the dominance of": 1.0,
    "dominance of chomskyan": 1.0,
    "of chomskyan theories": 1.0,
    "chomskyan theories of": 1.0,
    "theories of linguistics": 0.3333333333333333,
    "of linguistics -lrb-": 1.0,
    "linguistics -lrb- e.g.": 0.5,
    "-lrb- e.g. transformational": 0.02631578947368421,
    "e.g. transformational grammar": 1.0,
    "transformational grammar -rrb-": 0.5,
    "grammar -rrb- ,": 0.3333333333333333,
    "-rrb- , whose": 0.01282051282051282,
    ", whose theoretical": 0.5,
    "whose theoretical underpinnings": 1.0,
    "theoretical underpinnings discouraged": 1.0,
    "underpinnings discouraged the": 1.0,
    "discouraged the sort": 1.0,
    "the sort of": 1.0,
    "sort of corpus": 0.5,
    "of corpus linguistics": 1.0,
    "corpus linguistics that": 0.3333333333333333,
    "linguistics that underlies": 0.5,
    "that underlies the": 1.0,
    "underlies the machine-learning": 1.0,
    "the machine-learning approach": 0.5,
    "machine-learning approach to": 1.0,
    "approach to language": 0.16666666666666666,
    "to language processing": 1.0,
    "<s> some of": 0.1875,
    "some of the": 0.5882352941176471,
    "of the earliest-used": 0.010256410256410256,
    "the earliest-used machine": 0.5,
    "earliest-used machine learning": 1.0,
    "learning algorithms ,": 0.2,
    "algorithms , such": 0.4,
    ", such as": 0.9428571428571428,
    "such as decision": 0.03333333333333333,
    "as decision trees": 1.0,
    "decision trees ,": 0.75,
    "trees , produced": 0.6666666666666666,
    ", produced systems": 0.6666666666666666,
    "produced systems of": 1.0,
    "systems of hard": 0.3333333333333333,
    "of hard if-then": 1.0,
    "hard if-then rules": 1.0,
    "if-then rules similar": 1.0,
    "rules similar to": 1.0,
    "similar to existing": 0.06666666666666667,
    "to existing hand-written": 1.0,
    "existing hand-written rules": 1.0,
    "<s> increasingly ,": 1.0,
    "increasingly , however": 1.0,
    "however , research": 0.045454545454545456,
    ", research has": 1.0,
    "research has focused": 0.5,
    "has focused on": 1.0,
    "focused on statistical": 0.2,
    "on statistical models": 1.0,
    "statistical models ,": 0.25,
    "models , which": 1.0,
    ", which make": 0.03571428571428571,
    "which make soft": 1.0,
    "make soft ,": 0.5,
    "soft , probabilistic": 1.0,
    ", probabilistic decisions": 0.6666666666666666,
    "probabilistic decisions based": 1.0,
    "decisions based on": 1.0,
    "based on attaching": 0.043478260869565216,
    "on attaching real-valued": 1.0,
    "attaching real-valued weights": 1.0,
    "real-valued weights to": 1.0,
    "weights to the": 0.5,
    "to the features": 0.012987012987012988,
    "the features making": 0.16666666666666666,
    "features making up": 1.0,
    "making up the": 1.0,
    "up the input": 1.0,
    "the input data": 0.25,
    "input data .": 0.6666666666666666,
    "<s> the cache": 0.006802721088435374,
    "the cache language": 1.0,
    "cache language models": 1.0,
    "language models upon": 0.5,
    "models upon which": 1.0,
    "upon which many": 1.0,
    "which many speech": 1.0,
    "many speech recognition": 1.0,
    "speech recognition systems": 0.11842105263157894,
    "recognition systems now": 0.1,
    "systems now rely": 1.0,
    "now rely are": 1.0,
    "rely are examples": 1.0,
    "are examples of": 1.0,
    "examples of such": 0.4,
    "of such statistical": 0.2,
    "such statistical models": 1.0,
    "statistical models .": 0.125,
    "<s> such models": 0.25,
    "such models are": 0.5,
    "models are generally": 0.5,
    "are generally more": 0.5,
    "generally more robust": 1.0,
    "more robust when": 1.0,
    "robust when given": 1.0,
    "when given unfamiliar": 1.0,
    "given unfamiliar input": 1.0,
    "unfamiliar input ,": 0.6666666666666666,
    "input , especially": 0.6666666666666666,
    ", especially input": 0.2222222222222222,
    "especially input that": 1.0,
    "input that contains": 1.0,
    "that contains errors": 0.6666666666666666,
    "contains errors -lrb-": 1.0,
    "errors -lrb- as": 1.0,
    "-lrb- as is": 0.2857142857142857,
    "as is very": 0.5,
    "is very common": 0.3333333333333333,
    "very common for": 1.0,
    "common for real-world": 1.0,
    "for real-world data": 1.0,
    "real-world data -rrb-": 1.0,
    "data -rrb- ,": 0.3333333333333333,
    ", and produce": 0.005291005291005291,
    "and produce more": 0.5,
    "produce more reliable": 1.0,
    "more reliable results": 0.6666666666666666,
    "reliable results when": 1.0,
    "results when integrated": 0.5,
    "when integrated into": 1.0,
    "integrated into a": 1.0,
    "into a larger": 0.058823529411764705,
    "a larger system": 0.5,
    "larger system comprising": 0.5,
    "system comprising multiple": 1.0,
    "comprising multiple subtasks": 1.0,
    "multiple subtasks .": 1.0,
    "<s> many of": 0.18181818181818182,
    "many of the": 0.75,
    "of the notable": 0.005128205128205128,
    "the notable early": 1.0,
    "notable early successes": 1.0,
    "early successes occurred": 1.0,
    "successes occurred in": 1.0,
    "occurred in the": 1.0,
    "in the field": 0.0784313725490196,
    "field of machine": 0.08333333333333333,
    "of machine translation": 0.375,
    "machine translation ,": 0.1590909090909091,
    "translation , due": 0.125,
    ", due especially": 1.0,
    "due especially to": 1.0,
    "especially to work": 1.0,
    "to work at": 0.5,
    "work at ibm": 1.0,
    "at ibm research": 1.0,
    "ibm research ,": 1.0,
    "research , where": 0.25,
    ", where successively": 0.06666666666666667,
    "where successively more": 1.0,
    "successively more complicated": 1.0,
    "more complicated statistical": 1.0,
    "complicated statistical models": 1.0,
    "statistical models were": 0.125,
    "models were developed": 1.0,
    "<s> these systems": 0.25,
    "these systems were": 0.1111111111111111,
    "systems were able": 0.16666666666666666,
    "were able to": 1.0,
    "able to take": 0.0625,
    "to take advantage": 0.4,
    "take advantage of": 1.0,
    "advantage of existing": 0.25,
    "of existing multilingual": 0.5,
    "existing multilingual textual": 1.0,
    "multilingual textual corpora": 1.0,
    "textual corpora that": 1.0,
    "corpora that had": 1.0,
    "that had been": 1.0,
    "had been produced": 1.0,
    "been produced by": 1.0,
    "produced by the": 0.3333333333333333,
    "by the parliament": 0.03571428571428571,
    "the parliament of": 1.0,
    "parliament of canada": 1.0,
    "of canada and": 0.5,
    "canada and the": 1.0,
    "and the european": 0.024390243902439025,
    "the european union": 0.3333333333333333,
    "european union as": 1.0,
    "union as a": 1.0,
    "as a result": 0.08333333333333333,
    "a result of": 0.3333333333333333,
    "result of laws": 0.3333333333333333,
    "of laws calling": 1.0,
    "laws calling for": 1.0,
    "calling for the": 1.0,
    "for the translation": 0.03125,
    "the translation of": 0.5,
    "translation of all": 0.09090909090909091,
    "of all governmental": 0.25,
    "all governmental proceedings": 1.0,
    "governmental proceedings into": 1.0,
    "proceedings into all": 1.0,
    "into all official": 1.0,
    "all official languages": 1.0,
    "official languages of": 1.0,
    "languages of the": 1.0,
    "of the corresponding": 0.005128205128205128,
    "the corresponding systems": 0.5,
    "corresponding systems of": 1.0,
    "systems of government": 0.16666666666666666,
    "of government .": 0.5,
    "however , most": 0.045454545454545456,
    ", most other": 0.125,
    "most other systems": 1.0,
    "other systems depended": 0.3333333333333333,
    "systems depended on": 1.0,
    "depended on corpora": 1.0,
    "on corpora specifically": 1.0,
    "corpora specifically developed": 1.0,
    "specifically developed for": 1.0,
    "developed for the": 1.0,
    "for the tasks": 0.03125,
    "the tasks implemented": 1.0,
    "tasks implemented by": 1.0,
    "implemented by these": 1.0,
    "by these systems": 1.0,
    "these systems ,": 0.1111111111111111,
    "systems , which": 0.16666666666666666,
    ", which was": 0.07142857142857142,
    "which was -lrb-": 0.2,
    "was -lrb- and": 1.0,
    "-lrb- and often": 0.2,
    "and often continues": 0.3333333333333333,
    "often continues to": 1.0,
    "continues to be": 1.0,
    "to be -rrb-": 0.023255813953488372,
    "be -rrb- a": 1.0,
    "-rrb- a major": 0.5,
    "a major limitation": 0.2,
    "major limitation in": 1.0,
    "limitation in the": 1.0,
    "in the success": 0.006535947712418301,
    "the success of": 1.0,
    "success of these": 0.3333333333333333,
    "of these systems": 0.09090909090909091,
    "these systems .": 0.1111111111111111,
    "<s> as a": 0.14285714285714285,
    "a result ,": 0.6666666666666666,
    "result , a": 0.3333333333333333,
    ", a great": 0.020833333333333332,
    "a great deal": 0.5,
    "great deal of": 1.0,
    "deal of research": 1.0,
    "of research has": 0.125,
    "research has gone": 0.16666666666666666,
    "has gone into": 1.0,
    "gone into methods": 1.0,
    "into methods of": 1.0,
    "methods of more": 0.5,
    "of more effectively": 0.25,
    "more effectively learning": 1.0,
    "effectively learning from": 1.0,
    "learning from limited": 0.5,
    "from limited amounts": 1.0,
    "limited amounts of": 1.0,
    "amounts of data": 0.5,
    "of data .": 0.14285714285714285,
    "<s> recent research": 0.6666666666666666,
    "recent research has": 0.5,
    "research has increasingly": 0.16666666666666666,
    "has increasingly focused": 1.0,
    "increasingly focused on": 1.0,
    "focused on unsupervised": 0.1,
    "on unsupervised and": 1.0,
    "unsupervised and semi-supervised": 1.0,
    "and semi-supervised learning": 1.0,
    "semi-supervised learning algorithms": 1.0,
    "learning algorithms .": 0.2,
    "<s> such algorithms": 0.125,
    "such algorithms are": 1.0,
    "algorithms are able": 0.5,
    "are able to": 1.0,
    "able to learn": 0.0625,
    "to learn from": 0.16666666666666666,
    "learn from data": 1.0,
    "from data that": 0.5,
    "data that has": 0.5,
    "that has not": 0.16666666666666666,
    "has not been": 0.5,
    "not been hand-annotated": 0.5,
    "been hand-annotated with": 1.0,
    "hand-annotated with the": 1.0,
    "with the desired": 0.03333333333333333,
    "the desired answers": 0.25,
    "desired answers ,": 1.0,
    "answers , or": 1.0,
    ", or using": 0.06060606060606061,
    "or using a": 0.5,
    "using a combination": 0.1,
    "a combination of": 0.5,
    "combination of annotated": 1.0,
    "of annotated and": 1.0,
    "annotated and non-annotated": 1.0,
    "and non-annotated data": 1.0,
    "non-annotated data .": 0.5,
    "<s> generally ,": 0.6,
    "generally , this": 0.25,
    ", this task": 0.16666666666666666,
    "this task is": 0.3333333333333333,
    "task is much": 0.16666666666666666,
    "is much more": 0.5,
    "much more difficult": 0.75,
    "more difficult than": 0.42857142857142855,
    "difficult than supervised": 0.3333333333333333,
    "than supervised learning": 1.0,
    "supervised learning ,": 0.2,
    "learning , and": 0.25,
    ", and typically": 0.005291005291005291,
    "and typically produces": 0.5,
    "typically produces less": 1.0,
    "produces less accurate": 1.0,
    "less accurate results": 1.0,
    "accurate results for": 1.0,
    "results for a": 1.0,
    "for a given": 0.03225806451612903,
    "a given amount": 0.08333333333333333,
    "given amount of": 1.0,
    "amount of input": 0.2,
    "of input data": 0.3333333333333333,
    ", there is": 0.5454545454545454,
    "there is an": 0.058823529411764705,
    "is an enormous": 0.1,
    "an enormous amount": 1.0,
    "enormous amount of": 1.0,
    "amount of non-annotated": 0.2,
    "of non-annotated data": 1.0,
    "non-annotated data available": 0.5,
    "data available -lrb-": 0.3333333333333333,
    "available -lrb- including": 1.0,
    "-lrb- including ,": 1.0,
    "including , among": 1.0,
    ", among other": 1.0,
    "among other things": 0.6666666666666666,
    "other things ,": 0.3333333333333333,
    "things , the": 1.0,
    ", the entire": 0.009523809523809525,
    "the entire content": 1.0,
    "entire content of": 1.0,
    "content of the": 1.0,
    "of the world": 0.010256410256410256,
    "the world wide": 0.5,
    "world wide web": 1.0,
    "wide web -rrb-": 0.25,
    "web -rrb- ,": 1.0,
    "-rrb- , which": 0.038461538461538464,
    ", which can": 0.03571428571428571,
    "which can often": 0.2,
    "can often make": 1.0,
    "often make up": 1.0,
    "make up for": 0.5,
    "up for the": 0.5,
    "for the inferior": 0.03125,
    "the inferior results": 1.0,
    "inferior results .": 1.0,
    "<s> nlp using": 1.0,
    "nlp using machine": 1.0,
    "using machine learning": 1.0,
    "machine learning as": 0.047619047619047616,
    "learning as described": 1.0,
    "as described above": 0.6666666666666666,
    "described above ,": 0.25,
    "above , modern": 0.25,
    ", modern approaches": 1.0,
    "modern approaches to": 1.0,
    "approaches to natural": 0.2,
    "to natural language": 1.0,
    "nlp -rrb- are": 0.25,
    "-rrb- are grounded": 0.3333333333333333,
    "<s> the paradigm": 0.006802721088435374,
    "the paradigm of": 1.0,
    "paradigm of machine": 1.0,
    "machine learning is": 0.047619047619047616,
    "learning is different": 1.0,
    "is different from": 1.0,
    "different from that": 0.16666666666666666,
    "from that of": 1.0,
    "that of most": 0.125,
    "of most prior": 1.0,
    "most prior attempts": 1.0,
    "prior attempts at": 1.0,
    "attempts at language": 0.5,
    "at language processing": 1.0,
    "<s> prior implementations": 1.0,
    "prior implementations of": 1.0,
    "implementations of language-processing": 0.5,
    "of language-processing tasks": 1.0,
    "language-processing tasks typically": 1.0,
    "tasks typically involved": 1.0,
    "typically involved the": 1.0,
    "involved the direct": 1.0,
    "the direct hand": 1.0,
    "direct hand coding": 1.0,
    "hand coding of": 1.0,
    "coding of large": 1.0,
    "of large sets": 0.25,
    "large sets of": 1.0,
    "sets of rules": 0.5,
    "of rules .": 0.6666666666666666,
    "<s> the machine-learning": 0.006802721088435374,
    "the machine-learning paradigm": 0.5,
    "machine-learning paradigm calls": 1.0,
    "paradigm calls instead": 1.0,
    "calls instead for": 1.0,
    "instead for using": 1.0,
    "for using general": 1.0,
    "using general learning": 1.0,
    "general learning algorithms": 1.0,
    "learning algorithms --": 0.2,
    "algorithms -- often": 1.0,
    "-- often ,": 1.0,
    "often , although": 1.0,
    ", although not": 0.25,
    "although not always": 1.0,
    "not always ,": 1.0,
    "always , grounded": 1.0,
    ", grounded in": 1.0,
    "grounded in statistical": 0.3333333333333333,
    "in statistical inference": 0.3333333333333333,
    "statistical inference --": 0.5,
    "inference -- to": 1.0,
    "-- to automatically": 1.0,
    "to automatically learn": 0.3333333333333333,
    "automatically learn such": 0.5,
    "learn such rules": 1.0,
    "such rules through": 1.0,
    "rules through the": 1.0,
    "through the analysis": 0.25,
    "the analysis of": 1.0,
    "analysis of large": 0.15384615384615385,
    "of large corpora": 0.25,
    "large corpora of": 1.0,
    "corpora of typical": 1.0,
    "of typical real-world": 1.0,
    "typical real-world examples": 1.0,
    "real-world examples .": 1.0,
    "<s> a corpus": 0.022727272727272728,
    "a corpus -lrb-": 0.25,
    "corpus -lrb- plural": 0.5,
    "-lrb- plural ,": 1.0,
    "plural , ``": 0.5,
    ", `` corpora": 0.04,
    "`` corpora ''": 1.0,
    "corpora '' -rrb-": 1.0,
    "'' -rrb- is": 0.07142857142857142,
    "is a set": 0.037037037037037035,
    "a set of": 1.0,
    "set of documents": 0.10714285714285714,
    "of documents -lrb-": 0.2,
    "documents -lrb- or": 0.2,
    "-lrb- or sometimes": 0.1,
    "or sometimes ,": 1.0,
    "sometimes , individual": 1.0,
    ", individual sentences": 1.0,
    "individual sentences -rrb-": 1.0,
    "sentences -rrb- that": 0.5,
    "-rrb- that have": 0.5,
    "that have been": 0.5,
    "have been hand-annotated": 0.038461538461538464,
    "with the correct": 0.03333333333333333,
    "the correct values": 0.16666666666666666,
    "correct values to": 1.0,
    "values to be": 1.0,
    "to be learned": 0.023255813953488372,
    "be learned .": 1.0,
    "<s> consider the": 1.0,
    "consider the task": 0.25,
    "the task of": 0.5454545454545454,
    "task of part": 0.1111111111111111,
    "of part of": 1.0,
    "part of speech": 0.6363636363636364,
    "of speech tagging": 0.0425531914893617,
    "speech tagging ,": 1.0,
    "tagging , i.e.": 0.5,
    ", i.e. determining": 0.14285714285714285,
    "i.e. determining the": 1.0,
    "determining the correct": 0.25,
    "the correct part": 0.5,
    "correct part of": 1.0,
    "of speech of": 0.02127659574468085,
    "speech of each": 1.0,
    "of each word": 0.2857142857142857,
    "each word in": 0.16666666666666666,
    "word in a": 0.75,
    "in a given": 0.038461538461538464,
    "a given sentence": 0.16666666666666666,
    "given sentence ,": 0.5,
    "sentence , typically": 0.3333333333333333,
    ", typically one": 0.3333333333333333,
    "typically one that": 1.0,
    "one that has": 1.0,
    "that has never": 0.16666666666666666,
    "has never been": 1.0,
    "never been seen": 0.5,
    "been seen before": 0.6666666666666666,
    "seen before .": 0.5,
    "<s> a typical": 0.045454545454545456,
    "a typical machine-learning-based": 0.25,
    "typical machine-learning-based implementation": 1.0,
    "machine-learning-based implementation of": 1.0,
    "implementation of a": 0.5,
    "of a part": 0.010869565217391304,
    "a part of": 1.0,
    "of speech tagger": 0.02127659574468085,
    "speech tagger proceeds": 1.0,
    "tagger proceeds in": 1.0,
    "proceeds in two": 1.0,
    "in two steps": 1.0,
    "two steps ,": 1.0,
    "steps , a": 1.0,
    ", a training": 0.020833333333333332,
    "a training step": 1.0,
    "training step and": 0.5,
    "step and an": 1.0,
    "and an evaluation": 0.3333333333333333,
    "an evaluation step": 1.0,
    "evaluation step .": 0.5,
    "<s> the first": 0.04081632653061224,
    "the first step": 0.045454545454545456,
    "first step --": 0.5,
    "step -- the": 0.5,
    "-- the training": 0.3333333333333333,
    "the training step": 0.25,
    "training step --": 0.5,
    "step -- makes": 0.5,
    "-- makes use": 1.0,
    "makes use of": 1.0,
    "use of a": 0.18181818181818182,
    "of a corpus": 0.010869565217391304,
    "a corpus of": 0.5,
    "corpus of training": 0.25,
    "of training data": 0.75,
    "training data ,": 0.3,
    "data , which": 0.1,
    ", which consists": 0.017857142857142856,
    "which consists of": 1.0,
    "consists of a": 0.5,
    "of a large": 0.010869565217391304,
    "a large number": 0.1111111111111111,
    "large number of": 1.0,
    "number of sentences": 0.05555555555555555,
    "of sentences ,": 0.2857142857142857,
    "sentences , each": 0.125,
    ", each of": 0.5,
    "each of which": 0.8,
    "of which has": 0.1,
    "which has the": 0.14285714285714285,
    "has the correct": 0.5,
    "of speech attached": 0.02127659574468085,
    "speech attached to": 1.0,
    "attached to each": 1.0,
    "to each word": 0.2,
    "each word .": 0.5,
    "<s> -lrb- an": 0.10526315789473684,
    "-lrb- an example": 0.5,
    "example of such": 0.2857142857142857,
    "of such a": 0.6,
    "such a corpus": 0.14285714285714285,
    "a corpus in": 0.25,
    "corpus in common": 0.5,
    "in common use": 0.3333333333333333,
    "common use is": 0.5,
    "use is the": 1.0,
    "is the penn": 0.022222222222222223,
    "the penn treebank": 0.75,
    "penn treebank .": 0.3333333333333333,
    "<s> this includes": 0.019230769230769232,
    "this includes -lrb-": 1.0,
    "includes -lrb- among": 1.0,
    "-lrb- among other": 0.5,
    "other things -rrb-": 0.3333333333333333,
    "things -rrb- a": 1.0,
    "-rrb- a set": 0.5,
    "set of 500": 0.03571428571428571,
    "of 500 texts": 0.5,
    "500 texts from": 1.0,
    "texts from the": 1.0,
    "from the brown": 0.09090909090909091,
    "the brown corpus": 1.0,
    "brown corpus ,": 0.08333333333333333,
    "corpus , containing": 0.3333333333333333,
    ", containing examples": 0.5,
    "containing examples of": 1.0,
    "examples of various": 0.2,
    "of various genres": 1.0,
    "various genres of": 1.0,
    "genres of text": 0.5,
    "of text ,": 0.4166666666666667,
    "text , and": 0.1,
    ", and 2500": 0.005291005291005291,
    "and 2500 articles": 1.0,
    "2500 articles from": 1.0,
    "articles from the": 1.0,
    "from the wall": 0.045454545454545456,
    "the wall street": 1.0,
    "wall street journal": 1.0,
    "street journal .": 0.5,
    "journal . -rrb-": 1.0,
    "<s> this corpus": 0.038461538461538464,
    "this corpus is": 0.5,
    "corpus is analyzed": 1.0,
    "is analyzed and": 0.3333333333333333,
    "analyzed and a": 1.0,
    "and a learning": 0.0625,
    "a learning model": 0.5,
    "learning model is": 1.0,
    "model is generated": 0.3333333333333333,
    "is generated from": 0.3333333333333333,
    "generated from it": 0.5,
    "from it ,": 1.0,
    "it , consisting": 0.5,
    ", consisting of": 1.0,
    "consisting of automatically": 0.5,
    "of automatically created": 0.5,
    "automatically created rules": 1.0,
    "created rules for": 1.0,
    "rules for determining": 0.5,
    "for determining the": 0.5,
    "determining the part": 0.25,
    "the part of": 1.0,
    "of speech for": 0.0851063829787234,
    "speech for a": 0.25,
    "for a word": 0.03225806451612903,
    "a word in": 0.16666666666666666,
    "in a sentence": 0.038461538461538464,
    "a sentence ,": 0.14285714285714285,
    ", typically based": 0.3333333333333333,
    "typically based on": 1.0,
    "based on the": 0.2391304347826087,
    "on the nature": 0.014925373134328358,
    "the nature of": 1.0,
    "nature of the": 0.8333333333333334,
    "of the word": 0.020512820512820513,
    "the word in": 0.125,
    "word in question": 0.25,
    "in question ,": 0.5,
    "question , the": 0.18181818181818182,
    ", the nature": 0.009523809523809525,
    "nature of surrounding": 0.16666666666666666,
    "of surrounding words": 1.0,
    "surrounding words ,": 0.5,
    "words , and": 0.1875,
    ", and the": 0.05291005291005291,
    "and the most": 0.024390243902439025,
    "the most likely": 0.08333333333333333,
    "most likely part": 0.3333333333333333,
    "likely part of": 1.0,
    "speech for those": 0.25,
    "for those surrounding": 0.5,
    "those surrounding words": 1.0,
    "surrounding words .": 0.5,
    "<s> the model": 0.006802721088435374,
    "the model that": 0.75,
    "model that is": 0.25,
    "that is generated": 0.05263157894736842,
    "is generated is": 0.3333333333333333,
    "generated is typically": 1.0,
    "is typically the": 0.3333333333333333,
    "typically the best": 1.0,
    "the best model": 0.07142857142857142,
    "best model that": 1.0,
    "model that can": 0.25,
    "that can be": 0.38461538461538464,
    "can be found": 0.03296703296703297,
    "be found that": 0.3333333333333333,
    "found that simultaneously": 0.2,
    "that simultaneously meets": 1.0,
    "simultaneously meets two": 1.0,
    "meets two conflicting": 1.0,
    "two conflicting objectives": 1.0,
    "conflicting objectives :": 1.0,
    "objectives : to": 1.0,
    ": to perform": 1.0,
    "to perform as": 0.2,
    "perform as well": 1.0,
    "as well as": 0.8666666666666667,
    "well as possible": 0.15384615384615385,
    "as possible on": 0.2,
    "possible on the": 1.0,
    "on the training": 0.014925373134328358,
    "the training data": 0.75,
    "data , and": 0.3,
    ", and to": 0.021164021164021163,
    "and to be": 0.09090909090909091,
    "to be as": 0.023255813953488372,
    "be as simple": 0.6666666666666666,
    "as simple as": 1.0,
    "simple as possible": 0.5,
    "as possible -lrb-": 0.2,
    "possible -lrb- so": 1.0,
    "-lrb- so that": 0.5,
    "so that the": 0.3333333333333333,
    "that the model": 0.043478260869565216,
    "the model avoids": 0.25,
    "model avoids overfitting": 1.0,
    "avoids overfitting the": 1.0,
    "overfitting the training": 1.0,
    "data , i.e.": 0.1,
    ", i.e. so": 0.14285714285714285,
    "i.e. so that": 1.0,
    "so that it": 0.16666666666666666,
    "that it generalizes": 0.3333333333333333,
    "it generalizes as": 1.0,
    "generalizes as well": 1.0,
    "as possible to": 0.2,
    "possible to new": 0.3333333333333333,
    "to new data": 0.25,
    "new data rather": 1.0,
    "data rather than": 1.0,
    "rather than only": 0.14285714285714285,
    "than only succeeding": 0.5,
    "only succeeding on": 1.0,
    "succeeding on sentences": 1.0,
    "on sentences that": 1.0,
    "sentences that have": 0.2,
    "that have already": 0.16666666666666666,
    "have already been": 1.0,
    "already been seen": 0.5,
    "been seen -rrb-": 0.3333333333333333,
    "seen -rrb- .": 1.0,
    "<s> in the": 0.12371134020618557,
    "in the second": 0.006535947712418301,
    "the second step": 0.3333333333333333,
    "second step -lrb-": 0.5,
    "step -lrb- the": 1.0,
    "-lrb- the evaluation": 0.125,
    "the evaluation step": 0.2,
    "evaluation step -rrb-": 0.5,
    "step -rrb- ,": 1.0,
    "-rrb- , the": 0.0641025641025641,
    ", the model": 0.009523809523809525,
    "model that has": 0.5,
    "that has been": 0.6666666666666666,
    "has been learned": 0.07142857142857142,
    "been learned is": 0.5,
    "learned is used": 1.0,
    "is used to": 0.5384615384615384,
    "used to process": 0.045454545454545456,
    "to process new": 0.3333333333333333,
    "process new sentences": 1.0,
    "new sentences .": 1.0,
    "<s> an important": 0.18181818181818182,
    "an important part": 0.25,
    "important part of": 1.0,
    "part of the": 0.09090909090909091,
    "of the development": 0.005128205128205128,
    "the development of": 1.0,
    "development of any": 0.14285714285714285,
    "of any learning": 0.3333333333333333,
    "any learning algorithm": 1.0,
    "learning algorithm is": 0.2,
    "algorithm is testing": 0.2,
    "is testing the": 1.0,
    "testing the model": 1.0,
    "been learned on": 0.5,
    "learned on new": 1.0,
    "on new ,": 1.0,
    "new , previously": 1.0,
    ", previously unseen": 1.0,
    "previously unseen data": 1.0,
    "unseen data .": 1.0,
    "<s> it is": 0.5588235294117647,
    "it is critical": 0.02127659574468085,
    "is critical that": 1.0,
    "critical that the": 1.0,
    "that the data": 0.043478260869565216,
    "the data used": 0.5,
    "data used for": 1.0,
    "used for testing": 0.06666666666666667,
    "for testing is": 1.0,
    "testing is not": 1.0,
    "is not the": 0.05263157894736842,
    "not the same": 0.2,
    "the same as": 0.08333333333333333,
    "same as the": 1.0,
    "as the data": 0.03571428571428571,
    "used for training": 0.06666666666666667,
    "for training ;": 0.3333333333333333,
    "training ; otherwise": 1.0,
    "; otherwise ,": 1.0,
    "otherwise , the": 1.0,
    ", the testing": 0.009523809523809525,
    "the testing accuracy": 1.0,
    "testing accuracy will": 1.0,
    "accuracy will be": 1.0,
    "will be unrealistically": 0.1111111111111111,
    "be unrealistically high": 1.0,
    "unrealistically high .": 1.0,
    "<s> many different": 0.18181818181818182,
    "many different classes": 0.16666666666666666,
    "different classes of": 1.0,
    "classes of machine": 0.5,
    "learning algorithms have": 0.2,
    "algorithms have been": 0.6666666666666666,
    "have been applied": 0.038461538461538464,
    "been applied to": 0.8333333333333334,
    "applied to nlp": 0.09090909090909091,
    "to nlp tasks": 1.0,
    "nlp tasks .": 0.5,
    "<s> in common": 0.010309278350515464,
    "in common to": 0.3333333333333333,
    "common to all": 1.0,
    "to all of": 0.3333333333333333,
    "all of these": 0.25,
    "of these algorithms": 0.09090909090909091,
    "these algorithms is": 1.0,
    "algorithms is that": 1.0,
    "is that they": 0.16666666666666666,
    "that they take": 0.14285714285714285,
    "they take as": 1.0,
    "take as input": 1.0,
    "as input a": 0.5,
    "input a large": 1.0,
    "a large set": 0.1111111111111111,
    "large set of": 1.0,
    "set of ``": 0.03571428571428571,
    "of `` features": 0.125,
    "`` features ''": 1.0,
    "features '' that": 1.0,
    "'' that are": 0.25,
    "that are generated": 0.06666666666666667,
    "are generated from": 1.0,
    "generated from the": 0.5,
    "from the input": 0.045454545454545456,
    "<s> as an": 0.14285714285714285,
    "as an example": 0.13333333333333333,
    "an example ,": 0.25,
    "example , for": 0.018518518518518517,
    ", for a": 0.09090909090909091,
    "for a part-of-speech": 0.03225806451612903,
    "a part-of-speech tagger": 1.0,
    "part-of-speech tagger ,": 1.0,
    "tagger , typical": 0.2,
    ", typical features": 1.0,
    "typical features might": 1.0,
    "features might be": 0.5,
    "might be the": 0.16666666666666666,
    "be the identity": 0.3333333333333333,
    "the identity of": 1.0,
    "identity of the": 0.5,
    "the word being": 0.25,
    "word being processed": 0.5,
    "being processed ,": 1.0,
    "processed , the": 1.0,
    ", the identity": 0.009523809523809525,
    "of the words": 0.015384615384615385,
    "the words immediately": 0.16666666666666666,
    "words immediately to": 1.0,
    "immediately to the": 1.0,
    "to the left": 0.025974025974025976,
    "the left and": 0.5,
    "left and right": 1.0,
    "and right ,": 0.5,
    "right , the": 1.0,
    ", the part-of-speech": 0.009523809523809525,
    "the part-of-speech tag": 1.0,
    "part-of-speech tag of": 1.0,
    "tag of the": 1.0,
    "the word to": 0.125,
    "word to the": 1.0,
    "the left ,": 0.5,
    "left , and": 1.0,
    ", and whether": 0.005291005291005291,
    "and whether the": 1.0,
    "whether the word": 0.5,
    "word being considered": 0.5,
    "being considered or": 0.5,
    "considered or its": 1.0,
    "or its immediate": 1.0,
    "its immediate neighbors": 1.0,
    "immediate neighbors are": 1.0,
    "neighbors are content": 1.0,
    "are content words": 1.0,
    "content words or": 1.0,
    "words or function": 0.14285714285714285,
    "or function words": 1.0,
    "function words .": 1.0,
    "<s> the algorithms": 0.013605442176870748,
    "the algorithms differ": 0.25,
    "algorithms differ ,": 1.0,
    "differ , however": 1.0,
    "however , in": 0.09090909090909091,
    ", in the": 0.23529411764705882,
    "in the nature": 0.006535947712418301,
    "of the rules": 0.010256410256410256,
    "the rules generated": 0.2,
    "rules generated .": 1.0,
    "the earliest-used algorithms": 0.5,
    "earliest-used algorithms ,": 1.0,
    "similar to the": 0.3333333333333333,
    "to the systems": 0.012987012987012988,
    "the systems of": 0.25,
    "systems of hand-written": 0.3333333333333333,
    "hand-written rules that": 0.3333333333333333,
    "rules that were": 0.25,
    "that were then": 0.25,
    "were then common": 1.0,
    "then common .": 1.0,
    "weights to each": 0.5,
    "to each input": 0.2,
    "each input feature": 1.0,
    "input feature .": 1.0,
    "such models have": 0.5,
    "models have the": 1.0,
    "have the advantage": 1.0,
    "the advantage that": 1.0,
    "advantage that they": 1.0,
    "that they can": 0.42857142857142855,
    "they can express": 0.2857142857142857,
    "can express the": 0.5,
    "express the relative": 0.5,
    "the relative certainty": 1.0,
    "relative certainty of": 1.0,
    "certainty of many": 1.0,
    "of many different": 1.0,
    "many different possible": 0.16666666666666666,
    "different possible answers": 1.0,
    "possible answers rather": 1.0,
    "answers rather than": 1.0,
    "than only one": 0.5,
    "only one ,": 1.0,
    "one , producing": 0.25,
    ", producing more": 1.0,
    "producing more reliable": 1.0,
    "results when such": 0.5,
    "when such a": 0.5,
    "such a model": 0.14285714285714285,
    "a model is": 1.0,
    "model is included": 0.3333333333333333,
    "is included as": 1.0,
    "included as a": 1.0,
    "as a component": 0.05555555555555555,
    "a component of": 1.0,
    "component of a": 0.6666666666666666,
    "of a larger": 0.021739130434782608,
    "larger system .": 0.5,
    "<s> in addition": 0.030927835051546393,
    "in addition ,": 0.3333333333333333,
    "addition , models": 0.5,
    ", models that": 1.0,
    "models that make": 0.3333333333333333,
    "that make soft": 0.6666666666666666,
    "make soft decisions": 0.5,
    "soft decisions are": 0.5,
    "decisions are generally": 1.0,
    "data -rrb- .": 0.6666666666666666,
    "<s> systems based": 0.375,
    "systems based on": 1.0,
    "based on machine-learning": 0.021739130434782608,
    "on machine-learning algorithms": 1.0,
    "machine-learning algorithms have": 1.0,
    "algorithms have many": 0.3333333333333333,
    "have many advantages": 0.2,
    "many advantages over": 1.0,
    "advantages over hand-produced": 1.0,
    "over hand-produced rules": 1.0,
    "hand-produced rules :": 1.0,
    "rules : the": 0.5,
    ": the learning": 0.16666666666666666,
    "the learning procedures": 0.5,
    "learning procedures used": 0.5,
    "procedures used during": 1.0,
    "used during machine": 1.0,
    "during machine learning": 1.0,
    "machine learning automatically": 0.047619047619047616,
    "learning automatically focus": 1.0,
    "automatically focus on": 1.0,
    "focus on the": 0.25,
    "on the most": 0.014925373134328358,
    "the most common": 0.25,
    "most common cases": 0.16666666666666666,
    "common cases ,": 1.0,
    "cases , whereas": 0.14285714285714285,
    ", whereas when": 0.5,
    "whereas when writing": 1.0,
    "when writing rules": 0.5,
    "writing rules by": 1.0,
    "rules by hand": 1.0,
    "by hand it": 0.16666666666666666,
    "hand it is": 1.0,
    "it is often": 0.1276595744680851,
    "is often not": 0.18181818181818182,
    "often not obvious": 0.5,
    "not obvious at": 1.0,
    "obvious at all": 1.0,
    "at all where": 0.2,
    "all where the": 1.0,
    "where the effort": 0.07692307692307693,
    "the effort should": 1.0,
    "effort should be": 1.0,
    "should be directed": 0.1111111111111111,
    "be directed .": 1.0,
    "<s> automatic learning": 0.14285714285714285,
    "automatic learning procedures": 1.0,
    "learning procedures can": 0.5,
    "procedures can make": 0.5,
    "can make use": 0.3333333333333333,
    "make use of": 1.0,
    "use of statistical": 0.045454545454545456,
    "of statistical inference": 0.5,
    "statistical inference algorithms": 0.5,
    "inference algorithms to": 1.0,
    "algorithms to produce": 0.3333333333333333,
    "to produce models": 0.1,
    "produce models that": 1.0,
    "models that are": 0.3333333333333333,
    "that are robust": 0.06666666666666667,
    "are robust to": 1.0,
    "robust to unfamiliar": 1.0,
    "to unfamiliar input": 1.0,
    "unfamiliar input -lrb-": 0.3333333333333333,
    "input -lrb- e.g.": 1.0,
    "-lrb- e.g. containing": 0.02631578947368421,
    "e.g. containing words": 1.0,
    "containing words or": 1.0,
    "words or structures": 0.14285714285714285,
    "or structures that": 1.0,
    "structures that have": 0.5,
    "that have not": 0.16666666666666666,
    "have not been": 0.5,
    "not been seen": 0.5,
    "seen before -rrb-": 0.5,
    "before -rrb- and": 0.5,
    "-rrb- and to": 0.05,
    "and to erroneous": 0.09090909090909091,
    "to erroneous input": 1.0,
    "erroneous input -lrb-": 1.0,
    "-lrb- e.g. with": 0.02631578947368421,
    "e.g. with misspelled": 1.0,
    "with misspelled words": 1.0,
    "misspelled words or": 1.0,
    "words or words": 0.14285714285714285,
    "or words accidentally": 1.0,
    "words accidentally omitted": 1.0,
    "accidentally omitted -rrb-": 1.0,
    "omitted -rrb- .": 1.0,
    "generally , handling": 0.25,
    ", handling such": 0.5,
    "handling such input": 1.0,
    "such input gracefully": 1.0,
    "input gracefully with": 1.0,
    "gracefully with hand-written": 1.0,
    "with hand-written rules": 1.0,
    "hand-written rules --": 0.16666666666666666,
    "rules -- or": 1.0,
    "-- or more": 1.0,
    "or more generally": 0.25,
    "more generally ,": 1.0,
    "generally , creating": 0.25,
    ", creating systems": 0.5,
    "creating systems of": 1.0,
    "rules that make": 0.25,
    "soft decisions --": 0.5,
    "decisions -- is": 1.0,
    "-- is extremely": 1.0,
    "is extremely difficult": 0.5,
    "extremely difficult ,": 0.3333333333333333,
    "difficult , error-prone": 1.0,
    ", error-prone and": 1.0,
    "error-prone and time-consuming": 1.0,
    "and time-consuming .": 1.0,
    "based on automatically": 0.021739130434782608,
    "on automatically learning": 1.0,
    "automatically learning the": 1.0,
    "learning the rules": 1.0,
    "the rules can": 0.2,
    "rules can be": 0.6666666666666666,
    "can be made": 0.02197802197802198,
    "be made more": 0.5,
    "made more accurate": 1.0,
    "more accurate simply": 0.3333333333333333,
    "accurate simply by": 1.0,
    "simply by supplying": 1.0,
    "by supplying more": 1.0,
    "supplying more input": 1.0,
    "more input data": 1.0,
    "however , systems": 0.022727272727272728,
    ", systems based": 0.5,
    "based on hand-written": 0.021739130434782608,
    "on hand-written rules": 1.0,
    "hand-written rules can": 0.16666666666666666,
    "rules can only": 0.3333333333333333,
    "can only be": 0.5,
    "only be made": 1.0,
    "more accurate by": 0.3333333333333333,
    "accurate by increasing": 1.0,
    "by increasing the": 1.0,
    "increasing the complexity": 1.0,
    "the complexity of": 1.0,
    "complexity of the": 0.75,
    "the rules ,": 0.2,
    "rules , which": 0.4,
    ", which is": 0.125,
    "which is a": 0.15384615384615385,
    "is a much": 0.018518518518518517,
    "a much more": 0.3333333333333333,
    "more difficult task": 0.14285714285714285,
    "difficult task .": 1.0,
    "<s> in particular": 0.030927835051546393,
    "in particular ,": 1.0,
    "particular , there": 0.3333333333333333,
    "there is a": 0.23529411764705882,
    "is a limit": 0.018518518518518517,
    "a limit to": 1.0,
    "limit to the": 1.0,
    "to the complexity": 0.012987012987012988,
    "complexity of systems": 0.125,
    "of systems based": 0.5,
    "based on hand-crafted": 0.021739130434782608,
    "on hand-crafted rules": 1.0,
    "hand-crafted rules ,": 1.0,
    "rules , beyond": 0.2,
    ", beyond which": 1.0,
    "beyond which the": 1.0,
    "which the systems": 0.125,
    "the systems become": 0.25,
    "systems become more": 1.0,
    "become more and": 1.0,
    "more and more": 1.0,
    "and more unmanageable": 0.2,
    "more unmanageable .": 1.0,
    "however , creating": 0.022727272727272728,
    ", creating more": 0.5,
    "creating more data": 1.0,
    "more data to": 0.5,
    "data to input": 1.0,
    "to input to": 0.5,
    "input to machine-learning": 0.3333333333333333,
    "to machine-learning systems": 1.0,
    "machine-learning systems simply": 1.0,
    "systems simply requires": 1.0,
    "simply requires a": 1.0,
    "requires a corresponding": 1.0,
    "a corresponding increase": 1.0,
    "corresponding increase in": 1.0,
    "increase in the": 0.3333333333333333,
    "in the number": 0.006535947712418301,
    "the number of": 0.7142857142857143,
    "number of man-hours": 0.027777777777777776,
    "of man-hours worked": 1.0,
    "man-hours worked ,": 1.0,
    "worked , generally": 1.0,
    ", generally without": 1.0,
    "generally without significant": 1.0,
    "without significant increases": 1.0,
    "significant increases in": 1.0,
    "increases in the": 0.5,
    "in the complexity": 0.006535947712418301,
    "of the annotation": 0.005128205128205128,
    "the annotation process": 1.0,
    "annotation process .": 1.0,
    "<s> major tasks": 0.5,
    "major tasks in": 1.0,
    "tasks in nlp": 0.6666666666666666,
    "in nlp the": 0.25,
    "nlp the following": 0.5,
    "the following is": 0.09090909090909091,
    "following is a": 1.0,
    "is a list": 0.018518518518518517,
    "a list of": 0.8571428571428571,
    "list of some": 0.1,
    "of some of": 0.2,
    "of the most": 0.03076923076923077,
    "the most commonly": 0.041666666666666664,
    "most commonly researched": 1.0,
    "commonly researched tasks": 1.0,
    "researched tasks in": 1.0,
    "in nlp .": 0.125,
    "<s> note that": 0.7777777777777778,
    "note that some": 0.2857142857142857,
    "that some of": 0.25,
    "some of these": 0.11764705882352941,
    "of these tasks": 0.09090909090909091,
    "these tasks have": 0.5,
    "tasks have direct": 1.0,
    "have direct real-world": 1.0,
    "direct real-world applications": 1.0,
    "real-world applications ,": 1.0,
    "applications , while": 0.25,
    ", while others": 0.21428571428571427,
    "while others more": 0.25,
    "others more commonly": 1.0,
    "more commonly serve": 0.5,
    "commonly serve as": 1.0,
    "serve as subtasks": 0.25,
    "as subtasks that": 1.0,
    "subtasks that are": 1.0,
    "that are used": 0.06666666666666667,
    "are used to": 0.25,
    "used to aid": 0.045454545454545456,
    "to aid in": 1.0,
    "aid in solving": 0.3333333333333333,
    "in solving larger": 1.0,
    "solving larger tasks": 1.0,
    "larger tasks .": 1.0,
    "<s> what distinguishes": 0.25,
    "what distinguishes these": 1.0,
    "distinguishes these tasks": 1.0,
    "these tasks from": 0.5,
    "tasks from other": 1.0,
    "from other potential": 1.0,
    "other potential and": 1.0,
    "potential and actual": 1.0,
    "and actual nlp": 1.0,
    "actual nlp tasks": 1.0,
    "nlp tasks is": 0.5,
    "tasks is not": 1.0,
    "is not only": 0.05263157894736842,
    "not only the": 0.2857142857142857,
    "only the volume": 0.25,
    "the volume of": 1.0,
    "volume of research": 0.5,
    "of research devoted": 0.125,
    "research devoted to": 1.0,
    "devoted to them": 0.3333333333333333,
    "to them but": 0.5,
    "them but the": 1.0,
    "but the fact": 0.25,
    "the fact that": 1.0,
    "fact that for": 0.2,
    "that for each": 1.0,
    "for each one": 0.14285714285714285,
    "each one there": 0.5,
    "one there is": 1.0,
    "there is typically": 0.058823529411764705,
    "is typically a": 0.3333333333333333,
    "typically a well-defined": 1.0,
    "a well-defined problem": 1.0,
    "well-defined problem setting": 1.0,
    "problem setting ,": 1.0,
    "setting , a": 0.5,
    ", a standard": 0.020833333333333332,
    "a standard metric": 0.3333333333333333,
    "standard metric for": 1.0,
    "metric for evaluating": 1.0,
    "for evaluating the": 0.3333333333333333,
    "evaluating the task": 1.0,
    "the task ,": 0.09090909090909091,
    "task , standard": 0.25,
    ", standard corpora": 0.5,
    "standard corpora on": 1.0,
    "corpora on which": 1.0,
    "on which the": 0.3333333333333333,
    "which the task": 0.125,
    "the task can": 0.09090909090909091,
    "task can be": 1.0,
    "can be evaluated": 0.02197802197802198,
    "be evaluated ,": 0.5,
    "evaluated , and": 1.0,
    ", and competitions": 0.005291005291005291,
    "and competitions devoted": 1.0,
    "competitions devoted to": 1.0,
    "devoted to the": 0.3333333333333333,
    "to the specific": 0.012987012987012988,
    "the specific task": 0.3333333333333333,
    "specific task .": 1.0,
    "<s> automatic summarization": 0.2857142857142857,
    "automatic summarization :": 0.25,
    "summarization : produce": 1.0,
    ": produce a": 1.0,
    "produce a readable": 0.25,
    "a readable summary": 1.0,
    "readable summary of": 1.0,
    "summary of a": 0.3333333333333333,
    "of a chunk": 0.010869565217391304,
    "a chunk of": 1.0,
    "chunk of text": 0.8571428571428571,
    "of text .": 0.125,
    "<s> often used": 0.3333333333333333,
    "often used to": 0.5,
    "used to provide": 0.045454545454545456,
    "to provide summaries": 0.25,
    "provide summaries of": 1.0,
    "summaries of text": 0.25,
    "of text of": 0.041666666666666664,
    "text of a": 1.0,
    "of a known": 0.010869565217391304,
    "a known type": 0.5,
    "known type ,": 1.0,
    "type , such": 1.0,
    "such as articles": 0.011111111111111112,
    "as articles in": 1.0,
    "articles in the": 0.5,
    "in the financial": 0.006535947712418301,
    "the financial section": 1.0,
    "financial section of": 1.0,
    "section of a": 1.0,
    "of a newspaper": 0.010869565217391304,
    "a newspaper .": 1.0,
    "<s> coreference resolution": 1.0,
    "coreference resolution :": 0.5,
    "resolution : given": 1.0,
    ": given a": 0.9,
    "given a sentence": 0.14285714285714285,
    "a sentence or": 0.14285714285714285,
    "sentence or larger": 0.5,
    "or larger chunk": 1.0,
    "larger chunk of": 1.0,
    "text , determine": 0.1,
    ", determine which": 0.3333333333333333,
    "determine which words": 0.5,
    "which words -lrb-": 0.5,
    "words -lrb- ``": 0.3333333333333333,
    "-lrb- `` mentions": 0.125,
    "`` mentions ''": 1.0,
    "mentions '' -rrb-": 1.0,
    "'' -rrb- refer": 0.07142857142857142,
    "-rrb- refer to": 1.0,
    "refer to the": 0.3333333333333333,
    "to the same": 0.012987012987012988,
    "the same objects": 0.041666666666666664,
    "same objects -lrb-": 1.0,
    "objects -lrb- ``": 1.0,
    "-lrb- `` entities": 0.125,
    "`` entities ''": 1.0,
    "entities '' -rrb-": 1.0,
    "'' -rrb- .": 0.21428571428571427,
    "<s> anaphora resolution": 1.0,
    "anaphora resolution is": 1.0,
    "resolution is a": 1.0,
    "is a specific": 0.018518518518518517,
    "a specific example": 0.2,
    "specific example of": 1.0,
    "example of this": 0.14285714285714285,
    "of this task": 0.18181818181818182,
    "this task ,": 0.16666666666666666,
    "task , and": 0.5,
    ", and is": 0.015873015873015872,
    "and is specifically": 0.16666666666666666,
    "is specifically concerned": 1.0,
    "specifically concerned with": 1.0,
    "concerned with matching": 0.25,
    "with matching up": 1.0,
    "matching up pronouns": 1.0,
    "up pronouns with": 1.0,
    "pronouns with the": 1.0,
    "with the nouns": 0.03333333333333333,
    "the nouns or": 1.0,
    "nouns or names": 1.0,
    "or names that": 1.0,
    "names that they": 0.5,
    "that they refer": 0.14285714285714285,
    "they refer to": 1.0,
    "refer to .": 0.16666666666666666,
    "<s> for example": 0.6140350877192983,
    "example , in": 0.05555555555555555,
    ", in a": 0.08823529411764706,
    "a sentence such": 0.07142857142857142,
    "sentence such as": 1.0,
    "such as ``": 0.08888888888888889,
    "as `` he": 0.07142857142857142,
    "`` he entered": 1.0,
    "he entered john": 1.0,
    "entered john 's": 1.0,
    "john 's house": 1.0,
    "'s house through": 0.5,
    "house through the": 1.0,
    "through the front": 0.25,
    "the front door": 1.0,
    "front door ''": 0.6666666666666666,
    "door '' ,": 0.5,
    "'' , ``": 0.36666666666666664,
    ", `` the": 0.04,
    "`` the front": 0.125,
    "door '' is": 0.5,
    "'' is a": 0.3333333333333333,
    "is a referring": 0.018518518518518517,
    "a referring expression": 1.0,
    "referring expression and": 0.5,
    "expression and the": 1.0,
    "and the bridging": 0.024390243902439025,
    "the bridging relationship": 1.0,
    "bridging relationship to": 1.0,
    "relationship to be": 1.0,
    "to be identified": 0.023255813953488372,
    "be identified is": 0.5,
    "identified is the": 1.0,
    "is the fact": 0.022222222222222223,
    "fact that the": 0.4,
    "that the door": 0.043478260869565216,
    "the door being": 1.0,
    "door being referred": 1.0,
    "being referred to": 1.0,
    "referred to is": 0.125,
    "to is the": 1.0,
    "is the front": 0.022222222222222223,
    "front door of": 0.3333333333333333,
    "door of john": 1.0,
    "of john 's": 1.0,
    "'s house -lrb-": 0.5,
    "house -lrb- rather": 1.0,
    "-lrb- rather than": 1.0,
    "rather than of": 0.07142857142857142,
    "than of some": 1.0,
    "of some other": 0.4,
    "some other structure": 0.14285714285714285,
    "other structure that": 1.0,
    "structure that might": 1.0,
    "that might also": 0.5,
    "might also be": 1.0,
    "also be referred": 0.14285714285714285,
    "be referred to": 1.0,
    "referred to -rrb-": 0.125,
    "to -rrb- .": 1.0,
    "<s> discourse analysis": 1.0,
    "discourse analysis :": 0.18181818181818182,
    "analysis : this": 0.25,
    ": this rubric": 0.25,
    "this rubric includes": 1.0,
    "rubric includes a": 1.0,
    "includes a number": 1.0,
    "number of related": 0.027777777777777776,
    "of related tasks": 0.6666666666666666,
    "related tasks .": 0.6666666666666666,
    "<s> one task": 0.08333333333333333,
    "one task is": 1.0,
    "task is identifying": 0.16666666666666666,
    "is identifying the": 1.0,
    "identifying the discourse": 0.25,
    "the discourse structure": 0.3333333333333333,
    "discourse structure of": 1.0,
    "structure of connected": 0.25,
    "of connected text": 1.0,
    "connected text ,": 1.0,
    "text , i.e.": 0.03333333333333333,
    ", i.e. the": 0.2857142857142857,
    "i.e. the nature": 0.2,
    "of the discourse": 0.005128205128205128,
    "the discourse relationships": 0.3333333333333333,
    "discourse relationships between": 1.0,
    "relationships between sentences": 1.0,
    "between sentences -lrb-": 0.5,
    "sentences -lrb- e.g.": 1.0,
    "-lrb- e.g. elaboration": 0.02631578947368421,
    "e.g. elaboration ,": 1.0,
    "elaboration , explanation": 1.0,
    ", explanation ,": 1.0,
    "explanation , contrast": 1.0,
    ", contrast -rrb-": 1.0,
    "contrast -rrb- .": 1.0,
    "<s> another possible": 0.07692307692307693,
    "another possible task": 1.0,
    "possible task is": 1.0,
    "task is recognizing": 0.16666666666666666,
    "is recognizing and": 1.0,
    "recognizing and classifying": 1.0,
    "and classifying the": 1.0,
    "classifying the speech": 1.0,
    "the speech acts": 0.1,
    "speech acts in": 0.3333333333333333,
    "acts in a": 1.0,
    "in a chunk": 0.019230769230769232,
    "of text -lrb-": 0.041666666666666664,
    "text -lrb- e.g.": 0.16666666666666666,
    "-lrb- e.g. yes-no": 0.02631578947368421,
    "e.g. yes-no question": 1.0,
    "yes-no question ,": 1.0,
    "question , content": 0.09090909090909091,
    ", content question": 1.0,
    "content question ,": 1.0,
    "question , statement": 0.09090909090909091,
    ", statement ,": 1.0,
    "statement , assertion": 1.0,
    ", assertion ,": 1.0,
    "assertion , etc.": 1.0,
    ", etc. -rrb-": 0.45,
    "etc. -rrb- .": 0.2222222222222222,
    "<s> machine translation": 1.0,
    "machine translation :": 0.045454545454545456,
    "translation : automatically": 0.5,
    ": automatically translate": 1.0,
    "automatically translate text": 1.0,
    "translate text from": 0.5,
    "text from one": 0.5,
    "from one human": 0.3333333333333333,
    "one human language": 1.0,
    "human language to": 0.3333333333333333,
    "language to another": 0.5,
    "to another .": 0.6666666666666666,
    "<s> this is": 0.2692307692307692,
    "this is one": 0.038461538461538464,
    "is one of": 0.5,
    "one of the": 0.75,
    "the most difficult": 0.041666666666666664,
    "most difficult problems": 1.0,
    "difficult problems ,": 0.3333333333333333,
    "problems , and": 0.16666666666666666,
    "and is a": 0.16666666666666666,
    "is a member": 0.018518518518518517,
    "a member of": 1.0,
    "member of a": 1.0,
    "of a class": 0.010869565217391304,
    "a class of": 1.0,
    "class of problems": 0.3333333333333333,
    "of problems colloquially": 0.5,
    "problems colloquially termed": 1.0,
    "colloquially termed ``": 1.0,
    "termed `` ai-complete": 1.0,
    "`` ai-complete ''": 1.0,
    "ai-complete '' ,": 0.5,
    "'' , i.e.": 0.03333333333333333,
    ", i.e. requiring": 0.14285714285714285,
    "i.e. requiring all": 1.0,
    "requiring all of": 1.0,
    "all of the": 0.75,
    "of the different": 0.005128205128205128,
    "the different types": 1.0,
    "different types of": 1.0,
    "types of knowledge": 0.07142857142857142,
    "of knowledge that": 0.3333333333333333,
    "knowledge that humans": 1.0,
    "that humans possess": 0.5,
    "humans possess -lrb-": 1.0,
    "possess -lrb- grammar": 1.0,
    "-lrb- grammar ,": 1.0,
    "grammar , semantics": 0.4,
    ", semantics ,": 1.0,
    "semantics , facts": 0.25,
    ", facts about": 1.0,
    "facts about the": 1.0,
    "about the real": 0.125,
    "the real world": 0.6666666666666666,
    "real world ,": 0.3333333333333333,
    "world , etc.": 0.5,
    "etc. -rrb- in": 0.1111111111111111,
    "-rrb- in order": 0.25,
    "in order to": 0.8888888888888888,
    "order to solve": 0.125,
    "to solve properly": 0.25,
    "solve properly .": 1.0,
    "<s> morphological segmentation": 1.0,
    "morphological segmentation :": 1.0,
    "segmentation : separate": 0.6666666666666666,
    ": separate words": 0.5,
    "separate words into": 0.25,
    "words into individual": 0.25,
    "into individual morphemes": 1.0,
    "individual morphemes and": 1.0,
    "morphemes and identify": 1.0,
    "and identify the": 1.0,
    "identify the class": 0.16666666666666666,
    "the class of": 1.0,
    "class of the": 0.3333333333333333,
    "of the morphemes": 0.005128205128205128,
    "the morphemes .": 1.0,
    "<s> the difficulty": 0.02040816326530612,
    "the difficulty of": 0.75,
    "difficulty of this": 0.6666666666666666,
    "this task depends": 0.16666666666666666,
    "task depends greatly": 1.0,
    "depends greatly on": 1.0,
    "greatly on the": 1.0,
    "on the complexity": 0.029850746268656716,
    "of the morphology": 0.005128205128205128,
    "the morphology -lrb-": 1.0,
    "morphology -lrb- i.e.": 1.0,
    "-lrb- i.e. the": 0.2727272727272727,
    "i.e. the structure": 0.2,
    "the structure of": 1.0,
    "structure of words": 0.25,
    "of words -rrb-": 0.13333333333333333,
    "words -rrb- of": 0.3333333333333333,
    "-rrb- of the": 0.42857142857142855,
    "of the language": 0.03076923076923077,
    "the language being": 0.25,
    "language being considered": 0.5,
    "being considered .": 0.5,
    "<s> english has": 1.0,
    "english has fairly": 0.5,
    "has fairly simple": 1.0,
    "fairly simple morphology": 1.0,
    "simple morphology ,": 1.0,
    "morphology , especially": 0.2,
    ", especially inflectional": 0.1111111111111111,
    "especially inflectional morphology": 1.0,
    "inflectional morphology ,": 1.0,
    "morphology , and": 0.4,
    ", and thus": 0.010582010582010581,
    "and thus it": 0.3333333333333333,
    "thus it is": 1.0,
    "is often possible": 0.09090909090909091,
    "often possible to": 1.0,
    "possible to ignore": 0.3333333333333333,
    "to ignore this": 1.0,
    "ignore this task": 1.0,
    "this task entirely": 0.16666666666666666,
    "task entirely and": 1.0,
    "entirely and simply": 1.0,
    "and simply model": 1.0,
    "simply model all": 1.0,
    "model all possible": 1.0,
    "all possible forms": 0.3333333333333333,
    "possible forms of": 1.0,
    "forms of a": 0.5,
    "of a word": 0.03260869565217391,
    "a word -lrb-": 0.08333333333333333,
    "word -lrb- e.g.": 1.0,
    "-lrb- e.g. ``": 0.02631578947368421,
    "e.g. `` open": 1.0,
    "`` open ,": 1.0,
    "open , opens": 1.0,
    ", opens ,": 1.0,
    "opens , opened": 1.0,
    ", opened ,": 1.0,
    "opened , opening": 1.0,
    ", opening ''": 1.0,
    "opening '' -rrb-": 1.0,
    "'' -rrb- as": 0.07142857142857142,
    "-rrb- as separate": 0.3333333333333333,
    "as separate words": 1.0,
    "separate words .": 0.5,
    "<s> in languages": 0.010309278350515464,
    "in languages such": 1.0,
    "languages such as": 0.8,
    "such as turkish": 0.011111111111111112,
    "as turkish ,": 1.0,
    "turkish , however": 1.0,
    "however , such": 0.045454545454545456,
    ", such an": 0.02857142857142857,
    "such an approach": 0.5,
    "an approach is": 0.5,
    "approach is not": 0.2,
    "is not possible": 0.05263157894736842,
    "not possible ,": 1.0,
    "possible , as": 0.6666666666666666,
    ", as each": 0.043478260869565216,
    "as each dictionary": 1.0,
    "each dictionary entry": 1.0,
    "dictionary entry has": 1.0,
    "entry has thousands": 1.0,
    "has thousands of": 1.0,
    "thousands of possible": 0.5,
    "of possible word": 0.3333333333333333,
    "possible word forms": 1.0,
    "word forms .": 1.0,
    "<s> named entity": 1.0,
    "named entity recognition": 0.6666666666666666,
    "entity recognition -lrb-": 0.5,
    "recognition -lrb- ner": 0.14285714285714285,
    "-lrb- ner -rrb-": 1.0,
    "ner -rrb- :": 1.0,
    "-rrb- : given": 0.3333333333333333,
    "given a stream": 0.07142857142857142,
    "a stream of": 1.0,
    "stream of text": 1.0,
    "determine which items": 0.5,
    "which items in": 1.0,
    "items in the": 1.0,
    "in the text": 0.05228758169934641,
    "the text map": 0.038461538461538464,
    "text map to": 1.0,
    "map to proper": 1.0,
    "to proper names": 1.0,
    "proper names ,": 1.0,
    "names , such": 0.5,
    "such as people": 0.011111111111111112,
    "as people or": 1.0,
    "people or places": 1.0,
    "or places ,": 1.0,
    "places , and": 1.0,
    ", and what": 0.005291005291005291,
    "and what the": 1.0,
    "what the type": 0.25,
    "the type of": 1.0,
    "type of each": 0.125,
    "of each such": 0.14285714285714285,
    "each such name": 1.0,
    "such name is": 1.0,
    "name is -lrb-": 1.0,
    "is -lrb- e.g.": 1.0,
    "-lrb- e.g. person": 0.02631578947368421,
    "e.g. person ,": 1.0,
    "person , location": 0.25,
    ", location ,": 1.0,
    "location , organization": 1.0,
    ", organization -rrb-": 0.5,
    "organization -rrb- .": 1.0,
    "note that ,": 0.14285714285714285,
    "that , although": 1.0,
    ", although capitalization": 0.25,
    "although capitalization can": 1.0,
    "capitalization can aid": 1.0,
    "can aid in": 1.0,
    "aid in recognizing": 0.3333333333333333,
    "in recognizing named": 0.5,
    "recognizing named entities": 1.0,
    "named entities in": 0.3333333333333333,
    "entities in languages": 1.0,
    "such as english": 0.03333333333333333,
    "as english ,": 0.3333333333333333,
    "english , this": 0.3333333333333333,
    ", this information": 0.16666666666666666,
    "this information can": 1.0,
    "information can not": 1.0,
    "can not aid": 0.06666666666666667,
    "not aid in": 1.0,
    "aid in determining": 0.3333333333333333,
    "in determining the": 1.0,
    "determining the type": 0.25,
    "type of named": 0.125,
    "of named entity": 1.0,
    "named entity ,": 0.3333333333333333,
    "entity , and": 0.5,
    ", and in": 0.010582010582010581,
    "and in any": 0.14285714285714285,
    "in any case": 1.0,
    "any case is": 0.3333333333333333,
    "case is often": 1.0,
    "is often inaccurate": 0.09090909090909091,
    "often inaccurate or": 1.0,
    "inaccurate or insufficient": 1.0,
    "or insufficient .": 1.0,
    "example , the": 0.07407407407407407,
    ", the first": 0.02857142857142857,
    "the first word": 0.045454545454545456,
    "first word of": 1.0,
    "word of a": 1.0,
    "of a sentence": 0.021739130434782608,
    "a sentence is": 0.07142857142857142,
    "sentence is also": 0.5,
    "is also capitalized": 0.1,
    "also capitalized ,": 1.0,
    "capitalized , and": 0.5,
    ", and named": 0.005291005291005291,
    "and named entities": 1.0,
    "named entities often": 0.3333333333333333,
    "entities often span": 1.0,
    "often span several": 1.0,
    "span several words": 1.0,
    "several words ,": 1.0,
    "words , only": 0.0625,
    ", only some": 0.5,
    "only some of": 1.0,
    "some of which": 0.17647058823529413,
    "of which are": 0.4,
    "which are capitalized": 0.08333333333333333,
    "are capitalized .": 1.0,
    "<s> furthermore ,": 1.0,
    "furthermore , many": 0.16666666666666666,
    ", many other": 0.14285714285714285,
    "many other languages": 0.6,
    "other languages in": 0.2,
    "languages in non-western": 1.0,
    "in non-western scripts": 1.0,
    "non-western scripts -lrb-": 1.0,
    "scripts -lrb- e.g.": 0.5,
    "-lrb- e.g. chinese": 0.02631578947368421,
    "e.g. chinese or": 1.0,
    "chinese or arabic": 1.0,
    "or arabic -rrb-": 1.0,
    "arabic -rrb- do": 1.0,
    "-rrb- do not": 1.0,
    "do not have": 0.15384615384615385,
    "not have any": 0.5,
    "have any capitalization": 1.0,
    "any capitalization at": 1.0,
    "capitalization at all": 1.0,
    "at all ,": 0.4,
    "all , and": 0.3333333333333333,
    ", and even": 0.031746031746031744,
    "and even languages": 0.16666666666666666,
    "even languages with": 1.0,
    "languages with capitalization": 0.5,
    "with capitalization may": 1.0,
    "capitalization may not": 1.0,
    "may not consistently": 0.2,
    "not consistently use": 0.5,
    "consistently use it": 1.0,
    "use it to": 1.0,
    "it to distinguish": 0.2,
    "to distinguish names": 0.2,
    "distinguish names .": 1.0,
    "example , german": 0.018518518518518517,
    ", german capitalizes": 0.5,
    "german capitalizes all": 1.0,
    "capitalizes all nouns": 1.0,
    "all nouns ,": 1.0,
    "nouns , regardless": 0.16666666666666666,
    ", regardless of": 1.0,
    "regardless of whether": 0.25,
    "of whether they": 1.0,
    "whether they refer": 1.0,
    "refer to names": 0.16666666666666666,
    "to names ,": 1.0,
    "names , and": 0.5,
    ", and french": 0.005291005291005291,
    "and french and": 1.0,
    "french and spanish": 0.5,
    "and spanish do": 1.0,
    "spanish do not": 1.0,
    "do not capitalize": 0.07692307692307693,
    "not capitalize names": 1.0,
    "capitalize names that": 1.0,
    "names that serve": 0.5,
    "that serve as": 1.0,
    "serve as adjectives": 0.25,
    "as adjectives .": 1.0,
    "natural language generation": 0.07246376811594203,
    "language generation :": 0.16666666666666666,
    "generation : convert": 0.5,
    ": convert information": 0.5,
    "convert information from": 1.0,
    "information from computer": 0.3333333333333333,
    "from computer databases": 1.0,
    "computer databases into": 1.0,
    "databases into readable": 1.0,
    "into readable human": 1.0,
    "readable human language": 1.0,
    "human language .": 0.3333333333333333,
    "language understanding :": 0.06666666666666667,
    "understanding : convert": 1.0,
    ": convert chunks": 0.5,
    "convert chunks of": 1.0,
    "chunks of text": 1.0,
    "of text into": 0.08333333333333333,
    "text into more": 0.14285714285714285,
    "into more formal": 0.5,
    "more formal representations": 1.0,
    "formal representations such": 0.5,
    "representations such as": 1.0,
    "such as first-order": 0.011111111111111112,
    "as first-order logic": 1.0,
    "first-order logic structures": 1.0,
    "logic structures that": 1.0,
    "structures that are": 0.5,
    "that are easier": 0.06666666666666667,
    "are easier for": 1.0,
    "easier for computer": 1.0,
    "for computer programs": 0.3333333333333333,
    "computer programs to": 0.5,
    "programs to manipulate": 1.0,
    "to manipulate .": 0.5,
    "language understanding involves": 0.06666666666666667,
    "understanding involves the": 1.0,
    "involves the identification": 0.5,
    "the identification of": 1.0,
    "identification of the": 0.5,
    "of the intended": 0.005128205128205128,
    "the intended semantic": 0.5,
    "intended semantic from": 1.0,
    "semantic from the": 1.0,
    "from the multiple": 0.045454545454545456,
    "the multiple possible": 1.0,
    "multiple possible semantics": 0.5,
    "possible semantics which": 1.0,
    "semantics which can": 0.5,
    "which can be": 0.4,
    "can be derived": 0.02197802197802198,
    "be derived from": 1.0,
    "derived from a": 0.3333333333333333,
    "from a natural": 0.08333333333333333,
    "natural language expression": 0.014492753623188406,
    "language expression which": 1.0,
    "expression which usually": 1.0,
    "which usually takes": 1.0,
    "usually takes the": 1.0,
    "takes the form": 1.0,
    "the form of": 1.0,
    "form of organized": 0.14285714285714285,
    "of organized notations": 1.0,
    "organized notations of": 1.0,
    "notations of natural": 1.0,
    "of natural languages": 0.21739130434782608,
    "natural languages concepts": 0.1111111111111111,
    "languages concepts .": 1.0,
    "<s> introduction and": 1.0,
    "introduction and creation": 1.0,
    "and creation of": 1.0,
    "creation of language": 0.5,
    "of language metamodel": 0.2,
    "language metamodel and": 1.0,
    "metamodel and ontology": 1.0,
    "and ontology are": 1.0,
    "ontology are efficient": 1.0,
    "are efficient however": 1.0,
    "efficient however empirical": 1.0,
    "however empirical solutions": 1.0,
    "empirical solutions .": 1.0,
    "<s> an explicit": 0.09090909090909091,
    "an explicit formalization": 1.0,
    "explicit formalization of": 1.0,
    "formalization of natural": 1.0,
    "natural languages semantics": 0.1111111111111111,
    "languages semantics without": 1.0,
    "semantics without confusions": 1.0,
    "without confusions with": 1.0,
    "confusions with implicit": 1.0,
    "with implicit assumptions": 1.0,
    "implicit assumptions such": 1.0,
    "assumptions such as": 1.0,
    "such as closed": 0.011111111111111112,
    "as closed world": 1.0,
    "closed world assumption": 1.0,
    "world assumption -lrb-": 0.5,
    "assumption -lrb- cwa": 1.0,
    "-lrb- cwa -rrb-": 1.0,
    "cwa -rrb- vs.": 1.0,
    "-rrb- vs. open": 1.0,
    "vs. open world": 1.0,
    "open world assumption": 1.0,
    "world assumption ,": 0.5,
    "assumption , or": 1.0,
    ", or subjective": 0.030303030303030304,
    "or subjective yes\\/no": 0.5,
    "subjective yes\\/no vs.": 1.0,
    "yes\\/no vs. objective": 1.0,
    "vs. objective true\\/false": 1.0,
    "objective true\\/false is": 1.0,
    "true\\/false is expected": 1.0,
    "is expected for": 1.0,
    "expected for the": 1.0,
    "for the construction": 0.03125,
    "the construction of": 1.0,
    "construction of a": 1.0,
    "of a basis": 0.010869565217391304,
    "a basis of": 0.5,
    "basis of semantics": 0.25,
    "of semantics formalization": 1.0,
    "semantics formalization .": 1.0,
    "<s> optical character": 1.0,
    "optical character recognition": 1.0,
    "character recognition -lrb-": 0.15384615384615385,
    "recognition -lrb- ocr": 0.14285714285714285,
    "-lrb- ocr -rrb-": 1.0,
    "ocr -rrb- :": 1.0,
    ": given an": 0.1,
    "given an image": 0.5,
    "an image representing": 1.0,
    "image representing printed": 1.0,
    "representing printed text": 1.0,
    "printed text ,": 0.3333333333333333,
    ", determine the": 0.5,
    "determine the corresponding": 0.1,
    "the corresponding text": 0.5,
    "corresponding text .": 1.0,
    "<s> part-of-speech tagging": 1.0,
    "part-of-speech tagging :": 0.1111111111111111,
    "tagging : given": 1.0,
    "sentence , determine": 0.16666666666666666,
    "determine the part": 0.1,
    "speech for each": 0.25,
    "for each word": 0.2857142857142857,
    "<s> many words": 0.09090909090909091,
    "many words ,": 0.25,
    "words , especially": 0.0625,
    ", especially common": 0.1111111111111111,
    "especially common ones": 0.5,
    "common ones ,": 1.0,
    "ones , can": 0.3333333333333333,
    ", can serve": 0.16666666666666666,
    "can serve as": 0.5,
    "serve as multiple": 0.25,
    "as multiple parts": 1.0,
    "multiple parts of": 1.0,
    "parts of speech": 0.6875,
    "of speech .": 0.06382978723404255,
    "example , ``": 0.037037037037037035,
    ", `` book": 0.04,
    "`` book ''": 1.0,
    "book '' can": 1.0,
    "'' can be": 1.0,
    "can be a": 0.03296703296703297,
    "be a noun": 0.23076923076923078,
    "a noun -lrb-": 0.16666666666666666,
    "noun -lrb- ``": 1.0,
    "-lrb- `` the": 0.125,
    "`` the book": 0.125,
    "the book on": 0.5,
    "book on the": 1.0,
    "on the table": 0.014925373134328358,
    "the table ''": 0.5,
    "table '' -rrb-": 1.0,
    "'' -rrb- or": 0.07142857142857142,
    "-rrb- or verb": 0.25,
    "or verb -lrb-": 1.0,
    "verb -lrb- ``": 0.5,
    "-lrb- `` to": 0.125,
    "`` to book": 0.5,
    "to book a": 1.0,
    "book a flight": 1.0,
    "a flight ''": 1.0,
    "flight '' -rrb-": 1.0,
    "'' -rrb- ;": 0.14285714285714285,
    "-rrb- ; ``": 0.125,
    "; `` set": 1.0,
    "`` set ''": 1.0,
    "set '' can": 0.5,
    "a noun ,": 0.3333333333333333,
    "noun , verb": 0.2857142857142857,
    ", verb or": 0.5,
    "verb or adjective": 0.3333333333333333,
    "or adjective ;": 1.0,
    "adjective ; and": 1.0,
    "; and ``": 0.25,
    "and `` out": 0.05,
    "`` out ''": 1.0,
    "out '' can": 1.0,
    "can be any": 0.01098901098901099,
    "be any of": 1.0,
    "any of at": 0.5,
    "of at least": 1.0,
    "at least five": 0.2,
    "least five different": 1.0,
    "five different parts": 1.0,
    "different parts of": 1.0,
    "that some languages": 0.25,
    "some languages have": 0.5,
    "languages have more": 0.5,
    "have more such": 0.3333333333333333,
    "more such ambiguity": 1.0,
    "such ambiguity than": 0.3333333333333333,
    "ambiguity than others": 1.0,
    "than others .": 1.0,
    "<s> languages with": 0.3333333333333333,
    "languages with little": 0.5,
    "with little inflectional": 1.0,
    "little inflectional morphology": 1.0,
    "morphology , such": 0.2,
    "as english are": 0.3333333333333333,
    "english are particularly": 1.0,
    "are particularly prone": 1.0,
    "particularly prone to": 1.0,
    "prone to such": 1.0,
    "to such ambiguity": 1.0,
    "such ambiguity .": 0.3333333333333333,
    "<s> chinese is": 1.0,
    "chinese is prone": 1.0,
    "is prone to": 1.0,
    "such ambiguity because": 0.3333333333333333,
    "ambiguity because it": 1.0,
    "because it is": 0.3333333333333333,
    "it is a": 0.1276595744680851,
    "is a tonal": 0.018518518518518517,
    "a tonal language": 1.0,
    "tonal language during": 1.0,
    "language during verbalization": 1.0,
    "during verbalization .": 1.0,
    "<s> such inflection": 0.125,
    "such inflection is": 1.0,
    "inflection is not": 1.0,
    "is not readily": 0.05263157894736842,
    "not readily conveyed": 1.0,
    "readily conveyed via": 1.0,
    "conveyed via the": 1.0,
    "via the entities": 1.0,
    "the entities employed": 1.0,
    "entities employed within": 1.0,
    "employed within the": 1.0,
    "within the orthography": 0.3333333333333333,
    "the orthography to": 1.0,
    "orthography to convey": 1.0,
    "to convey intended": 0.3333333333333333,
    "convey intended meaning": 1.0,
    "intended meaning .": 1.0,
    "<s> parsing :": 0.25,
    "parsing : determine": 1.0,
    ": determine the": 1.0,
    "determine the parse": 0.1,
    "the parse tree": 1.0,
    "parse tree -lrb-": 1.0,
    "tree -lrb- grammatical": 1.0,
    "-lrb- grammatical analysis": 1.0,
    "grammatical analysis -rrb-": 1.0,
    "analysis -rrb- of": 0.5,
    "-rrb- of a": 0.2857142857142857,
    "of a given": 0.021739130434782608,
    "given sentence .": 0.5,
    "<s> the grammar": 0.013605442176870748,
    "the grammar for": 0.09090909090909091,
    "grammar for natural": 1.0,
    "for natural languages": 0.25,
    "natural languages is": 0.1111111111111111,
    "languages is ambiguous": 1.0,
    "is ambiguous and": 1.0,
    "ambiguous and typical": 0.5,
    "and typical sentences": 1.0,
    "typical sentences have": 1.0,
    "sentences have multiple": 0.5,
    "have multiple possible": 1.0,
    "multiple possible analyses": 0.5,
    "possible analyses .": 1.0,
    "<s> in fact": 0.041237113402061855,
    "in fact ,": 0.8,
    "fact , perhaps": 0.2,
    ", perhaps surprisingly": 0.3333333333333333,
    "perhaps surprisingly ,": 1.0,
    "surprisingly , for": 1.0,
    "for a typical": 0.03225806451612903,
    "a typical sentence": 0.25,
    "typical sentence there": 1.0,
    "sentence there may": 1.0,
    "there may be": 1.0,
    "may be thousands": 0.047619047619047616,
    "be thousands of": 1.0,
    "thousands of potential": 0.5,
    "of potential parses": 0.5,
    "potential parses -lrb-": 1.0,
    "parses -lrb- most": 1.0,
    "-lrb- most of": 0.25,
    "most of which": 0.16666666666666666,
    "of which will": 0.1,
    "which will seem": 0.3333333333333333,
    "will seem completely": 1.0,
    "seem completely nonsensical": 1.0,
    "completely nonsensical to": 1.0,
    "nonsensical to a": 1.0,
    "to a human": 0.07142857142857142,
    "a human -rrb-": 0.18181818181818182,
    "human -rrb- .": 0.5,
    "<s> question answering": 0.4,
    "question answering :": 0.08333333333333333,
    "answering : given": 1.0,
    "given a human-language": 0.07142857142857142,
    "a human-language question": 1.0,
    "human-language question ,": 1.0,
    "question , determine": 0.09090909090909091,
    ", determine its": 0.16666666666666666,
    "determine its answer": 0.5,
    "its answer .": 1.0,
    "<s> typical questions": 0.5,
    "typical questions have": 1.0,
    "questions have a": 1.0,
    "have a specific": 0.07692307692307693,
    "a specific right": 0.2,
    "specific right answer": 1.0,
    "right answer -lrb-": 1.0,
    "answer -lrb- such": 1.0,
    "-lrb- such as": 1.0,
    "as `` what": 0.14285714285714285,
    "`` what is": 1.0,
    "what is the": 0.5,
    "is the capital": 0.044444444444444446,
    "the capital of": 1.0,
    "capital of canada": 0.5,
    "of canada ?": 0.5,
    "canada ? ''": 1.0,
    "? '' -rrb-": 0.8333333333333334,
    "<s> , but": 1.0,
    ", but sometimes": 0.020833333333333332,
    "but sometimes open-ended": 1.0,
    "sometimes open-ended questions": 1.0,
    "open-ended questions are": 1.0,
    "questions are also": 0.3333333333333333,
    "are also considered": 0.125,
    "also considered -lrb-": 1.0,
    "considered -lrb- such": 1.0,
    "is the meaning": 0.022222222222222223,
    "the meaning of": 0.6,
    "meaning of life": 0.14285714285714285,
    "of life ?": 1.0,
    "life ? ''": 1.0,
    "<s> relationship extraction": 1.0,
    "relationship extraction :": 0.3333333333333333,
    "extraction : given": 0.5,
    "given a chunk": 0.21428571428571427,
    "text , identify": 0.03333333333333333,
    ", identify the": 0.5,
    "identify the relationships": 0.16666666666666666,
    "the relationships among": 0.5,
    "relationships among named": 1.0,
    "among named entities": 1.0,
    "named entities -lrb-": 0.3333333333333333,
    "entities -lrb- e.g.": 1.0,
    "-lrb- e.g. who": 0.02631578947368421,
    "e.g. who is": 1.0,
    "who is the": 1.0,
    "is the wife": 0.022222222222222223,
    "the wife of": 1.0,
    "wife of whom": 1.0,
    "of whom -rrb-": 1.0,
    "whom -rrb- .": 1.0,
    "<s> sentence breaking": 0.3333333333333333,
    "sentence breaking -lrb-": 0.5,
    "breaking -lrb- also": 1.0,
    "-lrb- also known": 0.75,
    "also known as": 1.0,
    "known as sentence": 0.2,
    "as sentence boundary": 0.5,
    "sentence boundary disambiguation": 0.5,
    "boundary disambiguation -rrb-": 0.5,
    "disambiguation -rrb- :": 0.5,
    "text , find": 0.03333333333333333,
    ", find the": 0.5,
    "find the sentence": 0.25,
    "the sentence boundaries": 0.16666666666666666,
    "sentence boundaries .": 0.6,
    "<s> sentence boundaries": 0.3333333333333333,
    "sentence boundaries are": 0.2,
    "boundaries are often": 1.0,
    "are often marked": 0.25,
    "often marked by": 1.0,
    "marked by periods": 1.0,
    "by periods or": 1.0,
    "periods or other": 1.0,
    "or other punctuation": 0.5,
    "other punctuation marks": 1.0,
    "punctuation marks ,": 0.5,
    "marks , but": 1.0,
    ", but these": 0.020833333333333332,
    "but these same": 1.0,
    "these same characters": 1.0,
    "same characters can": 1.0,
    "characters can serve": 0.3333333333333333,
    "can serve other": 0.5,
    "serve other purposes": 1.0,
    "other purposes -lrb-": 1.0,
    "purposes -lrb- e.g.": 1.0,
    "-lrb- e.g. marking": 0.02631578947368421,
    "e.g. marking abbreviations": 1.0,
    "marking abbreviations -rrb-": 1.0,
    "abbreviations -rrb- .": 1.0,
    "<s> sentiment analysis": 1.0,
    "sentiment analysis :": 0.05263157894736842,
    "analysis : extract": 0.25,
    ": extract subjective": 1.0,
    "extract subjective information": 1.0,
    "subjective information usually": 0.5,
    "information usually from": 1.0,
    "usually from a": 1.0,
    "from a set": 0.16666666666666666,
    "of documents ,": 0.4,
    "documents , often": 0.1111111111111111,
    ", often using": 0.3333333333333333,
    "often using online": 1.0,
    "using online reviews": 1.0,
    "online reviews to": 0.5,
    "reviews to determine": 1.0,
    "to determine ``": 0.09090909090909091,
    "determine `` polarity": 1.0,
    "`` polarity ''": 1.0,
    "polarity '' about": 0.5,
    "'' about specific": 1.0,
    "about specific objects": 1.0,
    "specific objects .": 1.0,
    "it is especially": 0.02127659574468085,
    "is especially useful": 0.5,
    "especially useful for": 1.0,
    "useful for identifying": 0.3333333333333333,
    "for identifying trends": 1.0,
    "identifying trends of": 1.0,
    "trends of public": 1.0,
    "of public opinion": 1.0,
    "public opinion in": 1.0,
    "opinion in the": 0.5,
    "in the social": 0.006535947712418301,
    "the social media": 0.3333333333333333,
    "social media ,": 0.5,
    "media , for": 0.3333333333333333,
    ", for the": 0.09090909090909091,
    "for the purpose": 0.03125,
    "the purpose of": 0.5,
    "purpose of marketing": 1.0,
    "of marketing .": 1.0,
    "<s> speech recognition": 0.4666666666666667,
    "speech recognition :": 0.013157894736842105,
    "recognition : given": 1.0,
    "given a sound": 0.14285714285714285,
    "a sound clip": 0.2857142857142857,
    "sound clip of": 1.0,
    "clip of a": 1.0,
    "of a person": 0.03260869565217391,
    "a person or": 0.18181818181818182,
    "person or people": 1.0,
    "or people speaking": 1.0,
    "people speaking ,": 1.0,
    "speaking , determine": 0.2,
    "determine the textual": 0.1,
    "the textual representation": 1.0,
    "textual representation of": 1.0,
    "representation of the": 0.5,
    "of the speech": 0.020512820512820513,
    "the speech .": 0.3,
    "this is the": 0.11538461538461539,
    "is the opposite": 0.022222222222222223,
    "the opposite of": 1.0,
    "opposite of text": 0.5,
    "of text to": 0.041666666666666664,
    "text to speech": 0.14285714285714285,
    "to speech and": 0.3333333333333333,
    "speech and is": 0.14285714285714285,
    "and is one": 0.16666666666666666,
    "of the extremely": 0.005128205128205128,
    "the extremely difficult": 1.0,
    "extremely difficult problems": 0.3333333333333333,
    "difficult problems colloquially": 0.3333333333333333,
    "ai-complete '' -lrb-": 0.5,
    "'' -lrb- see": 0.1111111111111111,
    "-lrb- see above": 0.0625,
    "see above -rrb-": 1.0,
    "above -rrb- .": 1.0,
    "<s> in natural": 0.010309278350515464,
    "in natural speech": 0.125,
    "natural speech there": 0.5,
    "speech there are": 1.0,
    "there are hardly": 0.047619047619047616,
    "are hardly any": 1.0,
    "hardly any pauses": 1.0,
    "any pauses between": 1.0,
    "pauses between successive": 0.5,
    "between successive words": 1.0,
    "successive words ,": 1.0,
    "and thus speech": 0.3333333333333333,
    "thus speech segmentation": 1.0,
    "speech segmentation is": 0.375,
    "segmentation is a": 0.3333333333333333,
    "is a necessary": 0.018518518518518517,
    "a necessary subtask": 1.0,
    "necessary subtask of": 1.0,
    "subtask of speech": 1.0,
    "of speech recognition": 0.2978723404255319,
    "speech recognition -lrb-": 0.05263157894736842,
    "recognition -lrb- see": 0.2857142857142857,
    "-lrb- see below": 0.0625,
    "see below -rrb-": 1.0,
    "below -rrb- .": 1.0,
    "<s> note also": 0.1111111111111111,
    "note also that": 1.0,
    "also that in": 1.0,
    "that in most": 0.5,
    "in most spoken": 0.25,
    "most spoken languages": 1.0,
    "spoken languages ,": 1.0,
    "languages , the": 0.2727272727272727,
    ", the sounds": 0.009523809523809525,
    "the sounds representing": 0.5,
    "sounds representing successive": 1.0,
    "representing successive letters": 1.0,
    "successive letters blend": 1.0,
    "letters blend into": 1.0,
    "blend into each": 1.0,
    "into each other": 1.0,
    "each other in": 0.16666666666666666,
    "other in a": 1.0,
    "in a process": 0.019230769230769232,
    "a process termed": 0.25,
    "process termed coarticulation": 1.0,
    "termed coarticulation ,": 1.0,
    "coarticulation , so": 1.0,
    ", so the": 0.3333333333333333,
    "so the conversion": 0.14285714285714285,
    "the conversion of": 1.0,
    "conversion of the": 0.5,
    "of the analog": 0.005128205128205128,
    "the analog signal": 1.0,
    "analog signal to": 1.0,
    "signal to discrete": 1.0,
    "to discrete characters": 1.0,
    "discrete characters can": 1.0,
    "characters can be": 0.6666666666666666,
    "be a very": 0.07692307692307693,
    "a very difficult": 0.08333333333333333,
    "very difficult process": 0.5,
    "difficult process .": 1.0,
    "<s> speech segmentation": 0.2,
    "speech segmentation :": 0.125,
    "segmentation : given": 0.3333333333333333,
    "speaking , separate": 0.2,
    ", separate it": 1.0,
    "separate it into": 1.0,
    "it into words": 0.2,
    "into words .": 1.0,
    "<s> a subtask": 0.022727272727272728,
    "a subtask of": 1.0,
    "speech recognition and": 0.07894736842105263,
    "recognition and typically": 0.14285714285714285,
    "and typically grouped": 0.5,
    "typically grouped with": 1.0,
    "grouped with it": 1.0,
    "with it .": 0.3333333333333333,
    "<s> topic segmentation": 1.0,
    "topic segmentation and": 1.0,
    "segmentation and recognition": 0.5,
    "and recognition :": 1.0,
    "text , separate": 0.03333333333333333,
    "it into segments": 0.2,
    "into segments each": 0.5,
    "segments each of": 1.0,
    "of which is": 0.3,
    "which is devoted": 0.07692307692307693,
    "is devoted to": 1.0,
    "devoted to a": 0.3333333333333333,
    "to a topic": 0.03571428571428571,
    "a topic ,": 1.0,
    "topic , and": 0.5,
    ", and identify": 0.005291005291005291,
    "identify the topic": 0.16666666666666666,
    "the topic of": 0.3333333333333333,
    "topic of the": 1.0,
    "of the segment": 0.005128205128205128,
    "the segment .": 1.0,
    "<s> word segmentation": 0.2,
    "word segmentation :": 0.25,
    ": separate a": 0.5,
    "separate a chunk": 1.0,
    "chunk of continuous": 0.14285714285714285,
    "of continuous text": 0.5,
    "continuous text into": 1.0,
    "text into separate": 0.14285714285714285,
    "into separate words": 0.5,
    "for a language": 0.06451612903225806,
    "a language like": 0.16666666666666666,
    "language like english": 1.0,
    "like english ,": 0.5,
    ", this is": 0.3333333333333333,
    "this is fairly": 0.038461538461538464,
    "is fairly trivial": 1.0,
    "fairly trivial ,": 1.0,
    "trivial , since": 1.0,
    ", since words": 0.2,
    "since words are": 1.0,
    "words are usually": 0.1,
    "are usually separated": 0.3333333333333333,
    "usually separated by": 1.0,
    "separated by spaces": 0.5,
    "by spaces .": 1.0,
    "however , some": 0.022727272727272728,
    ", some written": 0.1111111111111111,
    "some written languages": 1.0,
    "written languages like": 0.2,
    "languages like chinese": 0.5,
    "like chinese ,": 0.5,
    "chinese , japanese": 1.0,
    ", japanese and": 0.5,
    "japanese and thai": 0.5,
    "and thai do": 1.0,
    "thai do not": 1.0,
    "do not mark": 0.07692307692307693,
    "not mark word": 1.0,
    "mark word boundaries": 1.0,
    "word boundaries in": 1.0,
    "boundaries in such": 1.0,
    "in such a": 0.5,
    "such a fashion": 0.14285714285714285,
    "a fashion ,": 1.0,
    "fashion , and": 1.0,
    "and in those": 0.14285714285714285,
    "in those languages": 1.0,
    "those languages text": 0.5,
    "languages text segmentation": 1.0,
    "text segmentation is": 0.3333333333333333,
    "is a significant": 0.018518518518518517,
    "a significant task": 1.0,
    "significant task requiring": 1.0,
    "task requiring knowledge": 1.0,
    "requiring knowledge of": 1.0,
    "knowledge of the": 1.0,
    "of the vocabulary": 0.005128205128205128,
    "the vocabulary and": 0.5,
    "vocabulary and morphology": 0.5,
    "and morphology of": 1.0,
    "morphology of words": 1.0,
    "of words in": 0.26666666666666666,
    "words in the": 0.36363636363636365,
    "in the language": 0.006535947712418301,
    "the language .": 0.25,
    "<s> word sense": 0.2,
    "word sense disambiguation": 1.0,
    "sense disambiguation :": 0.5,
    "disambiguation : many": 1.0,
    ": many words": 1.0,
    "many words have": 0.25,
    "words have more": 1.0,
    "have more than": 0.6666666666666666,
    "more than one": 0.75,
    "than one meaning": 0.6666666666666666,
    "one meaning ;": 0.5,
    "meaning ; we": 1.0,
    "; we have": 1.0,
    "we have to": 0.25,
    "have to select": 0.5,
    "to select the": 0.5,
    "select the meaning": 0.5,
    "the meaning which": 0.1,
    "meaning which makes": 1.0,
    "which makes the": 0.3333333333333333,
    "makes the most": 0.5,
    "the most sense": 0.041666666666666664,
    "most sense in": 1.0,
    "sense in context": 1.0,
    "in context .": 0.5,
    "<s> for this": 0.05263157894736842,
    "for this problem": 0.125,
    "this problem ,": 0.09090909090909091,
    "problem , we": 0.25,
    ", we are": 0.058823529411764705,
    "we are typically": 0.5,
    "are typically given": 0.3333333333333333,
    "typically given a": 1.0,
    "given a list": 0.07142857142857142,
    "list of words": 0.1,
    "of words and": 0.2,
    "words and associated": 0.125,
    "and associated word": 1.0,
    "associated word senses": 1.0,
    "word senses ,": 1.0,
    "senses , e.g.": 1.0,
    ", e.g. from": 0.1,
    "e.g. from a": 1.0,
    "from a dictionary": 0.16666666666666666,
    "a dictionary or": 0.3333333333333333,
    "dictionary or from": 1.0,
    "or from an": 1.0,
    "from an online": 1.0,
    "an online resource": 1.0,
    "online resource such": 1.0,
    "resource such as": 1.0,
    "such as wordnet": 0.011111111111111112,
    "as wordnet .": 1.0,
    "<s> in some": 0.030927835051546393,
    "in some cases": 0.25,
    "some cases ,": 0.5,
    "cases , sets": 0.14285714285714285,
    ", sets of": 1.0,
    "sets of related": 0.25,
    "related tasks are": 0.3333333333333333,
    "tasks are grouped": 0.25,
    "are grouped into": 1.0,
    "grouped into subfields": 1.0,
    "into subfields of": 1.0,
    "subfields of nlp": 1.0,
    "of nlp that": 0.2,
    "nlp that are": 1.0,
    "that are often": 0.06666666666666667,
    "are often considered": 0.25,
    "often considered separately": 1.0,
    "considered separately from": 1.0,
    "separately from nlp": 1.0,
    "from nlp as": 1.0,
    "nlp as a": 1.0,
    "as a whole": 0.027777777777777776,
    "a whole .": 0.5,
    "<s> examples include": 0.3333333333333333,
    "examples include :": 1.0,
    "include : information": 0.3333333333333333,
    ": information retrieval": 1.0,
    "information retrieval -lrb-": 0.16666666666666666,
    "retrieval -lrb- ir": 1.0,
    "-lrb- ir -rrb-": 1.0,
    "ir -rrb- :": 1.0,
    "-rrb- : this": 0.2222222222222222,
    ": this is": 0.5,
    "this is concerned": 0.07692307692307693,
    "is concerned with": 0.5,
    "concerned with storing": 0.25,
    "with storing ,": 1.0,
    "storing , searching": 1.0,
    ", searching and": 1.0,
    "searching and retrieving": 1.0,
    "and retrieving information": 1.0,
    "retrieving information .": 1.0,
    "is a separate": 0.018518518518518517,
    "a separate field": 0.5,
    "separate field within": 1.0,
    "field within computer": 1.0,
    "within computer science": 1.0,
    "computer science -lrb-": 0.2,
    "science -lrb- closer": 1.0,
    "-lrb- closer to": 1.0,
    "closer to databases": 0.5,
    "to databases -rrb-": 1.0,
    "databases -rrb- ,": 1.0,
    "-rrb- , but": 0.038461538461538464,
    ", but ir": 0.020833333333333332,
    "but ir relies": 1.0,
    "ir relies on": 1.0,
    "relies on some": 1.0,
    "on some nlp": 0.1111111111111111,
    "some nlp methods": 1.0,
    "nlp methods -lrb-": 1.0,
    "methods -lrb- for": 0.5,
    "-lrb- for example": 0.8888888888888888,
    "example , stemming": 0.018518518518518517,
    ", stemming -rrb-": 1.0,
    "stemming -rrb- .": 1.0,
    "<s> some current": 0.0625,
    "some current research": 0.5,
    "current research and": 1.0,
    "research and applications": 0.16666666666666666,
    "and applications seek": 1.0,
    "applications seek to": 1.0,
    "seek to bridge": 1.0,
    "to bridge the": 1.0,
    "bridge the gap": 1.0,
    "the gap between": 1.0,
    "gap between ir": 1.0,
    "between ir and": 1.0,
    "ir and nlp": 1.0,
    "and nlp .": 0.5,
    "<s> information extraction": 1.0,
    "information extraction -lrb-": 1.0,
    "extraction -lrb- ie": 1.0,
    "-lrb- ie -rrb-": 1.0,
    "ie -rrb- :": 0.5,
    "is concerned in": 0.5,
    "concerned in general": 1.0,
    "in general with": 0.125,
    "general with the": 1.0,
    "with the extraction": 0.03333333333333333,
    "the extraction of": 0.75,
    "extraction of semantic": 0.3333333333333333,
    "of semantic information": 0.2,
    "semantic information from": 0.5,
    "information from text": 0.3333333333333333,
    "from text .": 0.5,
    "<s> this covers": 0.019230769230769232,
    "this covers tasks": 0.5,
    "covers tasks such": 1.0,
    "tasks such as": 1.0,
    "such as named": 0.011111111111111112,
    "as named entity": 1.0,
    "entity recognition ,": 0.5,
    "recognition , coreference": 0.07142857142857142,
    ", coreference resolution": 1.0,
    "coreference resolution ,": 0.5,
    "resolution , relationship": 1.0,
    ", relationship extraction": 1.0,
    "relationship extraction ,": 0.3333333333333333,
    "extraction , etc.": 0.16666666666666666,
    ", etc. .": 0.35,
    "<s> speech processing": 0.06666666666666667,
    "speech processing :": 0.5,
    "processing : this": 1.0,
    ": this covers": 0.25,
    "this covers speech": 0.5,
    "covers speech recognition": 1.0,
    "speech recognition ,": 0.06578947368421052,
    "recognition , text-to-speech": 0.07142857142857142,
    ", text-to-speech and": 1.0,
    "text-to-speech and related": 0.5,
    "and related tasks": 0.3333333333333333,
    "<s> other tasks": 0.14285714285714285,
    "other tasks include": 1.0,
    "tasks include :": 1.0,
    "include : stemming": 0.3333333333333333,
    ": stemming text": 1.0,
    "stemming text simplification": 1.0,
    "text simplification text-to-speech": 1.0,
    "simplification text-to-speech text-proofing": 1.0,
    "text-to-speech text-proofing natural": 1.0,
    "text-proofing natural language": 1.0,
    "natural language search": 0.014492753623188406,
    "language search query": 1.0,
    "search query expansion": 1.0,
    "query expansion automated": 1.0,
    "expansion automated essay": 1.0,
    "automated essay scoring": 1.0,
    "essay scoring truecasing": 1.0,
    "scoring truecasing statistical": 1.0,
    "truecasing statistical nlp": 1.0,
    "statistical nlp main": 0.25,
    "nlp main article": 1.0,
    "main article :": 1.0,
    "article : statistical": 0.15384615384615385,
    ": statistical natural": 0.5,
    "statistical natural language": 1.0,
    "language processing statistical": 0.027777777777777776,
    "processing statistical natural-language": 1.0,
    "statistical natural-language processing": 1.0,
    "natural-language processing uses": 1.0,
    "processing uses stochastic": 1.0,
    "uses stochastic ,": 1.0,
    "stochastic , probabilistic": 0.5,
    ", probabilistic and": 0.3333333333333333,
    "probabilistic and statistical": 1.0,
    "and statistical methods": 0.3333333333333333,
    "statistical methods to": 0.6,
    "methods to resolve": 0.25,
    "to resolve some": 0.3333333333333333,
    "resolve some of": 1.0,
    "of the difficulties": 0.005128205128205128,
    "the difficulties discussed": 1.0,
    "difficulties discussed above": 1.0,
    "discussed above ,": 1.0,
    "above , especially": 0.25,
    ", especially those": 0.2222222222222222,
    "especially those which": 0.3333333333333333,
    "those which arise": 1.0,
    "which arise because": 1.0,
    "arise because longer": 1.0,
    "because longer sentences": 1.0,
    "longer sentences are": 1.0,
    "sentences are highly": 0.14285714285714285,
    "are highly ambiguous": 1.0,
    "highly ambiguous when": 1.0,
    "ambiguous when processed": 1.0,
    "when processed with": 1.0,
    "processed with realistic": 0.5,
    "with realistic grammars": 1.0,
    "realistic grammars ,": 1.0,
    "grammars , yielding": 0.5,
    ", yielding thousands": 1.0,
    "yielding thousands or": 1.0,
    "thousands or millions": 1.0,
    "or millions of": 1.0,
    "millions of possible": 0.5,
    "of possible analyses": 0.3333333333333333,
    "<s> methods for": 0.3333333333333333,
    "methods for disambiguation": 0.25,
    "for disambiguation often": 1.0,
    "disambiguation often involve": 1.0,
    "often involve the": 1.0,
    "involve the use": 1.0,
    "the use of": 1.0,
    "use of corpora": 0.045454545454545456,
    "of corpora and": 1.0,
    "corpora and markov": 1.0,
    "and markov models": 1.0,
    "markov models .": 0.2222222222222222,
    "<s> statistical nlp": 0.3333333333333333,
    "statistical nlp comprises": 0.25,
    "nlp comprises all": 1.0,
    "comprises all quantitative": 1.0,
    "all quantitative approaches": 1.0,
    "quantitative approaches to": 1.0,
    "approaches to automated": 0.2,
    "to automated language": 1.0,
    "automated language processing": 1.0,
    "language processing ,": 0.16666666666666666,
    "processing , including": 0.1111111111111111,
    ", including probabilistic": 0.125,
    "including probabilistic modeling": 1.0,
    "probabilistic modeling ,": 1.0,
    "modeling , information": 1.0,
    ", information theory": 0.5,
    "information theory ,": 1.0,
    "theory , and": 0.5,
    ", and linear": 0.005291005291005291,
    "and linear algebra": 1.0,
    "linear algebra .": 1.0,
    "<s> the technology": 0.006802721088435374,
    "the technology for": 0.5,
    "technology for statistical": 0.5,
    "for statistical nlp": 0.5,
    "statistical nlp comes": 0.25,
    "nlp comes mainly": 1.0,
    "comes mainly from": 1.0,
    "mainly from machine": 1.0,
    "from machine learning": 1.0,
    "machine learning and": 0.047619047619047616,
    "learning and data": 1.0,
    "and data mining": 0.25,
    "data mining ,": 0.5,
    "mining , both": 1.0,
    ", both of": 0.6666666666666666,
    "both of which": 1.0,
    "which are fields": 0.08333333333333333,
    "are fields of": 1.0,
    "fields of artificial": 0.5,
    "of artificial intelligence": 1.0,
    "artificial intelligence that": 0.25,
    "intelligence that involve": 0.5,
    "that involve learning": 1.0,
    "involve learning from": 1.0,
    "learning from data": 0.5,
    "from data .": 0.5,
    "<s> evaluation of": 0.2,
    "evaluation of natural": 0.2,
    "language processing objectives": 0.027777777777777776,
    "processing objectives the": 1.0,
    "objectives the goal": 1.0,
    "the goal of": 0.4,
    "goal of nlp": 0.5,
    "of nlp evaluation": 0.2,
    "nlp evaluation is": 0.3333333333333333,
    "evaluation is to": 0.25,
    "is to measure": 0.05263157894736842,
    "to measure one": 0.25,
    "measure one or": 1.0,
    "one or more": 1.0,
    "or more qualities": 0.25,
    "more qualities of": 1.0,
    "qualities of an": 1.0,
    "of an algorithm": 0.07692307692307693,
    "an algorithm or": 0.3333333333333333,
    "algorithm or a": 1.0,
    "or a system": 0.05263157894736842,
    "a system ,": 0.2,
    "system , in": 0.1,
    ", in order": 0.08823529411764706,
    "order to determine": 0.125,
    "to determine whether": 0.09090909090909091,
    "determine whether -lrb-": 1.0,
    "whether -lrb- or": 1.0,
    "-lrb- or to": 0.1,
    "or to what": 0.5,
    "to what extent": 0.25,
    "what extent -rrb-": 1.0,
    "extent -rrb- the": 1.0,
    "-rrb- the system": 0.3333333333333333,
    "the system answers": 0.038461538461538464,
    "system answers the": 1.0,
    "answers the goals": 1.0,
    "the goals of": 1.0,
    "goals of its": 1.0,
    "of its designers": 0.125,
    "its designers ,": 1.0,
    "designers , or": 1.0,
    ", or meets": 0.030303030303030304,
    "or meets the": 1.0,
    "meets the needs": 1.0,
    "the needs of": 1.0,
    "needs of its": 1.0,
    "of its users": 0.125,
    "its users .": 1.0,
    "<s> research in": 0.5,
    "research in nlp": 0.14285714285714285,
    "in nlp evaluation": 0.25,
    "nlp evaluation has": 0.3333333333333333,
    "evaluation has received": 1.0,
    "has received considerable": 1.0,
    "received considerable attention": 1.0,
    "considerable attention ,": 1.0,
    "attention , because": 1.0,
    ", because the": 0.25,
    "because the definition": 0.25,
    "the definition of": 1.0,
    "definition of proper": 0.3333333333333333,
    "of proper evaluation": 1.0,
    "proper evaluation criteria": 1.0,
    "evaluation criteria is": 0.5,
    "criteria is one": 1.0,
    "is one way": 0.16666666666666666,
    "one way to": 1.0,
    "way to specify": 0.1,
    "to specify precisely": 1.0,
    "specify precisely an": 1.0,
    "precisely an nlp": 1.0,
    "an nlp problem": 0.3333333333333333,
    "nlp problem ,": 0.5,
    "problem , going": 0.25,
    ", going thus": 1.0,
    "going thus beyond": 1.0,
    "thus beyond the": 1.0,
    "beyond the vagueness": 0.3333333333333333,
    "the vagueness of": 1.0,
    "vagueness of tasks": 1.0,
    "of tasks defined": 1.0,
    "tasks defined only": 1.0,
    "defined only as": 1.0,
    "only as language": 1.0,
    "as language understanding": 1.0,
    "language understanding or": 0.06666666666666667,
    "understanding or language": 1.0,
    "or language generation": 1.0,
    "language generation .": 0.16666666666666666,
    "<s> a precise": 0.022727272727272728,
    "a precise set": 0.5,
    "precise set of": 1.0,
    "set of evaluation": 0.03571428571428571,
    "of evaluation criteria": 0.2,
    "evaluation criteria ,": 0.5,
    "criteria , which": 1.0,
    ", which includes": 0.03571428571428571,
    "which includes mainly": 0.5,
    "includes mainly evaluation": 1.0,
    "mainly evaluation data": 1.0,
    "evaluation data and": 1.0,
    "data and evaluation": 0.5,
    "and evaluation metrics": 0.3333333333333333,
    "evaluation metrics ,": 1.0,
    "metrics , enables": 1.0,
    ", enables several": 1.0,
    "enables several teams": 1.0,
    "several teams to": 1.0,
    "teams to compare": 1.0,
    "to compare their": 0.25,
    "compare their solutions": 1.0,
    "their solutions to": 1.0,
    "solutions to a": 1.0,
    "to a given": 0.10714285714285714,
    "a given nlp": 0.08333333333333333,
    "given nlp problem": 1.0,
    "nlp problem .": 0.5,
    "<s> short history": 1.0,
    "short history of": 1.0,
    "history of evaluation": 0.5,
    "of evaluation in": 0.2,
    "evaluation in nlp": 0.25,
    "nlp the first": 0.5,
    "the first evaluation": 0.045454545454545456,
    "first evaluation campaign": 1.0,
    "evaluation campaign on": 1.0,
    "campaign on written": 1.0,
    "on written texts": 1.0,
    "written texts seems": 0.5,
    "texts seems to": 1.0,
    "seems to be": 0.5,
    "to be a": 0.11627906976744186,
    "be a campaign": 0.07692307692307693,
    "a campaign dedicated": 1.0,
    "campaign dedicated to": 1.0,
    "dedicated to message": 0.5,
    "to message understanding": 1.0,
    "message understanding in": 0.5,
    "understanding in 1987": 1.0,
    "in 1987 -lrb-": 0.3333333333333333,
    "1987 -lrb- pallet": 1.0,
    "-lrb- pallet 1998": 1.0,
    "pallet 1998 -rrb-": 1.0,
    "1998 -rrb- .": 1.0,
    "<s> then ,": 0.4,
    "then , the": 0.6,
    ", the parseval\\/geig": 0.009523809523809525,
    "the parseval\\/geig project": 1.0,
    "parseval\\/geig project compared": 1.0,
    "project compared phrase-structure": 0.5,
    "compared phrase-structure grammars": 1.0,
    "phrase-structure grammars -lrb-": 1.0,
    "grammars -lrb- black": 1.0,
    "-lrb- black 1991": 1.0,
    "black 1991 -rrb-": 1.0,
    "1991 -rrb- .": 1.0,
    "<s> a series": 0.022727272727272728,
    "a series of": 1.0,
    "series of campaigns": 0.14285714285714285,
    "of campaigns within": 1.0,
    "campaigns within tipster": 1.0,
    "within tipster project": 1.0,
    "tipster project were": 1.0,
    "project were realized": 1.0,
    "were realized on": 1.0,
    "realized on tasks": 1.0,
    "on tasks like": 1.0,
    "tasks like summarization": 0.5,
    "like summarization ,": 1.0,
    "summarization , translation": 0.25,
    ", translation and": 0.5,
    "translation and searching": 0.3333333333333333,
    "and searching -lrb-": 1.0,
    "searching -lrb- hirschman": 1.0,
    "-lrb- hirschman 1998": 1.0,
    "hirschman 1998 -rrb-": 1.0,
    "<s> in 1994": 0.010309278350515464,
    "in 1994 ,": 1.0,
    "1994 , in": 1.0,
    ", in germany": 0.029411764705882353,
    "in germany ,": 0.5,
    "germany , the": 1.0,
    ", the morpholympics": 0.009523809523809525,
    "the morpholympics compared": 1.0,
    "morpholympics compared german": 1.0,
    "compared german taggers": 1.0,
    "german taggers .": 1.0,
    ", the senseval": 0.009523809523809525,
    "the senseval and": 1.0,
    "senseval and romanseval": 1.0,
    "and romanseval campaigns": 1.0,
    "romanseval campaigns were": 1.0,
    "campaigns were conducted": 1.0,
    "were conducted with": 1.0,
    "conducted with the": 1.0,
    "with the objectives": 0.03333333333333333,
    "the objectives of": 1.0,
    "objectives of semantic": 1.0,
    "of semantic disambiguation": 0.2,
    "semantic disambiguation .": 1.0,
    "<s> in 1996": 0.010309278350515464,
    "in 1996 ,": 1.0,
    "1996 , the": 1.0,
    ", the sparkle": 0.009523809523809525,
    "the sparkle campaign": 1.0,
    "sparkle campaign compared": 1.0,
    "campaign compared syntactic": 1.0,
    "compared syntactic parsers": 1.0,
    "syntactic parsers in": 1.0,
    "parsers in four": 1.0,
    "in four different": 1.0,
    "four different languages": 0.5,
    "different languages -lrb-": 1.0,
    "languages -lrb- english": 0.5,
    "-lrb- english ,": 1.0,
    "english , french": 0.16666666666666666,
    ", french ,": 1.0,
    "french , german": 1.0,
    ", german and": 0.5,
    "german and italian": 1.0,
    "and italian -rrb-": 1.0,
    "italian -rrb- .": 1.0,
    "<s> in france": 0.020618556701030927,
    "in france ,": 0.5,
    "france , the": 0.5,
    ", the grace": 0.009523809523809525,
    "the grace project": 1.0,
    "grace project compared": 1.0,
    "project compared a": 0.5,
    "compared a set": 1.0,
    "set of 21": 0.03571428571428571,
    "of 21 taggers": 1.0,
    "21 taggers for": 1.0,
    "taggers for french": 1.0,
    "for french in": 0.3333333333333333,
    "french in 1997": 1.0,
    "in 1997 -lrb-": 0.5,
    "1997 -lrb- adda": 1.0,
    "-lrb- adda 1999": 1.0,
    "adda 1999 -rrb-": 1.0,
    "1999 -rrb- .": 1.0,
    "<s> in 2004": 0.010309278350515464,
    "in 2004 ,": 0.5,
    "2004 , during": 1.0,
    ", during the": 1.0,
    "during the technolangue\\/easy": 0.16666666666666666,
    "the technolangue\\/easy project": 1.0,
    "technolangue\\/easy project ,": 1.0,
    "project , 13": 0.16666666666666666,
    ", 13 parsers": 1.0,
    "13 parsers for": 1.0,
    "parsers for french": 1.0,
    "for french were": 0.6666666666666666,
    "french were compared": 1.0,
    "were compared .": 0.5,
    "<s> large-scale evaluation": 1.0,
    "large-scale evaluation of": 1.0,
    "evaluation of dependency": 0.2,
    "of dependency parsers": 1.0,
    "dependency parsers were": 1.0,
    "parsers were performed": 1.0,
    "were performed in": 1.0,
    "performed in the": 0.5,
    "in the context": 0.032679738562091505,
    "the context of": 0.7142857142857143,
    "context of the": 0.2,
    "of the conll": 0.005128205128205128,
    "the conll shared": 1.0,
    "conll shared tasks": 1.0,
    "shared tasks in": 0.5,
    "tasks in 2006": 0.3333333333333333,
    "in 2006 and": 0.5,
    "2006 and 2007": 1.0,
    "and 2007 .": 1.0,
    "<s> in italy": 0.010309278350515464,
    "in italy ,": 1.0,
    "italy , the": 0.5,
    ", the evalita": 0.009523809523809525,
    "the evalita campaign": 1.0,
    "evalita campaign was": 1.0,
    "campaign was conducted": 1.0,
    "was conducted in": 0.5,
    "conducted in 2007": 0.5,
    "in 2007 and": 1.0,
    "2007 and 2009": 1.0,
    "and 2009 to": 1.0,
    "2009 to compare": 1.0,
    "to compare various": 0.25,
    "compare various nlp": 1.0,
    "various nlp and": 1.0,
    "nlp and speech": 1.0,
    "and speech tools": 0.5,
    "speech tools for": 1.0,
    "tools for italian": 1.0,
    "for italian ;": 1.0,
    "italian ; the": 1.0,
    "; the 2011": 0.25,
    "the 2011 campaign": 1.0,
    "2011 campaign is": 1.0,
    "campaign is in": 1.0,
    "is in full": 0.3333333333333333,
    "in full progress": 1.0,
    "full progress -": 1.0,
    "progress - evalita": 1.0,
    "- evalita web": 1.0,
    "evalita web site": 1.0,
    "web site .": 1.0,
    "france , within": 0.5,
    ", within the": 1.0,
    "within the anr-passage": 0.3333333333333333,
    "the anr-passage project": 1.0,
    "anr-passage project -lrb-": 1.0,
    "project -lrb- end": 1.0,
    "-lrb- end of": 1.0,
    "end of 2007": 0.5,
    "of 2007 -rrb-": 0.5,
    "2007 -rrb- ,": 1.0,
    "-rrb- , 10": 0.01282051282051282,
    ", 10 parsers": 0.5,
    "10 parsers for": 1.0,
    "were compared -": 0.5,
    "compared - passage": 1.0,
    "- passage web": 1.0,
    "passage web site": 1.0,
    "<s> adda g.": 1.0,
    "adda g. ,": 1.0,
    "g. , mariani": 1.0,
    ", mariani j.": 1.0,
    "mariani j. ,": 1.0,
    "j. , paroubek": 0.5,
    ", paroubek p.": 1.0,
    "paroubek p. ,": 1.0,
    "p. , rajman": 0.5,
    ", rajman m.": 1.0,
    "rajman m. 1999": 1.0,
    "m. 1999 l'action": 1.0,
    "1999 l'action grace": 1.0,
    "l'action grace d'\u00e9valuation": 1.0,
    "grace d'\u00e9valuation de": 1.0,
    "d'\u00e9valuation de l'assignation": 1.0,
    "de l'assignation des": 1.0,
    "l'assignation des parties": 1.0,
    "des parties du": 1.0,
    "parties du discors": 1.0,
    "du discors pour": 1.0,
    "discors pour le": 1.0,
    "pour le fran\u00e7ais": 1.0,
    "le fran\u00e7ais .": 1.0,
    "<s> langues vol-2": 1.0,
    "langues vol-2 black": 1.0,
    "vol-2 black e.": 1.0,
    "black e. ,": 1.0,
    "e. , abney": 1.0,
    ", abney s.": 1.0,
    "abney s. ,": 1.0,
    "s. , flickinger": 0.5,
    ", flickinger d.": 1.0,
    "flickinger d. ,": 1.0,
    "d. , gdaniec": 0.5,
    ", gdaniec c.": 1.0,
    "gdaniec c. ,": 1.0,
    "c. , grishman": 1.0,
    ", grishman r.": 1.0,
    "grishman r. ,": 1.0,
    "r. , harrison": 0.5,
    ", harrison p.": 1.0,
    "harrison p. ,": 1.0,
    "p. , hindle": 0.5,
    ", hindle d.": 1.0,
    "hindle d. ,": 1.0,
    "d. , ingria": 0.5,
    ", ingria r.": 1.0,
    "ingria r. ,": 1.0,
    "r. , jelinek": 0.5,
    ", jelinek f.": 1.0,
    "jelinek f. ,": 1.0,
    "f. , klavans": 1.0,
    ", klavans j.": 1.0,
    "klavans j. ,": 1.0,
    "j. , liberman": 0.5,
    ", liberman m.": 1.0,
    "liberman m. ,": 1.0,
    "m. , marcus": 0.5,
    ", marcus m.": 1.0,
    "marcus m. ,": 1.0,
    "m. , reukos": 0.5,
    ", reukos s.": 1.0,
    "reukos s. ,": 1.0,
    "s. , santoni": 0.5,
    ", santoni b.": 1.0,
    "santoni b. ,": 1.0,
    "b. , strzalkowski": 1.0,
    ", strzalkowski t.": 1.0,
    "strzalkowski t. 1991": 1.0,
    "t. 1991 a": 1.0,
    "1991 a procedure": 1.0,
    "a procedure for": 1.0,
    "procedure for quantitatively": 1.0,
    "for quantitatively comparing": 1.0,
    "quantitatively comparing the": 1.0,
    "comparing the syntactic": 1.0,
    "the syntactic coverage": 1.0,
    "syntactic coverage of": 1.0,
    "coverage of english": 1.0,
    "of english grammars": 0.3333333333333333,
    "english grammars .": 1.0,
    "<s> darpa speech": 1.0,
    "darpa speech and": 1.0,
    "speech and natural": 0.14285714285714285,
    "and natural language": 1.0,
    "natural language workshop": 0.014492753623188406,
    "language workshop hirschman": 1.0,
    "workshop hirschman l.": 1.0,
    "hirschman l. 1998": 1.0,
    "l. 1998 language": 1.0,
    "1998 language understanding": 1.0,
    "language understanding evaluation": 0.06666666666666667,
    "understanding evaluation :": 1.0,
    "evaluation : lessons": 0.5,
    ": lessons learned": 1.0,
    "lessons learned from": 1.0,
    "learned from muc": 1.0,
    "from muc and": 1.0,
    "muc and atis": 1.0,
    "and atis .": 1.0,
    "<s> lrec granada": 1.0,
    "lrec granada pallet": 0.5,
    "granada pallet d.s.": 1.0,
    "pallet d.s. 1998": 1.0,
    "d.s. 1998 the": 1.0,
    "1998 the nist": 1.0,
    "the nist role": 1.0,
    "nist role in": 1.0,
    "role in automatic": 1.0,
    "in automatic speech": 0.5,
    "automatic speech recognition": 1.0,
    "speech recognition benchmark": 0.013157894736842105,
    "recognition benchmark tests": 1.0,
    "benchmark tests .": 1.0,
    "lrec granada different": 0.5,
    "granada different types": 1.0,
    "types of evaluation": 0.07142857142857142,
    "of evaluation depending": 0.2,
    "evaluation depending on": 1.0,
    "depending on the": 0.5,
    "on the evaluation": 0.014925373134328358,
    "the evaluation procedures": 0.2,
    "evaluation procedures ,": 1.0,
    "procedures , a": 1.0,
    ", a number": 0.08333333333333333,
    "number of distinctions": 0.027777777777777776,
    "of distinctions are": 1.0,
    "distinctions are traditionally": 1.0,
    "are traditionally made": 0.5,
    "traditionally made in": 1.0,
    "made in nlp": 0.5,
    "nlp evaluation .": 0.3333333333333333,
    "<s> intrinsic vs.": 0.5,
    "intrinsic vs. extrinsic": 1.0,
    "vs. extrinsic evaluation": 1.0,
    "extrinsic evaluation intrinsic": 0.25,
    "evaluation intrinsic evaluation": 1.0,
    "intrinsic evaluation considers": 0.3333333333333333,
    "evaluation considers an": 1.0,
    "considers an isolated": 1.0,
    "an isolated nlp": 1.0,
    "isolated nlp system": 1.0,
    "nlp system and": 0.25,
    "system and characterizes": 0.3333333333333333,
    "and characterizes its": 1.0,
    "characterizes its performance": 1.0,
    "its performance mainly": 1.0,
    "performance mainly with": 1.0,
    "mainly with respect": 1.0,
    "with respect to": 1.0,
    "respect to a": 0.2857142857142857,
    "to a gold": 0.03571428571428571,
    "a gold standard": 1.0,
    "gold standard result": 0.2,
    "standard result ,": 1.0,
    "result , pre-defined": 0.3333333333333333,
    ", pre-defined by": 1.0,
    "pre-defined by the": 1.0,
    "by the evaluators": 0.03571428571428571,
    "the evaluators .": 1.0,
    "<s> extrinsic evaluation": 0.5,
    "extrinsic evaluation ,": 0.25,
    "evaluation , also": 0.3333333333333333,
    ", also called": 0.4,
    "also called evaluation": 0.3333333333333333,
    "called evaluation in": 0.5,
    "evaluation in use": 0.25,
    "in use considers": 0.5,
    "use considers the": 1.0,
    "considers the nlp": 1.0,
    "the nlp system": 1.0,
    "nlp system in": 0.25,
    "system in a": 0.5,
    "in a more": 0.019230769230769232,
    "a more complex": 0.4,
    "more complex setting": 0.1111111111111111,
    "complex setting ,": 1.0,
    "setting , either": 0.5,
    ", either as": 0.5,
    "either as an": 0.6666666666666666,
    "as an embedded": 0.06666666666666667,
    "an embedded system": 1.0,
    "embedded system or": 1.0,
    "system or serving": 0.5,
    "or serving a": 1.0,
    "serving a precise": 1.0,
    "a precise function": 0.5,
    "precise function for": 1.0,
    "function for a": 1.0,
    "for a human": 0.03225806451612903,
    "a human user": 0.09090909090909091,
    "human user .": 1.0,
    "<s> the extrinsic": 0.006802721088435374,
    "the extrinsic performance": 1.0,
    "extrinsic performance of": 1.0,
    "performance of the": 0.5,
    "of the system": 0.020512820512820513,
    "the system is": 0.15384615384615385,
    "system is then": 0.1111111111111111,
    "is then characterized": 0.2,
    "then characterized in": 1.0,
    "characterized in terms": 1.0,
    "in terms of": 1.0,
    "terms of its": 0.14285714285714285,
    "of its utility": 0.125,
    "its utility with": 1.0,
    "utility with respect": 1.0,
    "respect to the": 0.14285714285714285,
    "to the overall": 0.012987012987012988,
    "the overall task": 0.3333333333333333,
    "overall task of": 1.0,
    "task of the": 0.2222222222222222,
    "of the complex": 0.005128205128205128,
    "the complex system": 1.0,
    "complex system or": 0.5,
    "system or the": 0.5,
    "or the human": 0.1111111111111111,
    "the human user": 0.25,
    "example , consider": 0.018518518518518517,
    ", consider a": 1.0,
    "consider a syntactic": 1.0,
    "a syntactic parser": 1.0,
    "syntactic parser that": 1.0,
    "parser that is": 1.0,
    "that is based": 0.05263157894736842,
    "is based on": 0.75,
    "on the output": 0.014925373134328358,
    "the output of": 0.6666666666666666,
    "output of some": 0.25,
    "of some new": 0.2,
    "some new part": 1.0,
    "new part of": 1.0,
    "of speech -lrb-": 0.02127659574468085,
    "speech -lrb- pos": 0.25,
    "-lrb- pos -rrb-": 0.5,
    "pos -rrb- tagger": 1.0,
    "-rrb- tagger .": 1.0,
    "<s> an intrinsic": 0.18181818181818182,
    "an intrinsic evaluation": 1.0,
    "intrinsic evaluation would": 0.3333333333333333,
    "evaluation would run": 0.6666666666666666,
    "would run the": 1.0,
    "run the pos": 0.5,
    "the pos tagger": 0.6666666666666666,
    "pos tagger on": 0.25,
    "tagger on some": 1.0,
    "on some labeled": 0.1111111111111111,
    "some labeled data": 1.0,
    "labeled data ,": 1.0,
    ", and compare": 0.010582010582010581,
    "and compare the": 1.0,
    "compare the system": 0.5,
    "the system output": 0.038461538461538464,
    "system output of": 1.0,
    "output of the": 0.5,
    "of the pos": 0.005128205128205128,
    "pos tagger to": 0.25,
    "tagger to the": 1.0,
    "to the gold": 0.012987012987012988,
    "the gold standard": 1.0,
    "gold standard -lrb-": 0.4,
    "standard -lrb- correct": 0.5,
    "-lrb- correct -rrb-": 1.0,
    "correct -rrb- output": 1.0,
    "-rrb- output .": 1.0,
    "<s> an extrinsic": 0.09090909090909091,
    "an extrinsic evaluation": 1.0,
    "extrinsic evaluation would": 0.25,
    "run the parser": 0.5,
    "the parser with": 0.2,
    "parser with some": 1.0,
    "with some other": 0.25,
    "some other pos": 0.14285714285714285,
    "other pos tagger": 1.0,
    "pos tagger ,": 0.5,
    "tagger , and": 0.4,
    ", and then": 0.021164021164021163,
    "and then with": 0.14285714285714285,
    "then with the": 1.0,
    "with the new": 0.03333333333333333,
    "the new pos": 1.0,
    "new pos tagger": 1.0,
    "compare the parsing": 0.5,
    "the parsing accuracy": 0.5,
    "parsing accuracy .": 1.0,
    "<s> black-box vs.": 1.0,
    "black-box vs. glass-box": 1.0,
    "vs. glass-box evaluation": 1.0,
    "glass-box evaluation black-box": 0.3333333333333333,
    "evaluation black-box evaluation": 1.0,
    "black-box evaluation requires": 1.0,
    "evaluation requires one": 1.0,
    "requires one to": 1.0,
    "one to run": 0.5,
    "to run an": 1.0,
    "run an nlp": 1.0,
    "an nlp system": 0.6666666666666666,
    "nlp system on": 0.25,
    "system on a": 1.0,
    "on a given": 0.041666666666666664,
    "a given data": 0.08333333333333333,
    "given data set": 1.0,
    "data set and": 1.0,
    "set and to": 1.0,
    "and to measure": 0.09090909090909091,
    "to measure a": 0.25,
    "measure a number": 1.0,
    "number of parameters": 0.027777777777777776,
    "of parameters related": 1.0,
    "parameters related to": 1.0,
    "related to the": 0.5,
    "to the quality": 0.025974025974025976,
    "the quality of": 0.8,
    "quality of the": 0.4,
    "of the process": 0.005128205128205128,
    "the process -lrb-": 0.07142857142857142,
    "process -lrb- speed": 1.0,
    "-lrb- speed ,": 1.0,
    "speed , reliability": 0.5,
    ", reliability ,": 1.0,
    "reliability , resource": 1.0,
    ", resource consumption": 1.0,
    "resource consumption -rrb-": 1.0,
    "consumption -rrb- and": 1.0,
    "-rrb- and ,": 0.05,
    "and , most": 0.3333333333333333,
    ", most importantly": 0.125,
    "most importantly ,": 1.0,
    "importantly , to": 1.0,
    ", to the": 0.15384615384615385,
    "of the result": 0.005128205128205128,
    "the result -lrb-": 0.2,
    "result -lrb- e.g.": 1.0,
    "-lrb- e.g. the": 0.07894736842105263,
    "e.g. the accuracy": 0.2,
    "the accuracy of": 0.6666666666666666,
    "accuracy of data": 0.14285714285714285,
    "of data annotation": 0.14285714285714285,
    "data annotation or": 1.0,
    "annotation or the": 1.0,
    "or the fidelity": 0.1111111111111111,
    "the fidelity of": 1.0,
    "fidelity of a": 1.0,
    "of a translation": 0.010869565217391304,
    "a translation -rrb-": 0.5,
    "translation -rrb- .": 0.5,
    "<s> glass-box evaluation": 1.0,
    "glass-box evaluation looks": 0.3333333333333333,
    "evaluation looks at": 1.0,
    "looks at the": 1.0,
    "at the design": 0.0625,
    "the design of": 0.5,
    "design of the": 1.0,
    "the system ,": 0.07692307692307693,
    "system , the": 0.3,
    ", the algorithms": 0.009523809523809525,
    "the algorithms that": 0.25,
    "algorithms that are": 0.5,
    "that are implemented": 0.06666666666666667,
    "are implemented ,": 1.0,
    "implemented , the": 1.0,
    ", the linguistic": 0.009523809523809525,
    "the linguistic resources": 1.0,
    "linguistic resources it": 1.0,
    "resources it uses": 1.0,
    "it uses -lrb-": 0.5,
    "uses -lrb- e.g.": 1.0,
    "-lrb- e.g. vocabulary": 0.02631578947368421,
    "e.g. vocabulary size": 1.0,
    "vocabulary size -rrb-": 0.3333333333333333,
    "size -rrb- ,": 1.0,
    "-rrb- , etc.": 0.02564102564102564,
    "<s> given the": 0.3333333333333333,
    "given the complexity": 1.0,
    "complexity of nlp": 0.125,
    "of nlp problems": 0.2,
    "nlp problems ,": 1.0,
    "problems , it": 0.16666666666666666,
    "is often difficult": 0.09090909090909091,
    "often difficult to": 1.0,
    "difficult to predict": 0.09090909090909091,
    "to predict performance": 0.5,
    "predict performance only": 1.0,
    "performance only on": 1.0,
    "only on the": 0.5,
    "basis of glass-box": 0.25,
    "of glass-box evaluation": 1.0,
    "glass-box evaluation ,": 0.3333333333333333,
    "evaluation , but": 0.3333333333333333,
    ", but this": 0.0625,
    "but this type": 0.25,
    "this type of": 0.6666666666666666,
    "type of evaluation": 0.125,
    "of evaluation is": 0.2,
    "evaluation is more": 0.25,
    "is more informative": 0.3333333333333333,
    "more informative with": 1.0,
    "informative with respect": 1.0,
    "respect to error": 0.14285714285714285,
    "to error analysis": 1.0,
    "error analysis or": 1.0,
    "analysis or future": 0.3333333333333333,
    "or future developments": 1.0,
    "future developments of": 1.0,
    "developments of a": 1.0,
    "of a system": 0.043478260869565216,
    "a system .": 0.1,
    "<s> automatic vs.": 0.14285714285714285,
    "automatic vs. manual": 1.0,
    "vs. manual evaluation": 1.0,
    "manual evaluation in": 0.3333333333333333,
    "evaluation in many": 0.25,
    "in many cases": 0.1,
    "many cases ,": 0.5,
    "cases , automatic": 0.14285714285714285,
    ", automatic procedures": 0.3333333333333333,
    "automatic procedures can": 1.0,
    "procedures can be": 0.5,
    "can be defined": 0.01098901098901099,
    "be defined to": 1.0,
    "defined to evaluate": 1.0,
    "to evaluate an": 0.25,
    "evaluate an nlp": 1.0,
    "nlp system by": 0.25,
    "system by comparing": 1.0,
    "by comparing its": 1.0,
    "comparing its output": 1.0,
    "its output with": 0.3333333333333333,
    "output with the": 1.0,
    "with the gold": 0.03333333333333333,
    "standard -lrb- or": 0.5,
    "-lrb- or desired": 0.1,
    "or desired -rrb-": 1.0,
    "desired -rrb- one": 1.0,
    "-rrb- one .": 1.0,
    "<s> although the": 0.42857142857142855,
    "although the cost": 0.3333333333333333,
    "the cost of": 1.0,
    "cost of producing": 1.0,
    "of producing the": 1.0,
    "producing the gold": 1.0,
    "gold standard can": 0.2,
    "standard can be": 1.0,
    "can be quite": 0.01098901098901099,
    "be quite high": 1.0,
    "quite high ,": 1.0,
    "high , automatic": 1.0,
    ", automatic evaluation": 0.3333333333333333,
    "automatic evaluation can": 0.3333333333333333,
    "evaluation can be": 1.0,
    "can be repeated": 0.01098901098901099,
    "be repeated as": 1.0,
    "repeated as often": 1.0,
    "as often as": 1.0,
    "often as needed": 0.5,
    "as needed without": 1.0,
    "needed without much": 1.0,
    "without much additional": 1.0,
    "much additional costs": 1.0,
    "additional costs -lrb-": 1.0,
    "costs -lrb- on": 1.0,
    "-lrb- on the": 0.5,
    "on the same": 0.029850746268656716,
    "the same input": 0.08333333333333333,
    "same input data": 1.0,
    "input data -rrb-": 0.16666666666666666,
    "however , for": 0.022727272727272728,
    ", for many": 0.045454545454545456,
    "for many nlp": 0.5,
    "many nlp problems": 1.0,
    "problems , the": 0.16666666666666666,
    ", the definition": 0.009523809523809525,
    "definition of a": 0.3333333333333333,
    "of a gold": 0.010869565217391304,
    "gold standard is": 0.2,
    "standard is a": 1.0,
    "is a complex": 0.018518518518518517,
    "a complex task": 0.2,
    "complex task ,": 1.0,
    ", and can": 0.026455026455026454,
    "and can prove": 0.125,
    "can prove impossible": 1.0,
    "prove impossible when": 1.0,
    "impossible when inter-annotator": 1.0,
    "when inter-annotator agreement": 1.0,
    "inter-annotator agreement is": 1.0,
    "agreement is insufficient": 1.0,
    "is insufficient .": 1.0,
    "<s> manual evaluation": 1.0,
    "manual evaluation is": 0.3333333333333333,
    "evaluation is performed": 0.25,
    "is performed by": 0.5,
    "performed by human": 0.5,
    "by human judges": 0.3333333333333333,
    "human judges ,": 0.5,
    "judges , which": 1.0,
    ", which are": 0.08928571428571429,
    "which are instructed": 0.08333333333333333,
    "are instructed to": 1.0,
    "instructed to estimate": 1.0,
    "to estimate the": 0.6666666666666666,
    "estimate the quality": 0.5,
    "quality of a": 0.6,
    "system , or": 0.1,
    ", or most": 0.030303030303030304,
    "or most often": 1.0,
    "most often of": 1.0,
    "often of a": 1.0,
    "of a sample": 0.010869565217391304,
    "a sample of": 1.0,
    "sample of its": 1.0,
    "of its output": 0.125,
    "its output ,": 0.3333333333333333,
    "output , based": 1.0,
    ", based on": 1.0,
    "based on a": 0.08695652173913043,
    "on a number": 0.041666666666666664,
    "number of criteria": 0.027777777777777776,
    "of criteria .": 1.0,
    "<s> although ,": 0.14285714285714285,
    "although , thanks": 1.0,
    ", thanks to": 1.0,
    "thanks to their": 1.0,
    "to their linguistic": 0.5,
    "their linguistic competence": 1.0,
    "linguistic competence ,": 1.0,
    "competence , human": 1.0,
    ", human judges": 0.16666666666666666,
    "human judges can": 0.5,
    "judges can be": 1.0,
    "can be considered": 0.01098901098901099,
    "be considered as": 0.5,
    "considered as the": 1.0,
    "as the reference": 0.03571428571428571,
    "the reference for": 1.0,
    "reference for a": 1.0,
    "for a number": 0.16129032258064516,
    "number of language": 0.027777777777777776,
    "of language processing": 0.2,
    "language processing tasks": 0.027777777777777776,
    "processing tasks ,": 1.0,
    "tasks , there": 0.25,
    "there is also": 0.11764705882352941,
    "is also considerable": 0.1,
    "also considerable variation": 1.0,
    "considerable variation across": 1.0,
    "variation across their": 1.0,
    "across their ratings": 1.0,
    "their ratings .": 1.0,
    "this is why": 0.038461538461538464,
    "is why automatic": 1.0,
    "why automatic evaluation": 1.0,
    "automatic evaluation is": 0.3333333333333333,
    "evaluation is sometimes": 0.25,
    "to as objective": 0.25,
    "as objective evaluation": 1.0,
    "objective evaluation ,": 1.0,
    "evaluation , while": 0.3333333333333333,
    ", while the": 0.07142857142857142,
    "while the human": 1.0,
    "the human kind": 0.25,
    "human kind appears": 1.0,
    "kind appears to": 1.0,
    "appears to be": 1.0,
    "to be more": 0.023255813953488372,
    "be more subjective": 0.2,
    "more subjective .": 1.0,
    "<s> shared tasks": 1.0,
    "shared tasks -lrb-": 0.5,
    "tasks -lrb- campaigns": 1.0,
    "-lrb- campaigns -rrb-": 1.0,
    "campaigns -rrb- biocreative": 1.0,
    "-rrb- biocreative message": 1.0,
    "biocreative message understanding": 1.0,
    "message understanding conference": 0.5,
    "understanding conference technolangue\\/easy": 1.0,
    "conference technolangue\\/easy text": 1.0,
    "technolangue\\/easy text retrieval": 1.0,
    "text retrieval conference": 1.0,
    "retrieval conference evaluation": 1.0,
    "conference evaluation exercises": 1.0,
    "evaluation exercises on": 1.0,
    "exercises on semantic": 1.0,
    "on semantic evaluation": 1.0,
    "semantic evaluation -lrb-": 1.0,
    "evaluation -lrb- semeval": 0.5,
    "-lrb- semeval -rrb-": 1.0,
    "semeval -rrb- morphochallenge": 1.0,
    "-rrb- morphochallenge semi-supervised": 1.0,
    "morphochallenge semi-supervised and": 1.0,
    "semi-supervised and unsupervised": 1.0,
    "and unsupervised morpheme": 1.0,
    "unsupervised morpheme analysis": 1.0,
    "morpheme analysis standardization": 1.0,
    "analysis standardization in": 1.0,
    "standardization in nlp": 1.0,
    "in nlp an": 0.125,
    "nlp an iso": 1.0,
    "an iso sub-committee": 1.0,
    "iso sub-committee is": 1.0,
    "sub-committee is working": 0.5,
    "is working in": 0.5,
    "working in order": 0.5,
    "order to ease": 0.125,
    "to ease interoperability": 1.0,
    "ease interoperability between": 1.0,
    "interoperability between lexical": 1.0,
    "between lexical resources": 0.5,
    "lexical resources and": 1.0,
    "resources and nlp": 1.0,
    "and nlp programs": 0.5,
    "nlp programs .": 1.0,
    "<s> the sub-committee": 0.006802721088435374,
    "the sub-committee is": 1.0,
    "sub-committee is part": 0.5,
    "is part of": 1.0,
    "part of iso\\/tc37": 0.045454545454545456,
    "of iso\\/tc37 and": 1.0,
    "iso\\/tc37 and is": 1.0,
    "and is called": 0.16666666666666666,
    "is called iso\\/tc37\\/sc4": 0.16666666666666666,
    "called iso\\/tc37\\/sc4 .": 1.0,
    "<s> some iso": 0.0625,
    "some iso standards": 1.0,
    "iso standards are": 1.0,
    "standards are already": 1.0,
    "are already published": 1.0,
    "already published but": 1.0,
    "published but most": 1.0,
    "but most of": 0.5,
    "most of them": 0.16666666666666666,
    "of them are": 0.5,
    "them are under": 0.5,
    "are under construction": 1.0,
    "under construction ,": 1.0,
    "construction , mainly": 1.0,
    ", mainly on": 1.0,
    "mainly on lexicon": 1.0,
    "on lexicon representation": 1.0,
    "lexicon representation -lrb-": 1.0,
    "representation -lrb- see": 0.5,
    "-lrb- see lmf": 0.0625,
    "see lmf -rrb-": 1.0,
    "lmf -rrb- ,": 1.0,
    "-rrb- , annotation": 0.01282051282051282,
    ", annotation and": 1.0,
    "annotation and data": 1.0,
    "and data category": 0.25,
    "data category registry": 1.0,
    "category registry .": 1.0,
    "automatic summarization is": 0.25,
    "summarization is the": 0.3333333333333333,
    "is the creation": 0.022222222222222223,
    "the creation of": 1.0,
    "creation of a": 0.5,
    "of a shortened": 0.010869565217391304,
    "a shortened version": 1.0,
    "shortened version of": 1.0,
    "version of a": 0.5,
    "of a text": 0.043478260869565216,
    "a text by": 0.07142857142857142,
    "text by a": 1.0,
    "by a computer": 0.05555555555555555,
    "computer program .": 0.6,
    "<s> the product": 0.013605442176870748,
    "the product of": 0.5,
    "product of this": 1.0,
    "of this procedure": 0.09090909090909091,
    "this procedure still": 1.0,
    "procedure still contains": 1.0,
    "still contains the": 1.0,
    "contains the most": 0.5,
    "the most important": 0.041666666666666664,
    "most important points": 0.5,
    "important points of": 1.0,
    "points of the": 1.0,
    "of the original": 0.010256410256410256,
    "the original text": 0.6,
    "original text .": 0.5,
    "discourse analysis -lrb-": 0.18181818181818182,
    "analysis -lrb- da": 0.5,
    "-lrb- da -rrb-": 1.0,
    "da -rrb- ,": 0.5,
    "-rrb- , or": 0.038461538461538464,
    ", or discourse": 0.030303030303030304,
    "or discourse studies": 0.5,
    "discourse studies ,": 1.0,
    "studies , is": 0.5,
    ", is a": 0.3076923076923077,
    "is a general": 0.037037037037037035,
    "a general term": 0.3333333333333333,
    "general term for": 1.0,
    "term for a": 0.3333333333333333,
    "number of approaches": 0.027777777777777776,
    "of approaches to": 1.0,
    "approaches to analyzing": 0.2,
    "to analyzing written": 1.0,
    "analyzing written ,": 1.0,
    "written , spoken": 1.0,
    ", spoken ,": 1.0,
    "spoken , signed": 0.5,
    ", signed language": 1.0,
    "signed language use": 1.0,
    "language use or": 0.25,
    "use or any": 0.5,
    "or any significant": 0.3333333333333333,
    "any significant semiotic": 1.0,
    "significant semiotic event": 1.0,
    "semiotic event .": 1.0,
    "translation , sometimes": 0.125,
    ", sometimes referred": 1.0,
    "referred to by": 0.25,
    "to by the": 0.5,
    "by the abbreviation": 0.03571428571428571,
    "the abbreviation mt": 1.0,
    "abbreviation mt -lrb-": 1.0,
    "mt -lrb- not": 1.0,
    "-lrb- not to": 1.0,
    "not to be": 1.0,
    "to be confused": 0.023255813953488372,
    "be confused with": 1.0,
    "confused with computer-aided": 0.5,
    "with computer-aided translation": 1.0,
    "computer-aided translation ,": 1.0,
    "translation , machine-aided": 0.125,
    ", machine-aided human": 1.0,
    "machine-aided human translation": 1.0,
    "human translation maht": 0.5,
    "translation maht and": 1.0,
    "maht and interactive": 1.0,
    "and interactive translation": 1.0,
    "interactive translation -rrb-": 1.0,
    "translation -rrb- is": 0.5,
    "is a sub-field": 0.018518518518518517,
    "a sub-field of": 1.0,
    "sub-field of computational": 1.0,
    "computational linguistics that": 0.1111111111111111,
    "linguistics that investigates": 0.5,
    "that investigates the": 1.0,
    "investigates the use": 1.0,
    "use of software": 0.045454545454545456,
    "of software to": 1.0,
    "software to translate": 0.5,
    "to translate text": 0.25,
    "translate text or": 0.5,
    "text or speech": 0.3333333333333333,
    "or speech from": 1.0,
    "speech from one": 1.0,
    "from one natural": 0.3333333333333333,
    "one natural language": 1.0,
    "natural language to": 0.014492753623188406,
    "<s> on a": 0.2,
    "on a basic": 0.041666666666666664,
    "a basic level": 0.5,
    "basic level ,": 1.0,
    "level , mt": 0.25,
    ", mt performs": 0.5,
    "mt performs simple": 1.0,
    "performs simple substitution": 1.0,
    "simple substitution of": 1.0,
    "substitution of words": 0.5,
    "words in one": 0.09090909090909091,
    "in one natural": 0.2,
    "natural language for": 0.014492753623188406,
    "language for words": 0.3333333333333333,
    "for words in": 1.0,
    "words in another": 0.09090909090909091,
    "in another ,": 0.25,
    "another , but": 1.0,
    ", but that": 0.041666666666666664,
    "but that alone": 0.3333333333333333,
    "that alone usually": 1.0,
    "alone usually can": 1.0,
    "usually can not": 1.0,
    "can not produce": 0.06666666666666667,
    "not produce a": 1.0,
    "produce a good": 0.25,
    "a good translation": 0.2,
    "good translation of": 1.0,
    "translation of a": 0.18181818181818182,
    "a text ,": 0.2857142857142857,
    "text , because": 0.03333333333333333,
    ", because recognition": 0.125,
    "because recognition of": 1.0,
    "recognition of whole": 0.09090909090909091,
    "of whole phrases": 0.5,
    "whole phrases and": 1.0,
    "phrases and their": 0.3333333333333333,
    "and their closest": 0.16666666666666666,
    "their closest counterparts": 1.0,
    "closest counterparts in": 1.0,
    "counterparts in the": 1.0,
    "in the target": 0.032679738562091505,
    "the target language": 0.8,
    "target language is": 0.375,
    "language is needed": 0.2,
    "is needed .": 1.0,
    "<s> solving this": 1.0,
    "solving this problem": 1.0,
    "this problem with": 0.09090909090909091,
    "problem with corpus": 1.0,
    "with corpus and": 1.0,
    "corpus and statistical": 0.3333333333333333,
    "and statistical techniques": 0.3333333333333333,
    "statistical techniques is": 0.3333333333333333,
    "techniques is a": 1.0,
    "is a rapidly": 0.018518518518518517,
    "a rapidly growing": 1.0,
    "rapidly growing field": 1.0,
    "growing field that": 0.5,
    "field that is": 0.5,
    "that is leading": 0.05263157894736842,
    "is leading to": 1.0,
    "leading to better": 0.5,
    "to better translations": 0.3333333333333333,
    "better translations ,": 1.0,
    "translations , handling": 1.0,
    ", handling differences": 0.5,
    "handling differences in": 1.0,
    "differences in linguistic": 1.0,
    "in linguistic typology": 0.5,
    "linguistic typology ,": 1.0,
    "typology , translation": 1.0,
    ", translation of": 0.5,
    "translation of idioms": 0.09090909090909091,
    "of idioms ,": 1.0,
    "idioms , and": 0.5,
    "and the isolation": 0.024390243902439025,
    "the isolation of": 1.0,
    "isolation of anomalies": 1.0,
    "of anomalies .": 1.0,
    "<s> -lrb- citation": 0.2631578947368421,
    "-lrb- citation needed": 1.0,
    "citation needed -rrb-": 1.0,
    "needed -rrb- current": 0.07692307692307693,
    "-rrb- current machine": 1.0,
    "current machine translation": 1.0,
    "machine translation software": 0.045454545454545456,
    "translation software often": 0.3333333333333333,
    "software often allows": 1.0,
    "often allows for": 1.0,
    "allows for customisation": 1.0,
    "for customisation by": 1.0,
    "customisation by domain": 1.0,
    "by domain or": 1.0,
    "domain or profession": 1.0,
    "or profession -lrb-": 1.0,
    "profession -lrb- such": 1.0,
    "such as weather": 0.011111111111111112,
    "as weather reports": 1.0,
    "weather reports -rrb-": 1.0,
    "reports -rrb- ,": 0.5,
    "-rrb- , improving": 0.01282051282051282,
    ", improving output": 1.0,
    "improving output by": 1.0,
    "output by limiting": 1.0,
    "by limiting the": 1.0,
    "limiting the scope": 1.0,
    "the scope of": 1.0,
    "scope of allowable": 0.5,
    "of allowable substitutions": 1.0,
    "allowable substitutions .": 1.0,
    "<s> this technique": 0.019230769230769232,
    "this technique is": 1.0,
    "technique is particularly": 1.0,
    "is particularly effective": 0.5,
    "particularly effective in": 1.0,
    "effective in domains": 0.5,
    "in domains where": 1.0,
    "domains where formal": 1.0,
    "where formal or": 1.0,
    "formal or formulaic": 1.0,
    "or formulaic language": 1.0,
    "formulaic language is": 1.0,
    "language is used": 0.2,
    "is used .": 0.07692307692307693,
    "<s> it follows": 0.029411764705882353,
    "it follows that": 1.0,
    "follows that machine": 1.0,
    "that machine translation": 0.6666666666666666,
    "machine translation of": 0.045454545454545456,
    "translation of government": 0.09090909090909091,
    "of government and": 0.5,
    "government and legal": 1.0,
    "and legal documents": 1.0,
    "legal documents more": 1.0,
    "documents more readily": 1.0,
    "more readily produces": 1.0,
    "readily produces usable": 1.0,
    "produces usable output": 1.0,
    "usable output than": 1.0,
    "output than conversation": 1.0,
    "than conversation or": 1.0,
    "conversation or less": 1.0,
    "or less standardised": 0.25,
    "less standardised text": 1.0,
    "standardised text .": 1.0,
    "<s> improved output": 1.0,
    "improved output quality": 1.0,
    "output quality can": 1.0,
    "quality can also": 1.0,
    "can also be": 0.5,
    "also be achieved": 0.14285714285714285,
    "be achieved by": 0.2,
    "achieved by human": 0.5,
    "by human intervention": 0.3333333333333333,
    "human intervention :": 1.0,
    "intervention : for": 1.0,
    ": for example": 1.0,
    "example , some": 0.018518518518518517,
    ", some systems": 0.1111111111111111,
    "some systems are": 0.5,
    "systems are able": 0.15384615384615385,
    "able to translate": 0.0625,
    "to translate more": 0.25,
    "translate more accurately": 1.0,
    "more accurately if": 1.0,
    "accurately if the": 1.0,
    "if the user": 0.07142857142857142,
    "the user has": 0.16666666666666666,
    "user has unambiguously": 1.0,
    "has unambiguously identified": 1.0,
    "unambiguously identified which": 1.0,
    "identified which words": 1.0,
    "which words in": 0.5,
    "the text are": 0.038461538461538464,
    "text are names": 1.0,
    "are names .": 1.0,
    "<s> with the": 0.4,
    "with the assistance": 0.03333333333333333,
    "the assistance of": 1.0,
    "assistance of these": 1.0,
    "of these techniques": 0.09090909090909091,
    "these techniques ,": 1.0,
    "techniques , mt": 0.5,
    ", mt has": 0.5,
    "mt has proven": 1.0,
    "has proven useful": 1.0,
    "proven useful as": 1.0,
    "useful as a": 1.0,
    "as a tool": 0.027777777777777776,
    "a tool to": 0.5,
    "tool to assist": 1.0,
    "to assist human": 1.0,
    "assist human translators": 1.0,
    "human translators and": 1.0,
    "translators and ,": 1.0,
    "and , in": 0.3333333333333333,
    "in a very": 0.019230769230769232,
    "a very limited": 0.08333333333333333,
    "very limited number": 0.5,
    "limited number of": 1.0,
    "number of cases": 0.027777777777777776,
    "of cases ,": 1.0,
    "cases , can": 0.14285714285714285,
    ", can even": 0.16666666666666666,
    "can even produce": 1.0,
    "even produce output": 1.0,
    "produce output that": 0.5,
    "output that can": 0.5,
    "can be used": 0.054945054945054944,
    "be used as": 0.10526315789473684,
    "used as is": 0.2,
    "as is -lrb-": 0.25,
    "-lrb- e.g. ,": 0.5,
    "e.g. , weather": 0.038461538461538464,
    ", weather reports": 1.0,
    "reports -rrb- .": 0.5,
    "<s> the progress": 0.006802721088435374,
    "the progress and": 1.0,
    "progress and potential": 1.0,
    "and potential of": 1.0,
    "potential of machine": 0.5,
    "machine translation has": 0.022727272727272728,
    "translation has been": 0.5,
    "has been debated": 0.03571428571428571,
    "been debated much": 1.0,
    "debated much through": 1.0,
    "much through its": 1.0,
    "through its history": 1.0,
    "its history .": 1.0,
    "<s> since the": 0.25,
    "since the 1950s": 0.5,
    "the 1950s ,": 0.6666666666666666,
    "1950s , a": 0.5,
    "number of scholars": 0.027777777777777776,
    "of scholars have": 1.0,
    "scholars have questioned": 1.0,
    "have questioned the": 1.0,
    "questioned the possibility": 1.0,
    "the possibility of": 0.75,
    "possibility of achieving": 0.3333333333333333,
    "of achieving fully": 0.5,
    "achieving fully automatic": 1.0,
    "fully automatic machine": 0.3333333333333333,
    "automatic machine translation": 1.0,
    "translation of high": 0.09090909090909091,
    "of high quality": 1.0,
    "high quality .": 1.0,
    "<s> some critics": 0.0625,
    "some critics claim": 1.0,
    "critics claim that": 1.0,
    "claim that there": 1.0,
    "that there are": 1.0,
    "there are in-principle": 0.047619047619047616,
    "are in-principle obstacles": 1.0,
    "in-principle obstacles to": 1.0,
    "obstacles to automatizing": 1.0,
    "to automatizing the": 1.0,
    "automatizing the translation": 1.0,
    "the translation process": 0.16666666666666666,
    "translation process .": 0.25,
    "<s> in 1629": 0.010309278350515464,
    "in 1629 ,": 1.0,
    "1629 , ren\u00e9": 1.0,
    ", ren\u00e9 descartes": 1.0,
    "ren\u00e9 descartes proposed": 1.0,
    "descartes proposed a": 1.0,
    "proposed a universal": 0.5,
    "a universal language": 0.5,
    "universal language ,": 1.0,
    "language , with": 0.14285714285714285,
    ", with equivalent": 0.125,
    "with equivalent ideas": 0.5,
    "equivalent ideas in": 1.0,
    "ideas in different": 0.5,
    "in different tongues": 0.3333333333333333,
    "different tongues sharing": 1.0,
    "tongues sharing one": 1.0,
    "sharing one symbol": 1.0,
    "one symbol .": 1.0,
    "in the 1950s": 0.013071895424836602,
    "1950s , the": 0.5,
    ", the georgetown": 0.009523809523809525,
    "georgetown experiment -lrb-": 0.3333333333333333,
    "experiment -lrb- 1954": 1.0,
    "-lrb- 1954 -rrb-": 1.0,
    "1954 -rrb- involved": 1.0,
    "-rrb- involved fully": 1.0,
    "translation of over": 0.09090909090909091,
    "of over sixty": 1.0,
    "over sixty russian": 1.0,
    "<s> the experiment": 0.006802721088435374,
    "the experiment was": 1.0,
    "experiment was a": 0.5,
    "was a great": 0.3333333333333333,
    "a great success": 0.5,
    "great success and": 1.0,
    "success and ushered": 1.0,
    "and ushered in": 1.0,
    "ushered in an": 1.0,
    "in an era": 0.125,
    "an era of": 1.0,
    "era of substantial": 1.0,
    "of substantial funding": 1.0,
    "substantial funding for": 1.0,
    "funding for machine-translation": 0.5,
    "for machine-translation research": 1.0,
    "machine-translation research .": 1.0,
    "within three to": 0.5,
    "three to five": 1.0,
    "to five years": 1.0,
    "<s> real progress": 0.5,
    "slower , however": 0.5,
    "however , and": 0.022727272727272728,
    "alpac report -lrb-": 0.5,
    "report -lrb- 1966": 1.0,
    "-lrb- 1966 -rrb-": 1.0,
    "1966 -rrb- ,": 1.0,
    "found that the": 0.2,
    "that the ten-year-long": 0.043478260869565216,
    "the ten-year-long research": 1.0,
    "ten-year-long research had": 1.0,
    "to fulfill expectations": 0.5,
    "fulfill expectations ,": 1.0,
    ", funding was": 0.3333333333333333,
    "funding was greatly": 1.0,
    "was greatly reduced": 1.0,
    "greatly reduced .": 1.0,
    "<s> beginning in": 1.0,
    "beginning in the": 0.5,
    "1980s , as": 0.2,
    ", as computational": 0.043478260869565216,
    "as computational power": 1.0,
    "computational power increased": 0.5,
    "power increased and": 1.0,
    "increased and became": 1.0,
    "and became less": 1.0,
    "became less expensive": 1.0,
    "less expensive ,": 1.0,
    "expensive , more": 0.3333333333333333,
    ", more interest": 0.25,
    "more interest was": 1.0,
    "interest was shown": 1.0,
    "was shown in": 0.5,
    "shown in statistical": 0.5,
    "in statistical models": 0.3333333333333333,
    "statistical models for": 0.125,
    "models for machine": 0.16666666666666666,
    "machine translation .": 0.06818181818181818,
    "<s> the idea": 0.013605442176870748,
    "the idea of": 0.5,
    "idea of using": 0.5,
    "of using digital": 1.0,
    "using digital computers": 1.0,
    "digital computers for": 1.0,
    "computers for translation": 1.0,
    "for translation of": 1.0,
    "translation of natural": 0.09090909090909091,
    "natural languages was": 0.1111111111111111,
    "languages was proposed": 1.0,
    "was proposed as": 0.5,
    "proposed as early": 1.0,
    "as early as": 1.0,
    "early as 1946": 1.0,
    "as 1946 by": 1.0,
    "1946 by a.": 1.0,
    "by a. d.": 1.0,
    "a. d. booth": 1.0,
    "d. booth and": 1.0,
    "booth and possibly": 1.0,
    "and possibly others": 1.0,
    "possibly others .": 1.0,
    "<s> warren weaver": 1.0,
    "warren weaver wrote": 1.0,
    "weaver wrote an": 1.0,
    "wrote an important": 0.5,
    "an important memorandum": 0.25,
    "important memorandum ``": 1.0,
    "memorandum `` translation": 1.0,
    "`` translation ''": 1.0,
    "translation '' in": 1.0,
    "'' in 1949": 0.14285714285714285,
    "in 1949 .": 0.5,
    "georgetown experiment was": 0.3333333333333333,
    "experiment was by": 0.5,
    "was by no": 0.5,
    "by no means": 1.0,
    "no means the": 1.0,
    "means the first": 1.0,
    "the first such": 0.045454545454545456,
    "first such application": 1.0,
    "such application ,": 1.0,
    "application , and": 0.5,
    ", and a": 0.031746031746031744,
    "and a demonstration": 0.125,
    "a demonstration was": 0.3333333333333333,
    "demonstration was made": 1.0,
    "was made in": 1.0,
    "made in 1954": 0.5,
    "in 1954 on": 0.5,
    "1954 on the": 1.0,
    "on the apexc": 0.014925373134328358,
    "the apexc machine": 1.0,
    "apexc machine at": 1.0,
    "machine at birkbeck": 1.0,
    "at birkbeck college": 1.0,
    "birkbeck college -lrb-": 0.5,
    "college -lrb- university": 1.0,
    "-lrb- university of": 1.0,
    "university of london": 0.3333333333333333,
    "of london -rrb-": 1.0,
    "london -rrb- of": 1.0,
    "of a rudimentary": 0.010869565217391304,
    "a rudimentary translation": 1.0,
    "rudimentary translation of": 1.0,
    "translation of english": 0.09090909090909091,
    "of english into": 0.3333333333333333,
    "english into french": 1.0,
    "into french .": 1.0,
    "<s> several papers": 0.3333333333333333,
    "several papers on": 1.0,
    "papers on the": 0.5,
    "on the topic": 0.014925373134328358,
    "the topic were": 0.3333333333333333,
    "topic were published": 1.0,
    "were published at": 1.0,
    "published at the": 1.0,
    "at the time": 0.125,
    "the time ,": 0.8333333333333334,
    "time , and": 0.18181818181818182,
    "and even articles": 0.16666666666666666,
    "even articles in": 1.0,
    "articles in popular": 0.5,
    "in popular journals": 1.0,
    "popular journals -lrb-": 1.0,
    "journals -lrb- see": 1.0,
    "-lrb- see for": 0.0625,
    "see for example": 1.0,
    "for example wireless": 0.017857142857142856,
    "example wireless world": 1.0,
    "wireless world ,": 1.0,
    "world , sept.": 0.5,
    ", sept. 1955": 1.0,
    "sept. 1955 ,": 1.0,
    "1955 , cleave": 0.5,
    ", cleave and": 1.0,
    "cleave and zacharov": 1.0,
    "and zacharov -rrb-": 1.0,
    "zacharov -rrb- .": 1.0,
    "<s> a similar": 0.022727272727272728,
    "a similar application": 0.5,
    "similar application ,": 1.0,
    "application , also": 0.5,
    ", also pioneered": 0.2,
    "also pioneered at": 1.0,
    "pioneered at birkbeck": 1.0,
    "birkbeck college at": 0.5,
    "college at the": 1.0,
    "time , was": 0.09090909090909091,
    ", was reading": 0.25,
    "was reading and": 1.0,
    "reading and composing": 0.5,
    "and composing braille": 1.0,
    "composing braille texts": 1.0,
    "braille texts by": 1.0,
    "texts by computer": 1.0,
    "by computer .": 0.3333333333333333,
    "<s> translation process": 1.0,
    "translation process main": 0.25,
    "process main article": 1.0,
    "article : translation": 0.07692307692307693,
    ": translation process": 1.0,
    "translation process the": 0.25,
    "process the human": 1.0,
    "the human translation": 0.25,
    "human translation process": 0.5,
    "translation process may": 0.25,
    "process may be": 1.0,
    "may be described": 0.047619047619047616,
    "be described as": 1.0,
    "described as :": 0.5,
    "as : decoding": 1.0,
    ": decoding the": 1.0,
    "decoding the meaning": 1.0,
    "meaning of the": 0.2857142857142857,
    "of the source": 0.02564102564102564,
    "the source text": 0.3333333333333333,
    "source text ;": 0.2,
    "text ; and": 1.0,
    "; and re-encoding": 0.25,
    "and re-encoding this": 1.0,
    "re-encoding this meaning": 1.0,
    "this meaning in": 1.0,
    "meaning in the": 1.0,
    "target language .": 0.25,
    "<s> behind this": 1.0,
    "behind this ostensibly": 1.0,
    "this ostensibly simple": 1.0,
    "ostensibly simple procedure": 1.0,
    "simple procedure lies": 1.0,
    "procedure lies a": 1.0,
    "lies a complex": 1.0,
    "a complex cognitive": 0.2,
    "complex cognitive operation": 1.0,
    "cognitive operation .": 1.0,
    "<s> to decode": 0.125,
    "to decode the": 1.0,
    "decode the meaning": 1.0,
    "source text in": 0.2,
    "text in its": 0.125,
    "in its entirety": 0.5,
    "its entirety ,": 1.0,
    "entirety , the": 1.0,
    ", the translator": 0.009523809523809525,
    "the translator must": 0.5,
    "translator must interpret": 1.0,
    "must interpret and": 1.0,
    "interpret and analyze": 1.0,
    "and analyze all": 1.0,
    "analyze all the": 1.0,
    "all the features": 0.14285714285714285,
    "the features of": 0.16666666666666666,
    "features of the": 0.25,
    "of the text": 0.041025641025641026,
    "the text ,": 0.11538461538461539,
    "text , a": 0.03333333333333333,
    ", a process": 0.041666666666666664,
    "a process that": 0.5,
    "process that requires": 0.5,
    "that requires in-depth": 0.5,
    "requires in-depth knowledge": 1.0,
    "in-depth knowledge of": 0.5,
    "of the grammar": 0.015384615384615385,
    "the grammar ,": 0.09090909090909091,
    "semantics , syntax": 0.25,
    ", syntax ,": 1.0,
    "syntax , idioms": 0.2,
    ", idioms ,": 1.0,
    "idioms , etc.": 0.5,
    ", etc. ,": 0.05,
    "etc. , of": 1.0,
    ", of the": 0.25,
    "the source language": 0.25,
    "source language ,": 0.6666666666666666,
    "language , as": 0.14285714285714285,
    ", as well": 0.2608695652173913,
    "well as the": 0.07692307692307693,
    "as the culture": 0.03571428571428571,
    "the culture of": 1.0,
    "culture of its": 1.0,
    "of its speakers": 0.125,
    "its speakers .": 1.0,
    "<s> the translator": 0.006802721088435374,
    "the translator needs": 0.5,
    "translator needs the": 1.0,
    "needs the same": 1.0,
    "the same in-depth": 0.041666666666666664,
    "same in-depth knowledge": 1.0,
    "in-depth knowledge to": 0.5,
    "knowledge to re-encode": 1.0,
    "to re-encode the": 1.0,
    "re-encode the meaning": 1.0,
    "the meaning in": 0.1,
    "<s> therein lies": 1.0,
    "therein lies the": 1.0,
    "lies the challenge": 1.0,
    "the challenge in": 1.0,
    "challenge in machine": 1.0,
    "translation : how": 0.5,
    ": how to": 1.0,
    "how to program": 0.2,
    "to program a": 1.0,
    "program a computer": 0.5,
    "a computer that": 0.0625,
    "computer that will": 1.0,
    "that will ``": 1.0,
    "will `` understand": 0.5,
    "`` understand ''": 1.0,
    "understand '' a": 1.0,
    "'' a text": 0.3333333333333333,
    "a text as": 0.07142857142857142,
    "text as a": 1.0,
    "as a person": 0.027777777777777776,
    "a person does": 0.09090909090909091,
    "person does ,": 1.0,
    "does , and": 1.0,
    ", and that": 0.005291005291005291,
    "and that will": 0.5,
    "will `` create": 0.5,
    "`` create ''": 1.0,
    "create '' a": 1.0,
    "'' a new": 0.3333333333333333,
    "a new text": 0.16666666666666666,
    "new text in": 0.5,
    "text in the": 0.375,
    "target language that": 0.125,
    "language that ``": 1.0,
    "that `` sounds": 0.16666666666666666,
    "`` sounds ''": 1.0,
    "sounds '' as": 1.0,
    "'' as if": 0.2,
    "as if it": 1.0,
    "if it has": 0.3333333333333333,
    "it has been": 0.75,
    "has been written": 0.03571428571428571,
    "been written by": 1.0,
    "written by a": 0.3333333333333333,
    "by a person": 0.05555555555555555,
    "a person .": 0.09090909090909091,
    "<s> this problem": 0.07692307692307693,
    "this problem may": 0.09090909090909091,
    "problem may be": 1.0,
    "may be approached": 0.047619047619047616,
    "be approached in": 1.0,
    "approached in a": 1.0,
    "in a number": 0.038461538461538464,
    "number of ways": 0.05555555555555555,
    "of ways .": 0.5,
    "<s> approaches bernard": 0.3333333333333333,
    "approaches bernard vauquois": 1.0,
    "bernard vauquois '": 1.0,
    "vauquois ' pyramid": 1.0,
    "' pyramid showing": 1.0,
    "pyramid showing comparative": 1.0,
    "showing comparative depths": 1.0,
    "comparative depths of": 1.0,
    "depths of intermediary": 1.0,
    "of intermediary representation": 1.0,
    "intermediary representation ,": 1.0,
    "representation , interlingual": 0.3333333333333333,
    ", interlingual machine": 1.0,
    "interlingual machine translation": 1.0,
    "machine translation at": 0.022727272727272728,
    "translation at the": 1.0,
    "at the peak": 0.0625,
    "the peak ,": 1.0,
    "peak , followed": 1.0,
    ", followed by": 1.0,
    "followed by transfer-based": 0.5,
    "by transfer-based ,": 1.0,
    "transfer-based , then": 1.0,
    ", then direct": 0.09090909090909091,
    "then direct translation": 1.0,
    "direct translation .": 1.0,
    "machine translation can": 0.045454545454545456,
    "translation can use": 1.0,
    "can use a": 0.6666666666666666,
    "use a method": 0.5,
    "a method based": 0.5,
    "method based on": 1.0,
    "based on linguistic": 0.021739130434782608,
    "on linguistic rules": 1.0,
    "linguistic rules ,": 1.0,
    ", which means": 0.07142857142857142,
    "which means that": 0.75,
    "means that words": 0.25,
    "that words will": 0.5,
    "words will be": 1.0,
    "will be translated": 0.2222222222222222,
    "be translated in": 0.3333333333333333,
    "translated in a": 1.0,
    "in a linguistic": 0.019230769230769232,
    "a linguistic way": 0.5,
    "linguistic way --": 1.0,
    "way -- the": 1.0,
    "-- the most": 0.3333333333333333,
    "the most suitable": 0.041666666666666664,
    "most suitable -lrb-": 1.0,
    "suitable -lrb- orally": 1.0,
    "-lrb- orally speaking": 1.0,
    "orally speaking -rrb-": 1.0,
    "speaking -rrb- words": 1.0,
    "-rrb- words of": 1.0,
    "words of the": 0.6666666666666666,
    "of the target": 0.010256410256410256,
    "target language will": 0.125,
    "language will replace": 1.0,
    "will replace the": 1.0,
    "replace the ones": 1.0,
    "the ones in": 0.5,
    "ones in the": 1.0,
    "in the source": 0.013071895424836602,
    "source language .": 0.3333333333333333,
    "is often argued": 0.09090909090909091,
    "often argued that": 1.0,
    "argued that the": 1.0,
    "that the success": 0.043478260869565216,
    "success of machine": 0.3333333333333333,
    "machine translation requires": 0.022727272727272728,
    "translation requires the": 1.0,
    "requires the problem": 0.3333333333333333,
    "the problem of": 0.5,
    "problem of natural": 0.25,
    "language understanding to": 0.06666666666666667,
    "understanding to be": 0.5,
    "to be solved": 0.023255813953488372,
    "be solved first": 1.0,
    "solved first .": 1.0,
    "generally , rule-based": 0.25,
    ", rule-based methods": 1.0,
    "rule-based methods parse": 1.0,
    "methods parse a": 1.0,
    "parse a text": 1.0,
    "text , usually": 0.03333333333333333,
    ", usually creating": 0.2,
    "usually creating an": 1.0,
    "creating an intermediary": 0.5,
    "an intermediary ,": 1.0,
    "intermediary , symbolic": 1.0,
    ", symbolic representation": 1.0,
    "symbolic representation ,": 1.0,
    "representation , from": 0.3333333333333333,
    ", from which": 1.0,
    "from which the": 0.3333333333333333,
    "which the text": 0.125,
    "the text in": 0.11538461538461539,
    "language is generated": 0.2,
    "is generated .": 0.3333333333333333,
    "<s> according to": 1.0,
    "according to the": 0.5,
    "to the nature": 0.012987012987012988,
    "of the intermediary": 0.005128205128205128,
    "the intermediary representation": 1.0,
    "representation , an": 0.3333333333333333,
    ", an approach": 0.1,
    "approach is described": 0.2,
    "is described as": 1.0,
    "described as interlingual": 0.5,
    "as interlingual machine": 1.0,
    "machine translation or": 0.022727272727272728,
    "translation or transfer-based": 1.0,
    "or transfer-based machine": 1.0,
    "transfer-based machine translation": 1.0,
    "<s> these methods": 0.125,
    "these methods require": 0.3333333333333333,
    "methods require extensive": 1.0,
    "require extensive lexicons": 0.5,
    "extensive lexicons with": 1.0,
    "lexicons with morphological": 1.0,
    "with morphological ,": 1.0,
    "morphological , syntactic": 1.0,
    ", syntactic ,": 0.3333333333333333,
    "syntactic , and": 1.0,
    ", and semantic": 0.005291005291005291,
    "and semantic information": 0.25,
    "semantic information ,": 0.5,
    "information , and": 1.0,
    ", and large": 0.005291005291005291,
    "and large sets": 1.0,
    "<s> given enough": 0.3333333333333333,
    "given enough data": 1.0,
    "enough data ,": 0.5,
    "data , machine": 0.1,
    "machine translation programs": 0.022727272727272728,
    "translation programs often": 1.0,
    "programs often work": 1.0,
    "often work well": 1.0,
    "work well enough": 1.0,
    "well enough for": 1.0,
    "enough for a": 1.0,
    "for a native": 0.03225806451612903,
    "a native speaker": 1.0,
    "native speaker of": 0.5,
    "speaker of one": 0.5,
    "of one language": 0.25,
    "one language to": 0.5,
    "language to get": 0.25,
    "to get the": 0.25,
    "get the approximate": 0.5,
    "the approximate meaning": 1.0,
    "approximate meaning of": 1.0,
    "meaning of what": 0.14285714285714285,
    "of what is": 0.25,
    "what is written": 0.16666666666666666,
    "is written by": 1.0,
    "written by the": 0.16666666666666666,
    "by the other": 0.03571428571428571,
    "the other native": 0.125,
    "other native speaker": 1.0,
    "native speaker .": 0.5,
    "the difficulty is": 0.25,
    "difficulty is getting": 1.0,
    "is getting enough": 0.5,
    "getting enough data": 1.0,
    "enough data of": 0.5,
    "data of the": 1.0,
    "of the right": 0.005128205128205128,
    "the right kind": 0.3333333333333333,
    "right kind to": 1.0,
    "kind to support": 1.0,
    "to support the": 0.5,
    "support the particular": 1.0,
    "the particular method": 0.5,
    "particular method .": 1.0,
    ", the large": 0.009523809523809525,
    "the large multilingual": 1.0,
    "large multilingual corpus": 1.0,
    "multilingual corpus of": 1.0,
    "corpus of data": 0.125,
    "of data needed": 0.14285714285714285,
    "data needed for": 1.0,
    "needed for statistical": 0.5,
    "for statistical methods": 0.5,
    "methods to work": 0.25,
    "to work is": 0.5,
    "work is not": 0.3333333333333333,
    "is not necessary": 0.05263157894736842,
    "not necessary for": 1.0,
    "necessary for the": 0.3333333333333333,
    "for the grammar-based": 0.03125,
    "the grammar-based methods": 1.0,
    "grammar-based methods .": 1.0,
    "<s> but then": 0.16666666666666666,
    "but then ,": 1.0,
    ", the grammar": 0.009523809523809525,
    "the grammar methods": 0.09090909090909091,
    "grammar methods need": 1.0,
    "methods need a": 0.5,
    "need a skilled": 0.25,
    "a skilled linguist": 1.0,
    "skilled linguist to": 1.0,
    "linguist to carefully": 1.0,
    "to carefully design": 1.0,
    "carefully design the": 1.0,
    "design the grammar": 1.0,
    "the grammar that": 0.09090909090909091,
    "grammar that they": 1.0,
    "that they use": 0.14285714285714285,
    "they use .": 1.0,
    "<s> to translate": 0.125,
    "to translate between": 0.25,
    "translate between closely": 1.0,
    "between closely related": 1.0,
    "closely related languages": 0.5,
    "related languages ,": 1.0,
    "languages , a": 0.09090909090909091,
    ", a technique": 0.020833333333333332,
    "a technique referred": 0.5,
    "technique referred to": 1.0,
    "to as shallow-transfer": 0.25,
    "as shallow-transfer machine": 1.0,
    "shallow-transfer machine translation": 1.0,
    "machine translation may": 0.022727272727272728,
    "translation may be": 1.0,
    "may be used": 0.047619047619047616,
    "be used .": 0.10526315789473684,
    "<s> rule-based the": 1.0,
    "rule-based the rule-based": 1.0,
    "the rule-based machine": 1.0,
    "rule-based machine translation": 1.0,
    "machine translation paradigm": 0.022727272727272728,
    "translation paradigm includes": 1.0,
    "paradigm includes transfer-based": 1.0,
    "includes transfer-based machine": 1.0,
    "translation , interlingual": 0.125,
    "machine translation and": 0.045454545454545456,
    "translation and dictionary-based": 0.3333333333333333,
    "and dictionary-based machine": 1.0,
    "dictionary-based machine translation": 1.0,
    "machine translation paradigms": 0.022727272727272728,
    "translation paradigms .": 1.0,
    "<s> main article": 1.0,
    "article : rule-based": 0.07692307692307693,
    ": rule-based machine": 0.5,
    "machine translation transfer-based": 0.022727272727272728,
    "translation transfer-based machine": 1.0,
    "machine translation main": 0.022727272727272728,
    "translation main article": 1.0,
    "article : transfer-based": 0.07692307692307693,
    ": transfer-based machine": 1.0,
    "machine translation interlingual": 0.045454545454545456,
    "translation interlingual main": 0.5,
    "interlingual main article": 1.0,
    "article : interlingual": 0.07692307692307693,
    ": interlingual machine": 1.0,
    "translation interlingual machine": 0.5,
    "machine translation is": 0.022727272727272728,
    "translation is one": 1.0,
    "is one instance": 0.16666666666666666,
    "one instance of": 1.0,
    "instance of rule-based": 0.5,
    "of rule-based machine-translation": 1.0,
    "rule-based machine-translation approaches": 1.0,
    "machine-translation approaches .": 1.0,
    "<s> in this": 0.05154639175257732,
    "in this approach": 0.06666666666666667,
    "this approach ,": 0.25,
    "approach , the": 0.5,
    ", the source": 0.009523809523809525,
    "language , i.e.": 0.14285714285714285,
    "i.e. the text": 0.2,
    "the text to": 0.07692307692307693,
    "text to be": 0.14285714285714285,
    "to be translated": 0.023255813953488372,
    "be translated ,": 0.3333333333333333,
    "translated , is": 1.0,
    ", is transformed": 0.07692307692307693,
    "is transformed into": 1.0,
    "transformed into an": 1.0,
    "into an interlingual": 0.5,
    "an interlingual ,": 1.0,
    "interlingual , i.e.": 1.0,
    ", i.e. source": 0.14285714285714285,
    "i.e. source -": 1.0,
    "source - \\/": 1.0,
    "- \\/ target-language-independent": 1.0,
    "\\/ target-language-independent representation": 1.0,
    "target-language-independent representation .": 1.0,
    "<s> the target": 0.006802721088435374,
    "language is then": 0.2,
    "is then generated": 0.2,
    "then generated out": 1.0,
    "generated out of": 1.0,
    "out of the": 1.0,
    "of the interlingua": 0.005128205128205128,
    "the interlingua .": 1.0,
    "<s> dictionary-based main": 1.0,
    "dictionary-based main article": 1.0,
    "article : dictionary-based": 0.07692307692307693,
    ": dictionary-based machine": 1.0,
    "machine translation machine": 0.022727272727272728,
    "translation machine translation": 1.0,
    "based on dictionary": 0.021739130434782608,
    "on dictionary entries": 1.0,
    "dictionary entries ,": 1.0,
    "entries , which": 1.0,
    "means that the": 0.25,
    "that the words": 0.043478260869565216,
    "the words will": 0.16666666666666666,
    "be translated as": 0.3333333333333333,
    "translated as they": 1.0,
    "as they are": 0.6666666666666666,
    "they are by": 0.14285714285714285,
    "are by a": 1.0,
    "by a dictionary": 0.05555555555555555,
    "a dictionary .": 0.3333333333333333,
    "<s> statistical main": 0.3333333333333333,
    "statistical main article": 1.0,
    ": statistical machine": 0.5,
    "machine translation statistical": 0.022727272727272728,
    "translation statistical machine": 1.0,
    "machine translation tries": 0.022727272727272728,
    "translation tries to": 1.0,
    "tries to generate": 1.0,
    "to generate translations": 0.16666666666666666,
    "generate translations using": 1.0,
    "translations using statistical": 1.0,
    "using statistical methods": 0.5,
    "statistical methods based": 0.2,
    "methods based on": 1.0,
    "based on bilingual": 0.021739130434782608,
    "on bilingual text": 1.0,
    "bilingual text corpora": 1.0,
    "text corpora ,": 1.0,
    "corpora , such": 1.0,
    "such as the": 0.15555555555555556,
    "as the canadian": 0.03571428571428571,
    "the canadian hansard": 0.5,
    "canadian hansard corpus": 1.0,
    "hansard corpus ,": 1.0,
    "corpus , the": 0.3333333333333333,
    ", the english-french": 0.009523809523809525,
    "the english-french record": 1.0,
    "english-french record of": 1.0,
    "record of the": 1.0,
    "of the canadian": 0.005128205128205128,
    "the canadian parliament": 0.5,
    "canadian parliament and": 1.0,
    "parliament and europarl": 1.0,
    "and europarl ,": 1.0,
    "europarl , the": 1.0,
    ", the record": 0.009523809523809525,
    "the record of": 1.0,
    "of the european": 0.005128205128205128,
    "the european parliament": 0.3333333333333333,
    "european parliament .": 1.0,
    "<s> where such": 1.0,
    "where such corpora": 1.0,
    "such corpora are": 1.0,
    "corpora are available": 0.5,
    "are available ,": 0.5,
    "available , impressive": 0.25,
    ", impressive results": 1.0,
    "impressive results can": 1.0,
    "results can be": 1.0,
    "can be achieved": 0.04395604395604396,
    "be achieved translating": 0.2,
    "achieved translating texts": 1.0,
    "translating texts of": 1.0,
    "texts of a": 1.0,
    "of a similar": 0.010869565217391304,
    "a similar kind": 0.5,
    "similar kind ,": 1.0,
    "kind , but": 1.0,
    ", but such": 0.020833333333333332,
    "but such corpora": 1.0,
    "corpora are still": 0.5,
    "are still very": 0.25,
    "still very rare": 1.0,
    "very rare .": 1.0,
    "translation software was": 0.3333333333333333,
    "software was candide": 1.0,
    "was candide from": 1.0,
    "candide from ibm": 1.0,
    "from ibm .": 1.0,
    "<s> google used": 1.0,
    "google used systran": 1.0,
    "used systran for": 1.0,
    "systran for several": 1.0,
    "for several years": 1.0,
    "several years ,": 0.5,
    "years , but": 0.2,
    ", but switched": 0.020833333333333332,
    "but switched to": 1.0,
    "switched to a": 1.0,
    "to a statistical": 0.03571428571428571,
    "a statistical translation": 0.3333333333333333,
    "statistical translation method": 1.0,
    "translation method in": 1.0,
    "method in october": 1.0,
    "in october 2007": 1.0,
    "october 2007 .": 1.0,
    "<s> recently ,": 1.0,
    "recently , they": 1.0,
    ", they improved": 0.125,
    "they improved their": 1.0,
    "improved their translation": 1.0,
    "their translation capabilities": 1.0,
    "translation capabilities by": 1.0,
    "capabilities by inputting": 1.0,
    "by inputting approximately": 1.0,
    "inputting approximately 200": 1.0,
    "approximately 200 billion": 1.0,
    "200 billion words": 1.0,
    "billion words from": 1.0,
    "words from united": 0.5,
    "from united nations": 1.0,
    "united nations materials": 0.5,
    "nations materials to": 1.0,
    "materials to train": 1.0,
    "to train their": 1.0,
    "train their system": 1.0,
    "their system .": 1.0,
    "<s> accuracy of": 0.4,
    "accuracy of the": 0.14285714285714285,
    "of the translation": 0.005128205128205128,
    "the translation has": 0.16666666666666666,
    "translation has improved": 0.5,
    "has improved .": 1.0,
    "<s> example-based main": 1.0,
    "example-based main article": 1.0,
    "article : example-based": 0.07692307692307693,
    ": example-based machine": 1.0,
    "example-based machine translation": 1.0,
    "machine translation example-based": 0.022727272727272728,
    "translation example-based machine": 1.0,
    "machine translation -lrb-": 0.045454545454545456,
    "translation -lrb- ebmt": 0.5,
    "-lrb- ebmt -rrb-": 1.0,
    "ebmt -rrb- approach": 1.0,
    "-rrb- approach was": 1.0,
    "approach was proposed": 1.0,
    "was proposed by": 0.5,
    "proposed by makoto": 1.0,
    "by makoto nagao": 1.0,
    "makoto nagao in": 1.0,
    "nagao in 1984": 1.0,
    "in 1984 .": 1.0,
    "is often characterised": 0.09090909090909091,
    "often characterised by": 1.0,
    "characterised by its": 1.0,
    "by its use": 1.0,
    "its use of": 1.0,
    "of a bilingual": 0.010869565217391304,
    "a bilingual corpus": 1.0,
    "bilingual corpus as": 1.0,
    "corpus as its": 1.0,
    "as its main": 0.3333333333333333,
    "its main knowledge": 0.5,
    "main knowledge base": 1.0,
    "base , at": 0.5,
    ", at run-time": 0.3333333333333333,
    "at run-time .": 1.0,
    "it is essentially": 0.0425531914893617,
    "is essentially a": 0.6666666666666666,
    "essentially a translation": 0.5,
    "a translation by": 0.5,
    "translation by analogy": 1.0,
    "by analogy and": 1.0,
    "analogy and can": 1.0,
    "and can be": 0.625,
    "can be viewed": 0.03296703296703297,
    "be viewed as": 1.0,
    "viewed as an": 0.5,
    "as an implementation": 0.06666666666666667,
    "an implementation of": 1.0,
    "implementation of case-based": 0.5,
    "of case-based reasoning": 1.0,
    "case-based reasoning approach": 1.0,
    "reasoning approach of": 1.0,
    "approach of machine": 1.0,
    "<s> hybrid mt": 1.0,
    "hybrid mt hybrid": 1.0,
    "mt hybrid machine": 1.0,
    "hybrid machine translation": 1.0,
    "translation -lrb- hmt": 0.5,
    "-lrb- hmt -rrb-": 1.0,
    "hmt -rrb- leverages": 1.0,
    "-rrb- leverages the": 1.0,
    "leverages the strengths": 1.0,
    "the strengths of": 1.0,
    "strengths of statistical": 1.0,
    "of statistical and": 0.5,
    "statistical and rule-based": 1.0,
    "and rule-based translation": 1.0,
    "rule-based translation methodologies": 1.0,
    "translation methodologies .": 1.0,
    "<s> several mt": 0.3333333333333333,
    "several mt companies": 1.0,
    "mt companies -lrb-": 1.0,
    "companies -lrb- asia": 1.0,
    "-lrb- asia online": 1.0,
    "asia online ,": 1.0,
    "online , linguasys": 1.0,
    ", linguasys ,": 1.0,
    "linguasys , systran": 1.0,
    ", systran ,": 1.0,
    "systran , pangeamt": 1.0,
    ", pangeamt ,": 1.0,
    "pangeamt , upv": 1.0,
    ", upv -rrb-": 1.0,
    "upv -rrb- are": 1.0,
    "-rrb- are claiming": 0.3333333333333333,
    "are claiming to": 1.0,
    "claiming to have": 1.0,
    "to have a": 0.4,
    "have a hybrid": 0.07692307692307693,
    "a hybrid approach": 0.5,
    "hybrid approach using": 1.0,
    "approach using both": 1.0,
    "using both rules": 1.0,
    "both rules and": 1.0,
    "rules and statistics": 1.0,
    "<s> the approaches": 0.006802721088435374,
    "the approaches differ": 1.0,
    "approaches differ in": 1.0,
    "differ in a": 1.0,
    "of ways :": 0.5,
    "ways : rules": 0.5,
    ": rules post-processed": 0.5,
    "rules post-processed by": 1.0,
    "post-processed by statistics": 1.0,
    "by statistics :": 1.0,
    "statistics : translations": 1.0,
    ": translations are": 1.0,
    "translations are performed": 1.0,
    "are performed using": 1.0,
    "performed using a": 1.0,
    "using a rules": 0.1,
    "a rules based": 1.0,
    "rules based engine": 1.0,
    "based engine .": 1.0,
    "<s> statistics are": 0.3333333333333333,
    "statistics are then": 1.0,
    "are then used": 1.0,
    "then used in": 1.0,
    "used in an": 0.043478260869565216,
    "in an attempt": 0.25,
    "an attempt to": 1.0,
    "attempt to adjust\\/correct": 0.16666666666666666,
    "to adjust\\/correct the": 1.0,
    "adjust\\/correct the output": 1.0,
    "the output from": 0.3333333333333333,
    "output from the": 1.0,
    "from the rules": 0.045454545454545456,
    "the rules engine": 0.2,
    "rules engine .": 1.0,
    "<s> statistics guided": 0.3333333333333333,
    "statistics guided by": 1.0,
    "guided by rules": 1.0,
    "by rules :": 1.0,
    "rules : rules": 0.5,
    ": rules are": 0.5,
    "rules are used": 0.3333333333333333,
    "used to pre-process": 0.045454545454545456,
    "to pre-process data": 1.0,
    "pre-process data in": 1.0,
    "data in an": 0.5,
    "attempt to better": 0.16666666666666666,
    "to better guide": 0.3333333333333333,
    "better guide the": 1.0,
    "guide the statistical": 0.5,
    "the statistical engine": 0.5,
    "statistical engine .": 1.0,
    "<s> rules are": 1.0,
    "rules are also": 0.3333333333333333,
    "are also used": 0.125,
    "also used to": 0.5,
    "used to post-process": 0.045454545454545456,
    "to post-process the": 1.0,
    "post-process the statistical": 1.0,
    "the statistical output": 0.5,
    "statistical output to": 1.0,
    "output to perform": 1.0,
    "to perform functions": 0.2,
    "perform functions such": 1.0,
    "functions such as": 1.0,
    "such as normalization": 0.011111111111111112,
    "as normalization .": 1.0,
    "<s> this approach": 0.038461538461538464,
    "this approach has": 0.25,
    "approach has a": 1.0,
    "has a lot": 0.25,
    "a lot more": 0.3333333333333333,
    "lot more power": 1.0,
    "more power ,": 1.0,
    "power , flexibility": 1.0,
    ", flexibility and": 1.0,
    "flexibility and control": 1.0,
    "and control when": 0.3333333333333333,
    "control when translating": 1.0,
    "when translating .": 1.0,
    "<s> major issues": 0.5,
    "major issues disambiguation": 0.5,
    "issues disambiguation main": 1.0,
    "disambiguation main article": 1.0,
    "article : word": 0.07692307692307693,
    ": word sense": 1.0,
    "sense disambiguation word-sense": 0.5,
    "disambiguation word-sense disambiguation": 1.0,
    "word-sense disambiguation concerns": 1.0,
    "disambiguation concerns finding": 1.0,
    "concerns finding a": 1.0,
    "finding a suitable": 0.5,
    "a suitable translation": 0.3333333333333333,
    "suitable translation when": 1.0,
    "translation when a": 1.0,
    "when a word": 0.2,
    "a word can": 0.16666666666666666,
    "word can have": 0.5,
    "can have more": 0.5,
    "one meaning .": 0.5,
    "<s> the problem": 0.02040816326530612,
    "the problem was": 0.08333333333333333,
    "problem was first": 1.0,
    "was first raised": 1.0,
    "first raised in": 1.0,
    "raised in the": 1.0,
    "the 1950s by": 0.3333333333333333,
    "1950s by yehoshua": 1.0,
    "by yehoshua bar-hillel": 1.0,
    "yehoshua bar-hillel .": 1.0,
    "<s> he pointed": 0.14285714285714285,
    "he pointed out": 1.0,
    "pointed out that": 1.0,
    "out that without": 1.0,
    "that without a": 1.0,
    "without a ``": 1.0,
    "a `` universal": 0.3333333333333333,
    "`` universal encyclopedia": 0.5,
    "universal encyclopedia ''": 1.0,
    "encyclopedia '' ,": 1.0,
    "'' , a": 0.03333333333333333,
    ", a machine": 0.041666666666666664,
    "a machine would": 0.25,
    "machine would never": 0.5,
    "would never be": 1.0,
    "never be able": 1.0,
    "be able to": 1.0,
    "able to distinguish": 0.0625,
    "to distinguish between": 0.4,
    "distinguish between the": 0.5,
    "between the two": 0.42857142857142855,
    "the two meanings": 0.14285714285714285,
    "two meanings of": 1.0,
    "meanings of a": 1.0,
    "a word .": 0.08333333333333333,
    "<s> today there": 1.0,
    "today there are": 1.0,
    "there are numerous": 0.047619047619047616,
    "are numerous approaches": 1.0,
    "numerous approaches designed": 1.0,
    "approaches designed to": 1.0,
    "designed to overcome": 0.2,
    "to overcome this": 0.5,
    "overcome this problem": 1.0,
    "this problem .": 0.09090909090909091,
    "<s> they can": 0.3333333333333333,
    "they can be": 0.5714285714285714,
    "can be approximately": 0.01098901098901099,
    "be approximately divided": 1.0,
    "approximately divided into": 1.0,
    "divided into ``": 0.5,
    "into `` shallow": 1.0,
    "`` shallow ''": 1.0,
    "shallow '' approaches": 1.0,
    "'' approaches and": 0.5,
    "approaches and ``": 1.0,
    "and `` deep": 0.05,
    "`` deep ''": 1.0,
    "deep '' approaches": 1.0,
    "'' approaches .": 0.5,
    "<s> shallow approaches": 0.5,
    "shallow approaches assume": 0.5,
    "approaches assume no": 1.0,
    "assume no knowledge": 1.0,
    "no knowledge of": 1.0,
    "the text .": 0.3076923076923077,
    "<s> they simply": 0.3333333333333333,
    "they simply apply": 1.0,
    "simply apply statistical": 1.0,
    "apply statistical methods": 1.0,
    "methods to the": 0.25,
    "to the words": 0.012987012987012988,
    "the words surrounding": 0.16666666666666666,
    "words surrounding the": 1.0,
    "surrounding the ambiguous": 1.0,
    "the ambiguous word": 0.5,
    "ambiguous word .": 1.0,
    "<s> deep approaches": 1.0,
    "deep approaches presume": 1.0,
    "approaches presume a": 1.0,
    "presume a comprehensive": 1.0,
    "a comprehensive knowledge": 0.25,
    "comprehensive knowledge of": 1.0,
    "the word .": 0.125,
    "<s> so far": 0.3333333333333333,
    "so far ,": 0.5,
    "far , shallow": 1.0,
    ", shallow approaches": 1.0,
    "shallow approaches have": 0.5,
    "approaches have been": 1.0,
    "have been more": 0.038461538461538464,
    "been more successful": 0.5,
    "more successful .": 0.3333333333333333,
    "needed -rrb- the": 0.07692307692307693,
    "-rrb- the late": 0.3333333333333333,
    "the late claude": 0.1111111111111111,
    "late claude piron": 1.0,
    "claude piron ,": 1.0,
    "piron , a": 1.0,
    ", a long-time": 0.020833333333333332,
    "a long-time translator": 1.0,
    "long-time translator for": 1.0,
    "translator for the": 1.0,
    "for the united": 0.03125,
    "the united nations": 0.125,
    "united nations and": 0.5,
    "nations and the": 1.0,
    "and the world": 0.024390243902439025,
    "the world health": 0.125,
    "world health organization": 1.0,
    "health organization ,": 1.0,
    "organization , wrote": 0.5,
    ", wrote that": 1.0,
    "wrote that machine": 1.0,
    "translation , at": 0.125,
    ", at its": 0.3333333333333333,
    "at its best": 1.0,
    "its best ,": 1.0,
    "best , automates": 1.0,
    ", automates the": 1.0,
    "automates the easier": 1.0,
    "the easier part": 1.0,
    "easier part of": 1.0,
    "part of a": 0.13636363636363635,
    "of a translator": 0.010869565217391304,
    "a translator 's": 0.3333333333333333,
    "translator 's job": 1.0,
    "'s job ;": 0.5,
    "job ; the": 1.0,
    "; the harder": 0.25,
    "the harder and": 0.3333333333333333,
    "harder and more": 1.0,
    "and more time-consuming": 0.2,
    "more time-consuming part": 1.0,
    "time-consuming part usually": 1.0,
    "part usually involves": 1.0,
    "usually involves doing": 1.0,
    "involves doing extensive": 1.0,
    "doing extensive research": 1.0,
    "extensive research to": 1.0,
    "research to resolve": 1.0,
    "to resolve ambiguities": 0.3333333333333333,
    "resolve ambiguities in": 0.5,
    "ambiguities in the": 1.0,
    "source text ,": 0.4,
    "text , which": 0.06666666666666667,
    ", which the": 0.017857142857142856,
    "which the grammatical": 0.125,
    "the grammatical and": 0.3333333333333333,
    "grammatical and lexical": 1.0,
    "and lexical exigencies": 1.0,
    "lexical exigencies of": 1.0,
    "exigencies of the": 1.0,
    "target language require": 0.125,
    "language require to": 1.0,
    "require to be": 1.0,
    "to be resolved": 0.023255813953488372,
    "be resolved :": 1.0,
    "resolved : why": 1.0,
    ": why does": 1.0,
    "why does a": 1.0,
    "does a translator": 0.5,
    "a translator need": 0.3333333333333333,
    "translator need a": 1.0,
    "need a whole": 0.25,
    "a whole workday": 0.5,
    "whole workday to": 1.0,
    "workday to translate": 1.0,
    "to translate five": 0.25,
    "translate five pages": 1.0,
    "five pages ,": 1.0,
    "pages , and": 0.6666666666666666,
    ", and not": 0.015873015873015872,
    "and not an": 0.125,
    "not an hour": 1.0,
    "an hour or": 1.0,
    "hour or two": 1.0,
    "or two ?": 0.5,
    "<s> ... about": 1.0,
    "... about 90": 1.0,
    "about 90 %": 1.0,
    "90 % of": 0.5,
    "% of an": 0.125,
    "of an average": 0.07692307692307693,
    "an average text": 1.0,
    "average text corresponds": 1.0,
    "text corresponds to": 1.0,
    "corresponds to these": 1.0,
    "to these simple": 0.5,
    "these simple conditions": 1.0,
    "simple conditions .": 1.0,
    "<s> but unfortunately": 0.16666666666666666,
    "but unfortunately ,": 1.0,
    "unfortunately , there": 0.5,
    ", there 's": 0.09090909090909091,
    "there 's the": 1.0,
    "'s the other": 1.0,
    "the other 10": 0.125,
    "other 10 %": 1.0,
    "10 % .": 0.5,
    "<s> it 's": 0.058823529411764705,
    "it 's that": 0.3333333333333333,
    "'s that part": 1.0,
    "that part that": 1.0,
    "part that requires": 1.0,
    "that requires six": 0.5,
    "requires six -lrb-": 1.0,
    "six -lrb- more": 1.0,
    "-lrb- more -rrb-": 0.5,
    "more -rrb- hours": 1.0,
    "-rrb- hours of": 1.0,
    "hours of work": 1.0,
    "of work .": 1.0,
    "<s> there are": 0.5555555555555556,
    "there are ambiguities": 0.047619047619047616,
    "are ambiguities one": 1.0,
    "ambiguities one has": 1.0,
    "one has to": 1.0,
    "has to resolve": 0.2,
    "to resolve .": 0.3333333333333333,
    "<s> for instance": 0.12280701754385964,
    "for instance ,": 0.75,
    "instance , the": 0.2222222222222222,
    ", the author": 0.009523809523809525,
    "the author of": 0.3333333333333333,
    "author of the": 1.0,
    "text , an": 0.03333333333333333,
    ", an australian": 0.1,
    "an australian physician": 1.0,
    "australian physician ,": 1.0,
    "physician , cited": 1.0,
    ", cited the": 1.0,
    "cited the example": 1.0,
    "the example of": 0.3333333333333333,
    "of an epidemic": 0.07692307692307693,
    "an epidemic which": 1.0,
    "epidemic which was": 1.0,
    "which was declared": 0.2,
    "was declared during": 1.0,
    "declared during world": 1.0,
    "during world war": 1.0,
    "world war ii": 1.0,
    "war ii in": 1.0,
    "ii in a": 1.0,
    "in a ``": 0.019230769230769232,
    "a `` japanese": 0.16666666666666666,
    "`` japanese prisoner": 1.0,
    "japanese prisoner of": 1.0,
    "prisoner of war": 1.0,
    "of war camp": 1.0,
    "war camp ''": 1.0,
    "camp '' .": 1.0,
    "<s> was he": 1.0,
    "was he talking": 1.0,
    "he talking about": 1.0,
    "talking about an": 1.0,
    "about an american": 1.0,
    "an american camp": 1.0,
    "american camp with": 1.0,
    "camp with japanese": 0.5,
    "with japanese prisoners": 1.0,
    "japanese prisoners or": 1.0,
    "prisoners or a": 1.0,
    "or a japanese": 0.05263157894736842,
    "a japanese camp": 1.0,
    "japanese camp with": 1.0,
    "camp with american": 0.5,
    "with american prisoners": 1.0,
    "american prisoners ?": 1.0,
    "<s> the english": 0.006802721088435374,
    "the english has": 0.25,
    "english has two": 0.5,
    "has two senses": 1.0,
    "two senses .": 1.0,
    "it 's necessary": 0.3333333333333333,
    "'s necessary therefore": 1.0,
    "necessary therefore to": 1.0,
    "therefore to do": 1.0,
    "to do research": 0.3333333333333333,
    "do research ,": 1.0,
    "research , maybe": 0.25,
    ", maybe to": 1.0,
    "maybe to the": 1.0,
    "to the extent": 0.012987012987012988,
    "the extent of": 0.5,
    "extent of a": 1.0,
    "of a phone": 0.010869565217391304,
    "a phone call": 1.0,
    "phone call to": 1.0,
    "call to australia": 1.0,
    "to australia .": 1.0,
    "<s> the ideal": 0.006802721088435374,
    "the ideal deep": 1.0,
    "ideal deep approach": 1.0,
    "deep approach would": 1.0,
    "approach would require": 1.0,
    "would require the": 0.3333333333333333,
    "require the translation": 0.25,
    "the translation software": 0.16666666666666666,
    "translation software to": 0.3333333333333333,
    "software to do": 0.5,
    "to do all": 0.3333333333333333,
    "do all the": 1.0,
    "all the research": 0.14285714285714285,
    "the research necessary": 0.3333333333333333,
    "research necessary for": 1.0,
    "necessary for this": 0.3333333333333333,
    "for this kind": 0.125,
    "this kind of": 1.0,
    "kind of disambiguation": 0.125,
    "of disambiguation on": 1.0,
    "disambiguation on its": 1.0,
    "on its own": 1.0,
    "its own ;": 0.2,
    "own ; but": 1.0,
    "; but this": 0.5,
    "but this would": 0.25,
    "this would require": 1.0,
    "would require a": 0.6666666666666666,
    "require a higher": 0.2,
    "a higher degree": 0.5,
    "higher degree of": 1.0,
    "degree of ai": 0.3333333333333333,
    "of ai than": 1.0,
    "ai than has": 1.0,
    "than has yet": 1.0,
    "has yet been": 1.0,
    "yet been attained": 1.0,
    "been attained .": 1.0,
    "<s> a shallow": 0.045454545454545456,
    "a shallow approach": 1.0,
    "shallow approach which": 0.5,
    "approach which simply": 0.5,
    "which simply guessed": 1.0,
    "simply guessed at": 1.0,
    "guessed at the": 1.0,
    "at the sense": 0.0625,
    "the sense of": 1.0,
    "sense of the": 1.0,
    "of the ambiguous": 0.005128205128205128,
    "the ambiguous english": 0.5,
    "ambiguous english phrase": 1.0,
    "english phrase that": 1.0,
    "phrase that piron": 1.0,
    "that piron mentions": 1.0,
    "piron mentions -lrb-": 1.0,
    "mentions -lrb- based": 1.0,
    "-lrb- based ,": 0.5,
    "based , perhaps": 0.5,
    ", perhaps ,": 0.3333333333333333,
    "perhaps , on": 1.0,
    ", on which": 0.14285714285714285,
    "on which kind": 0.3333333333333333,
    "which kind of": 1.0,
    "kind of prisoner-of-war": 0.125,
    "of prisoner-of-war camp": 1.0,
    "prisoner-of-war camp is": 1.0,
    "camp is more": 1.0,
    "is more often": 0.3333333333333333,
    "more often mentioned": 1.0,
    "often mentioned in": 1.0,
    "mentioned in a": 1.0,
    "a given corpus": 0.08333333333333333,
    "given corpus -rrb-": 1.0,
    "corpus -rrb- would": 0.14285714285714285,
    "-rrb- would have": 0.5,
    "would have a": 0.3333333333333333,
    "have a reasonable": 0.07692307692307693,
    "a reasonable chance": 0.5,
    "reasonable chance of": 1.0,
    "chance of guessing": 1.0,
    "of guessing wrong": 1.0,
    "guessing wrong fairly": 1.0,
    "wrong fairly often": 1.0,
    "fairly often .": 1.0,
    "shallow approach that": 0.5,
    "approach that involves": 0.5,
    "that involves ``": 1.0,
    "involves `` ask": 1.0,
    "`` ask the": 1.0,
    "ask the user": 0.5,
    "the user about": 0.16666666666666666,
    "user about each": 1.0,
    "about each ambiguity": 1.0,
    "each ambiguity ''": 1.0,
    "ambiguity '' would": 1.0,
    "'' would ,": 0.5,
    "would , by": 1.0,
    ", by piron": 0.2,
    "by piron 's": 1.0,
    "piron 's estimate": 1.0,
    "'s estimate ,": 1.0,
    "estimate , only": 1.0,
    ", only automate": 0.5,
    "only automate about": 1.0,
    "automate about 25": 1.0,
    "about 25 %": 1.0,
    "25 % of": 1.0,
    "% of a": 0.125,
    "of a professional": 0.010869565217391304,
    "a professional translator": 1.0,
    "professional translator 's": 1.0,
    "'s job ,": 0.5,
    "job , leaving": 1.0,
    ", leaving the": 1.0,
    "leaving the harder": 1.0,
    "the harder 75": 0.3333333333333333,
    "harder 75 %": 1.0,
    "75 % still": 1.0,
    "% still to": 1.0,
    "still to be": 1.0,
    "to be done": 0.06976744186046512,
    "be done by": 0.2,
    "done by a": 0.5,
    "by a human": 0.16666666666666666,
    "a human .": 0.18181818181818182,
    "<s> the objects": 0.006802721088435374,
    "the objects of": 1.0,
    "objects of discourse": 1.0,
    "of discourse analysis": 0.36363636363636365,
    "discourse analysis --": 0.09090909090909091,
    "analysis -- discourse": 1.0,
    "-- discourse ,": 1.0,
    "discourse , writing": 0.3333333333333333,
    ", writing ,": 0.5,
    "writing , conversation": 0.5,
    ", conversation ,": 1.0,
    "conversation , communicative": 1.0,
    ", communicative event": 1.0,
    "communicative event ,": 1.0,
    "event , etc.": 0.5,
    ", etc. --": 0.05,
    "etc. -- are": 1.0,
    "-- are variously": 0.5,
    "are variously defined": 1.0,
    "variously defined in": 1.0,
    "defined in terms": 1.0,
    "terms of coherent": 0.14285714285714285,
    "of coherent sequences": 1.0,
    "coherent sequences of": 1.0,
    "sequences of sentences": 0.3333333333333333,
    "sentences , propositions": 0.25,
    ", propositions ,": 1.0,
    "propositions , speech": 0.5,
    ", speech acts": 0.18181818181818182,
    "speech acts or": 0.3333333333333333,
    "acts or turns-at-talk": 1.0,
    "or turns-at-talk .": 1.0,
    "<s> contrary to": 1.0,
    "contrary to much": 0.5,
    "to much of": 1.0,
    "much of traditional": 0.3333333333333333,
    "of traditional linguistics": 1.0,
    "traditional linguistics ,": 1.0,
    "linguistics , discourse": 0.125,
    ", discourse analysts": 1.0,
    "discourse analysts not": 0.5,
    "analysts not only": 1.0,
    "not only study": 0.14285714285714285,
    "only study language": 1.0,
    "study language use": 1.0,
    "language use `": 0.25,
    "use ` beyond": 1.0,
    "` beyond the": 1.0,
    "beyond the sentence": 0.3333333333333333,
    "the sentence boundary": 0.16666666666666666,
    "sentence boundary '": 0.25,
    "boundary ' ,": 1.0,
    "' , but": 0.16666666666666666,
    ", but also": 0.0625,
    "but also prefer": 0.16666666666666666,
    "also prefer to": 1.0,
    "prefer to analyze": 1.0,
    "to analyze `": 1.0,
    "analyze ` naturally": 1.0,
    "` naturally occurring": 1.0,
    "naturally occurring '": 1.0,
    "occurring ' language": 1.0,
    "' language use": 1.0,
    "language use ,": 0.5,
    "use , and": 0.75,
    "and not invented": 0.125,
    "not invented examples": 1.0,
    "invented examples .": 1.0,
    "<s> text linguistics": 0.5,
    "text linguistics is": 1.0,
    "linguistics is related": 0.3333333333333333,
    "is related .": 1.0,
    "<s> the essential": 0.006802721088435374,
    "the essential difference": 1.0,
    "essential difference between": 1.0,
    "difference between discourse": 1.0,
    "between discourse analysis": 0.2,
    "discourse analysis and": 0.09090909090909091,
    "analysis and text": 0.3333333333333333,
    "and text linguistics": 0.25,
    "linguistics is that": 0.3333333333333333,
    "is that it": 0.08333333333333333,
    "that it aims": 0.3333333333333333,
    "it aims at": 1.0,
    "aims at revealing": 1.0,
    "at revealing socio-psychological": 1.0,
    "revealing socio-psychological characteristics": 1.0,
    "socio-psychological characteristics of": 1.0,
    "characteristics of a": 1.0,
    "of a person\\/persons": 0.010869565217391304,
    "a person\\/persons rather": 1.0,
    "person\\/persons rather than": 1.0,
    "rather than text": 0.07142857142857142,
    "than text structure": 1.0,
    "text structure .": 1.0,
    "discourse analysis has": 0.09090909090909091,
    "analysis has been": 1.0,
    "has been taken": 0.03571428571428571,
    "been taken up": 1.0,
    "taken up in": 1.0,
    "up in a": 0.3333333333333333,
    "in a variety": 0.038461538461538464,
    "a variety of": 1.0,
    "variety of social": 0.125,
    "of social science": 0.5,
    "social science disciplines": 1.0,
    "science disciplines ,": 1.0,
    "disciplines , including": 0.5,
    "linguistics , sociology": 0.125,
    ", sociology ,": 1.0,
    "sociology , anthropology": 1.0,
    ", anthropology ,": 1.0,
    "anthropology , social": 1.0,
    ", social work": 0.5,
    "social work ,": 1.0,
    "work , cognitive": 0.3333333333333333,
    ", cognitive psychology": 1.0,
    "cognitive psychology ,": 1.0,
    "psychology , social": 0.3333333333333333,
    ", social psychology": 0.5,
    "social psychology ,": 1.0,
    "psychology , international": 0.3333333333333333,
    ", international relations": 1.0,
    "international relations ,": 1.0,
    "relations , human": 0.5,
    ", human geography": 0.16666666666666666,
    "human geography ,": 1.0,
    "geography , communication": 1.0,
    ", communication studies": 1.0,
    "communication studies and": 1.0,
    "studies and translation": 1.0,
    "and translation studies": 0.3333333333333333,
    "translation studies ,": 1.0,
    "studies , each": 0.5,
    "which is subject": 0.07692307692307693,
    "is subject to": 1.0,
    "subject to its": 1.0,
    "to its own": 1.0,
    "its own assumptions": 0.2,
    "own assumptions ,": 1.0,
    "assumptions , dimensions": 1.0,
    ", dimensions of": 1.0,
    "dimensions of analysis": 0.5,
    "of analysis ,": 1.0,
    "analysis , and": 0.2857142857142857,
    ", and methodologies": 0.005291005291005291,
    "and methodologies .": 1.0,
    "<s> the examples": 0.006802721088435374,
    "the examples and": 0.5,
    "examples and perspective": 0.25,
    "and perspective in": 1.0,
    "perspective in this": 1.0,
    "in this article": 0.13333333333333333,
    "this article deal": 0.2,
    "article deal primarily": 1.0,
    "deal primarily with": 1.0,
    "primarily with the": 1.0,
    "with the united": 0.03333333333333333,
    "the united states": 0.875,
    "united states and": 0.14285714285714285,
    "states and do": 1.0,
    "and do not": 1.0,
    "do not represent": 0.07692307692307693,
    "not represent a": 1.0,
    "represent a worldwide": 0.5,
    "a worldwide view": 1.0,
    "worldwide view of": 1.0,
    "view of the": 1.0,
    "of the subject": 0.010256410256410256,
    "the subject .": 0.4,
    "<s> please improve": 0.3333333333333333,
    "please improve this": 1.0,
    "improve this article": 1.0,
    "this article and": 0.2,
    "article and discuss": 0.5,
    "and discuss the": 1.0,
    "discuss the issue": 1.0,
    "the issue on": 0.25,
    "issue on the": 1.0,
    "on the talk": 0.014925373134328358,
    "the talk page": 1.0,
    "talk page .": 1.0,
    "<s> -lrb- december": 0.05263157894736842,
    "-lrb- december 2010": 1.0,
    "december 2010 -rrb-": 1.0,
    "2010 -rrb- some": 1.0,
    "-rrb- some scholars": 1.0,
    "some scholars -lrb-": 1.0,
    "scholars -lrb- which": 1.0,
    "-lrb- which ?": 0.3333333333333333,
    "which ? -rrb-": 1.0,
    "consider the austrian": 0.25,
    "the austrian emigre": 1.0,
    "austrian emigre leo": 1.0,
    "emigre leo spitzer": 1.0,
    "leo spitzer 's": 1.0,
    "spitzer 's stilstudien": 1.0,
    "'s stilstudien -lrb-": 1.0,
    "stilstudien -lrb- style": 1.0,
    "-lrb- style studies": 1.0,
    "style studies -rrb-": 1.0,
    "studies -rrb- of": 1.0,
    "-rrb- of 1928": 0.14285714285714285,
    "of 1928 the": 1.0,
    "1928 the earliest": 1.0,
    "the earliest example": 0.5,
    "earliest example of": 1.0,
    "example of discourse": 0.14285714285714285,
    "da -rrb- ;": 0.5,
    "-rrb- ; michel": 0.125,
    "; michel foucault": 1.0,
    "michel foucault himself": 0.3333333333333333,
    "foucault himself translated": 1.0,
    "himself translated it": 1.0,
    "translated it into": 1.0,
    "it into french": 0.2,
    "<s> but the": 0.16666666666666666,
    "but the term": 0.25,
    "the term first": 0.1111111111111111,
    "term first came": 1.0,
    "first came into": 1.0,
    "came into general": 1.0,
    "into general use": 1.0,
    "general use following": 1.0,
    "use following the": 1.0,
    "following the publication": 1.0,
    "the publication of": 1.0,
    "publication of a": 0.5,
    "of a series": 0.021739130434782608,
    "series of papers": 0.14285714285714285,
    "of papers by": 1.0,
    "papers by zellig": 1.0,
    "by zellig harris": 1.0,
    "zellig harris beginning": 0.3333333333333333,
    "harris beginning in": 1.0,
    "beginning in 1952": 0.5,
    "in 1952 and": 1.0,
    "1952 and reporting": 1.0,
    "and reporting on": 1.0,
    "reporting on work": 1.0,
    "on work from": 1.0,
    "work from which": 1.0,
    "from which he": 0.3333333333333333,
    "which he developed": 1.0,
    "he developed transformational": 1.0,
    "developed transformational grammar": 1.0,
    "transformational grammar in": 0.5,
    "grammar in the": 1.0,
    "the late 1930s": 0.1111111111111111,
    "late 1930s .": 1.0,
    "<s> formal equivalence": 1.0,
    "formal equivalence relations": 1.0,
    "equivalence relations among": 1.0,
    "relations among the": 0.5,
    "among the sentences": 1.0,
    "the sentences of": 0.1111111111111111,
    "sentences of a": 0.5,
    "of a coherent": 0.010869565217391304,
    "a coherent discourse": 0.5,
    "coherent discourse are": 1.0,
    "discourse are made": 1.0,
    "are made explicit": 0.3333333333333333,
    "made explicit by": 1.0,
    "explicit by using": 1.0,
    "by using sentence": 0.3333333333333333,
    "using sentence transformations": 1.0,
    "sentence transformations to": 1.0,
    "transformations to put": 1.0,
    "to put the": 0.5,
    "put the text": 1.0,
    "text in a": 0.125,
    "in a canonical": 0.019230769230769232,
    "a canonical form": 1.0,
    "canonical form .": 1.0,
    "<s> words and": 0.5,
    "words and sentences": 0.125,
    "and sentences with": 0.3333333333333333,
    "sentences with equivalent": 1.0,
    "with equivalent information": 0.5,
    "equivalent information then": 1.0,
    "information then appear": 1.0,
    "then appear in": 1.0,
    "appear in the": 0.42857142857142855,
    "in the same": 0.026143790849673203,
    "the same column": 0.041666666666666664,
    "same column of": 1.0,
    "column of an": 1.0,
    "of an array": 0.07692307692307693,
    "an array .": 1.0,
    "<s> this work": 0.038461538461538464,
    "this work progressed": 0.3333333333333333,
    "work progressed over": 1.0,
    "progressed over the": 1.0,
    "over the next": 0.3333333333333333,
    "the next four": 0.14285714285714285,
    "next four decades": 1.0,
    "four decades -lrb-": 1.0,
    "decades -lrb- see": 1.0,
    "-lrb- see references": 0.0625,
    "see references -rrb-": 1.0,
    "references -rrb- into": 0.5,
    "-rrb- into a": 0.5,
    "into a science": 0.058823529411764705,
    "a science of": 0.5,
    "science of sublanguage": 1.0,
    "of sublanguage analysis": 0.5,
    "sublanguage analysis -lrb-": 0.5,
    "analysis -lrb- kittredge": 0.25,
    "-lrb- kittredge &": 1.0,
    "kittredge & lehrberger": 1.0,
    "& lehrberger 1982": 1.0,
    "lehrberger 1982 -rrb-": 1.0,
    "1982 -rrb- ,": 1.0,
    "-rrb- , culminating": 0.01282051282051282,
    ", culminating in": 1.0,
    "culminating in a": 1.0,
    "in a demonstration": 0.019230769230769232,
    "a demonstration of": 0.3333333333333333,
    "demonstration of the": 0.5,
    "of the informational": 0.005128205128205128,
    "the informational structures": 1.0,
    "informational structures in": 1.0,
    "structures in texts": 1.0,
    "in texts of": 1.0,
    "of a sublanguage": 0.010869565217391304,
    "a sublanguage of": 1.0,
    "sublanguage of science": 1.0,
    "of science ,": 1.0,
    "science , that": 0.2,
    ", that of": 0.25,
    "that of immunology": 0.125,
    "of immunology ,": 1.0,
    "immunology , -lrb-": 1.0,
    ", -lrb- harris": 0.3333333333333333,
    "-lrb- harris et": 0.5,
    "harris et al.": 1.0,
    "et al. 1989": 1.0,
    "al. 1989 -rrb-": 1.0,
    "1989 -rrb- and": 1.0,
    "-rrb- and a": 0.05,
    "and a fully": 0.0625,
    "a fully articulated": 1.0,
    "fully articulated theory": 1.0,
    "articulated theory of": 1.0,
    "theory of linguistic": 1.0,
    "of linguistic informational": 0.5,
    "linguistic informational content": 1.0,
    "informational content -lrb-": 1.0,
    "content -lrb- harris": 1.0,
    "-lrb- harris 1991": 0.5,
    "harris 1991 -rrb-": 1.0,
    "time , however": 0.09090909090909091,
    ", most linguists": 0.125,
    "most linguists decided": 1.0,
    "linguists decided a": 1.0,
    "decided a succession": 1.0,
    "a succession of": 1.0,
    "succession of elaborate": 1.0,
    "of elaborate theories": 1.0,
    "elaborate theories of": 1.0,
    "theories of sentence-level": 0.3333333333333333,
    "of sentence-level syntax": 1.0,
    "sentence-level syntax and": 1.0,
    "syntax and semantics": 1.0,
    "and semantics .": 0.3333333333333333,
    "<s> although harris": 0.14285714285714285,
    "although harris had": 1.0,
    "harris had mentioned": 1.0,
    "had mentioned the": 1.0,
    "mentioned the analysis": 1.0,
    "analysis of whole": 0.07692307692307693,
    "of whole discourses": 0.5,
    "whole discourses ,": 1.0,
    "discourses , he": 1.0,
    ", he had": 0.5,
    "he had not": 1.0,
    "had not worked": 1.0,
    "not worked out": 1.0,
    "worked out a": 1.0,
    "out a comprehensive": 1.0,
    "a comprehensive model": 0.25,
    "comprehensive model ,": 1.0,
    "model , as": 0.3333333333333333,
    ", as of": 0.043478260869565216,
    "as of january": 0.5,
    "of january ,": 1.0,
    "january , 1952": 1.0,
    ", 1952 .": 1.0,
    "<s> a linguist": 0.022727272727272728,
    "a linguist working": 1.0,
    "linguist working for": 1.0,
    "working for the": 1.0,
    "for the american": 0.03125,
    "the american bible": 0.5,
    "american bible society": 1.0,
    "bible society ,": 1.0,
    "society , james": 1.0,
    ", james a.": 0.5,
    "james a. lauriault\\/loriot": 1.0,
    "a. lauriault\\/loriot ,": 1.0,
    "lauriault\\/loriot , needed": 0.5,
    ", needed to": 1.0,
    "needed to find": 0.5,
    "to find answers": 0.1111111111111111,
    "find answers to": 1.0,
    "answers to some": 1.0,
    "to some fundamental": 0.2,
    "some fundamental errors": 1.0,
    "fundamental errors in": 1.0,
    "errors in translating": 1.0,
    "in translating quechua": 1.0,
    "translating quechua ,": 1.0,
    "quechua , in": 0.5,
    "in the cuzco": 0.006535947712418301,
    "the cuzco area": 1.0,
    "cuzco area of": 1.0,
    "area of peru": 0.2,
    "of peru .": 1.0,
    "<s> he took": 0.14285714285714285,
    "he took harris": 1.0,
    "took harris 's": 1.0,
    "harris 's idea": 0.5,
    "'s idea ,": 1.0,
    "idea , recorded": 1.0,
    ", recorded all": 1.0,
    "recorded all of": 1.0,
    "of the legends": 0.005128205128205128,
    "the legends and": 1.0,
    "legends and ,": 1.0,
    "and , after": 0.3333333333333333,
    ", after going": 1.0,
    "after going over": 1.0,
    "going over the": 1.0,
    "over the meaning": 0.3333333333333333,
    "the meaning and": 0.1,
    "meaning and placement": 1.0,
    "and placement of": 1.0,
    "placement of each": 1.0,
    "each word with": 0.16666666666666666,
    "word with a": 1.0,
    "with a native": 0.05,
    "speaker of quechua": 0.5,
    "of quechua ,": 1.0,
    "quechua , was": 0.5,
    ", was able": 0.5,
    "was able to": 1.0,
    "able to form": 0.0625,
    "to form logical": 0.25,
    "form logical ,": 1.0,
    "logical , mathematical": 1.0,
    ", mathematical rules": 1.0,
    "mathematical rules that": 1.0,
    "rules that transcended": 0.25,
    "that transcended the": 1.0,
    "transcended the simple": 1.0,
    "the simple sentence": 1.0,
    "simple sentence structure": 1.0,
    "sentence structure .": 1.0,
    "<s> he then": 0.14285714285714285,
    "he then applied": 1.0,
    "then applied the": 0.5,
    "applied the process": 1.0,
    "the process to": 0.14285714285714285,
    "process to another": 0.25,
    "to another language": 0.3333333333333333,
    "another language of": 0.3333333333333333,
    "language of eastern": 1.0,
    "of eastern peru": 1.0,
    "eastern peru ,": 1.0,
    "peru , shipibo": 1.0,
    ", shipibo .": 1.0,
    "<s> he taught": 0.14285714285714285,
    "he taught the": 1.0,
    "taught the theory": 1.0,
    "the theory in": 0.3333333333333333,
    "theory in norman": 1.0,
    "in norman ,": 1.0,
    "norman , oklahoma": 1.0,
    ", oklahoma ,": 1.0,
    "oklahoma , in": 1.0,
    "in the summers": 0.006535947712418301,
    "the summers of": 1.0,
    "summers of 1956": 1.0,
    "of 1956 and": 1.0,
    "1956 and 1957": 1.0,
    "and 1957 and": 1.0,
    "1957 and entered": 1.0,
    "and entered the": 1.0,
    "entered the university": 1.0,
    "the university of": 1.0,
    "university of pennsylvania": 0.3333333333333333,
    "of pennsylvania in": 1.0,
    "pennsylvania in the": 1.0,
    "in the interim": 0.006535947712418301,
    "the interim year": 1.0,
    "interim year .": 1.0,
    "<s> he tried": 0.14285714285714285,
    "he tried to": 1.0,
    "tried to publish": 1.0,
    "to publish a": 1.0,
    "publish a paper": 1.0,
    "a paper shipibo": 1.0,
    "paper shipibo paragraph": 1.0,
    "shipibo paragraph structure": 1.0,
    "paragraph structure ,": 1.0,
    "structure , but": 1.0,
    ", but it": 0.0625,
    "but it was": 0.25,
    "it was delayed": 0.2,
    "was delayed until": 1.0,
    "delayed until 1970": 1.0,
    "until 1970 -lrb-": 1.0,
    "1970 -lrb- loriot": 1.0,
    "-lrb- loriot &": 1.0,
    "loriot & hollenbach": 1.0,
    "& hollenbach 1970": 1.0,
    "hollenbach 1970 -rrb-": 1.0,
    "1970 -rrb- .": 1.0,
    "in the meantime": 0.006535947712418301,
    "the meantime ,": 1.0,
    "meantime , dr.": 1.0,
    ", dr. kenneth": 1.0,
    "dr. kenneth lee": 1.0,
    "kenneth lee pike": 1.0,
    "lee pike ,": 1.0,
    "pike , a": 1.0,
    ", a professor": 0.020833333333333332,
    "a professor at": 1.0,
    "professor at university": 1.0,
    "at university of": 1.0,
    "university of michigan": 0.3333333333333333,
    "of michigan ,": 1.0,
    "michigan , ann": 1.0,
    ", ann arbor": 1.0,
    "ann arbor ,": 1.0,
    "arbor , taught": 1.0,
    ", taught the": 1.0,
    "the theory ,": 0.3333333333333333,
    ", and one": 0.005291005291005291,
    "and one of": 1.0,
    "one of his": 0.0625,
    "of his students": 0.3333333333333333,
    "his students ,": 0.5,
    "students , robert": 1.0,
    ", robert e.": 0.6666666666666666,
    "robert e. longacre": 1.0,
    "e. longacre ,": 1.0,
    "longacre , was": 0.5,
    "able to disseminate": 0.0625,
    "to disseminate it": 1.0,
    "disseminate it in": 1.0,
    "it in a": 1.0,
    "in a dissertation": 0.019230769230769232,
    "a dissertation .": 1.0,
    "<s> harris 's": 1.0,
    "harris 's methodology": 0.5,
    "'s methodology was": 1.0,
    "methodology was developed": 1.0,
    "was developed into": 1.0,
    "developed into a": 1.0,
    "into a system": 0.058823529411764705,
    "a system for": 0.1,
    "system for the": 0.5,
    "for the computer-aided": 0.03125,
    "the computer-aided analysis": 1.0,
    "computer-aided analysis of": 1.0,
    "natural language by": 0.014492753623188406,
    "language by a": 1.0,
    "by a team": 0.05555555555555555,
    "a team led": 1.0,
    "team led by": 1.0,
    "led by naomi": 1.0,
    "by naomi sager": 1.0,
    "naomi sager at": 0.5,
    "sager at nyu": 1.0,
    "at nyu ,": 1.0,
    "nyu , which": 1.0,
    ", which has": 0.017857142857142856,
    "which has been": 0.42857142857142855,
    "has been applied": 0.10714285714285714,
    "applied to a": 0.18181818181818182,
    "to a number": 0.03571428571428571,
    "number of sublanguage": 0.027777777777777776,
    "of sublanguage domains": 0.5,
    "sublanguage domains ,": 1.0,
    "domains , most": 1.0,
    ", most notably": 0.125,
    "most notably to": 1.0,
    "notably to medical": 1.0,
    "to medical informatics": 1.0,
    "medical informatics .": 1.0,
    "<s> the software": 0.006802721088435374,
    "the software for": 0.25,
    "software for the": 1.0,
    "for the medical": 0.03125,
    "the medical language": 1.0,
    "medical language processor": 1.0,
    "language processor is": 1.0,
    "processor is publicly": 1.0,
    "is publicly available": 1.0,
    "publicly available on": 1.0,
    "available on sourceforge": 1.0,
    "on sourceforge .": 1.0,
    "the late 1960s": 0.1111111111111111,
    "late 1960s and": 1.0,
    "1960s and 1970s": 1.0,
    "and 1970s ,": 1.0,
    "1970s , and": 1.0,
    ", and without": 0.010582010582010581,
    "and without reference": 0.5,
    "without reference to": 1.0,
    "reference to this": 0.5,
    "to this prior": 0.16666666666666666,
    "this prior work": 1.0,
    "prior work ,": 1.0,
    "work , a": 0.3333333333333333,
    ", a variety": 0.020833333333333332,
    "variety of other": 0.125,
    "of other approaches": 0.25,
    "other approaches to": 1.0,
    "approaches to a": 0.2,
    "to a new": 0.03571428571428571,
    "a new cross-discipline": 0.16666666666666666,
    "new cross-discipline of": 1.0,
    "cross-discipline of da": 1.0,
    "of da began": 1.0,
    "da began to": 1.0,
    "began to develop": 0.5,
    "to develop in": 0.2,
    "develop in most": 1.0,
    "in most of": 0.25,
    "most of the": 0.5,
    "of the humanities": 0.005128205128205128,
    "the humanities and": 1.0,
    "humanities and social": 1.0,
    "and social sciences": 0.3333333333333333,
    "social sciences concurrently": 0.5,
    "sciences concurrently with": 1.0,
    "concurrently with ,": 1.0,
    "with , and": 1.0,
    ", and related": 0.005291005291005291,
    "and related to": 0.3333333333333333,
    "related to ,": 0.25,
    "to , other": 0.5,
    ", other disciplines": 1.0,
    "other disciplines ,": 1.0,
    "disciplines , such": 0.5,
    "such as semiotics": 0.011111111111111112,
    "as semiotics ,": 1.0,
    "semiotics , psycholinguistics": 1.0,
    ", psycholinguistics ,": 1.0,
    "psycholinguistics , sociolinguistics": 1.0,
    ", sociolinguistics ,": 1.0,
    "sociolinguistics , and": 1.0,
    ", and pragmatics": 0.005291005291005291,
    "and pragmatics .": 1.0,
    "many of these": 0.25,
    "of these approaches": 0.09090909090909091,
    "these approaches ,": 0.5,
    "approaches , especially": 1.0,
    "especially those influenced": 0.3333333333333333,
    "those influenced by": 1.0,
    "influenced by the": 1.0,
    "by the social": 0.03571428571428571,
    "the social sciences": 0.3333333333333333,
    "social sciences ,": 0.5,
    "sciences , favor": 1.0,
    ", favor a": 1.0,
    "favor a more": 1.0,
    "a more dynamic": 0.2,
    "more dynamic study": 1.0,
    "dynamic study of": 1.0,
    "study of oral": 1.0,
    "of oral talk-in-interaction": 1.0,
    "oral talk-in-interaction .": 1.0,
    "<s> mention must": 1.0,
    "mention must also": 1.0,
    "must also be": 1.0,
    "also be made": 0.14285714285714285,
    "be made of": 0.25,
    "made of the": 0.3333333333333333,
    "of the term": 0.005128205128205128,
    "the term ``": 0.1111111111111111,
    "term `` conversational": 0.5,
    "`` conversational analysis": 1.0,
    "conversational analysis ''": 1.0,
    "analysis '' ,": 1.0,
    "'' , which": 0.06666666666666667,
    "which was influenced": 0.2,
    "was influenced by": 1.0,
    "by the sociologist": 0.03571428571428571,
    "the sociologist harold": 1.0,
    "sociologist harold garfinkel": 1.0,
    "harold garfinkel who": 1.0,
    "garfinkel who is": 1.0,
    "is the founder": 0.022222222222222223,
    "the founder of": 1.0,
    "founder of ethnomethodology": 1.0,
    "of ethnomethodology .": 1.0,
    "<s> in europe": 0.020618556701030927,
    "in europe ,": 0.5,
    "europe , michel": 0.3333333333333333,
    ", michel foucault": 1.0,
    "michel foucault became": 0.3333333333333333,
    "foucault became one": 1.0,
    "became one of": 1.0,
    "of the key": 0.005128205128205128,
    "the key theorists": 1.0,
    "key theorists of": 1.0,
    "theorists of the": 1.0,
    "the subject ,": 0.2,
    "subject , especially": 0.5,
    ", especially of": 0.1111111111111111,
    "especially of discourse": 1.0,
    "of discourse ,": 0.18181818181818182,
    "discourse , and": 0.3333333333333333,
    ", and wrote": 0.005291005291005291,
    "and wrote the": 1.0,
    "wrote the archaeology": 1.0,
    "the archaeology of": 1.0,
    "archaeology of knowledge": 1.0,
    "of knowledge on": 0.3333333333333333,
    "knowledge on the": 1.0,
    "on the subject": 0.014925373134328358,
    "<s> topics of": 1.0,
    "topics of interest": 0.5,
    "of interest topics": 0.3333333333333333,
    "interest topics of": 1.0,
    "topics of discourse": 0.5,
    "discourse analysis include": 0.09090909090909091,
    "analysis include :": 1.0,
    "include : the": 0.3333333333333333,
    ": the various": 0.16666666666666666,
    "the various levels": 1.0,
    "various levels or": 1.0,
    "levels or dimensions": 1.0,
    "or dimensions of": 1.0,
    "dimensions of discourse": 0.5,
    "discourse , such": 0.3333333333333333,
    "such as sounds": 0.011111111111111112,
    "as sounds -lrb-": 1.0,
    "sounds -lrb- intonation": 0.5,
    "-lrb- intonation ,": 1.0,
    "intonation , etc.": 1.0,
    "etc. -rrb- ,": 0.3333333333333333,
    "-rrb- , gestures": 0.01282051282051282,
    ", gestures ,": 1.0,
    "gestures , syntax": 1.0,
    "syntax , the": 0.2,
    ", the lexicon": 0.009523809523809525,
    "the lexicon ,": 1.0,
    "lexicon , style": 1.0,
    ", style ,": 1.0,
    "style , rhetoric": 1.0,
    ", rhetoric ,": 1.0,
    "rhetoric , meanings": 1.0,
    ", meanings ,": 1.0,
    "meanings , speech": 1.0,
    "speech acts ,": 0.3333333333333333,
    "acts , moves": 1.0,
    ", moves ,": 1.0,
    "moves , strategies": 1.0,
    ", strategies ,": 1.0,
    "strategies , turns": 1.0,
    ", turns and": 1.0,
    "turns and other": 1.0,
    "and other aspects": 0.1111111111111111,
    "other aspects of": 1.0,
    "aspects of interaction": 0.16666666666666666,
    "of interaction genres": 1.0,
    "interaction genres of": 1.0,
    "genres of discourse": 0.5,
    "of discourse -lrb-": 0.18181818181818182,
    "discourse -lrb- various": 0.5,
    "-lrb- various types": 1.0,
    "various types of": 1.0,
    "types of discourse": 0.14285714285714285,
    "of discourse in": 0.09090909090909091,
    "discourse in politics": 0.5,
    "in politics ,": 1.0,
    "politics , the": 1.0,
    ", the media": 0.009523809523809525,
    "the media ,": 1.0,
    "media , education": 0.3333333333333333,
    ", education ,": 1.0,
    "education , science": 1.0,
    ", science ,": 1.0,
    "science , business": 0.2,
    ", business ,": 1.0,
    "business , etc.": 1.0,
    "etc. -rrb- the": 0.1111111111111111,
    "-rrb- the relations": 0.3333333333333333,
    "the relations between": 1.0,
    "relations between discourse": 0.8,
    "between discourse and": 0.8,
    "discourse and the": 0.25,
    "and the emergence": 0.024390243902439025,
    "the emergence of": 1.0,
    "emergence of syntactic": 1.0,
    "of syntactic structure": 0.5,
    "syntactic structure the": 1.0,
    "structure the relations": 1.0,
    "relations between text": 0.2,
    "between text -lrb-": 1.0,
    "text -lrb- discourse": 0.16666666666666666,
    "-lrb- discourse -rrb-": 1.0,
    "discourse -rrb- and": 1.0,
    "-rrb- and context": 0.05,
    "and context the": 0.6666666666666666,
    "context the relations": 0.5,
    "discourse and power": 0.25,
    "and power the": 1.0,
    "power the relations": 1.0,
    "discourse and interaction": 0.25,
    "and interaction the": 1.0,
    "interaction the relations": 1.0,
    "discourse and cognition": 0.25,
    "and cognition and": 1.0,
    "cognition and memory": 1.0,
    "and memory political": 1.0,
    "memory political discourse": 1.0,
    "political discourse political": 0.25,
    "discourse political discourse": 1.0,
    "political discourse analysis": 0.25,
    "discourse analysis is": 0.09090909090909091,
    "analysis is a": 1.0,
    "field of discourse": 0.08333333333333333,
    "discourse analysis which": 0.09090909090909091,
    "analysis which focuses": 1.0,
    "which focuses on": 1.0,
    "focuses on discourse": 0.5,
    "on discourse in": 1.0,
    "discourse in political": 0.5,
    "in political forums": 1.0,
    "political forums -lrb-": 1.0,
    "forums -lrb- such": 1.0,
    "such as debates": 0.011111111111111112,
    "as debates ,": 1.0,
    "debates , speeches": 0.5,
    ", speeches ,": 1.0,
    "speeches , and": 1.0,
    ", and hearings": 0.005291005291005291,
    "and hearings -rrb-": 1.0,
    "hearings -rrb- as": 1.0,
    "-rrb- as the": 0.3333333333333333,
    "as the phenomenon": 0.03571428571428571,
    "the phenomenon of": 1.0,
    "phenomenon of interest": 0.3333333333333333,
    "of interest .": 0.3333333333333333,
    "<s> political discourse": 1.0,
    "political discourse is": 0.5,
    "discourse is the": 0.3333333333333333,
    "is the informal": 0.022222222222222223,
    "the informal exchange": 1.0,
    "informal exchange of": 1.0,
    "exchange of reasoned": 1.0,
    "of reasoned views": 1.0,
    "reasoned views as": 1.0,
    "views as to": 1.0,
    "as to which": 0.5,
    "to which of": 0.2,
    "which of several": 1.0,
    "of several alternative": 0.3333333333333333,
    "several alternative courses": 1.0,
    "alternative courses of": 1.0,
    "courses of action": 1.0,
    "of action should": 1.0,
    "action should be": 1.0,
    "should be taken": 0.1111111111111111,
    "be taken to": 1.0,
    "taken to solve": 1.0,
    "to solve a": 0.25,
    "solve a societal": 1.0,
    "a societal problem": 1.0,
    "societal problem .": 1.0,
    "is a science": 0.018518518518518517,
    "a science that": 0.5,
    "science that has": 1.0,
    "has been used": 0.07142857142857142,
    "been used through": 0.2,
    "used through the": 1.0,
    "through the history": 0.25,
    "the history of": 1.0,
    "history of the": 0.5,
    "of the united": 0.015384615384615385,
    "united states .": 0.2857142857142857,
    "is the essence": 0.022222222222222223,
    "the essence of": 1.0,
    "essence of democracy": 0.5,
    "of democracy .": 1.0,
    "<s> full of": 1.0,
    "full of problems": 1.0,
    "of problems and": 0.5,
    "problems and persuasion": 0.5,
    "and persuasion ,": 1.0,
    "persuasion , political": 1.0,
    ", political discourse": 1.0,
    "discourse is used": 0.3333333333333333,
    "is used in": 0.15384615384615385,
    "used in many": 0.13043478260869565,
    "in many debates": 0.1,
    "many debates ,": 1.0,
    "debates , candidacies": 0.5,
    ", candidacies and": 1.0,
    "candidacies and in": 1.0,
    "and in our": 0.14285714285714285,
    "in our everyday": 1.0,
    "our everyday life": 1.0,
    "everyday life .": 1.0,
    "<s> perspectives the": 1.0,
    "perspectives the following": 1.0,
    "the following are": 0.09090909090909091,
    "following are some": 1.0,
    "are some of": 1.0,
    "of the specific": 0.010256410256410256,
    "the specific theoretical": 0.3333333333333333,
    "specific theoretical perspectives": 1.0,
    "theoretical perspectives and": 1.0,
    "perspectives and analytical": 1.0,
    "and analytical approaches": 1.0,
    "analytical approaches used": 1.0,
    "approaches used in": 1.0,
    "used in linguistic": 0.043478260869565216,
    "in linguistic discourse": 0.5,
    "linguistic discourse analysis": 1.0,
    "analysis : emergent": 0.25,
    ": emergent grammar": 1.0,
    "emergent grammar text": 1.0,
    "grammar text grammar": 1.0,
    "text grammar -lrb-": 1.0,
    "grammar -lrb- or": 1.0,
    "-lrb- or `": 0.1,
    "or ` discourse": 1.0,
    "` discourse grammar": 1.0,
    "discourse grammar '": 1.0,
    "grammar ' -rrb-": 1.0,
    "' -rrb- cohesion": 1.0,
    "-rrb- cohesion and": 1.0,
    "cohesion and relevance": 1.0,
    "and relevance theory": 1.0,
    "relevance theory functional": 1.0,
    "theory functional grammar": 1.0,
    "functional grammar rhetoric": 0.5,
    "grammar rhetoric stylistics": 1.0,
    "rhetoric stylistics -lrb-": 1.0,
    "stylistics -lrb- linguistics": 1.0,
    "-lrb- linguistics -rrb-": 1.0,
    "linguistics -rrb- interactional": 0.5,
    "-rrb- interactional sociolinguistics": 1.0,
    "interactional sociolinguistics ethnography": 1.0,
    "sociolinguistics ethnography of": 1.0,
    "ethnography of communication": 1.0,
    "of communication pragmatics": 0.5,
    "communication pragmatics ,": 1.0,
    "pragmatics , particularly": 1.0,
    ", particularly speech": 0.5,
    "particularly speech act": 1.0,
    "speech act theory": 1.0,
    "act theory conversation": 1.0,
    "theory conversation analysis": 1.0,
    "conversation analysis variation": 1.0,
    "analysis variation analysis": 1.0,
    "variation analysis applied": 1.0,
    "analysis applied linguistics": 1.0,
    "applied linguistics cognitive": 1.0,
    "linguistics cognitive psychology": 1.0,
    "psychology , often": 0.3333333333333333,
    ", often under": 0.3333333333333333,
    "often under the": 1.0,
    "under the label": 1.0,
    "the label discourse": 1.0,
    "label discourse processing": 1.0,
    "discourse processing ,": 1.0,
    "processing , studying": 0.1111111111111111,
    ", studying the": 1.0,
    "studying the production": 1.0,
    "the production and": 1.0,
    "production and comprehension": 1.0,
    "and comprehension of": 1.0,
    "comprehension of discourse": 0.5,
    "of discourse .": 0.09090909090909091,
    "<s> discursive psychology": 1.0,
    "discursive psychology response": 1.0,
    "psychology response based": 1.0,
    "response based therapy": 1.0,
    "based therapy -lrb-": 1.0,
    "therapy -lrb- counselling": 1.0,
    "-lrb- counselling -rrb-": 1.0,
    "counselling -rrb- critical": 1.0,
    "-rrb- critical discourse": 1.0,
    "critical discourse analysis": 1.0,
    "discourse analysis sublanguage": 0.09090909090909091,
    "analysis sublanguage analysis": 1.0,
    "sublanguage analysis genre": 0.5,
    "analysis genre analysis": 1.0,
    "genre analysis &": 0.5,
    "analysis & critical": 1.0,
    "& critical genre": 1.0,
    "critical genre analysis": 1.0,
    "genre analysis although": 0.5,
    "analysis although these": 1.0,
    "although these approaches": 0.5,
    "these approaches emphasize": 0.5,
    "approaches emphasize different": 1.0,
    "emphasize different aspects": 1.0,
    "different aspects of": 1.0,
    "aspects of language": 0.16666666666666666,
    "of language use": 0.2,
    "use , they": 0.25,
    ", they all": 0.25,
    "they all view": 0.5,
    "all view language": 1.0,
    "view language as": 1.0,
    "language as social": 0.5,
    "as social interaction": 1.0,
    "social interaction ,": 1.0,
    "interaction , and": 1.0,
    ", and are": 0.005291005291005291,
    "and are concerned": 0.2,
    "are concerned with": 1.0,
    "with the social": 0.03333333333333333,
    "the social contexts": 0.3333333333333333,
    "social contexts in": 1.0,
    "contexts in which": 1.0,
    "in which discourse": 0.125,
    "which discourse is": 1.0,
    "discourse is embedded": 0.3333333333333333,
    "is embedded .": 1.0,
    "<s> often a": 0.3333333333333333,
    "often a distinction": 0.5,
    "a distinction is": 1.0,
    "distinction is made": 0.5,
    "is made between": 0.5,
    "made between `": 1.0,
    "between ` local": 1.0,
    "` local '": 1.0,
    "local ' structures": 1.0,
    "' structures of": 0.5,
    "structures of discourse": 1.0,
    "discourse -lrb- such": 0.5,
    "such as relations": 0.011111111111111112,
    "as relations among": 1.0,
    "relations among sentences": 0.5,
    "among sentences ,": 1.0,
    "propositions , and": 0.5,
    ", and turns": 0.005291005291005291,
    "and turns -rrb-": 1.0,
    "turns -rrb- and": 1.0,
    "-rrb- and `": 0.05,
    "and ` global": 1.0,
    "` global '": 1.0,
    "global ' structures": 1.0,
    "' structures ,": 0.5,
    "structures , such": 1.0,
    "such as overall": 0.011111111111111112,
    "as overall topics": 1.0,
    "overall topics and": 1.0,
    "topics and the": 1.0,
    "and the schematic": 0.024390243902439025,
    "the schematic organization": 1.0,
    "schematic organization of": 1.0,
    "organization of discourses": 0.5,
    "of discourses and": 1.0,
    "discourses and conversations": 1.0,
    "and conversations .": 1.0,
    "instance , many": 0.1111111111111111,
    ", many types": 0.14285714285714285,
    "many types of": 1.0,
    "of discourse begin": 0.09090909090909091,
    "discourse begin with": 1.0,
    "begin with some": 0.5,
    "with some kind": 0.25,
    "some kind of": 1.0,
    "kind of global": 0.125,
    "of global `": 1.0,
    "global ` summary": 1.0,
    "` summary '": 1.0,
    "summary ' ,": 1.0,
    "' , in": 0.16666666666666666,
    ", in titles": 0.029411764705882353,
    "in titles ,": 1.0,
    "titles , headlines": 1.0,
    ", headlines ,": 1.0,
    "headlines , leads": 1.0,
    ", leads ,": 1.0,
    "leads , abstracts": 1.0,
    ", abstracts ,": 1.0,
    "abstracts , and": 1.0,
    ", and so": 0.031746031746031744,
    "and so on": 0.8333333333333334,
    "so on .": 0.8,
    "<s> a problem": 0.022727272727272728,
    "a problem for": 0.25,
    "problem for the": 1.0,
    "for the discourse": 0.03125,
    "the discourse analyst": 0.3333333333333333,
    "discourse analyst is": 1.0,
    "analyst is to": 1.0,
    "is to decide": 0.05263157894736842,
    "to decide when": 0.5,
    "decide when a": 1.0,
    "when a particular": 0.2,
    "a particular feature": 0.25,
    "particular feature is": 1.0,
    "feature is relevant": 1.0,
    "is relevant to": 1.0,
    "relevant to the": 1.0,
    "to the specification": 0.012987012987012988,
    "the specification is": 0.5,
    "specification is required": 1.0,
    "is required .": 0.5,
    "<s> are there": 1.0,
    "are there general": 1.0,
    "there general principles": 1.0,
    "general principles which": 1.0,
    "principles which will": 1.0,
    "which will determine": 0.3333333333333333,
    "will determine the": 1.0,
    "determine the relevance": 0.1,
    "the relevance or": 1.0,
    "relevance or nature": 1.0,
    "or nature of": 1.0,
    "of the specification": 0.005128205128205128,
    "the specification .": 0.5,
    "<s> prominent discourse": 1.0,
    "prominent discourse analysts": 1.0,
    "discourse analysts this": 0.5,
    "analysts this article": 1.0,
    "this article contains": 0.2,
    "article contains embedded": 1.0,
    "contains embedded lists": 1.0,
    "embedded lists that": 1.0,
    "lists that may": 1.0,
    "that may be": 0.5,
    "may be poorly": 0.047619047619047616,
    "be poorly defined": 1.0,
    "poorly defined ,": 1.0,
    "defined , unverified": 1.0,
    ", unverified or": 1.0,
    "unverified or indiscriminate": 1.0,
    "or indiscriminate .": 1.0,
    "<s> please help": 0.6666666666666666,
    "please help to": 0.5,
    "help to clean": 1.0,
    "to clean it": 1.0,
    "clean it up": 1.0,
    "it up to": 1.0,
    "up to meet": 0.16666666666666666,
    "to meet wikipedia": 0.25,
    "meet wikipedia 's": 1.0,
    "wikipedia 's quality": 1.0,
    "'s quality standards": 1.0,
    "quality standards .": 1.0,
    "<s> -lrb- may": 0.10526315789473684,
    "-lrb- may 2012": 0.5,
    "may 2012 -rrb-": 1.0,
    "2012 -rrb- marc": 1.0,
    "-rrb- marc angenot": 1.0,
    "marc angenot ,": 1.0,
    "angenot , robert": 1.0,
    ", robert de": 0.3333333333333333,
    "robert de beaugrande": 1.0,
    "de beaugrande ,": 1.0,
    "beaugrande , jan": 1.0,
    ", jan blommaert": 1.0,
    "jan blommaert ,": 1.0,
    "blommaert , adriana": 1.0,
    ", adriana bolivar": 1.0,
    "adriana bolivar ,": 1.0,
    "bolivar , carmen": 1.0,
    ", carmen rosa": 1.0,
    "carmen rosa caldas-coulthard": 1.0,
    "rosa caldas-coulthard ,": 1.0,
    "caldas-coulthard , robyn": 1.0,
    ", robyn carston": 1.0,
    "robyn carston ,": 1.0,
    "carston , wallace": 1.0,
    ", wallace chafe": 1.0,
    "wallace chafe ,": 1.0,
    "chafe , paul": 1.0,
    ", paul chilton": 0.3333333333333333,
    "paul chilton ,": 1.0,
    "chilton , guy": 1.0,
    ", guy cook": 1.0,
    "guy cook ,": 1.0,
    "cook , malcolm": 1.0,
    ", malcolm coulthard": 1.0,
    "malcolm coulthard ,": 1.0,
    "coulthard , james": 1.0,
    ", james deese": 0.25,
    "james deese ,": 1.0,
    "deese , paul": 1.0,
    ", paul drew": 0.3333333333333333,
    "paul drew ,": 1.0,
    "drew , john": 1.0,
    ", john du": 0.2,
    "john du bois": 1.0,
    "du bois ,": 1.0,
    "bois , alessandro": 1.0,
    ", alessandro duranti": 1.0,
    "alessandro duranti ,": 1.0,
    "duranti , brenton": 1.0,
    ", brenton d.": 1.0,
    "brenton d. faber": 1.0,
    "d. faber ,": 1.0,
    "faber , norman": 1.0,
    ", norman fairclough": 1.0,
    "norman fairclough ,": 1.0,
    "fairclough , michel": 1.0,
    "michel foucault ,": 0.3333333333333333,
    "foucault , roger": 1.0,
    ", roger fowler": 1.0,
    "roger fowler ,": 1.0,
    "fowler , james": 1.0,
    ", james paul": 0.25,
    "james paul gee": 1.0,
    "paul gee ,": 1.0,
    "gee , talmy": 1.0,
    ", talmy giv\u00f3n": 1.0,
    "talmy giv\u00f3n ,": 1.0,
    "giv\u00f3n , charles": 1.0,
    ", charles goodwin": 1.0,
    "charles goodwin ,": 1.0,
    "goodwin , art": 1.0,
    ", art graesser": 1.0,
    "art graesser ,": 1.0,
    "graesser , michael": 1.0,
    ", michael halliday": 0.25,
    "michael halliday ,": 1.0,
    "halliday , zellig": 1.0,
    ", zellig harris": 1.0,
    "zellig harris ,": 0.3333333333333333,
    "harris , john": 1.0,
    ", john heritage": 0.2,
    "john heritage ,": 1.0,
    "heritage , janet": 1.0,
    ", janet holmes": 1.0,
    "janet holmes ,": 1.0,
    "holmes , david": 1.0,
    ", david r.": 0.3333333333333333,
    "david r. howarth": 1.0,
    "r. howarth ,": 1.0,
    "howarth , paul": 1.0,
    ", paul hopper": 0.3333333333333333,
    "paul hopper ,": 1.0,
    "hopper , gail": 1.0,
    ", gail jefferson": 1.0,
    "gail jefferson ,": 1.0,
    "jefferson , barbara": 1.0,
    ", barbara johnstone": 1.0,
    "barbara johnstone ,": 1.0,
    "johnstone , walter": 1.0,
    ", walter kintsch": 1.0,
    "walter kintsch ,": 1.0,
    "kintsch , richard": 1.0,
    ", richard kittredge": 1.0,
    "richard kittredge ,": 1.0,
    "kittredge , adam": 1.0,
    ", adam jaworski": 1.0,
    "adam jaworski ,": 1.0,
    "jaworski , william": 1.0,
    ", william labov": 0.5,
    "william labov ,": 1.0,
    "labov , george": 1.0,
    ", george lakoff": 1.0,
    "george lakoff ,": 1.0,
    "lakoff , jay": 1.0,
    ", jay lemke": 1.0,
    "jay lemke ,": 1.0,
    "lemke , stephen": 1.0,
    ", stephen h.": 1.0,
    "stephen h. levinsohn": 1.0,
    "h. levinsohn ,": 1.0,
    "levinsohn , james": 1.0,
    "lauriault\\/loriot , robert": 0.5,
    "longacre , jim": 0.5,
    ", jim martin": 1.0,
    "jim martin ,": 1.0,
    "martin , aletta": 1.0,
    ", aletta norval": 1.0,
    "aletta norval ,": 1.0,
    "norval , david": 1.0,
    ", david nunan": 0.3333333333333333,
    "david nunan ,": 1.0,
    "nunan , elinor": 1.0,
    ", elinor ochs": 1.0,
    "elinor ochs ,": 1.0,
    "ochs , gina": 1.0,
    ", gina poncini": 1.0,
    "gina poncini ,": 1.0,
    "poncini , jonathan": 1.0,
    ", jonathan potter": 1.0,
    "jonathan potter ,": 1.0,
    "potter , edward": 1.0,
    ", edward robinson": 1.0,
    "edward robinson ,": 1.0,
    "robinson , nikolas": 1.0,
    ", nikolas rose": 1.0,
    "nikolas rose ,": 1.0,
    "rose , harvey": 1.0,
    ", harvey sacks": 1.0,
    "harvey sacks ,": 1.0,
    "sacks , svenka": 1.0,
    ", svenka savic": 1.0,
    "svenka savic naomi": 1.0,
    "savic naomi sager": 1.0,
    "naomi sager ,": 0.5,
    "sager , emanuel": 1.0,
    ", emanuel schegloff": 0.5,
    "emanuel schegloff ,": 1.0,
    "schegloff , deborah": 1.0,
    ", deborah schiffrin": 0.5,
    "deborah schiffrin ,": 1.0,
    "schiffrin , michael": 1.0,
    ", michael schober": 0.25,
    "michael schober ,": 1.0,
    "schober , stef": 1.0,
    ", stef slembrouck": 1.0,
    "stef slembrouck ,": 1.0,
    "slembrouck , michael": 1.0,
    ", michael stubbs": 0.25,
    "michael stubbs ,": 1.0,
    "stubbs , john": 1.0,
    ", john swales": 0.4,
    "john swales ,": 1.0,
    "swales , deborah": 0.5,
    ", deborah tannen": 0.5,
    "deborah tannen ,": 1.0,
    "tannen , sandra": 1.0,
    ", sandra thompson": 1.0,
    "sandra thompson ,": 1.0,
    "thompson , teun": 1.0,
    ", teun a.": 1.0,
    "teun a. van": 1.0,
    "a. van dijk": 1.0,
    "van dijk ,": 1.0,
    "dijk , theo": 1.0,
    ", theo van": 1.0,
    "theo van leeuwen": 1.0,
    "van leeuwen ,": 1.0,
    "leeuwen , jef": 1.0,
    ", jef verschueren": 1.0,
    "jef verschueren ,": 1.0,
    "verschueren , henry": 1.0,
    ", henry widdowson": 1.0,
    "henry widdowson ,": 1.0,
    "widdowson , carla": 1.0,
    ", carla willig": 1.0,
    "carla willig ,": 1.0,
    "willig , deirdre": 1.0,
    ", deirdre wilson": 1.0,
    "deirdre wilson ,": 1.0,
    "wilson , ruth": 1.0,
    ", ruth wodak": 1.0,
    "ruth wodak ,": 1.0,
    "wodak , margaret": 1.0,
    ", margaret wetherell": 1.0,
    "margaret wetherell ,": 1.0,
    "wetherell , ernesto": 1.0,
    ", ernesto laclau": 1.0,
    "ernesto laclau ,": 1.0,
    "laclau , chantal": 1.0,
    ", chantal mouffe": 1.0,
    "chantal mouffe ,": 1.0,
    "mouffe , judith": 1.0,
    ", judith m.": 1.0,
    "judith m. de": 1.0,
    "m. de guzman": 1.0,
    "de guzman ,": 1.0,
    "guzman , cynthia": 1.0,
    ", cynthia hardy": 1.0,
    "cynthia hardy ,": 1.0,
    "hardy , louise": 1.0,
    ", louise j.": 1.0,
    "louise j. phillips": 1.0,
    "j. phillips .": 1.0,
    "needed -rrb- bhatia": 0.07692307692307693,
    "-rrb- bhatia ,": 1.0,
    "bhatia , v.j.": 1.0,
    ", v.j. ,": 1.0,
    "v.j. , john": 1.0,
    "swales , zellig": 0.5,
    "zellig harris the": 0.3333333333333333,
    "harris the phenomenon": 1.0,
    "phenomenon of information": 0.3333333333333333,
    "of information overload": 0.2,
    "information overload has": 1.0,
    "overload has meant": 1.0,
    "has meant that": 1.0,
    "meant that access": 1.0,
    "that access to": 1.0,
    "access to coherent": 0.3333333333333333,
    "to coherent and": 1.0,
    "coherent and correctly-developed": 1.0,
    "and correctly-developed summaries": 1.0,
    "correctly-developed summaries is": 1.0,
    "summaries is vital": 0.3333333333333333,
    "is vital .": 1.0,
    "<s> as access": 0.07142857142857142,
    "as access to": 1.0,
    "access to data": 0.3333333333333333,
    "to data has": 0.5,
    "data has increased": 1.0,
    "has increased so": 1.0,
    "increased so has": 1.0,
    "so has interest": 1.0,
    "has interest in": 1.0,
    "interest in automatic": 0.14285714285714285,
    "in automatic summarization": 0.5,
    "automatic summarization .": 0.5,
    "<s> an example": 0.18181818181818182,
    "example of the": 0.14285714285714285,
    "of the use": 0.005128205128205128,
    "use of summarization": 0.045454545454545456,
    "of summarization technology": 0.125,
    "summarization technology is": 1.0,
    "technology is search": 0.3333333333333333,
    "is search engines": 1.0,
    "search engines such": 0.5,
    "engines such as": 1.0,
    "such as google": 0.011111111111111112,
    "as google .": 1.0,
    "<s> technologies that": 1.0,
    "technologies that can": 1.0,
    "that can make": 0.15384615384615385,
    "can make a": 0.3333333333333333,
    "make a coherent": 0.25,
    "a coherent summary": 0.5,
    "coherent summary ,": 1.0,
    "summary , of": 0.16666666666666666,
    ", of any": 0.25,
    "of any kind": 0.3333333333333333,
    "any kind of": 1.0,
    "kind of text": 0.125,
    "text , need": 0.03333333333333333,
    ", need to": 1.0,
    "need to take": 0.2,
    "to take into": 0.4,
    "take into account": 0.6666666666666666,
    "into account several": 0.3333333333333333,
    "account several variables": 1.0,
    "several variables such": 1.0,
    "variables such as": 1.0,
    "such as length": 0.011111111111111112,
    "as length ,": 1.0,
    "length , writing": 0.5,
    ", writing style": 0.5,
    "writing style and": 1.0,
    "style and syntax": 1.0,
    "and syntax to": 1.0,
    "syntax to make": 0.5,
    "to make a": 0.5,
    "make a useful": 0.25,
    "a useful summary": 0.5,
    "useful summary .": 1.0,
    "<s> extractive methods": 1.0,
    "extractive methods work": 0.5,
    "methods work by": 0.5,
    "work by selecting": 0.5,
    "by selecting a": 0.5,
    "selecting a subset": 1.0,
    "a subset of": 1.0,
    "subset of existing": 0.3333333333333333,
    "of existing words": 0.5,
    "existing words ,": 1.0,
    "words , phrases": 0.125,
    ", phrases ,": 1.0,
    "phrases , or": 0.3333333333333333,
    ", or sentences": 0.030303030303030304,
    "or sentences in": 1.0,
    "sentences in the": 0.5,
    "in the original": 0.026143790849673203,
    "original text to": 0.16666666666666666,
    "text to form": 0.14285714285714285,
    "to form the": 0.25,
    "form the summary": 1.0,
    "the summary .": 0.625,
    "<s> in contrast": 0.05154639175257732,
    "in contrast ,": 0.8333333333333334,
    "contrast , abstractive": 0.2,
    ", abstractive methods": 1.0,
    "abstractive methods build": 0.5,
    "methods build an": 1.0,
    "build an internal": 0.5,
    "an internal semantic": 0.3333333333333333,
    "internal semantic representation": 1.0,
    "semantic representation and": 1.0,
    "representation and then": 0.5,
    "and then use": 0.14285714285714285,
    "then use natural": 1.0,
    "use natural language": 1.0,
    "language generation techniques": 0.16666666666666666,
    "generation techniques to": 1.0,
    "techniques to create": 0.25,
    "to create a": 0.5555555555555556,
    "create a summary": 0.14285714285714285,
    "a summary that": 0.1111111111111111,
    "summary that is": 1.0,
    "that is closer": 0.05263157894736842,
    "is closer to": 1.0,
    "closer to what": 0.5,
    "to what a": 0.25,
    "what a human": 0.6666666666666666,
    "a human might": 0.09090909090909091,
    "human might generate": 1.0,
    "might generate .": 1.0,
    "<s> such a": 0.125,
    "such a summary": 0.14285714285714285,
    "a summary might": 0.1111111111111111,
    "summary might contain": 1.0,
    "might contain words": 1.0,
    "contain words not": 1.0,
    "words not explicitly": 1.0,
    "not explicitly present": 1.0,
    "explicitly present in": 1.0,
    "present in the": 0.4,
    "the original .": 0.1,
    "<s> the state-of-the-art": 0.006802721088435374,
    "the state-of-the-art abstractive": 0.5,
    "state-of-the-art abstractive methods": 1.0,
    "abstractive methods are": 0.5,
    "methods are still": 0.5,
    "are still quite": 0.25,
    "still quite weak": 1.0,
    "quite weak ,": 1.0,
    "weak , so": 1.0,
    ", so most": 0.08333333333333333,
    "so most research": 1.0,
    "most research has": 1.0,
    "focused on extractive": 0.1,
    "on extractive methods": 1.0,
    "extractive methods ,": 0.5,
    "methods , and": 0.25,
    ", and this": 0.005291005291005291,
    "and this is": 1.0,
    "this is what": 0.038461538461538464,
    "is what we": 0.5,
    "what we will": 0.3333333333333333,
    "we will cover": 0.25,
    "will cover .": 1.0,
    "<s> two particular": 0.14285714285714285,
    "two particular types": 1.0,
    "particular types of": 1.0,
    "types of summarization": 0.07142857142857142,
    "of summarization often": 0.125,
    "summarization often addressed": 1.0,
    "often addressed in": 1.0,
    "addressed in the": 1.0,
    "in the literature": 0.006535947712418301,
    "the literature are": 1.0,
    "literature are keyphrase": 1.0,
    "are keyphrase extraction": 1.0,
    "keyphrase extraction ,": 0.26666666666666666,
    "extraction , where": 0.16666666666666666,
    ", where the": 0.3333333333333333,
    "where the goal": 0.15384615384615385,
    "the goal is": 0.6,
    "goal is to": 1.0,
    "is to select": 0.10526315789473684,
    "to select individual": 0.25,
    "select individual words": 1.0,
    "individual words or": 1.0,
    "words or phrases": 0.2857142857142857,
    "or phrases to": 0.5,
    "phrases to ``": 1.0,
    "to `` tag": 0.25,
    "`` tag ''": 0.5,
    "tag '' a": 1.0,
    "'' a document": 0.3333333333333333,
    "a document ,": 0.25,
    "document , and": 0.2,
    ", and document": 0.005291005291005291,
    "and document summarization": 0.5,
    "document summarization ,": 0.3333333333333333,
    "summarization , where": 0.25,
    "to select whole": 0.25,
    "select whole sentences": 1.0,
    "whole sentences to": 0.5,
    "sentences to create": 0.16666666666666666,
    "create a short": 0.14285714285714285,
    "a short paragraph": 0.2,
    "short paragraph summary": 1.0,
    "paragraph summary .": 1.0,
    "<s> extraction and": 0.5,
    "extraction and abstraction": 0.6666666666666666,
    "and abstraction broadly": 0.5,
    "abstraction broadly ,": 1.0,
    "broadly , one": 1.0,
    ", one distinguishes": 0.16666666666666666,
    "one distinguishes two": 1.0,
    "distinguishes two approaches": 1.0,
    "two approaches :": 1.0,
    "approaches : extraction": 0.25,
    ": extraction and": 1.0,
    "and abstraction .": 0.5,
    "<s> extraction techniques": 0.5,
    "extraction techniques merely": 1.0,
    "techniques merely copy": 1.0,
    "merely copy the": 1.0,
    "copy the information": 1.0,
    "the information deemed": 0.16666666666666666,
    "information deemed most": 1.0,
    "deemed most important": 1.0,
    "most important by": 0.5,
    "important by the": 1.0,
    "by the system": 0.03571428571428571,
    "the system to": 0.07692307692307693,
    "system to the": 0.2,
    "to the summary": 0.012987012987012988,
    "the summary -lrb-": 0.125,
    "summary -lrb- for": 1.0,
    "example , key": 0.018518518518518517,
    ", key clauses": 1.0,
    "key clauses ,": 1.0,
    "clauses , sentences": 1.0,
    ", sentences or": 0.5,
    "sentences or paragraphs": 1.0,
    "or paragraphs -rrb-": 0.5,
    "paragraphs -rrb- ,": 1.0,
    "-rrb- , while": 0.02564102564102564,
    ", while abstraction": 0.07142857142857142,
    "while abstraction involves": 1.0,
    "abstraction involves paraphrasing": 1.0,
    "involves paraphrasing sections": 1.0,
    "paraphrasing sections of": 1.0,
    "sections of the": 0.5,
    "the source document": 0.08333333333333333,
    "source document .": 0.5,
    "<s> in general": 0.030927835051546393,
    "in general ,": 0.75,
    "general , abstraction": 0.16666666666666666,
    ", abstraction can": 1.0,
    "abstraction can condense": 1.0,
    "can condense a": 1.0,
    "condense a text": 1.0,
    "a text more": 0.07142857142857142,
    "text more strongly": 1.0,
    "more strongly than": 1.0,
    "strongly than extraction": 1.0,
    "than extraction ,": 1.0,
    "extraction , but": 0.16666666666666666,
    ", but the": 0.041666666666666664,
    "but the programs": 0.25,
    "the programs that": 1.0,
    "programs that can": 1.0,
    "that can do": 0.07692307692307693,
    "can do this": 0.5,
    "do this are": 0.5,
    "this are harder": 0.5,
    "are harder to": 1.0,
    "harder to develop": 0.5,
    "to develop as": 0.2,
    "develop as they": 1.0,
    "as they require": 0.3333333333333333,
    "they require the": 0.5,
    "require the use": 0.75,
    "use of natural": 0.045454545454545456,
    "language generation technology": 0.16666666666666666,
    "generation technology ,": 1.0,
    "technology , which": 0.3333333333333333,
    ", which itself": 0.017857142857142856,
    "which itself is": 1.0,
    "itself is a": 1.0,
    "is a growing": 0.018518518518518517,
    "a growing field": 1.0,
    "growing field .": 0.5,
    "<s> types of": 1.0,
    "types of summaries": 0.14285714285714285,
    "of summaries there": 0.25,
    "summaries there are": 1.0,
    "there are different": 0.047619047619047616,
    "are different types": 1.0,
    "of summaries depending": 0.25,
    "summaries depending what": 0.5,
    "depending what the": 1.0,
    "what the summarization": 0.25,
    "the summarization program": 0.3333333333333333,
    "summarization program focuses": 1.0,
    "program focuses on": 1.0,
    "focuses on to": 0.5,
    "on to make": 0.5,
    "to make the": 0.25,
    "make the summary": 1.0,
    "the summary of": 0.125,
    "summary of the": 0.3333333333333333,
    "text , for": 0.03333333333333333,
    "for example generic": 0.017857142857142856,
    "example generic summaries": 1.0,
    "generic summaries or": 1.0,
    "summaries or query": 1.0,
    "or query relevant": 1.0,
    "query relevant summaries": 0.5,
    "relevant summaries -lrb-": 1.0,
    "summaries -lrb- sometimes": 0.5,
    "-lrb- sometimes called": 1.0,
    "sometimes called query-biased": 1.0,
    "called query-biased summaries": 1.0,
    "query-biased summaries -rrb-": 1.0,
    "summaries -rrb- .": 1.0,
    "<s> summarization systems": 0.5,
    "summarization systems are": 0.5,
    "able to create": 0.0625,
    "to create both": 0.1111111111111111,
    "create both query": 1.0,
    "both query relevant": 1.0,
    "query relevant text": 0.5,
    "relevant text summaries": 1.0,
    "text summaries and": 1.0,
    "summaries and generic": 0.5,
    "and generic machine-generated": 1.0,
    "generic machine-generated summaries": 1.0,
    "machine-generated summaries depending": 1.0,
    "summaries depending on": 0.5,
    "depending on what": 0.25,
    "on what the": 0.3333333333333333,
    "what the user": 0.25,
    "the user needs": 0.16666666666666666,
    "user needs .": 1.0,
    "<s> summarization of": 0.5,
    "summarization of multimedia": 1.0,
    "of multimedia documents": 1.0,
    "multimedia documents ,": 1.0,
    "documents , e.g.": 0.1111111111111111,
    ", e.g. pictures": 0.1,
    "e.g. pictures or": 1.0,
    "pictures or movies": 1.0,
    "or movies ,": 1.0,
    "movies , is": 1.0,
    ", is also": 0.07692307692307693,
    "is also possible": 0.1,
    "also possible .": 0.3333333333333333,
    "<s> some systems": 0.125,
    "some systems will": 0.25,
    "systems will generate": 1.0,
    "will generate a": 1.0,
    "generate a summary": 0.16666666666666666,
    "a summary based": 0.1111111111111111,
    "summary based on": 1.0,
    "on a single": 0.08333333333333333,
    "a single source": 0.1111111111111111,
    "single source document": 0.5,
    "source document ,": 0.5,
    "document , while": 0.2,
    "while others can": 0.25,
    "others can use": 1.0,
    "can use multiple": 0.3333333333333333,
    "use multiple source": 1.0,
    "multiple source documents": 1.0,
    "source documents -lrb-": 0.3333333333333333,
    "documents -lrb- for": 0.2,
    "example , a": 0.09259259259259259,
    ", a cluster": 0.020833333333333332,
    "a cluster of": 1.0,
    "cluster of news": 1.0,
    "of news stories": 0.5,
    "news stories on": 1.0,
    "stories on the": 1.0,
    "the same topic": 0.041666666666666664,
    "same topic -rrb-": 1.0,
    "topic -rrb- .": 1.0,
    "these systems are": 0.1111111111111111,
    "systems are known": 0.07692307692307693,
    "are known as": 0.3333333333333333,
    "known as multi-document": 0.1,
    "as multi-document summarization": 1.0,
    "multi-document summarization systems": 0.3333333333333333,
    "summarization systems .": 0.3333333333333333,
    "<s> keyphrase extraction": 0.6666666666666666,
    "keyphrase extraction task": 0.06666666666666667,
    "extraction task description": 0.5,
    "task description and": 1.0,
    "description and example": 1.0,
    "and example the": 1.0,
    "example the task": 0.5,
    "the task is": 0.18181818181818182,
    "task is the": 0.16666666666666666,
    "is the following": 0.044444444444444446,
    "the following .": 0.18181818181818182,
    "<s> you are": 1.0,
    "you are given": 1.0,
    "are given a": 0.3333333333333333,
    "given a piece": 0.07142857142857142,
    "a piece of": 1.0,
    "piece of text": 0.6666666666666666,
    "text , such": 0.03333333333333333,
    "such as a": 0.03333333333333333,
    "as a journal": 0.027777777777777776,
    "a journal article": 1.0,
    "journal article ,": 1.0,
    "article , and": 0.3333333333333333,
    ", and you": 0.015873015873015872,
    "and you must": 0.3333333333333333,
    "you must produce": 1.0,
    "must produce a": 1.0,
    "produce a list": 0.25,
    "list of keywords": 0.1,
    "of keywords or": 1.0,
    "keywords or keyphrases": 1.0,
    "or keyphrases that": 1.0,
    "keyphrases that capture": 0.3333333333333333,
    "that capture the": 1.0,
    "capture the primary": 1.0,
    "the primary topics": 0.5,
    "primary topics discussed": 1.0,
    "topics discussed in": 1.0,
    "discussed in the": 1.0,
    "in the case": 0.032679738562091505,
    "the case of": 0.625,
    "case of research": 0.16666666666666666,
    "of research articles": 0.125,
    "research articles ,": 1.0,
    "articles , many": 1.0,
    ", many authors": 0.14285714285714285,
    "many authors provide": 1.0,
    "authors provide manually": 1.0,
    "provide manually assigned": 1.0,
    "manually assigned keywords": 1.0,
    "assigned keywords ,": 1.0,
    "keywords , but": 1.0,
    ", but most": 0.020833333333333332,
    "but most text": 0.5,
    "most text lacks": 1.0,
    "text lacks pre-existing": 1.0,
    "lacks pre-existing keyphrases": 1.0,
    "pre-existing keyphrases .": 1.0,
    "example , news": 0.018518518518518517,
    ", news articles": 1.0,
    "news articles rarely": 0.3333333333333333,
    "articles rarely have": 1.0,
    "rarely have keyphrases": 1.0,
    "have keyphrases attached": 0.5,
    "keyphrases attached ,": 1.0,
    "attached , but": 1.0,
    "but it would": 0.25,
    "it would be": 0.5,
    "would be useful": 0.1111111111111111,
    "be useful to": 0.6666666666666666,
    "useful to be": 0.5,
    "to be able": 0.06976744186046512,
    "able to automatically": 0.0625,
    "to automatically do": 0.16666666666666666,
    "automatically do so": 1.0,
    "do so for": 1.0,
    "so for a": 1.0,
    "number of applications": 0.027777777777777776,
    "of applications discussed": 0.3333333333333333,
    "applications discussed below": 1.0,
    "discussed below .": 0.6666666666666666,
    "consider the example": 0.25,
    "the example text": 0.3333333333333333,
    "example text from": 1.0,
    "text from a": 0.5,
    "from a recent": 0.08333333333333333,
    "a recent news": 1.0,
    "recent news article": 1.0,
    "news article :": 0.5,
    "article : ``": 0.07692307692307693,
    ": `` the": 0.5,
    "`` the army": 0.125,
    "the army corps": 1.0,
    "army corps of": 1.0,
    "corps of engineers": 1.0,
    "of engineers ,": 0.5,
    "engineers , rushing": 1.0,
    ", rushing to": 1.0,
    "rushing to meet": 1.0,
    "to meet president": 0.25,
    "meet president bush": 1.0,
    "president bush 's": 0.5,
    "bush 's promise": 1.0,
    "'s promise to": 1.0,
    "promise to protect": 1.0,
    "to protect new": 1.0,
    "protect new orleans": 1.0,
    "new orleans by": 0.5,
    "orleans by the": 1.0,
    "by the start": 0.03571428571428571,
    "the start of": 0.5,
    "start of the": 0.5,
    "of the 2006": 0.005128205128205128,
    "the 2006 hurricane": 1.0,
    "2006 hurricane season": 1.0,
    "hurricane season ,": 1.0,
    "season , installed": 1.0,
    ", installed defective": 1.0,
    "installed defective flood-control": 1.0,
    "defective flood-control pumps": 1.0,
    "flood-control pumps last": 0.5,
    "pumps last year": 1.0,
    "last year despite": 1.0,
    "year despite warnings": 1.0,
    "despite warnings from": 1.0,
    "warnings from its": 1.0,
    "from its own": 1.0,
    "its own expert": 0.2,
    "own expert that": 1.0,
    "expert that the": 1.0,
    "that the equipment": 0.043478260869565216,
    "the equipment would": 1.0,
    "equipment would fail": 1.0,
    "would fail during": 1.0,
    "fail during a": 1.0,
    "during a storm": 0.5,
    "a storm ,": 1.0,
    "storm , according": 1.0,
    ", according to": 1.0,
    "according to documents": 0.16666666666666666,
    "to documents obtained": 1.0,
    "documents obtained by": 1.0,
    "obtained by the": 0.25,
    "by the associated": 0.03571428571428571,
    "the associated press": 1.0,
    "associated press ''": 1.0,
    "press '' .": 1.0,
    "<s> an extractive": 0.09090909090909091,
    "an extractive keyphrase": 0.5,
    "extractive keyphrase extractor": 1.0,
    "keyphrase extractor might": 1.0,
    "extractor might select": 1.0,
    "might select ``": 1.0,
    "select `` army": 1.0,
    "`` army corps": 1.0,
    "of engineers ''": 0.5,
    "engineers '' ,": 1.0,
    ", `` president": 0.04,
    "`` president bush": 1.0,
    "president bush ''": 0.5,
    "bush '' ,": 1.0,
    ", `` new": 0.04,
    "`` new orleans": 1.0,
    "new orleans ''": 0.5,
    "orleans '' ,": 1.0,
    "'' , and": 0.16666666666666666,
    ", and ``": 0.026455026455026454,
    "and `` defective": 0.05,
    "`` defective flood-control": 1.0,
    "flood-control pumps ''": 0.5,
    "pumps '' as": 1.0,
    "'' as keyphrases": 0.2,
    "as keyphrases .": 1.0,
    "<s> these are": 0.125,
    "these are pulled": 0.25,
    "are pulled directly": 1.0,
    "pulled directly from": 1.0,
    "directly from the": 1.0,
    "from the text": 0.045454545454545456,
    "contrast , an": 0.2,
    ", an abstractive": 0.1,
    "an abstractive keyphrase": 0.5,
    "abstractive keyphrase system": 1.0,
    "keyphrase system would": 1.0,
    "system would somehow": 0.5,
    "would somehow internalize": 1.0,
    "somehow internalize the": 1.0,
    "internalize the content": 1.0,
    "the content and": 0.3333333333333333,
    "content and generate": 0.5,
    "and generate keyphrases": 1.0,
    "generate keyphrases that": 1.0,
    "keyphrases that might": 0.3333333333333333,
    "that might be": 0.5,
    "might be more": 0.16666666666666666,
    "be more descriptive": 0.2,
    "more descriptive and": 1.0,
    "descriptive and more": 1.0,
    "and more like": 0.2,
    "more like what": 1.0,
    "like what a": 1.0,
    "a human would": 0.09090909090909091,
    "human would produce": 1.0,
    "would produce ,": 0.5,
    "produce , such": 1.0,
    "as `` political": 0.07142857142857142,
    "`` political negligence": 1.0,
    "political negligence ''": 1.0,
    "negligence '' or": 1.0,
    "'' or ``": 0.8,
    "or `` inadequate": 0.25,
    "`` inadequate protection": 1.0,
    "inadequate protection from": 1.0,
    "protection from floods": 1.0,
    "from floods ''": 1.0,
    "floods '' .": 1.0,
    "note that these": 0.14285714285714285,
    "that these terms": 0.3333333333333333,
    "these terms do": 1.0,
    "terms do not": 1.0,
    "do not appear": 0.07692307692307693,
    "not appear in": 1.0,
    "the text and": 0.038461538461538464,
    "text and require": 0.3333333333333333,
    "and require a": 0.3333333333333333,
    "require a deep": 0.2,
    "a deep understanding": 1.0,
    "deep understanding ,": 1.0,
    "understanding , which": 0.3333333333333333,
    ", which makes": 0.017857142857142856,
    "which makes it": 0.6666666666666666,
    "makes it difficult": 0.5,
    "it difficult for": 0.5,
    "difficult for a": 1.0,
    "for a computer": 0.06451612903225806,
    "a computer to": 0.125,
    "computer to produce": 0.5,
    "to produce such": 0.1,
    "produce such keyphrases": 1.0,
    "such keyphrases .": 1.0,
    "<s> keyphrases have": 1.0,
    "keyphrases have many": 1.0,
    "have many applications": 0.2,
    "many applications ,": 0.5,
    "applications , such": 0.25,
    "such as to": 0.011111111111111112,
    "as to improve": 0.25,
    "to improve document": 0.1111111111111111,
    "improve document browsing": 1.0,
    "document browsing by": 1.0,
    "browsing by providing": 1.0,
    "by providing a": 1.0,
    "providing a short": 1.0,
    "a short summary": 0.2,
    "short summary .": 1.0,
    "<s> also ,": 1.0,
    "also , keyphrases": 0.3333333333333333,
    ", keyphrases can": 1.0,
    "keyphrases can improve": 0.5,
    "can improve information": 1.0,
    "improve information retrieval": 1.0,
    "information retrieval --": 0.16666666666666666,
    "retrieval -- if": 1.0,
    "-- if documents": 0.5,
    "if documents have": 1.0,
    "documents have keyphrases": 1.0,
    "have keyphrases assigned": 0.5,
    "keyphrases assigned ,": 1.0,
    "assigned , a": 1.0,
    ", a user": 0.020833333333333332,
    "a user could": 0.5,
    "user could search": 1.0,
    "could search by": 1.0,
    "search by keyphrase": 1.0,
    "by keyphrase to": 1.0,
    "keyphrase to produce": 1.0,
    "to produce more": 0.1,
    "more reliable hits": 0.3333333333333333,
    "reliable hits than": 1.0,
    "hits than a": 1.0,
    "than a full-text": 0.2,
    "a full-text search": 1.0,
    "full-text search .": 1.0,
    "also , automatic": 0.3333333333333333,
    ", automatic keyphrase": 0.3333333333333333,
    "automatic keyphrase extraction": 1.0,
    "keyphrase extraction can": 0.06666666666666667,
    "extraction can be": 1.0,
    "can be useful": 0.02197802197802198,
    "be useful in": 0.3333333333333333,
    "useful in generating": 0.5,
    "in generating index": 1.0,
    "generating index entries": 1.0,
    "index entries for": 1.0,
    "entries for a": 1.0,
    "for a large": 0.03225806451612903,
    "a large text": 0.1111111111111111,
    "large text corpus": 1.0,
    "text corpus .": 0.5,
    "keyphrase extraction as": 0.13333333333333333,
    "extraction as supervised": 0.5,
    "as supervised learning": 1.0,
    "supervised learning beginning": 0.2,
    "learning beginning with": 1.0,
    "beginning with the": 1.0,
    "with the turney": 0.03333333333333333,
    "the turney paper": 1.0,
    "turney paper ,": 0.5,
    "paper , many": 1.0,
    ", many researchers": 0.14285714285714285,
    "many researchers have": 1.0,
    "researchers have approached": 0.3333333333333333,
    "have approached keyphrase": 1.0,
    "approached keyphrase extraction": 1.0,
    "extraction as a": 0.5,
    "as a supervised": 0.027777777777777776,
    "a supervised machine": 0.5,
    "supervised machine learning": 1.0,
    "machine learning problem": 0.047619047619047616,
    "learning problem .": 1.0,
    "<s> given a": 0.3333333333333333,
    "given a document": 0.07142857142857142,
    "document , we": 0.2,
    ", we construct": 0.058823529411764705,
    "we construct an": 1.0,
    "construct an example": 1.0,
    "an example for": 0.25,
    "example for each": 0.5,
    "for each unigram": 0.2857142857142857,
    "each unigram ,": 1.0,
    "unigram , bigram": 1.0,
    ", bigram ,": 1.0,
    "bigram , and": 0.3333333333333333,
    ", and trigram": 0.005291005291005291,
    "and trigram found": 1.0,
    "trigram found in": 1.0,
    "found in the": 0.3333333333333333,
    "the text -lrb-": 0.038461538461538464,
    "text -lrb- though": 0.16666666666666666,
    "-lrb- though other": 1.0,
    "though other text": 1.0,
    "other text units": 0.5,
    "text units are": 0.3333333333333333,
    "units are also": 0.5,
    "are also possible": 0.125,
    "also possible ,": 0.3333333333333333,
    ", as discussed": 0.043478260869565216,
    "as discussed below": 1.0,
    "discussed below -rrb-": 0.3333333333333333,
    "<s> we then": 0.14285714285714285,
    "we then compute": 1.0,
    "then compute various": 1.0,
    "compute various features": 1.0,
    "various features describing": 1.0,
    "features describing each": 1.0,
    "describing each example": 1.0,
    "each example -lrb-": 0.5,
    "example -lrb- e.g.": 1.0,
    "e.g. , does": 0.038461538461538464,
    ", does the": 0.5,
    "does the phrase": 1.0,
    "the phrase begin": 0.25,
    "phrase begin with": 1.0,
    "begin with an": 0.5,
    "with an upper-case": 0.2,
    "an upper-case letter": 1.0,
    "upper-case letter ?": 1.0,
    "letter ? -rrb-": 1.0,
    "? -rrb- .": 1.0,
    "<s> we assume": 0.14285714285714285,
    "we assume there": 1.0,
    "assume there are": 1.0,
    "there are known": 0.047619047619047616,
    "are known keyphrases": 0.3333333333333333,
    "known keyphrases available": 0.25,
    "keyphrases available for": 1.0,
    "available for a": 0.5,
    "for a set": 0.03225806451612903,
    "set of training": 0.03571428571428571,
    "of training documents": 0.25,
    "training documents .": 0.3333333333333333,
    "<s> using the": 0.5,
    "using the known": 0.14285714285714285,
    "the known keyphrases": 0.4,
    "known keyphrases ,": 0.25,
    "keyphrases , we": 0.5,
    ", we can": 0.11764705882352941,
    "we can assign": 0.2,
    "can assign positive": 1.0,
    "assign positive or": 1.0,
    "positive or negative": 1.0,
    "or negative labels": 0.5,
    "negative labels to": 1.0,
    "labels to the": 0.5,
    "to the examples": 0.012987012987012988,
    "the examples .": 0.25,
    "<s> then we": 0.2,
    "then we learn": 0.3333333333333333,
    "we learn a": 1.0,
    "learn a classifier": 0.3333333333333333,
    "a classifier that": 1.0,
    "classifier that can": 1.0,
    "that can discriminate": 0.07692307692307693,
    "can discriminate between": 1.0,
    "discriminate between positive": 1.0,
    "between positive and": 1.0,
    "positive and negative": 1.0,
    "and negative examples": 0.5,
    "negative examples as": 1.0,
    "examples as a": 1.0,
    "as a function": 0.027777777777777776,
    "a function of": 1.0,
    "function of the": 1.0,
    "of the features": 0.005128205128205128,
    "the features .": 0.16666666666666666,
    "<s> some classifiers": 0.0625,
    "some classifiers make": 1.0,
    "classifiers make a": 1.0,
    "make a binary": 0.25,
    "a binary classification": 0.5,
    "binary classification for": 0.5,
    "classification for a": 0.5,
    "for a test": 0.06451612903225806,
    "a test example": 0.3333333333333333,
    "test example ,": 1.0,
    "example , while": 0.018518518518518517,
    "while others assign": 0.25,
    "others assign a": 1.0,
    "assign a probability": 0.5,
    "a probability of": 1.0,
    "probability of being": 1.0,
    "of being a": 1.0,
    "being a keyphrase": 0.5,
    "a keyphrase .": 0.5,
    "instance , in": 0.2222222222222222,
    "in the above": 0.006535947712418301,
    "the above text": 0.5,
    "above text ,": 1.0,
    "text , we": 0.03333333333333333,
    ", we might": 0.058823529411764705,
    "we might learn": 1.0,
    "might learn a": 1.0,
    "learn a rule": 0.3333333333333333,
    "a rule that": 1.0,
    "rule that says": 1.0,
    "that says phrases": 1.0,
    "says phrases with": 1.0,
    "phrases with initial": 1.0,
    "with initial capital": 1.0,
    "initial capital letters": 1.0,
    "capital letters are": 1.0,
    "letters are likely": 1.0,
    "are likely to": 0.75,
    "likely to be": 0.5714285714285714,
    "to be keyphrases": 0.023255813953488372,
    "be keyphrases .": 1.0,
    "<s> after training": 0.3333333333333333,
    "after training a": 1.0,
    "training a learner": 1.0,
    "a learner ,": 1.0,
    "learner , we": 1.0,
    "we can select": 0.2,
    "can select keyphrases": 1.0,
    "select keyphrases for": 1.0,
    "keyphrases for test": 0.5,
    "for test documents": 1.0,
    "test documents in": 0.5,
    "documents in the": 1.0,
    "in the following": 0.0196078431372549,
    "the following manner": 0.09090909090909091,
    "following manner .": 1.0,
    "<s> we apply": 0.14285714285714285,
    "we apply the": 1.0,
    "apply the same": 1.0,
    "the same example-generation": 0.041666666666666664,
    "same example-generation strategy": 1.0,
    "example-generation strategy to": 1.0,
    "strategy to the": 0.3333333333333333,
    "to the test": 0.025974025974025976,
    "the test documents": 0.5,
    "test documents ,": 0.5,
    "documents , then": 0.1111111111111111,
    ", then run": 0.09090909090909091,
    "then run each": 1.0,
    "run each example": 1.0,
    "each example through": 0.5,
    "example through the": 1.0,
    "through the learner": 0.25,
    "the learner .": 1.0,
    "<s> we can": 0.2857142857142857,
    "we can determine": 0.2,
    "can determine the": 0.5,
    "determine the keyphrases": 0.1,
    "the keyphrases by": 0.5,
    "keyphrases by looking": 1.0,
    "by looking at": 1.0,
    "looking at binary": 1.0,
    "at binary classification": 1.0,
    "binary classification decisions": 0.5,
    "classification decisions or": 1.0,
    "decisions or probabilities": 1.0,
    "or probabilities returned": 1.0,
    "probabilities returned from": 1.0,
    "returned from our": 0.5,
    "from our learned": 1.0,
    "our learned model": 1.0,
    "learned model .": 1.0,
    "<s> if probabilities": 0.125,
    "if probabilities are": 1.0,
    "probabilities are given": 1.0,
    "are given ,": 0.3333333333333333,
    "given , a": 1.0,
    ", a threshold": 0.020833333333333332,
    "a threshold is": 0.3333333333333333,
    "threshold is used": 1.0,
    "used to select": 0.045454545454545456,
    "select the keyphrases": 0.5,
    "the keyphrases .": 0.5,
    "<s> keyphrase extractors": 0.3333333333333333,
    "keyphrase extractors are": 1.0,
    "extractors are generally": 1.0,
    "are generally evaluated": 0.25,
    "generally evaluated using": 1.0,
    "evaluated using precision": 1.0,
    "using precision and": 1.0,
    "precision and recall": 1.0,
    "and recall .": 1.0,
    "<s> precision measures": 1.0,
    "precision measures how": 1.0,
    "measures how many": 1.0,
    "how many of": 0.5,
    "of the proposed": 0.005128205128205128,
    "the proposed keyphrases": 1.0,
    "proposed keyphrases are": 0.5,
    "keyphrases are actually": 0.5,
    "are actually correct": 1.0,
    "actually correct .": 1.0,
    "<s> recall measures": 0.3333333333333333,
    "recall measures how": 1.0,
    "of the true": 0.005128205128205128,
    "the true keyphrases": 1.0,
    "true keyphrases your": 1.0,
    "keyphrases your system": 1.0,
    "your system proposed": 1.0,
    "system proposed .": 1.0,
    "<s> the two": 0.013605442176870748,
    "the two measures": 0.14285714285714285,
    "two measures can": 1.0,
    "measures can be": 1.0,
    "can be combined": 0.01098901098901099,
    "be combined in": 1.0,
    "combined in an": 1.0,
    "in an f-score": 0.125,
    "an f-score ,": 1.0,
    "f-score , which": 1.0,
    "which is the": 0.23076923076923078,
    "is the harmonic": 0.022222222222222223,
    "the harmonic mean": 1.0,
    "harmonic mean of": 1.0,
    "mean of the": 1.0,
    "of the two": 0.005128205128205128,
    "the two -lrb-": 0.14285714285714285,
    "two -lrb- f": 1.0,
    "-lrb- f =": 1.0,
    "f = 2pr": 1.0,
    "= 2pr \\/": 1.0,
    "2pr \\/ -lrb-": 1.0,
    "\\/ -lrb- p": 1.0,
    "-lrb- p +": 1.0,
    "p + r": 1.0,
    "+ r -rrb-": 1.0,
    "r -rrb- -rrb-": 1.0,
    "-rrb- -rrb- .": 0.5,
    "<s> matches between": 1.0,
    "matches between the": 1.0,
    "between the proposed": 0.14285714285714285,
    "proposed keyphrases and": 0.5,
    "keyphrases and the": 1.0,
    "and the known": 0.024390243902439025,
    "known keyphrases can": 0.25,
    "keyphrases can be": 0.5,
    "can be checked": 0.01098901098901099,
    "be checked after": 1.0,
    "checked after stemming": 1.0,
    "after stemming or": 1.0,
    "stemming or applying": 1.0,
    "or applying some": 1.0,
    "applying some other": 1.0,
    "some other text": 0.14285714285714285,
    "other text normalization": 0.5,
    "text normalization .": 1.0,
    "<s> design choices": 1.0,
    "design choices designing": 0.3333333333333333,
    "choices designing a": 1.0,
    "designing a supervised": 1.0,
    "a supervised keyphrase": 0.5,
    "supervised keyphrase extraction": 1.0,
    "keyphrase extraction system": 0.06666666666666667,
    "extraction system involves": 0.5,
    "system involves deciding": 1.0,
    "involves deciding on": 1.0,
    "deciding on several": 1.0,
    "on several choices": 1.0,
    "several choices -lrb-": 1.0,
    "choices -lrb- some": 1.0,
    "-lrb- some of": 0.5,
    "of these apply": 0.09090909090909091,
    "these apply to": 1.0,
    "apply to unsupervised": 0.5,
    "to unsupervised ,": 0.5,
    "unsupervised , too": 1.0,
    ", too -rrb-": 1.0,
    "too -rrb- :": 1.0,
    "-rrb- : what": 0.1111111111111111,
    ": what are": 1.0,
    "what are the": 1.0,
    "are the examples": 0.09090909090909091,
    "the examples ?": 0.25,
    "the first choice": 0.045454545454545456,
    "first choice is": 1.0,
    "choice is exactly": 0.5,
    "is exactly how": 1.0,
    "exactly how to": 1.0,
    "how to generate": 0.2,
    "to generate examples": 0.16666666666666666,
    "generate examples .": 1.0,
    "<s> turney and": 1.0,
    "turney and others": 0.5,
    "and others have": 0.5,
    "others have used": 1.0,
    "have used all": 0.5,
    "used all possible": 1.0,
    "all possible unigrams": 0.3333333333333333,
    "possible unigrams ,": 1.0,
    "unigrams , bigrams": 0.6666666666666666,
    ", bigrams ,": 1.0,
    "bigrams , and": 1.0,
    ", and trigrams": 0.010582010582010581,
    "and trigrams without": 0.5,
    "trigrams without intervening": 1.0,
    "without intervening punctuation": 1.0,
    "intervening punctuation and": 1.0,
    "punctuation and after": 0.5,
    "and after removing": 0.3333333333333333,
    "after removing stopwords": 1.0,
    "removing stopwords .": 1.0,
    "<s> hulth showed": 0.3333333333333333,
    "hulth showed that": 1.0,
    "showed that you": 0.3333333333333333,
    "that you can": 1.0,
    "you can get": 0.5,
    "can get some": 1.0,
    "get some improvement": 1.0,
    "some improvement by": 1.0,
    "improvement by selecting": 1.0,
    "by selecting examples": 0.5,
    "selecting examples to": 1.0,
    "examples to be": 1.0,
    "to be sequences": 0.023255813953488372,
    "be sequences of": 1.0,
    "sequences of tokens": 0.3333333333333333,
    "of tokens that": 0.5,
    "tokens that match": 1.0,
    "that match certain": 1.0,
    "match certain patterns": 1.0,
    "certain patterns of": 1.0,
    "patterns of part-of-speech": 1.0,
    "of part-of-speech tags": 0.5,
    "part-of-speech tags .": 1.0,
    "<s> ideally ,": 1.0,
    "ideally , the": 0.5,
    ", the mechanism": 0.009523809523809525,
    "the mechanism for": 1.0,
    "mechanism for generating": 1.0,
    "for generating examples": 1.0,
    "generating examples produces": 1.0,
    "examples produces all": 1.0,
    "produces all the": 1.0,
    "all the known": 0.14285714285714285,
    "the known labeled": 0.2,
    "known labeled keyphrases": 1.0,
    "labeled keyphrases as": 1.0,
    "keyphrases as candidates": 1.0,
    "as candidates ,": 1.0,
    "candidates , though": 1.0,
    ", though this": 0.16666666666666666,
    "though this is": 1.0,
    "this is often": 0.038461538461538464,
    "often not the": 0.5,
    "not the case": 0.2,
    "the case .": 0.25,
    "example , if": 0.1111111111111111,
    ", if we": 0.2,
    "if we use": 0.5,
    "we use only": 1.0,
    "use only unigrams": 0.5,
    "only unigrams ,": 1.0,
    "and trigrams ,": 0.5,
    "trigrams , then": 1.0,
    ", then we": 0.18181818181818182,
    "then we will": 0.3333333333333333,
    "we will never": 0.25,
    "will never be": 1.0,
    "able to extract": 0.0625,
    "to extract a": 0.3333333333333333,
    "extract a known": 1.0,
    "a known keyphrase": 0.5,
    "known keyphrase containing": 1.0,
    "keyphrase containing four": 1.0,
    "containing four words": 1.0,
    "four words .": 1.0,
    "<s> thus ,": 0.9166666666666666,
    "thus , recall": 0.09090909090909091,
    ", recall may": 1.0,
    "recall may suffer": 1.0,
    "may suffer .": 1.0,
    "however , generating": 0.022727272727272728,
    ", generating too": 1.0,
    "generating too many": 1.0,
    "too many examples": 0.5,
    "many examples can": 1.0,
    "examples can also": 1.0,
    "can also lead": 0.125,
    "also lead to": 1.0,
    "lead to low": 0.5,
    "to low precision": 1.0,
    "low precision .": 1.0,
    "<s> what are": 0.5,
    "are the features": 0.09090909090909091,
    "the features ?": 0.16666666666666666,
    "<s> we also": 0.14285714285714285,
    "we also need": 1.0,
    "also need to": 1.0,
    "need to create": 0.1,
    "to create features": 0.1111111111111111,
    "create features that": 1.0,
    "features that describe": 0.5,
    "that describe the": 1.0,
    "describe the examples": 0.5,
    "examples and are": 0.25,
    "and are informative": 0.2,
    "are informative enough": 1.0,
    "informative enough to": 1.0,
    "enough to allow": 1.0,
    "to allow a": 0.3333333333333333,
    "allow a learning": 1.0,
    "a learning algorithm": 0.5,
    "learning algorithm to": 0.2,
    "algorithm to discriminate": 0.5,
    "to discriminate keyphrases": 0.5,
    "discriminate keyphrases from": 1.0,
    "keyphrases from non": 1.0,
    "from non -": 1.0,
    "non - keyphrases": 1.0,
    "- keyphrases .": 1.0,
    "<s> typically features": 1.0,
    "typically features involve": 1.0,
    "features involve various": 1.0,
    "involve various term": 1.0,
    "various term frequencies": 1.0,
    "term frequencies -lrb-": 1.0,
    "frequencies -lrb- how": 1.0,
    "-lrb- how many": 0.3333333333333333,
    "how many times": 0.25,
    "many times a": 1.0,
    "times a phrase": 1.0,
    "a phrase appears": 0.5,
    "phrase appears in": 1.0,
    "appears in the": 1.0,
    "in the current": 0.006535947712418301,
    "the current text": 0.5,
    "current text or": 1.0,
    "text or in": 0.3333333333333333,
    "or in a": 1.0,
    "in a larger": 0.019230769230769232,
    "a larger corpus": 0.25,
    "larger corpus -rrb-": 1.0,
    "corpus -rrb- ,": 0.42857142857142855,
    ", the length": 0.009523809523809525,
    "the length of": 1.0,
    "length of the": 1.0,
    "of the example": 0.005128205128205128,
    "the example ,": 0.3333333333333333,
    "example , relative": 0.018518518518518517,
    ", relative position": 1.0,
    "relative position of": 1.0,
    "position of the": 1.0,
    "of the first": 0.020512820512820513,
    "the first occurrence": 0.045454545454545456,
    "first occurrence ,": 1.0,
    "occurrence , various": 1.0,
    ", various boolean": 1.0,
    "various boolean syntactic": 1.0,
    "boolean syntactic features": 1.0,
    "syntactic features -lrb-": 1.0,
    "features -lrb- e.g.": 1.0,
    "e.g. , contains": 0.038461538461538464,
    ", contains all": 1.0,
    "contains all caps": 1.0,
    "all caps -rrb-": 1.0,
    "caps -rrb- ,": 1.0,
    "<s> the turney": 0.006802721088435374,
    "turney paper used": 0.5,
    "paper used about": 1.0,
    "used about 12": 1.0,
    "about 12 such": 1.0,
    "12 such features": 1.0,
    "such features .": 1.0,
    "<s> hulth uses": 0.3333333333333333,
    "hulth uses a": 1.0,
    "uses a reduced": 0.25,
    "a reduced set": 1.0,
    "reduced set of": 1.0,
    "set of features": 0.03571428571428571,
    "of features ,": 1.0,
    "features , which": 1.0,
    ", which were": 0.017857142857142856,
    "which were found": 0.5,
    "were found most": 0.5,
    "found most successful": 1.0,
    "most successful in": 0.5,
    "successful in the": 1.0,
    "in the kea": 0.006535947712418301,
    "the kea -lrb-": 1.0,
    "kea -lrb- keyphrase": 1.0,
    "-lrb- keyphrase extraction": 1.0,
    "keyphrase extraction algorithm": 0.13333333333333333,
    "extraction algorithm -rrb-": 0.5,
    "algorithm -rrb- work": 0.5,
    "-rrb- work derived": 1.0,
    "work derived from": 1.0,
    "derived from turney": 0.3333333333333333,
    "from turney 's": 1.0,
    "turney 's seminal": 0.25,
    "'s seminal paper": 1.0,
    "seminal paper .": 1.0,
    "<s> how many": 0.25,
    "how many keyphrases": 0.25,
    "many keyphrases to": 1.0,
    "keyphrases to return": 1.0,
    "to return ?": 0.5,
    "in the end": 0.006535947712418301,
    "the end ,": 0.5,
    "end , the": 1.0,
    ", the system": 0.0380952380952381,
    "the system will": 0.038461538461538464,
    "system will need": 1.0,
    "will need to": 1.0,
    "need to return": 0.1,
    "to return a": 0.5,
    "return a list": 1.0,
    "list of keyphrases": 0.1,
    "of keyphrases for": 0.3333333333333333,
    "keyphrases for a": 0.5,
    "a test document": 0.3333333333333333,
    "test document ,": 1.0,
    "document , so": 0.2,
    ", so we": 0.08333333333333333,
    "so we need": 1.0,
    "we need to": 0.5,
    "need to have": 0.2,
    "have a way": 0.07692307692307693,
    "a way to": 0.6,
    "way to limit": 0.1,
    "to limit the": 1.0,
    "limit the number": 0.5,
    "the number .": 0.14285714285714285,
    "<s> ensemble methods": 1.0,
    "ensemble methods -lrb-": 1.0,
    "methods -lrb- i.e.": 0.5,
    "-lrb- i.e. ,": 0.6363636363636364,
    "i.e. , using": 0.14285714285714285,
    ", using votes": 0.1,
    "using votes from": 1.0,
    "votes from several": 1.0,
    "from several classifiers": 1.0,
    "several classifiers -rrb-": 1.0,
    "classifiers -rrb- have": 1.0,
    "-rrb- have been": 0.5,
    "have been used": 0.11538461538461539,
    "been used to": 0.2,
    "used to produce": 0.045454545454545456,
    "to produce numeric": 0.1,
    "produce numeric scores": 1.0,
    "numeric scores that": 1.0,
    "scores that can": 1.0,
    "can be thresholded": 0.01098901098901099,
    "be thresholded to": 1.0,
    "thresholded to provide": 1.0,
    "to provide a": 0.25,
    "provide a user-provided": 0.5,
    "a user-provided number": 1.0,
    "user-provided number of": 1.0,
    "number of keyphrases": 0.05555555555555555,
    "of keyphrases .": 0.6666666666666666,
    "is the technique": 0.022222222222222223,
    "the technique used": 0.5,
    "technique used by": 1.0,
    "used by turney": 0.1111111111111111,
    "by turney with": 1.0,
    "turney with c4": 1.0,
    "with c4 .5": 1.0,
    "c4 .5 decision": 1.0,
    ".5 decision trees": 1.0,
    "decision trees .": 0.25,
    "<s> hulth used": 0.3333333333333333,
    "hulth used a": 1.0,
    "used a single": 0.3333333333333333,
    "a single binary": 0.1111111111111111,
    "single binary classifier": 1.0,
    "binary classifier so": 1.0,
    "classifier so the": 1.0,
    "so the learning": 0.14285714285714285,
    "the learning algorithm": 0.5,
    "learning algorithm implicitly": 0.2,
    "algorithm implicitly determines": 1.0,
    "implicitly determines the": 1.0,
    "determines the appropriate": 0.5,
    "the appropriate number": 0.3333333333333333,
    "appropriate number .": 1.0,
    "<s> what learning": 0.25,
    "what learning algorithm": 1.0,
    "learning algorithm ?": 0.2,
    "<s> once examples": 0.2,
    "once examples and": 1.0,
    "examples and features": 0.25,
    "and features are": 1.0,
    "features are created": 0.3333333333333333,
    "are created ,": 0.6666666666666666,
    "created , we": 0.5,
    ", we need": 0.11764705882352941,
    "we need a": 0.3333333333333333,
    "need a way": 0.5,
    "way to learn": 0.1,
    "to learn to": 0.16666666666666666,
    "learn to predict": 1.0,
    "to predict keyphrases": 0.5,
    "predict keyphrases .": 1.0,
    "<s> virtually any": 1.0,
    "virtually any supervised": 0.5,
    "any supervised learning": 1.0,
    "supervised learning algorithm": 0.2,
    "learning algorithm could": 0.2,
    "algorithm could be": 1.0,
    "could be used": 0.75,
    "be used ,": 0.10526315789473684,
    "used , such": 0.125,
    "trees , naive": 0.3333333333333333,
    ", naive bayes": 1.0,
    "naive bayes ,": 0.5,
    "bayes , and": 1.0,
    ", and rule": 0.005291005291005291,
    "and rule induction": 1.0,
    "rule induction .": 1.0,
    "case of turney": 0.16666666666666666,
    "of turney 's": 1.0,
    "turney 's genex": 0.25,
    "'s genex algorithm": 1.0,
    "genex algorithm ,": 1.0,
    "algorithm , a": 0.3333333333333333,
    ", a genetic": 0.020833333333333332,
    "a genetic algorithm": 1.0,
    "genetic algorithm is": 0.5,
    "algorithm is used": 0.2,
    "used to learn": 0.045454545454545456,
    "to learn parameters": 0.16666666666666666,
    "learn parameters for": 1.0,
    "parameters for a": 0.5,
    "for a domain-specific": 0.03225806451612903,
    "a domain-specific keyphrase": 1.0,
    "domain-specific keyphrase extraction": 1.0,
    "extraction algorithm .": 0.5,
    "<s> the extractor": 0.006802721088435374,
    "the extractor follows": 1.0,
    "extractor follows a": 1.0,
    "follows a series": 1.0,
    "series of heuristics": 0.14285714285714285,
    "of heuristics to": 1.0,
    "heuristics to identify": 1.0,
    "to identify keyphrases": 0.2,
    "identify keyphrases .": 1.0,
    "<s> the genetic": 0.006802721088435374,
    "the genetic algorithm": 1.0,
    "genetic algorithm optimizes": 0.5,
    "algorithm optimizes parameters": 1.0,
    "optimizes parameters for": 1.0,
    "parameters for these": 0.5,
    "for these heuristics": 1.0,
    "these heuristics with": 1.0,
    "heuristics with respect": 1.0,
    "respect to performance": 0.14285714285714285,
    "to performance on": 1.0,
    "performance on training": 1.0,
    "on training documents": 1.0,
    "training documents with": 0.3333333333333333,
    "documents with known": 1.0,
    "with known key": 0.5,
    "known key phrases": 1.0,
    "key phrases .": 1.0,
    "<s> unsupervised keyphrase": 0.4,
    "unsupervised keyphrase extraction": 1.0,
    "keyphrase extraction :": 0.06666666666666667,
    "extraction : textrank": 0.5,
    ": textrank while": 0.5,
    "textrank while supervised": 1.0,
    "while supervised methods": 1.0,
    "supervised methods have": 0.5,
    "methods have some": 0.5,
    "have some nice": 1.0,
    "some nice properties": 1.0,
    "nice properties ,": 1.0,
    "properties , like": 1.0,
    ", like being": 0.3333333333333333,
    "like being able": 1.0,
    "being able to": 1.0,
    "able to produce": 0.125,
    "to produce interpretable": 0.1,
    "produce interpretable rules": 1.0,
    "interpretable rules for": 1.0,
    "rules for what": 0.5,
    "for what features": 0.3333333333333333,
    "what features characterize": 1.0,
    "features characterize a": 1.0,
    "characterize a keyphrase": 1.0,
    "a keyphrase ,": 0.5,
    "keyphrase , they": 1.0,
    ", they also": 0.125,
    "they also require": 1.0,
    "also require a": 1.0,
    "require a large": 0.2,
    "a large amount": 0.1111111111111111,
    "large amount of": 1.0,
    "amount of training": 0.2,
    "training data .": 0.4,
    "<s> many documents": 0.09090909090909091,
    "many documents with": 1.0,
    "with known keyphrases": 0.5,
    "known keyphrases are": 0.25,
    "keyphrases are needed": 0.5,
    "are needed .": 1.0,
    "furthermore , training": 0.16666666666666666,
    ", training on": 1.0,
    "training on a": 1.0,
    "on a specific": 0.041666666666666664,
    "a specific domain": 0.4,
    "specific domain tends": 0.3333333333333333,
    "domain tends to": 1.0,
    "tends to customize": 1.0,
    "to customize the": 0.5,
    "customize the extraction": 1.0,
    "the extraction process": 0.25,
    "extraction process to": 1.0,
    "process to that": 0.25,
    "to that domain": 0.5,
    "that domain ,": 1.0,
    "domain , so": 0.3333333333333333,
    "so the resulting": 0.14285714285714285,
    "the resulting classifier": 0.5,
    "resulting classifier is": 1.0,
    "classifier is not": 1.0,
    "is not necessarily": 0.05263157894736842,
    "not necessarily portable": 0.5,
    "necessarily portable ,": 1.0,
    "portable , as": 1.0,
    ", as some": 0.043478260869565216,
    "as some of": 1.0,
    "some of turney": 0.058823529411764705,
    "turney 's results": 0.25,
    "'s results demonstrate": 1.0,
    "results demonstrate .": 1.0,
    "keyphrase extraction removes": 0.06666666666666667,
    "extraction removes the": 1.0,
    "removes the need": 1.0,
    "the need for": 0.6666666666666666,
    "need for training": 0.3333333333333333,
    "for training data": 0.3333333333333333,
    "<s> it approaches": 0.029411764705882353,
    "it approaches the": 1.0,
    "approaches the problem": 1.0,
    "the problem from": 0.08333333333333333,
    "problem from a": 1.0,
    "from a different": 0.08333333333333333,
    "a different angle": 0.2,
    "different angle .": 1.0,
    "<s> instead of": 1.0,
    "instead of trying": 0.14285714285714285,
    "of trying to": 1.0,
    "trying to learn": 0.2,
    "to learn explicit": 0.16666666666666666,
    "learn explicit features": 1.0,
    "explicit features that": 1.0,
    "features that characterize": 0.5,
    "that characterize keyphrases": 1.0,
    "characterize keyphrases ,": 1.0,
    "keyphrases , the": 0.5,
    ", the textrank": 0.009523809523809525,
    "the textrank algorithm": 0.5,
    "textrank algorithm exploits": 1.0,
    "algorithm exploits the": 1.0,
    "exploits the structure": 1.0,
    "structure of the": 0.25,
    "the text itself": 0.038461538461538464,
    "text itself to": 1.0,
    "itself to determine": 1.0,
    "to determine keyphrases": 0.09090909090909091,
    "determine keyphrases that": 1.0,
    "keyphrases that appear": 0.3333333333333333,
    "that appear ``": 0.25,
    "appear `` central": 1.0,
    "`` central ''": 1.0,
    "central '' to": 0.5,
    "'' to the": 0.3333333333333333,
    "to the text": 0.012987012987012988,
    "the same way": 0.041666666666666664,
    "same way that": 1.0,
    "way that pagerank": 0.3333333333333333,
    "that pagerank selects": 1.0,
    "pagerank selects important": 1.0,
    "selects important web": 1.0,
    "important web pages": 1.0,
    "web pages .": 0.3333333333333333,
    "<s> recall this": 0.3333333333333333,
    "recall this is": 1.0,
    "this is based": 0.038461538461538464,
    "on the notion": 0.029850746268656716,
    "the notion of": 0.75,
    "notion of ``": 0.6666666666666666,
    "of `` prestige": 0.125,
    "`` prestige ''": 1.0,
    "prestige '' or": 1.0,
    "or `` recommendation": 0.25,
    "`` recommendation ''": 1.0,
    "recommendation '' from": 0.5,
    "'' from social": 1.0,
    "from social networks": 1.0,
    "social networks .": 0.3333333333333333,
    "in this way": 0.06666666666666667,
    "this way ,": 0.3333333333333333,
    "way , textrank": 1.0,
    ", textrank does": 0.5,
    "textrank does not": 1.0,
    "does not rely": 0.2,
    "not rely on": 1.0,
    "rely on any": 0.16666666666666666,
    "on any previous": 0.25,
    "any previous training": 1.0,
    "previous training data": 1.0,
    "training data at": 0.1,
    "data at all": 1.0,
    "all , but": 0.3333333333333333,
    ", but rather": 0.041666666666666664,
    "but rather can": 0.5,
    "rather can be": 1.0,
    "can be run": 0.01098901098901099,
    "be run on": 1.0,
    "run on any": 1.0,
    "on any arbitrary": 0.25,
    "any arbitrary piece": 0.5,
    "arbitrary piece of": 1.0,
    ", and it": 0.021164021164021163,
    "and it can": 0.2,
    "it can produce": 0.16666666666666666,
    "can produce output": 1.0,
    "produce output simply": 0.5,
    "output simply based": 1.0,
    "simply based on": 1.0,
    "on the text": 0.014925373134328358,
    "the text 's": 0.038461538461538464,
    "text 's intrinsic": 1.0,
    "'s intrinsic properties": 1.0,
    "intrinsic properties .": 1.0,
    "<s> thus the": 0.08333333333333333,
    "thus the algorithm": 1.0,
    "the algorithm is": 1.0,
    "algorithm is easily": 0.2,
    "is easily portable": 1.0,
    "easily portable to": 0.5,
    "portable to new": 1.0,
    "to new domains": 0.25,
    "new domains and": 1.0,
    "domains and languages": 0.5,
    "and languages .": 1.0,
    "<s> textrank is": 0.3333333333333333,
    "textrank is a": 1.0,
    "a general purpose": 0.6666666666666666,
    "general purpose graph-based": 1.0,
    "purpose graph-based ranking": 1.0,
    "graph-based ranking algorithm": 1.0,
    "ranking algorithm for": 0.5,
    "algorithm for nlp": 0.5,
    "for nlp .": 1.0,
    "<s> essentially ,": 1.0,
    "essentially , it": 1.0,
    ", it runs": 0.041666666666666664,
    "it runs pagerank": 1.0,
    "runs pagerank on": 1.0,
    "pagerank on a": 1.0,
    "on a graph": 0.041666666666666664,
    "a graph specially": 0.3333333333333333,
    "graph specially designed": 1.0,
    "specially designed for": 1.0,
    "designed for a": 1.0,
    "for a particular": 0.03225806451612903,
    "a particular nlp": 0.25,
    "particular nlp task": 1.0,
    "nlp task .": 1.0,
    "<s> for keyphrase": 0.017543859649122806,
    "for keyphrase extraction": 1.0,
    "extraction , it": 0.16666666666666666,
    ", it builds": 0.041666666666666664,
    "it builds a": 1.0,
    "builds a graph": 1.0,
    "a graph using": 0.3333333333333333,
    "graph using some": 1.0,
    "using some set": 0.5,
    "some set of": 1.0,
    "set of text": 0.03571428571428571,
    "of text units": 0.041666666666666664,
    "text units as": 0.3333333333333333,
    "units as vertices": 1.0,
    "as vertices .": 1.0,
    "<s> edges are": 1.0,
    "edges are based": 0.3333333333333333,
    "are based on": 1.0,
    "based on some": 0.08695652173913043,
    "on some measure": 0.1111111111111111,
    "some measure of": 1.0,
    "measure of semantic": 0.5,
    "of semantic or": 0.2,
    "semantic or lexical": 1.0,
    "or lexical similarity": 0.5,
    "lexical similarity between": 1.0,
    "similarity between the": 0.5,
    "between the text": 0.14285714285714285,
    "the text unit": 0.038461538461538464,
    "text unit vertices": 1.0,
    "unit vertices .": 1.0,
    "<s> unlike pagerank": 1.0,
    "unlike pagerank ,": 1.0,
    "pagerank , the": 1.0,
    ", the edges": 0.009523809523809525,
    "the edges are": 0.3333333333333333,
    "edges are typically": 0.3333333333333333,
    "are typically undirected": 0.3333333333333333,
    "typically undirected and": 1.0,
    "undirected and can": 1.0,
    "can be weighted": 0.01098901098901099,
    "be weighted to": 1.0,
    "weighted to reflect": 1.0,
    "to reflect a": 1.0,
    "reflect a degree": 1.0,
    "a degree of": 1.0,
    "degree of similarity": 0.3333333333333333,
    "of similarity .": 1.0,
    "<s> once the": 0.2,
    "once the graph": 1.0,
    "the graph is": 0.3333333333333333,
    "graph is constructed": 0.6666666666666666,
    "is constructed ,": 0.5,
    "constructed , it": 1.0,
    "it is used": 0.02127659574468085,
    "used to form": 0.045454545454545456,
    "to form a": 0.25,
    "form a stochastic": 0.3333333333333333,
    "a stochastic matrix": 1.0,
    "stochastic matrix ,": 1.0,
    "matrix , combined": 1.0,
    ", combined with": 1.0,
    "combined with a": 1.0,
    "with a damping": 0.05,
    "a damping factor": 1.0,
    "damping factor -lrb-": 1.0,
    "factor -lrb- as": 1.0,
    "-lrb- as in": 0.5714285714285714,
    "as in the": 0.3333333333333333,
    "in the ``": 0.006535947712418301,
    "the `` random": 0.14285714285714285,
    "`` random surfer": 1.0,
    "random surfer model": 1.0,
    "surfer model ''": 1.0,
    "model '' -rrb-": 1.0,
    "'' -rrb- ,": 0.2857142857142857,
    "and the ranking": 0.024390243902439025,
    "the ranking over": 0.5,
    "ranking over vertices": 1.0,
    "over vertices is": 1.0,
    "vertices is obtained": 1.0,
    "is obtained by": 1.0,
    "obtained by finding": 0.25,
    "by finding the": 1.0,
    "finding the eigenvector": 0.5,
    "the eigenvector corresponding": 1.0,
    "eigenvector corresponding to": 1.0,
    "corresponding to eigenvalue": 0.5,
    "to eigenvalue 1": 1.0,
    "eigenvalue 1 -lrb-": 1.0,
    "1 -lrb- i.e.": 1.0,
    "i.e. , the": 0.42857142857142855,
    ", the stationary": 0.009523809523809525,
    "the stationary distribution": 1.0,
    "stationary distribution of": 0.5,
    "distribution of the": 1.0,
    "of the random": 0.005128205128205128,
    "the random walk": 1.0,
    "random walk on": 0.5,
    "walk on the": 0.5,
    "on the graph": 0.029850746268656716,
    "the graph -rrb-": 0.16666666666666666,
    "graph -rrb- .": 1.0,
    "design choices what": 0.6666666666666666,
    "choices what should": 0.5,
    "what should vertices": 1.0,
    "should vertices be": 1.0,
    "vertices be ?": 1.0,
    "<s> the vertices": 0.006802721088435374,
    "the vertices should": 0.5,
    "vertices should correspond": 1.0,
    "should correspond to": 1.0,
    "correspond to what": 0.5,
    "to what we": 0.25,
    "what we want": 0.3333333333333333,
    "we want to": 1.0,
    "want to rank": 0.2,
    "to rank .": 0.3333333333333333,
    "<s> potentially ,": 1.0,
    "potentially , we": 1.0,
    ", we could": 0.058823529411764705,
    "we could do": 1.0,
    "could do something": 1.0,
    "do something similar": 1.0,
    "something similar to": 1.0,
    "to the supervised": 0.012987012987012988,
    "the supervised methods": 1.0,
    "supervised methods and": 0.5,
    "methods and create": 1.0,
    "and create a": 1.0,
    "create a vertex": 0.14285714285714285,
    "a vertex for": 1.0,
    "vertex for each": 1.0,
    "bigram , trigram": 0.6666666666666666,
    ", trigram ,": 1.0,
    "trigram , etc.": 0.5,
    "however , to": 0.022727272727272728,
    ", to keep": 0.07692307692307693,
    "to keep the": 0.5,
    "keep the graph": 1.0,
    "the graph small": 0.16666666666666666,
    "graph small ,": 1.0,
    "small , the": 0.5,
    ", the authors": 0.009523809523809525,
    "the authors decide": 0.25,
    "authors decide to": 1.0,
    "decide to rank": 1.0,
    "to rank individual": 0.3333333333333333,
    "rank individual unigrams": 1.0,
    "individual unigrams in": 1.0,
    "unigrams in a": 0.3333333333333333,
    "in a first": 0.019230769230769232,
    "a first step": 0.3333333333333333,
    "first step ,": 0.5,
    "step , and": 0.5,
    "and then include": 0.14285714285714285,
    "then include a": 1.0,
    "include a second": 0.3333333333333333,
    "a second step": 0.25,
    "second step that": 0.5,
    "step that merges": 0.5,
    "that merges highly": 1.0,
    "merges highly ranked": 1.0,
    "highly ranked adjacent": 1.0,
    "ranked adjacent unigrams": 1.0,
    "adjacent unigrams to": 1.0,
    "unigrams to form": 1.0,
    "to form multi-word": 0.25,
    "form multi-word phrases": 1.0,
    "multi-word phrases .": 1.0,
    "<s> this has": 0.019230769230769232,
    "this has a": 1.0,
    "has a nice": 0.25,
    "a nice side": 0.5,
    "nice side effect": 1.0,
    "side effect of": 1.0,
    "effect of allowing": 1.0,
    "of allowing us": 1.0,
    "allowing us to": 1.0,
    "us to produce": 1.0,
    "to produce keyphrases": 0.1,
    "produce keyphrases of": 1.0,
    "keyphrases of arbitrary": 1.0,
    "of arbitrary length": 1.0,
    "arbitrary length .": 1.0,
    "if we rank": 0.5,
    "we rank unigrams": 1.0,
    "rank unigrams and": 1.0,
    "unigrams and find": 1.0,
    "and find that": 1.0,
    "find that ``": 1.0,
    "that `` advanced": 0.16666666666666666,
    "`` advanced ''": 1.0,
    "advanced '' ,": 1.0,
    ", `` natural": 0.08,
    "`` natural ''": 0.75,
    "natural '' ,": 0.3333333333333333,
    ", `` language": 0.04,
    "`` language ''": 1.0,
    "language '' ,": 0.5,
    "and `` processing": 0.1,
    "`` processing ''": 1.0,
    "processing '' all": 0.5,
    "'' all get": 1.0,
    "all get high": 1.0,
    "get high ranks": 1.0,
    "high ranks ,": 1.0,
    "ranks , then": 1.0,
    "then we would": 0.3333333333333333,
    "we would look": 0.3333333333333333,
    "would look at": 1.0,
    "look at the": 0.5,
    "at the original": 0.0625,
    "original text and": 0.16666666666666666,
    "text and see": 0.3333333333333333,
    "and see that": 1.0,
    "see that these": 1.0,
    "that these words": 0.3333333333333333,
    "these words appear": 0.5,
    "words appear consecutively": 1.0,
    "appear consecutively and": 1.0,
    "consecutively and create": 1.0,
    "create a final": 0.14285714285714285,
    "a final keyphrase": 1.0,
    "final keyphrase using": 1.0,
    "keyphrase using all": 1.0,
    "using all four": 1.0,
    "all four together": 1.0,
    "four together .": 1.0,
    "note that the": 0.14285714285714285,
    "that the unigrams": 0.043478260869565216,
    "the unigrams placed": 0.5,
    "unigrams placed in": 1.0,
    "placed in the": 0.6666666666666666,
    "in the graph": 0.013071895424836602,
    "the graph can": 0.16666666666666666,
    "graph can be": 1.0,
    "can be filtered": 0.03296703296703297,
    "be filtered by": 0.3333333333333333,
    "filtered by part": 1.0,
    "by part of": 1.0,
    "the authors found": 0.25,
    "authors found that": 1.0,
    "found that adjectives": 0.2,
    "that adjectives and": 1.0,
    "adjectives and nouns": 1.0,
    "and nouns were": 1.0,
    "nouns were the": 1.0,
    "were the best": 1.0,
    "the best to": 0.07142857142857142,
    "best to include": 0.5,
    "to include .": 0.14285714285714285,
    "thus , some": 0.09090909090909091,
    ", some linguistic": 0.1111111111111111,
    "some linguistic knowledge": 1.0,
    "linguistic knowledge comes": 1.0,
    "knowledge comes into": 1.0,
    "comes into play": 1.0,
    "into play in": 1.0,
    "play in this": 1.0,
    "in this step": 0.06666666666666667,
    "this step .": 1.0,
    "<s> how should": 0.25,
    "how should we": 1.0,
    "should we create": 1.0,
    "we create edges": 0.5,
    "create edges ?": 1.0,
    "edges are created": 0.3333333333333333,
    "are created based": 0.3333333333333333,
    "created based on": 1.0,
    "based on word": 0.021739130434782608,
    "on word co-occurrence": 1.0,
    "word co-occurrence in": 1.0,
    "co-occurrence in this": 1.0,
    "in this application": 0.06666666666666667,
    "this application of": 1.0,
    "application of textrank": 0.25,
    "of textrank .": 1.0,
    "<s> two vertices": 0.14285714285714285,
    "two vertices are": 1.0,
    "vertices are connected": 1.0,
    "are connected by": 1.0,
    "connected by an": 1.0,
    "by an edge": 0.5,
    "an edge if": 0.5,
    "edge if the": 1.0,
    "if the unigrams": 0.07142857142857142,
    "the unigrams appear": 0.5,
    "unigrams appear within": 1.0,
    "appear within a": 1.0,
    "within a window": 0.2,
    "a window of": 1.0,
    "window of size": 0.5,
    "of size n": 1.0,
    "size n in": 1.0,
    "n in the": 1.0,
    "<s> n is": 0.5,
    "n is typically": 1.0,
    "is typically around": 0.3333333333333333,
    "typically around 2": 1.0,
    "around 2 --": 1.0,
    "2 -- 10": 1.0,
    "-- 10 .": 1.0,
    "thus , ``": 0.09090909090909091,
    "natural '' and": 0.6666666666666666,
    "'' and ``": 0.6923076923076923,
    "and `` language": 0.05,
    "language '' might": 0.5,
    "'' might be": 0.5,
    "might be linked": 0.16666666666666666,
    "be linked in": 0.5,
    "linked in a": 1.0,
    "in a text": 0.07692307692307693,
    "a text about": 0.14285714285714285,
    "text about nlp": 0.5,
    "about nlp .": 1.0,
    "<s> `` natural": 0.2,
    "processing '' would": 0.5,
    "'' would also": 0.5,
    "would also be": 1.0,
    "also be linked": 0.14285714285714285,
    "be linked because": 0.5,
    "linked because they": 1.0,
    "because they would": 0.25,
    "they would both": 1.0,
    "would both appear": 1.0,
    "both appear in": 1.0,
    "the same string": 0.041666666666666664,
    "same string of": 1.0,
    "string of n": 0.25,
    "of n words": 1.0,
    "n words .": 1.0,
    "<s> these edges": 0.0625,
    "these edges build": 1.0,
    "edges build on": 1.0,
    "build on the": 1.0,
    "of `` text": 0.125,
    "`` text cohesion": 1.0,
    "text cohesion ''": 1.0,
    "cohesion '' and": 1.0,
    "'' and the": 0.07692307692307693,
    "and the idea": 0.024390243902439025,
    "the idea that": 0.5,
    "idea that words": 0.5,
    "that words that": 0.5,
    "words that appear": 1.0,
    "that appear near": 0.25,
    "appear near each": 1.0,
    "near each other": 1.0,
    "each other are": 0.16666666666666666,
    "other are likely": 1.0,
    "are likely related": 0.25,
    "likely related in": 1.0,
    "related in a": 1.0,
    "in a meaningful": 0.019230769230769232,
    "a meaningful way": 0.5,
    "meaningful way and": 1.0,
    "way and ``": 1.0,
    "and `` recommend": 0.05,
    "`` recommend ''": 1.0,
    "recommend '' each": 0.5,
    "'' each other": 1.0,
    "each other to": 0.16666666666666666,
    "other to the": 1.0,
    "to the reader": 0.025974025974025976,
    "the reader .": 0.3333333333333333,
    "<s> how are": 0.5,
    "how are the": 0.5,
    "are the final": 0.09090909090909091,
    "the final keyphrases": 0.2,
    "final keyphrases formed": 0.5,
    "keyphrases formed ?": 1.0,
    "<s> since this": 0.25,
    "since this method": 1.0,
    "this method simply": 1.0,
    "method simply ranks": 1.0,
    "simply ranks the": 1.0,
    "ranks the individual": 1.0,
    "the individual vertices": 0.5,
    "individual vertices ,": 1.0,
    "vertices , we": 1.0,
    "way to threshold": 0.1,
    "to threshold or": 1.0,
    "threshold or produce": 0.5,
    "or produce a": 1.0,
    "produce a limited": 0.25,
    "a limited number": 0.5,
    "<s> the technique": 0.006802721088435374,
    "the technique chosen": 0.5,
    "technique chosen is": 1.0,
    "chosen is to": 1.0,
    "is to set": 0.05263157894736842,
    "to set a": 0.6666666666666666,
    "set a count": 0.5,
    "a count t": 1.0,
    "count t to": 1.0,
    "t to be": 1.0,
    "be a user-specified": 0.07692307692307693,
    "a user-specified fraction": 1.0,
    "user-specified fraction of": 1.0,
    "fraction of the": 1.0,
    "of the total": 0.005128205128205128,
    "the total number": 1.0,
    "total number of": 1.0,
    "number of vertices": 0.027777777777777776,
    "of vertices in": 1.0,
    "vertices in the": 1.0,
    "the graph .": 0.16666666666666666,
    "<s> then the": 0.4,
    "then the top": 0.25,
    "the top t": 0.5,
    "top t vertices\\/unigrams": 0.5,
    "t vertices\\/unigrams are": 1.0,
    "vertices\\/unigrams are selected": 1.0,
    "are selected based": 1.0,
    "selected based on": 1.0,
    "based on their": 0.021739130434782608,
    "on their stationary": 0.5,
    "their stationary probabilities": 1.0,
    "stationary probabilities .": 1.0,
    "<s> a post": 0.022727272727272728,
    "a post -": 1.0,
    "post - processing": 1.0,
    "- processing step": 1.0,
    "processing step is": 1.0,
    "step is then": 1.0,
    "is then applied": 0.2,
    "then applied to": 0.5,
    "applied to merge": 0.09090909090909091,
    "to merge adjacent": 1.0,
    "merge adjacent instances": 1.0,
    "adjacent instances of": 1.0,
    "instances of these": 0.5,
    "of these t": 0.09090909090909091,
    "these t unigrams": 1.0,
    "t unigrams .": 0.5,
    "result , potentially": 0.3333333333333333,
    ", potentially more": 1.0,
    "potentially more or": 1.0,
    "more or less": 1.0,
    "or less than": 0.25,
    "less than t": 0.3333333333333333,
    "than t final": 1.0,
    "t final keyphrases": 1.0,
    "final keyphrases will": 0.5,
    "keyphrases will be": 1.0,
    "will be produced": 0.1111111111111111,
    "be produced ,": 1.0,
    "produced , but": 1.0,
    "but the number": 0.25,
    "the number should": 0.14285714285714285,
    "number should be": 1.0,
    "should be roughly": 0.1111111111111111,
    "be roughly proportional": 1.0,
    "roughly proportional to": 1.0,
    "proportional to the": 1.0,
    "to the length": 0.012987012987012988,
    "<s> why it": 0.5,
    "why it works": 1.0,
    "it works it": 1.0,
    "works it is": 1.0,
    "it is not": 0.02127659574468085,
    "is not initially": 0.05263157894736842,
    "not initially clear": 1.0,
    "initially clear why": 1.0,
    "clear why applying": 1.0,
    "why applying pagerank": 1.0,
    "applying pagerank to": 1.0,
    "pagerank to a": 0.5,
    "to a co-occurrence": 0.03571428571428571,
    "a co-occurrence graph": 1.0,
    "co-occurrence graph would": 0.5,
    "graph would produce": 1.0,
    "would produce useful": 0.5,
    "produce useful keyphrases": 1.0,
    "useful keyphrases .": 1.0,
    "<s> one way": 0.08333333333333333,
    "way to think": 0.1,
    "to think about": 1.0,
    "think about it": 1.0,
    "about it is": 1.0,
    "<s> a word": 0.022727272727272728,
    "a word that": 0.08333333333333333,
    "word that appears": 0.5,
    "that appears multiple": 1.0,
    "appears multiple times": 1.0,
    "multiple times throughout": 1.0,
    "times throughout a": 1.0,
    "throughout a text": 1.0,
    "a text may": 0.07142857142857142,
    "text may have": 1.0,
    "may have many": 0.5,
    "have many different": 0.2,
    "many different co-occurring": 0.16666666666666666,
    "different co-occurring neighbors": 1.0,
    "co-occurring neighbors .": 1.0,
    "text about machine": 0.5,
    "about machine learning": 1.0,
    "learning , the": 0.25,
    ", the unigram": 0.009523809523809525,
    "the unigram ``": 1.0,
    "unigram `` learning": 1.0,
    "`` learning ''": 1.0,
    "learning '' might": 0.2,
    "'' might co-occur": 0.5,
    "might co-occur with": 1.0,
    "co-occur with ``": 1.0,
    "with `` machine": 0.3333333333333333,
    "`` machine ''": 1.0,
    "machine '' ,": 1.0,
    "'' , supervised": 0.03333333333333333,
    ", supervised ''": 1.0,
    "supervised '' ,": 0.3333333333333333,
    ", `` un-supervised": 0.04,
    "`` un-supervised ''": 1.0,
    "un-supervised '' ,": 1.0,
    "and `` semi-supervised": 0.05,
    "`` semi-supervised ''": 1.0,
    "semi-supervised '' in": 1.0,
    "'' in four": 0.14285714285714285,
    "four different sentences": 0.5,
    "different sentences .": 0.3333333333333333,
    "thus , the": 0.09090909090909091,
    ", the ``": 0.009523809523809525,
    "the `` learning": 0.14285714285714285,
    "learning '' vertex": 0.2,
    "'' vertex would": 1.0,
    "vertex would be": 1.0,
    "be a central": 0.07692307692307693,
    "a central ``": 1.0,
    "central `` hub": 1.0,
    "`` hub ''": 1.0,
    "hub '' that": 1.0,
    "'' that connects": 0.25,
    "that connects to": 1.0,
    "connects to these": 1.0,
    "to these other": 0.5,
    "these other modifying": 1.0,
    "other modifying words": 1.0,
    "modifying words .": 1.0,
    "<s> running pagerank\\/textrank": 1.0,
    "running pagerank\\/textrank on": 1.0,
    "pagerank\\/textrank on the": 1.0,
    "graph is likely": 0.3333333333333333,
    "is likely to": 1.0,
    "likely to rank": 0.14285714285714285,
    "to rank ``": 0.3333333333333333,
    "rank `` learning": 1.0,
    "learning '' highly": 0.2,
    "'' highly .": 1.0,
    "<s> similarly ,": 1.0,
    "similarly , if": 1.0,
    ", if the": 0.2,
    "if the text": 0.07142857142857142,
    "the text contains": 0.038461538461538464,
    "text contains the": 1.0,
    "contains the phrase": 0.5,
    "the phrase ``": 0.25,
    "phrase `` supervised": 1.0,
    "`` supervised classification": 0.4,
    "supervised classification ''": 1.0,
    "classification '' ,": 0.2,
    "'' , then": 0.03333333333333333,
    ", then there": 0.09090909090909091,
    "then there would": 1.0,
    "there would be": 1.0,
    "would be an": 0.1111111111111111,
    "be an edge": 1.0,
    "an edge between": 0.5,
    "edge between ``": 1.0,
    "between `` supervised": 1.0,
    "`` supervised ''": 0.4,
    "supervised '' and": 0.3333333333333333,
    "and `` classification": 0.05,
    "`` classification ''": 1.0,
    "classification '' .": 0.6,
    "<s> if ``": 0.125,
    "if `` classification": 1.0,
    "classification '' appears": 0.2,
    "'' appears several": 1.0,
    "appears several other": 1.0,
    "several other places": 1.0,
    "other places and": 1.0,
    "places and thus": 1.0,
    "and thus has": 0.3333333333333333,
    "thus has many": 1.0,
    "has many neighbors": 0.5,
    "many neighbors ,": 1.0,
    "neighbors , it": 1.0,
    "it is importance": 0.02127659574468085,
    "is importance would": 1.0,
    "importance would contribute": 1.0,
    "would contribute to": 1.0,
    "contribute to the": 1.0,
    "to the importance": 0.012987012987012988,
    "the importance of": 1.0,
    "importance of ``": 0.25,
    "of `` supervised": 0.125,
    "supervised '' .": 0.3333333333333333,
    "<s> if it": 0.125,
    "if it ends": 0.3333333333333333,
    "it ends up": 0.5,
    "ends up with": 1.0,
    "up with a": 0.3333333333333333,
    "with a high": 0.1,
    "a high rank": 0.25,
    "high rank ,": 1.0,
    "rank , it": 1.0,
    ", it will": 0.08333333333333333,
    "it will be": 0.5,
    "will be selected": 0.1111111111111111,
    "be selected as": 1.0,
    "selected as one": 1.0,
    "as one of": 0.5,
    "of the top": 0.005128205128205128,
    "top t unigrams": 0.5,
    "t unigrams ,": 0.5,
    "unigrams , along": 0.3333333333333333,
    ", along with": 1.0,
    "along with ``": 0.5,
    "with `` learning": 0.3333333333333333,
    "learning '' and": 0.4,
    "'' and probably": 0.07692307692307693,
    "and probably ``": 1.0,
    "probably `` classification": 1.0,
    "in the final": 0.006535947712418301,
    "the final post-processing": 0.2,
    "final post-processing step": 1.0,
    "post-processing step ,": 0.5,
    "step , we": 0.5,
    ", we would": 0.11764705882352941,
    "we would then": 0.3333333333333333,
    "would then end": 1.0,
    "then end up": 1.0,
    "end up with": 0.5,
    "up with keyphrases": 0.3333333333333333,
    "with keyphrases ``": 1.0,
    "keyphrases `` supervised": 1.0,
    "`` supervised learning": 0.2,
    "supervised learning ''": 0.2,
    "and `` supervised": 0.05,
    "<s> in short": 0.010309278350515464,
    "in short ,": 1.0,
    "short , the": 1.0,
    ", the co-occurrence": 0.009523809523809525,
    "the co-occurrence graph": 1.0,
    "co-occurrence graph will": 0.5,
    "graph will contain": 0.5,
    "will contain densely": 1.0,
    "contain densely connected": 1.0,
    "densely connected regions": 0.5,
    "connected regions for": 1.0,
    "regions for terms": 1.0,
    "for terms that": 1.0,
    "terms that appear": 1.0,
    "that appear often": 0.25,
    "appear often and": 1.0,
    "often and in": 1.0,
    "and in different": 0.14285714285714285,
    "in different contexts": 0.3333333333333333,
    "different contexts .": 1.0,
    "<s> a random": 0.022727272727272728,
    "a random walk": 1.0,
    "walk on this": 0.5,
    "on this graph": 0.3333333333333333,
    "this graph will": 1.0,
    "graph will have": 0.5,
    "will have a": 1.0,
    "have a stationary": 0.07692307692307693,
    "a stationary distribution": 0.5,
    "stationary distribution that": 0.5,
    "distribution that assigns": 0.5,
    "that assigns large": 1.0,
    "assigns large probabilities": 1.0,
    "large probabilities to": 1.0,
    "probabilities to the": 1.0,
    "to the terms": 0.012987012987012988,
    "the terms in": 1.0,
    "terms in the": 1.0,
    "in the centers": 0.006535947712418301,
    "the centers of": 1.0,
    "centers of the": 1.0,
    "of the clusters": 0.005128205128205128,
    "the clusters .": 1.0,
    "this is similar": 0.038461538461538464,
    "is similar to": 1.0,
    "similar to densely": 0.06666666666666667,
    "to densely connected": 1.0,
    "densely connected web": 0.5,
    "connected web pages": 1.0,
    "web pages getting": 0.3333333333333333,
    "pages getting ranked": 1.0,
    "getting ranked highly": 1.0,
    "ranked highly by": 0.5,
    "highly by pagerank": 1.0,
    "by pagerank .": 1.0,
    "<s> document summarization": 0.5,
    "document summarization like": 0.16666666666666666,
    "summarization like keyphrase": 1.0,
    "like keyphrase extraction": 1.0,
    "extraction , document": 0.16666666666666666,
    ", document summarization": 1.0,
    "document summarization hopes": 0.16666666666666666,
    "summarization hopes to": 1.0,
    "hopes to identify": 1.0,
    "to identify the": 0.4,
    "identify the essence": 0.16666666666666666,
    "essence of a": 0.5,
    "a text .": 0.07142857142857142,
    "<s> the only": 0.013605442176870748,
    "the only real": 0.3333333333333333,
    "only real difference": 1.0,
    "real difference is": 1.0,
    "difference is that": 1.0,
    "is that now": 0.08333333333333333,
    "that now we": 1.0,
    "now we are": 1.0,
    "we are dealing": 0.5,
    "are dealing with": 1.0,
    "dealing with larger": 0.5,
    "with larger text": 1.0,
    "larger text units": 1.0,
    "text units --": 0.3333333333333333,
    "units -- whole": 1.0,
    "-- whole sentences": 1.0,
    "whole sentences instead": 0.5,
    "sentences instead of": 1.0,
    "instead of words": 0.14285714285714285,
    "words and phrases": 0.25,
    "and phrases .": 0.5,
    "<s> while some": 0.3333333333333333,
    "while some work": 0.5,
    "some work has": 1.0,
    "work has been": 1.0,
    "has been done": 0.07142857142857142,
    "been done in": 1.0,
    "done in abstractive": 0.2,
    "in abstractive summarization": 1.0,
    "abstractive summarization -lrb-": 0.5,
    "summarization -lrb- creating": 0.5,
    "-lrb- creating an": 1.0,
    "creating an abstract": 0.5,
    "an abstract synopsis": 1.0,
    "abstract synopsis like": 1.0,
    "synopsis like that": 1.0,
    "like that of": 1.0,
    "that of a": 0.25,
    "of a human": 0.010869565217391304,
    "human -rrb- ,": 0.5,
    ", the majority": 0.009523809523809525,
    "the majority of": 1.0,
    "majority of summarization": 1.0,
    "of summarization systems": 0.125,
    "systems are extractive": 0.07692307692307693,
    "are extractive -lrb-": 1.0,
    "extractive -lrb- selecting": 1.0,
    "-lrb- selecting a": 1.0,
    "subset of sentences": 0.3333333333333333,
    "of sentences to": 0.2857142857142857,
    "sentences to place": 0.3333333333333333,
    "to place in": 1.0,
    "place in a": 0.5,
    "in a summary": 0.038461538461538464,
    "a summary -rrb-": 0.1111111111111111,
    "summary -rrb- .": 1.0,
    "<s> before getting": 1.0,
    "before getting into": 1.0,
    "getting into the": 1.0,
    "into the details": 0.125,
    "the details of": 1.0,
    "details of some": 1.0,
    "of some summarization": 0.2,
    "some summarization methods": 1.0,
    "summarization methods ,": 1.0,
    "methods , we": 0.25,
    ", we will": 0.058823529411764705,
    "we will mention": 0.25,
    "will mention how": 1.0,
    "mention how summarization": 1.0,
    "how summarization systems": 1.0,
    "systems are typically": 0.07692307692307693,
    "are typically evaluated": 0.3333333333333333,
    "typically evaluated .": 1.0,
    "<s> the most": 0.02040816326530612,
    "most common way": 0.3333333333333333,
    "common way is": 0.5,
    "way is using": 1.0,
    "is using the": 0.5,
    "using the so-called": 0.14285714285714285,
    "the so-called rouge": 1.0,
    "so-called rouge -lrb-": 1.0,
    "rouge -lrb- recall-oriented": 1.0,
    "-lrb- recall-oriented understudy": 1.0,
    "recall-oriented understudy for": 1.0,
    "understudy for gisting": 1.0,
    "for gisting evaluation": 1.0,
    "gisting evaluation -rrb-": 1.0,
    "evaluation -rrb- measure": 0.5,
    "-rrb- measure -lrb-": 1.0,
    "measure -lrb- http:\\/\\/haydn.isi.edu\\/rouge\\/": 1.0,
    "-lrb- http:\\/\\/haydn.isi.edu\\/rouge\\/ -rrb-": 1.0,
    "http:\\/\\/haydn.isi.edu\\/rouge\\/ -rrb- .": 1.0,
    "this is a": 0.07692307692307693,
    "is a recall-based": 0.018518518518518517,
    "a recall-based measure": 1.0,
    "recall-based measure that": 1.0,
    "measure that determines": 1.0,
    "that determines how": 0.5,
    "determines how well": 1.0,
    "how well a": 0.16666666666666666,
    "well a system-generated": 1.0,
    "a system-generated summary": 1.0,
    "system-generated summary covers": 1.0,
    "summary covers the": 1.0,
    "covers the content": 0.5,
    "the content present": 0.3333333333333333,
    "content present in": 1.0,
    "present in one": 0.2,
    "in one or": 0.2,
    "or more human-generated": 0.25,
    "more human-generated model": 1.0,
    "human-generated model summaries": 1.0,
    "model summaries known": 0.5,
    "summaries known as": 1.0,
    "known as references": 0.1,
    "as references .": 1.0,
    "it is recall-based": 0.02127659574468085,
    "is recall-based to": 1.0,
    "recall-based to encourage": 1.0,
    "to encourage systems": 1.0,
    "encourage systems to": 1.0,
    "systems to include": 1.0,
    "to include all": 0.14285714285714285,
    "include all the": 1.0,
    "all the important": 0.14285714285714285,
    "the important topics": 1.0,
    "important topics in": 1.0,
    "topics in the": 1.0,
    "<s> recall can": 0.3333333333333333,
    "recall can be": 1.0,
    "can be computed": 0.01098901098901099,
    "be computed with": 1.0,
    "computed with respect": 1.0,
    "respect to unigram": 0.14285714285714285,
    "to unigram ,": 1.0,
    "trigram , or": 0.5,
    ", or 4-gram": 0.030303030303030304,
    "or 4-gram matching": 1.0,
    "4-gram matching ,": 1.0,
    "matching , though": 1.0,
    ", though rouge-1": 0.16666666666666666,
    "though rouge-1 -lrb-": 1.0,
    "rouge-1 -lrb- unigram": 1.0,
    "-lrb- unigram matching": 1.0,
    "unigram matching -rrb-": 1.0,
    "matching -rrb- has": 1.0,
    "-rrb- has been": 0.3333333333333333,
    "has been shown": 0.03571428571428571,
    "been shown to": 1.0,
    "shown to correlate": 0.5,
    "to correlate best": 1.0,
    "correlate best with": 1.0,
    "best with human": 1.0,
    "with human assessments": 0.5,
    "human assessments of": 1.0,
    "assessments of system-generated": 1.0,
    "of system-generated summaries": 1.0,
    "system-generated summaries -lrb-": 1.0,
    "summaries -lrb- i.e.": 0.5,
    ", the summaries": 0.009523809523809525,
    "the summaries with": 0.25,
    "summaries with highest": 0.5,
    "with highest rouge-1": 0.5,
    "highest rouge-1 values": 1.0,
    "rouge-1 values correlate": 1.0,
    "values correlate with": 1.0,
    "correlate with the": 0.5,
    "with the summaries": 0.03333333333333333,
    "the summaries humans": 0.25,
    "summaries humans deemed": 1.0,
    "humans deemed the": 1.0,
    "deemed the best": 1.0,
    "the best -rrb-": 0.07142857142857142,
    "best -rrb- .": 1.0,
    "<s> rouge-1 is": 1.0,
    "rouge-1 is computed": 1.0,
    "is computed as": 1.0,
    "computed as division": 1.0,
    "as division of": 1.0,
    "division of count": 1.0,
    "of count of": 1.0,
    "count of unigrams": 1.0,
    "of unigrams in": 1.0,
    "unigrams in reference": 0.6666666666666666,
    "in reference that": 0.5,
    "reference that appear": 1.0,
    "that appear in": 0.25,
    "appear in system": 0.14285714285714285,
    "in system and": 1.0,
    "system and count": 0.3333333333333333,
    "and count of": 1.0,
    "in reference summary": 0.5,
    "reference summary .": 0.3333333333333333,
    "<s> if there": 0.125,
    "if there are": 0.6666666666666666,
    "there are multiple": 0.047619047619047616,
    "are multiple references": 1.0,
    "multiple references ,": 1.0,
    "references , the": 1.0,
    ", the rouge-1": 0.009523809523809525,
    "the rouge-1 scores": 1.0,
    "rouge-1 scores are": 1.0,
    "scores are averaged": 1.0,
    "are averaged .": 1.0,
    "<s> because rouge": 0.3333333333333333,
    "because rouge is": 1.0,
    "rouge is based": 0.5,
    "is based only": 0.25,
    "based only on": 1.0,
    "only on content": 0.5,
    "on content overlap": 1.0,
    "content overlap ,": 0.5,
    "overlap , it": 1.0,
    ", it can": 0.041666666666666664,
    "it can determine": 0.16666666666666666,
    "can determine if": 0.5,
    "determine if the": 0.6,
    "if the same": 0.07142857142857142,
    "the same general": 0.041666666666666664,
    "same general concepts": 1.0,
    "general concepts are": 1.0,
    "concepts are discussed": 0.5,
    "are discussed between": 1.0,
    "discussed between an": 1.0,
    "between an automatic": 1.0,
    "an automatic summary": 0.5,
    "automatic summary and": 1.0,
    "summary and a": 0.5,
    "and a reference": 0.0625,
    "a reference summary": 0.5,
    "reference summary ,": 0.6666666666666666,
    "summary , but": 0.16666666666666666,
    "but it can": 0.25,
    "it can not": 0.16666666666666666,
    "can not determine": 0.06666666666666667,
    "not determine if": 1.0,
    "if the result": 0.07142857142857142,
    "the result is": 0.4,
    "result is coherent": 0.5,
    "is coherent or": 1.0,
    "coherent or the": 1.0,
    "or the sentences": 0.1111111111111111,
    "the sentences flow": 0.1111111111111111,
    "sentences flow together": 1.0,
    "flow together in": 1.0,
    "together in a": 1.0,
    "in a sensible": 0.019230769230769232,
    "a sensible manner": 1.0,
    "sensible manner .": 1.0,
    "<s> high-order n-gram": 1.0,
    "high-order n-gram rouge": 1.0,
    "n-gram rouge measures": 1.0,
    "rouge measures try": 1.0,
    "measures try to": 1.0,
    "try to judge": 0.3333333333333333,
    "to judge fluency": 0.5,
    "judge fluency to": 1.0,
    "fluency to some": 1.0,
    "to some degree": 0.4,
    "some degree .": 0.5,
    "note that rouge": 0.14285714285714285,
    "that rouge is": 1.0,
    "rouge is similar": 0.5,
    "to the bleu": 0.012987012987012988,
    "the bleu measure": 1.0,
    "bleu measure for": 1.0,
    "measure for machine": 1.0,
    "translation , but": 0.125,
    ", but bleu": 0.020833333333333332,
    "but bleu is": 1.0,
    "bleu is precision": 1.0,
    "is precision -": 1.0,
    "precision - based": 1.0,
    "- based ,": 0.3333333333333333,
    "based , because": 0.5,
    ", because translation": 0.125,
    "because translation systems": 1.0,
    "translation systems favor": 0.5,
    "systems favor accuracy": 1.0,
    "favor accuracy .": 1.0,
    "<s> a promising": 0.022727272727272728,
    "a promising line": 1.0,
    "promising line in": 1.0,
    "line in document": 1.0,
    "in document summarization": 0.5,
    "document summarization is": 0.16666666666666666,
    "summarization is adaptive": 0.16666666666666666,
    "is adaptive document\\/text": 1.0,
    "adaptive document\\/text summarization": 1.0,
    "document\\/text summarization .": 1.0,
    "idea of adaptive": 0.5,
    "of adaptive summarization": 1.0,
    "adaptive summarization involves": 0.5,
    "summarization involves preliminary": 1.0,
    "involves preliminary recognition": 1.0,
    "preliminary recognition of": 1.0,
    "recognition of document\\/text": 0.09090909090909091,
    "of document\\/text genre": 1.0,
    "document\\/text genre and": 1.0,
    "genre and subsequent": 1.0,
    "and subsequent application": 1.0,
    "subsequent application of": 1.0,
    "application of summarization": 0.25,
    "of summarization algorithms": 0.125,
    "summarization algorithms optimized": 1.0,
    "algorithms optimized for": 1.0,
    "optimized for this": 1.0,
    "for this genre": 0.125,
    "this genre .": 1.0,
    "<s> first summarizes": 1.0,
    "first summarizes that": 1.0,
    "summarizes that perform": 1.0,
    "that perform adaptive": 1.0,
    "perform adaptive summarization": 1.0,
    "adaptive summarization have": 0.5,
    "summarization have been": 1.0,
    "have been created": 0.07692307692307693,
    "been created .": 0.5,
    "<s> overview of": 1.0,
    "overview of supervised": 0.5,
    "of supervised learning": 1.0,
    "supervised learning approaches": 0.2,
    "learning approaches supervised": 1.0,
    "approaches supervised text": 1.0,
    "supervised text summarization": 1.0,
    "text summarization is": 1.0,
    "summarization is very": 0.16666666666666666,
    "is very much": 0.16666666666666666,
    "very much like": 1.0,
    "much like supervised": 1.0,
    "like supervised keyphrase": 1.0,
    "extraction , and": 0.16666666666666666,
    ", and we": 0.005291005291005291,
    "and we will": 1.0,
    "we will not": 0.25,
    "will not spend": 0.25,
    "not spend much": 1.0,
    "spend much time": 1.0,
    "much time on": 1.0,
    "time on it": 1.0,
    "on it .": 1.0,
    "<s> basically ,": 1.0,
    "basically , if": 1.0,
    ", if you": 0.2,
    "if you have": 0.5,
    "you have a": 1.0,
    "have a collection": 0.07692307692307693,
    "a collection of": 1.0,
    "collection of documents": 0.3333333333333333,
    "of documents and": 0.2,
    "documents and human-generated": 1.0,
    "and human-generated summaries": 1.0,
    "human-generated summaries for": 1.0,
    "summaries for them": 1.0,
    "for them ,": 0.5,
    "them , you": 0.25,
    ", you can": 1.0,
    "you can learn": 0.5,
    "can learn features": 1.0,
    "learn features of": 1.0,
    "features of sentences": 0.25,
    "of sentences that": 0.14285714285714285,
    "sentences that make": 0.2,
    "that make them": 0.3333333333333333,
    "make them good": 1.0,
    "them good candidates": 1.0,
    "good candidates for": 0.3333333333333333,
    "candidates for inclusion": 1.0,
    "for inclusion in": 1.0,
    "inclusion in the": 1.0,
    "in the summary": 0.026143790849673203,
    "<s> features might": 1.0,
    "features might include": 0.5,
    "might include the": 1.0,
    "include the position": 0.2,
    "the position in": 1.0,
    "position in the": 1.0,
    "in the document": 0.026143790849673203,
    "the document -lrb-": 0.16666666666666666,
    "document -lrb- i.e.": 0.5,
    "the first few": 0.045454545454545456,
    "first few sentences": 1.0,
    "few sentences are": 1.0,
    "sentences are probably": 0.14285714285714285,
    "are probably important": 1.0,
    "probably important -rrb-": 1.0,
    "important -rrb- ,": 1.0,
    ", the number": 0.01904761904761905,
    "number of words": 0.05555555555555555,
    "in the sentence": 0.006535947712418301,
    "the sentence ,": 0.16666666666666666,
    "sentence , etc.": 0.16666666666666666,
    "<s> the main": 0.013605442176870748,
    "the main difficulty": 0.4,
    "main difficulty in": 1.0,
    "difficulty in supervised": 0.5,
    "in supervised extractive": 1.0,
    "supervised extractive summarization": 1.0,
    "extractive summarization is": 0.3333333333333333,
    "summarization is that": 0.16666666666666666,
    "is that the": 0.25,
    "that the known": 0.043478260869565216,
    "the known summaries": 0.2,
    "known summaries must": 1.0,
    "summaries must be": 1.0,
    "must be manually": 0.16666666666666666,
    "be manually created": 1.0,
    "manually created by": 1.0,
    "created by extracting": 0.5,
    "by extracting sentences": 1.0,
    "extracting sentences so": 1.0,
    "sentences so the": 1.0,
    "so the sentences": 0.14285714285714285,
    "the sentences in": 0.3333333333333333,
    "sentences in an": 0.125,
    "in an original": 0.125,
    "an original training": 1.0,
    "original training document": 1.0,
    "training document can": 1.0,
    "document can be": 1.0,
    "can be labeled": 0.01098901098901099,
    "be labeled as": 1.0,
    "labeled as ``": 1.0,
    "as `` in": 0.07142857142857142,
    "`` in summary": 0.5,
    "in summary ''": 1.0,
    "summary '' or": 0.5,
    "or `` not": 0.25,
    "`` not in": 1.0,
    "not in summary": 1.0,
    "summary '' .": 0.5,
    "this is not": 0.07692307692307693,
    "is not typically": 0.05263157894736842,
    "not typically how": 0.5,
    "typically how people": 1.0,
    "how people create": 1.0,
    "people create summaries": 1.0,
    "create summaries ,": 1.0,
    "summaries , so": 0.3333333333333333,
    ", so simply": 0.08333333333333333,
    "so simply using": 1.0,
    "simply using journal": 1.0,
    "using journal abstracts": 1.0,
    "journal abstracts or": 1.0,
    "abstracts or existing": 1.0,
    "or existing summaries": 1.0,
    "existing summaries is": 1.0,
    "summaries is usually": 0.3333333333333333,
    "is usually not": 0.125,
    "usually not sufficient": 1.0,
    "not sufficient .": 1.0,
    "<s> the sentences": 0.006802721088435374,
    "sentences in these": 0.125,
    "in these summaries": 0.25,
    "these summaries do": 0.5,
    "summaries do not": 1.0,
    "do not necessarily": 0.07692307692307693,
    "not necessarily match": 0.5,
    "necessarily match up": 1.0,
    "match up with": 1.0,
    "up with sentences": 0.3333333333333333,
    "with sentences in": 1.0,
    "original text ,": 0.16666666666666666,
    "text , so": 0.03333333333333333,
    ", so it": 0.08333333333333333,
    "so it would": 0.5,
    "it would difficult": 0.25,
    "would difficult to": 1.0,
    "difficult to assign": 0.09090909090909091,
    "to assign labels": 0.3333333333333333,
    "assign labels to": 1.0,
    "labels to examples": 0.5,
    "to examples for": 1.0,
    "examples for training": 1.0,
    "for training .": 0.3333333333333333,
    "<s> note ,": 0.1111111111111111,
    "note , however": 1.0,
    "however , that": 0.022727272727272728,
    ", that these": 0.25,
    "that these natural": 0.3333333333333333,
    "these natural summaries": 1.0,
    "natural summaries can": 1.0,
    "summaries can still": 0.5,
    "can still be": 1.0,
    "still be used": 1.0,
    "be used for": 0.15789473684210525,
    "used for evaluation": 0.06666666666666667,
    "for evaluation purposes": 1.0,
    "evaluation purposes ,": 1.0,
    "purposes , since": 1.0,
    ", since rouge-1": 0.2,
    "since rouge-1 only": 1.0,
    "rouge-1 only cares": 1.0,
    "only cares about": 1.0,
    "cares about unigrams": 1.0,
    "about unigrams .": 1.0,
    "<s> unsupervised approaches": 0.2,
    "unsupervised approaches :": 1.0,
    "approaches : textrank": 0.25,
    ": textrank and": 0.5,
    "textrank and lexrank": 1.0,
    "and lexrank the": 0.3333333333333333,
    "lexrank the unsupervised": 1.0,
    "the unsupervised approach": 0.5,
    "unsupervised approach to": 1.0,
    "approach to summarization": 0.16666666666666666,
    "to summarization is": 0.5,
    "summarization is also": 0.16666666666666666,
    "is also quite": 0.1,
    "also quite similar": 1.0,
    "quite similar in": 1.0,
    "similar in spirit": 1.0,
    "in spirit to": 1.0,
    "spirit to unsupervised": 1.0,
    "to unsupervised keyphrase": 0.5,
    "keyphrase extraction and": 0.06666666666666667,
    "extraction and gets": 0.3333333333333333,
    "and gets around": 1.0,
    "gets around the": 1.0,
    "around the issue": 0.25,
    "the issue of": 0.25,
    "issue of costly": 1.0,
    "of costly training": 1.0,
    "costly training data": 1.0,
    "<s> some unsupervised": 0.0625,
    "some unsupervised summarization": 1.0,
    "unsupervised summarization approaches": 0.5,
    "summarization approaches are": 1.0,
    "approaches are based": 1.0,
    "based on finding": 0.021739130434782608,
    "on finding a": 1.0,
    "finding a ``": 0.5,
    "a `` centroid": 0.16666666666666666,
    "`` centroid ''": 1.0,
    "centroid '' sentence": 1.0,
    "'' sentence ,": 1.0,
    "sentence , which": 0.16666666666666666,
    "is the mean": 0.022222222222222223,
    "the mean word": 1.0,
    "mean word vector": 1.0,
    "word vector of": 1.0,
    "vector of all": 1.0,
    "of all the": 0.5,
    "all the sentences": 0.14285714285714285,
    "the document .": 0.5,
    "then the sentences": 0.25,
    "the sentences can": 0.1111111111111111,
    "sentences can be": 0.3333333333333333,
    "can be ranked": 0.01098901098901099,
    "be ranked with": 1.0,
    "ranked with regard": 1.0,
    "with regard to": 1.0,
    "regard to their": 0.25,
    "to their similarity": 0.5,
    "their similarity to": 1.0,
    "similarity to this": 1.0,
    "to this centroid": 0.16666666666666666,
    "this centroid sentence": 1.0,
    "centroid sentence .": 1.0,
    "<s> a more": 0.022727272727272728,
    "a more principled": 0.2,
    "more principled way": 1.0,
    "principled way to": 1.0,
    "way to estimate": 0.1,
    "to estimate sentence": 0.3333333333333333,
    "estimate sentence importance": 1.0,
    "sentence importance is": 1.0,
    "importance is using": 1.0,
    "is using random": 0.5,
    "using random walks": 1.0,
    "random walks and": 0.5,
    "walks and eigenvector": 1.0,
    "and eigenvector centrality": 1.0,
    "eigenvector centrality .": 1.0,
    "<s> lexrank is": 0.5,
    "lexrank is an": 1.0,
    "is an algorithm": 0.2,
    "an algorithm essentially": 0.3333333333333333,
    "algorithm essentially identical": 1.0,
    "essentially identical to": 1.0,
    "identical to textrank": 0.5,
    "to textrank ,": 1.0,
    "textrank , and": 0.5,
    ", and both": 0.005291005291005291,
    "and both use": 1.0,
    "both use this": 1.0,
    "use this approach": 0.5,
    "this approach for": 0.25,
    "approach for document": 1.0,
    "for document summarization": 1.0,
    "document summarization .": 0.16666666666666666,
    "the two methods": 0.14285714285714285,
    "two methods were": 1.0,
    "methods were developed": 0.5,
    "were developed by": 0.2,
    "developed by different": 1.0,
    "by different groups": 1.0,
    "different groups at": 1.0,
    "groups at the": 1.0,
    "at the same": 0.0625,
    "the same time": 0.125,
    "same time ,": 1.0,
    ", and lexrank": 0.005291005291005291,
    "and lexrank simply": 0.3333333333333333,
    "lexrank simply focused": 1.0,
    "simply focused on": 1.0,
    "focused on summarization": 0.1,
    "on summarization ,": 1.0,
    "summarization , but": 0.25,
    ", but could": 0.020833333333333332,
    "but could just": 1.0,
    "could just as": 1.0,
    "just as easily": 1.0,
    "as easily be": 0.5,
    "easily be used": 1.0,
    "used for keyphrase": 0.06666666666666667,
    "keyphrase extraction or": 0.06666666666666667,
    "extraction or any": 1.0,
    "or any other": 0.3333333333333333,
    "any other nlp": 0.5,
    "other nlp ranking": 1.0,
    "nlp ranking task": 1.0,
    "ranking task .": 1.0,
    "choices what are": 0.5,
    "are the vertices": 0.09090909090909091,
    "the vertices ?": 0.5,
    "<s> in both": 0.020618556701030927,
    "in both lexrank": 0.3333333333333333,
    "both lexrank and": 1.0,
    "lexrank and textrank": 1.0,
    "and textrank ,": 1.0,
    "textrank , a": 0.5,
    ", a graph": 0.020833333333333332,
    "a graph is": 0.3333333333333333,
    "is constructed by": 0.5,
    "constructed by creating": 1.0,
    "by creating a": 1.0,
    "creating a vertex": 0.5,
    "for each sentence": 0.14285714285714285,
    "each sentence in": 1.0,
    "sentence in the": 0.5,
    "are the edges": 0.09090909090909091,
    "the edges ?": 0.3333333333333333,
    "<s> the edges": 0.006802721088435374,
    "the edges between": 0.3333333333333333,
    "edges between sentences": 1.0,
    "between sentences are": 0.5,
    "sentences are based": 0.14285714285714285,
    "on some form": 0.2222222222222222,
    "some form of": 1.0,
    "form of semantic": 0.14285714285714285,
    "of semantic similarity": 0.2,
    "semantic similarity or": 1.0,
    "similarity or content": 1.0,
    "or content overlap": 1.0,
    "content overlap .": 0.5,
    "<s> while lexrank": 0.3333333333333333,
    "while lexrank uses": 0.3333333333333333,
    "lexrank uses cosine": 1.0,
    "uses cosine similarity": 1.0,
    "cosine similarity of": 1.0,
    "similarity of tf-idf": 1.0,
    "of tf-idf vectors": 1.0,
    "tf-idf vectors ,": 1.0,
    "vectors , textrank": 1.0,
    ", textrank uses": 0.5,
    "textrank uses a": 0.5,
    "uses a very": 0.25,
    "a very similar": 0.08333333333333333,
    "very similar measure": 0.25,
    "similar measure based": 1.0,
    "measure based on": 1.0,
    "on the number": 0.014925373134328358,
    "of words two": 0.06666666666666667,
    "words two sentences": 1.0,
    "two sentences have": 0.5,
    "sentences have in": 0.5,
    "have in common": 0.5,
    "in common -lrb-": 0.3333333333333333,
    "common -lrb- normalized": 1.0,
    "-lrb- normalized by": 1.0,
    "normalized by the": 1.0,
    "by the sentences": 0.03571428571428571,
    "the sentences '": 0.1111111111111111,
    "sentences ' lengths": 1.0,
    "' lengths -rrb-": 1.0,
    "lengths -rrb- .": 1.0,
    "<s> the lexrank": 0.006802721088435374,
    "the lexrank paper": 0.5,
    "lexrank paper explored": 1.0,
    "paper explored using": 1.0,
    "explored using unweighted": 1.0,
    "using unweighted edges": 1.0,
    "unweighted edges after": 1.0,
    "edges after applying": 1.0,
    "after applying a": 1.0,
    "applying a threshold": 1.0,
    "a threshold to": 0.3333333333333333,
    "threshold to the": 1.0,
    "to the cosine": 0.012987012987012988,
    "the cosine values": 1.0,
    "cosine values ,": 1.0,
    "values , but": 1.0,
    "but also experimented": 0.16666666666666666,
    "also experimented with": 1.0,
    "experimented with using": 1.0,
    "with using edges": 1.0,
    "using edges with": 1.0,
    "edges with weights": 1.0,
    "with weights equal": 1.0,
    "weights equal to": 1.0,
    "equal to the": 1.0,
    "to the similarity": 0.012987012987012988,
    "the similarity score": 1.0,
    "similarity score .": 1.0,
    "<s> textrank uses": 0.3333333333333333,
    "textrank uses continuous": 0.5,
    "uses continuous similarity": 1.0,
    "continuous similarity scores": 1.0,
    "similarity scores as": 1.0,
    "scores as weights": 1.0,
    "as weights .": 1.0,
    "how are summaries": 0.5,
    "are summaries formed": 1.0,
    "summaries formed ?": 1.0,
    "in both algorithms": 0.3333333333333333,
    "both algorithms ,": 1.0,
    "algorithms , the": 0.4,
    ", the sentences": 0.009523809523809525,
    "the sentences are": 0.1111111111111111,
    "sentences are ranked": 0.14285714285714285,
    "are ranked by": 1.0,
    "ranked by applying": 1.0,
    "by applying pagerank": 1.0,
    "pagerank to the": 0.5,
    "to the resulting": 0.012987012987012988,
    "the resulting graph": 0.5,
    "resulting graph .": 1.0,
    "<s> a summary": 0.022727272727272728,
    "a summary is": 0.1111111111111111,
    "summary is formed": 0.5,
    "is formed by": 1.0,
    "formed by combining": 1.0,
    "by combining the": 0.5,
    "combining the top": 1.0,
    "the top ranking": 0.25,
    "top ranking sentences": 1.0,
    "ranking sentences ,": 1.0,
    "sentences , using": 0.125,
    ", using a": 0.1,
    "using a threshold": 0.1,
    "a threshold or": 0.3333333333333333,
    "threshold or length": 0.5,
    "or length cutoff": 1.0,
    "length cutoff to": 1.0,
    "cutoff to limit": 1.0,
    "limit the size": 0.5,
    "the size of": 0.5,
    "size of the": 1.0,
    "of the summary": 0.005128205128205128,
    "<s> textrank and": 0.3333333333333333,
    "and lexrank differences": 0.3333333333333333,
    "lexrank differences it": 1.0,
    "differences it is": 1.0,
    "it is worth": 0.0425531914893617,
    "is worth noting": 0.5,
    "worth noting that": 1.0,
    "noting that textrank": 1.0,
    "that textrank was": 1.0,
    "textrank was applied": 0.5,
    "was applied to": 1.0,
    "applied to summarization": 0.09090909090909091,
    "to summarization exactly": 0.5,
    "summarization exactly as": 1.0,
    "exactly as described": 1.0,
    "as described here": 0.3333333333333333,
    "described here ,": 1.0,
    "here , while": 1.0,
    ", while lexrank": 0.14285714285714285,
    "while lexrank was": 0.3333333333333333,
    "lexrank was used": 1.0,
    "was used as": 0.25,
    "used as part": 0.2,
    "as part of": 1.0,
    "a larger summarization": 0.25,
    "larger summarization system": 1.0,
    "summarization system -lrb-": 0.3333333333333333,
    "system -lrb- mead": 0.5,
    "-lrb- mead -rrb-": 1.0,
    "mead -rrb- that": 1.0,
    "-rrb- that combines": 0.5,
    "that combines the": 1.0,
    "combines the lexrank": 1.0,
    "the lexrank score": 0.5,
    "lexrank score -lrb-": 1.0,
    "score -lrb- stationary": 1.0,
    "-lrb- stationary probability": 1.0,
    "stationary probability -rrb-": 1.0,
    "probability -rrb- with": 0.5,
    "-rrb- with other": 0.3333333333333333,
    "with other features": 1.0,
    "other features like": 1.0,
    "features like sentence": 1.0,
    "like sentence position": 1.0,
    "sentence position and": 0.5,
    "position and length": 1.0,
    "and length using": 1.0,
    "length using a": 1.0,
    "using a linear": 0.1,
    "a linear combination": 0.5,
    "linear combination with": 1.0,
    "combination with either": 0.5,
    "with either user-specified": 1.0,
    "either user-specified or": 1.0,
    "user-specified or automatically": 1.0,
    "or automatically tuned": 0.5,
    "automatically tuned weights": 1.0,
    "tuned weights .": 1.0,
    "in this case": 0.06666666666666667,
    "this case ,": 1.0,
    "case , some": 0.3333333333333333,
    ", some training": 0.1111111111111111,
    "some training documents": 1.0,
    "training documents might": 0.3333333333333333,
    "documents might be": 1.0,
    "might be needed": 0.16666666666666666,
    "be needed ,": 1.0,
    "needed , though": 1.0,
    ", though the": 0.16666666666666666,
    "though the textrank": 1.0,
    "the textrank results": 0.5,
    "textrank results show": 1.0,
    "results show the": 1.0,
    "show the additional": 1.0,
    "the additional features": 1.0,
    "additional features are": 1.0,
    "features are not": 0.3333333333333333,
    "are not absolutely": 0.2,
    "not absolutely necessary": 1.0,
    "absolutely necessary .": 1.0,
    "<s> another important": 0.07692307692307693,
    "another important distinction": 1.0,
    "important distinction is": 0.5,
    "distinction is that": 0.5,
    "is that textrank": 0.08333333333333333,
    "textrank was used": 0.5,
    "was used for": 0.25,
    "used for single": 0.06666666666666667,
    "for single document": 1.0,
    "single document summarization": 1.0,
    "summarization , while": 0.25,
    "while lexrank has": 0.3333333333333333,
    "lexrank has been": 1.0,
    "applied to multi-document": 0.09090909090909091,
    "to multi-document summarization": 1.0,
    "multi-document summarization .": 0.3333333333333333,
    "<s> the task": 0.013605442176870748,
    "the task remains": 0.09090909090909091,
    "task remains the": 1.0,
    "remains the same": 1.0,
    "the same in": 0.041666666666666664,
    "same in both": 1.0,
    "in both cases": 0.3333333333333333,
    "both cases --": 1.0,
    "cases -- only": 1.0,
    "-- only the": 1.0,
    "only the number": 0.25,
    "sentences to choose": 0.16666666666666666,
    "to choose from": 1.0,
    "choose from has": 1.0,
    "from has grown": 1.0,
    "has grown .": 1.0,
    "however , when": 0.022727272727272728,
    ", when summarizing": 0.16666666666666666,
    "when summarizing multiple": 1.0,
    "summarizing multiple documents": 1.0,
    "multiple documents ,": 0.5,
    "documents , there": 0.1111111111111111,
    "is a greater": 0.018518518518518517,
    "a greater risk": 1.0,
    "greater risk of": 1.0,
    "risk of selecting": 1.0,
    "of selecting duplicate": 1.0,
    "selecting duplicate or": 1.0,
    "duplicate or highly": 1.0,
    "or highly redundant": 1.0,
    "highly redundant sentences": 1.0,
    "redundant sentences to": 1.0,
    "place in the": 0.5,
    "the same summary": 0.041666666666666664,
    "same summary .": 1.0,
    "<s> imagine you": 1.0,
    "imagine you have": 1.0,
    "have a cluster": 0.07692307692307693,
    "of news articles": 0.5,
    "news articles on": 0.3333333333333333,
    "articles on a": 1.0,
    "on a particular": 0.041666666666666664,
    "a particular event": 0.25,
    "particular event ,": 1.0,
    "event , and": 0.5,
    "and you want": 0.3333333333333333,
    "you want to": 1.0,
    "want to produce": 0.2,
    "to produce one": 0.1,
    "produce one summary": 1.0,
    "one summary .": 1.0,
    "<s> each article": 0.2,
    "each article is": 1.0,
    "article is likely": 1.0,
    "likely to have": 0.14285714285714285,
    "to have many": 0.1,
    "have many similar": 0.2,
    "many similar sentences": 1.0,
    "similar sentences ,": 0.3333333333333333,
    "sentences , and": 0.25,
    "and you would": 0.3333333333333333,
    "you would only": 1.0,
    "would only want": 1.0,
    "only want to": 1.0,
    "want to include": 0.2,
    "to include distinct": 0.14285714285714285,
    "include distinct ideas": 1.0,
    "distinct ideas in": 1.0,
    "ideas in the": 0.5,
    "<s> to address": 0.125,
    "to address this": 1.0,
    "address this issue": 1.0,
    "this issue ,": 1.0,
    "issue , lexrank": 1.0,
    ", lexrank applies": 1.0,
    "lexrank applies a": 1.0,
    "applies a heuristic": 0.5,
    "a heuristic post-processing": 0.5,
    "heuristic post-processing step": 1.0,
    "post-processing step that": 0.5,
    "step that builds": 0.5,
    "that builds up": 1.0,
    "builds up a": 1.0,
    "up a summary": 0.5,
    "a summary by": 0.1111111111111111,
    "summary by adding": 1.0,
    "by adding sentences": 0.5,
    "adding sentences in": 1.0,
    "sentences in rank": 0.125,
    "in rank order": 1.0,
    "rank order ,": 1.0,
    "order , but": 0.5,
    ", but discards": 0.020833333333333332,
    "but discards any": 1.0,
    "discards any sentences": 1.0,
    "any sentences that": 1.0,
    "sentences that are": 0.6,
    "that are too": 0.06666666666666667,
    "are too similar": 1.0,
    "too similar to": 1.0,
    "similar to ones": 0.06666666666666667,
    "to ones already": 1.0,
    "ones already placed": 1.0,
    "already placed in": 1.0,
    "<s> the method": 0.006802721088435374,
    "the method used": 1.0,
    "method used is": 1.0,
    "used is called": 1.0,
    "is called cross-sentence": 0.16666666666666666,
    "called cross-sentence information": 1.0,
    "cross-sentence information subsumption": 1.0,
    "information subsumption -lrb-": 1.0,
    "subsumption -lrb- csis": 1.0,
    "-lrb- csis -rrb-": 1.0,
    "csis -rrb- .": 1.0,
    "<s> why unsupervised": 0.5,
    "why unsupervised summarization": 1.0,
    "unsupervised summarization works": 0.5,
    "summarization works these": 1.0,
    "works these methods": 1.0,
    "these methods work": 0.3333333333333333,
    "methods work based": 0.5,
    "work based on": 1.0,
    "on the idea": 0.014925373134328358,
    "idea that sentences": 0.5,
    "that sentences ``": 1.0,
    "sentences `` recommend": 0.5,
    "recommend '' other": 0.5,
    "'' other similar": 1.0,
    "other similar sentences": 1.0,
    "similar sentences to": 0.6666666666666666,
    "sentences to the": 0.16666666666666666,
    "thus , if": 0.09090909090909091,
    ", if one": 0.1,
    "if one sentence": 1.0,
    "one sentence is": 0.5,
    "sentence is very": 0.5,
    "is very similar": 0.3333333333333333,
    "very similar to": 0.75,
    "similar to many": 0.2,
    "to many others": 0.25,
    "many others ,": 1.0,
    "others , it": 1.0,
    "it will likely": 0.5,
    "will likely be": 0.5,
    "likely be a": 1.0,
    "be a sentence": 0.07692307692307693,
    "a sentence of": 0.07142857142857142,
    "sentence of great": 1.0,
    "of great importance": 1.0,
    "great importance .": 1.0,
    "<s> the importance": 0.006802721088435374,
    "importance of this": 0.25,
    "of this sentence": 0.09090909090909091,
    "this sentence also": 1.0,
    "sentence also stems": 1.0,
    "also stems from": 1.0,
    "stems from the": 1.0,
    "from the importance": 0.045454545454545456,
    "importance of the": 0.25,
    "of the sentences": 0.005128205128205128,
    "the sentences ``": 0.1111111111111111,
    "sentences `` recommending": 0.5,
    "`` recommending ''": 1.0,
    "recommending '' it": 1.0,
    "'' it .": 1.0,
    "thus , to": 0.09090909090909091,
    ", to get": 0.07692307692307693,
    "to get ranked": 0.25,
    "get ranked highly": 1.0,
    "ranked highly and": 0.5,
    "highly and placed": 1.0,
    "and placed in": 1.0,
    "placed in a": 0.3333333333333333,
    "a summary ,": 0.1111111111111111,
    "summary , a": 0.16666666666666666,
    ", a sentence": 0.020833333333333332,
    "a sentence must": 0.07142857142857142,
    "sentence must be": 1.0,
    "must be similar": 0.16666666666666666,
    "be similar to": 1.0,
    "to many sentences": 0.25,
    "many sentences that": 1.0,
    "that are in": 0.06666666666666667,
    "are in turn": 0.3333333333333333,
    "in turn also": 0.2,
    "turn also similar": 1.0,
    "also similar to": 1.0,
    "to many other": 0.25,
    "many other sentences": 0.2,
    "other sentences .": 1.0,
    "<s> this makes": 0.019230769230769232,
    "this makes intuitive": 0.5,
    "makes intuitive sense": 1.0,
    "intuitive sense and": 1.0,
    "sense and allows": 1.0,
    "and allows the": 0.5,
    "allows the algorithms": 0.3333333333333333,
    "the algorithms to": 0.25,
    "algorithms to be": 0.3333333333333333,
    "to be applied": 0.023255813953488372,
    "be applied to": 0.6666666666666666,
    "applied to any": 0.09090909090909091,
    "to any arbitrary": 0.3333333333333333,
    "any arbitrary new": 0.5,
    "arbitrary new text": 1.0,
    "new text .": 0.5,
    "<s> the methods": 0.006802721088435374,
    "the methods are": 0.3333333333333333,
    "methods are domain-independent": 0.5,
    "are domain-independent and": 1.0,
    "domain-independent and easily": 1.0,
    "and easily portable": 1.0,
    "easily portable .": 0.5,
    "<s> one could": 0.08333333333333333,
    "one could imagine": 1.0,
    "could imagine the": 1.0,
    "imagine the features": 1.0,
    "the features indicating": 0.16666666666666666,
    "features indicating important": 1.0,
    "indicating important sentences": 1.0,
    "important sentences in": 0.5,
    "in the news": 0.013071895424836602,
    "the news domain": 1.0,
    "news domain might": 0.3333333333333333,
    "domain might vary": 1.0,
    "might vary considerably": 1.0,
    "vary considerably from": 1.0,
    "considerably from the": 1.0,
    "from the biomedical": 0.045454545454545456,
    "the biomedical domain": 1.0,
    "biomedical domain .": 1.0,
    "however , the": 0.045454545454545456,
    ", the unsupervised": 0.009523809523809525,
    "the unsupervised ``": 0.5,
    "unsupervised `` recommendation": 1.0,
    "recommendation '' -": 0.5,
    "'' - based": 0.5,
    "- based approach": 0.3333333333333333,
    "based approach applies": 1.0,
    "approach applies to": 1.0,
    "applies to any": 1.0,
    "to any domain": 0.3333333333333333,
    "any domain .": 1.0,
    "<s> incorporating diversity": 1.0,
    "incorporating diversity :": 1.0,
    "diversity : grasshopper": 1.0,
    ": grasshopper algorithm": 1.0,
    "grasshopper algorithm as": 1.0,
    "algorithm as mentioned": 1.0,
    "as mentioned above": 0.25,
    "mentioned above ,": 1.0,
    "above , multi-document": 0.25,
    ", multi-document extractive": 1.0,
    "multi-document extractive summarization": 1.0,
    "extractive summarization faces": 0.3333333333333333,
    "summarization faces a": 1.0,
    "faces a problem": 1.0,
    "a problem of": 0.25,
    "problem of potential": 0.125,
    "of potential redundancy": 0.5,
    "potential redundancy .": 1.0,
    "ideally , we": 0.5,
    "we would like": 0.3333333333333333,
    "would like to": 1.0,
    "like to extract": 0.5,
    "to extract sentences": 0.3333333333333333,
    "extract sentences that": 1.0,
    "that are both": 0.13333333333333333,
    "are both ``": 0.5,
    "both `` central": 0.5,
    "central '' -lrb-": 0.5,
    "'' -lrb- i.e.": 0.2222222222222222,
    "i.e. , contain": 0.14285714285714285,
    ", contain the": 1.0,
    "contain the main": 0.5,
    "the main ideas": 0.2,
    "main ideas -rrb-": 1.0,
    "ideas -rrb- and": 1.0,
    "-rrb- and ``": 0.05,
    "and `` diverse": 0.05,
    "`` diverse ''": 1.0,
    "diverse '' -lrb-": 1.0,
    "i.e. , they": 0.14285714285714285,
    ", they differ": 0.125,
    "they differ from": 1.0,
    "differ from one": 1.0,
    "from one another": 0.3333333333333333,
    "one another -rrb-": 1.0,
    "another -rrb- .": 1.0,
    "<s> lexrank deals": 0.5,
    "lexrank deals with": 1.0,
    "deals with diversity": 0.25,
    "with diversity as": 1.0,
    "diversity as a": 1.0,
    "as a heuristic": 0.027777777777777776,
    "a heuristic final": 0.5,
    "heuristic final stage": 1.0,
    "final stage using": 1.0,
    "stage using csis": 1.0,
    "using csis ,": 1.0,
    "csis , and": 1.0,
    ", and other": 0.015873015873015872,
    "and other systems": 0.1111111111111111,
    "other systems have": 0.3333333333333333,
    "systems have used": 0.2,
    "have used similar": 0.5,
    "used similar methods": 1.0,
    "similar methods ,": 1.0,
    "methods , such": 0.25,
    "such as maximal": 0.011111111111111112,
    "as maximal marginal": 1.0,
    "maximal marginal relevance": 1.0,
    "marginal relevance -lrb-": 1.0,
    "relevance -lrb- mmr": 1.0,
    "-lrb- mmr -rrb-": 1.0,
    "mmr -rrb- ,": 1.0,
    "-rrb- , in": 0.01282051282051282,
    ", in trying": 0.029411764705882353,
    "in trying to": 1.0,
    "trying to eliminate": 0.2,
    "to eliminate redundancy": 0.5,
    "eliminate redundancy in": 1.0,
    "redundancy in information": 0.5,
    "in information retrieval": 1.0,
    "information retrieval results": 0.16666666666666666,
    "retrieval results .": 1.0,
    "<s> we have": 0.14285714285714285,
    "we have developed": 0.25,
    "have developed a": 1.0,
    "developed a general": 0.3333333333333333,
    "ranking algorithm like": 0.5,
    "algorithm like page\\/lex\\/textrank": 1.0,
    "like page\\/lex\\/textrank that": 1.0,
    "page\\/lex\\/textrank that handles": 1.0,
    "that handles both": 1.0,
    "handles both ``": 1.0,
    "both `` centrality": 0.5,
    "`` centrality ''": 1.0,
    "centrality '' and": 1.0,
    "and `` diversity": 0.05,
    "`` diversity ''": 1.0,
    "diversity '' in": 1.0,
    "'' in a": 0.14285714285714285,
    "in a unified": 0.019230769230769232,
    "a unified mathematical": 1.0,
    "unified mathematical framework": 1.0,
    "mathematical framework based": 1.0,
    "framework based on": 1.0,
    "based on absorbing": 0.021739130434782608,
    "on absorbing markov": 1.0,
    "absorbing markov chain": 1.0,
    "markov chain random": 1.0,
    "chain random walks": 1.0,
    "random walks .": 0.5,
    "-lrb- an absorbing": 0.5,
    "an absorbing random": 1.0,
    "absorbing random walk": 1.0,
    "random walk is": 0.25,
    "walk is like": 1.0,
    "is like a": 1.0,
    "like a standard": 0.5,
    "a standard random": 0.3333333333333333,
    "standard random walk": 1.0,
    "random walk ,": 0.25,
    "walk , except": 1.0,
    ", except some": 1.0,
    "except some states": 1.0,
    "some states are": 1.0,
    "states are now": 1.0,
    "are now absorbing": 0.25,
    "now absorbing states": 1.0,
    "absorbing states that": 1.0,
    "states that act": 1.0,
    "that act as": 1.0,
    "act as ``": 0.3333333333333333,
    "as `` black": 0.07142857142857142,
    "`` black holes": 1.0,
    "black holes ''": 1.0,
    "holes '' that": 1.0,
    "'' that cause": 0.25,
    "that cause the": 1.0,
    "cause the walk": 1.0,
    "the walk to": 1.0,
    "walk to end": 1.0,
    "to end abruptly": 0.5,
    "end abruptly at": 1.0,
    "abruptly at that": 1.0,
    "at that state": 1.0,
    "that state .": 1.0,
    "state . -rrb-": 1.0,
    "<s> the algorithm": 0.006802721088435374,
    "algorithm is called": 0.2,
    "is called grasshopper": 0.16666666666666666,
    "called grasshopper for": 1.0,
    "grasshopper for reasons": 1.0,
    "for reasons that": 1.0,
    "reasons that should": 1.0,
    "that should soon": 0.5,
    "should soon become": 1.0,
    "soon become clear": 1.0,
    "become clear .": 1.0,
    "in addition to": 0.5,
    "addition to explicitly": 0.3333333333333333,
    "to explicitly promoting": 0.5,
    "explicitly promoting diversity": 1.0,
    "promoting diversity during": 1.0,
    "diversity during the": 1.0,
    "during the ranking": 0.16666666666666666,
    "the ranking process": 0.5,
    "ranking process ,": 1.0,
    "process , grasshopper": 1.0,
    ", grasshopper incorporates": 1.0,
    "grasshopper incorporates a": 1.0,
    "incorporates a prior": 1.0,
    "a prior ranking": 1.0,
    "prior ranking -lrb-": 1.0,
    "ranking -lrb- based": 1.0,
    "-lrb- based on": 0.5,
    "based on sentence": 0.021739130434782608,
    "on sentence position": 1.0,
    "sentence position in": 0.5,
    "case of summarization": 0.16666666666666666,
    "of summarization -rrb-": 0.125,
    "summarization -rrb- .": 0.6666666666666666,
    "<s> maximum entropy-based": 0.5,
    "maximum entropy-based summarization": 1.0,
    "entropy-based summarization it": 1.0,
    "summarization it is": 1.0,
    "it is an": 0.02127659574468085,
    "is an abstractive": 0.1,
    "an abstractive method": 0.5,
    "abstractive method .": 1.0,
    "<s> even though": 1.0,
    "even though automating": 0.3333333333333333,
    "though automating abstractive": 1.0,
    "automating abstractive summarization": 1.0,
    "abstractive summarization is": 0.5,
    "is the goal": 0.022222222222222223,
    "goal of summarization": 0.5,
    "of summarization research": 0.125,
    "summarization research ,": 1.0,
    "research , most": 0.25,
    ", most practical": 0.125,
    "most practical systems": 1.0,
    "practical systems are": 1.0,
    "systems are based": 0.15384615384615385,
    "form of extractive": 0.14285714285714285,
    "of extractive summarization": 1.0,
    "extractive summarization .": 0.3333333333333333,
    "<s> extracted sentences": 1.0,
    "extracted sentences can": 1.0,
    "sentences can form": 0.3333333333333333,
    "can form a": 1.0,
    "form a valid": 0.3333333333333333,
    "a valid summary": 1.0,
    "valid summary in": 1.0,
    "summary in itself": 0.5,
    "in itself or": 1.0,
    "itself or form": 1.0,
    "or form a": 1.0,
    "form a basis": 0.3333333333333333,
    "a basis for": 0.5,
    "basis for further": 0.5,
    "for further condensation": 0.3333333333333333,
    "further condensation operations": 1.0,
    "condensation operations .": 1.0,
    "furthermore , evaluation": 0.16666666666666666,
    ", evaluation of": 1.0,
    "evaluation of extracted": 0.2,
    "of extracted summaries": 1.0,
    "extracted summaries can": 1.0,
    "summaries can be": 0.5,
    "can be automated": 0.01098901098901099,
    "be automated ,": 1.0,
    "automated , since": 1.0,
    ", since it": 0.2,
    "since it is": 0.5,
    "essentially a classification": 0.5,
    "a classification task": 1.0,
    "classification task .": 1.0,
    "during the duc": 0.16666666666666666,
    "the duc 2001": 1.0,
    "duc 2001 and": 1.0,
    "2001 and 2002": 1.0,
    "and 2002 evaluation": 1.0,
    "2002 evaluation workshops": 1.0,
    "evaluation workshops ,": 1.0,
    "workshops , tno": 1.0,
    ", tno developed": 1.0,
    "tno developed a": 1.0,
    "developed a sentence": 0.3333333333333333,
    "a sentence extraction": 0.07142857142857142,
    "sentence extraction system": 1.0,
    "extraction system for": 0.5,
    "system for multi-document": 0.5,
    "for multi-document summarization": 1.0,
    "multi-document summarization in": 0.3333333333333333,
    "summarization in the": 1.0,
    "news domain .": 0.6666666666666666,
    "<s> the system": 0.04081632653061224,
    "the system was": 0.038461538461538464,
    "system was based": 0.2,
    "was based on": 1.0,
    "on a hybrid": 0.041666666666666664,
    "a hybrid system": 0.5,
    "hybrid system using": 1.0,
    "system using a": 1.0,
    "using a naive": 0.1,
    "a naive bayes": 1.0,
    "naive bayes classifier": 0.5,
    "bayes classifier and": 1.0,
    "classifier and statistical": 1.0,
    "and statistical language": 0.3333333333333333,
    "statistical language models": 1.0,
    "language models for": 0.5,
    "models for modeling": 0.16666666666666666,
    "for modeling salience": 1.0,
    "modeling salience .": 1.0,
    "although the system": 0.3333333333333333,
    "the system exhibited": 0.038461538461538464,
    "system exhibited good": 1.0,
    "exhibited good results": 1.0,
    "good results ,": 1.0,
    "results , we": 0.5,
    ", we wanted": 0.058823529411764705,
    "we wanted to": 1.0,
    "wanted to explore": 1.0,
    "to explore the": 0.5,
    "explore the effectiveness": 1.0,
    "the effectiveness of": 1.0,
    "effectiveness of a": 1.0,
    "of a maximum": 0.010869565217391304,
    "a maximum entropy": 1.0,
    "maximum entropy -lrb-": 0.2,
    "entropy -lrb- me": 1.0,
    "-lrb- me -rrb-": 1.0,
    "me -rrb- classifier": 1.0,
    "-rrb- classifier for": 1.0,
    "classifier for the": 1.0,
    "for the meeting": 0.03125,
    "the meeting summarization": 1.0,
    "meeting summarization task": 1.0,
    "summarization task ,": 1.0,
    "task , as": 0.25,
    ", as me": 0.043478260869565216,
    "as me is": 1.0,
    "me is known": 1.0,
    "is known to": 0.6666666666666666,
    "known to be": 1.0,
    "to be robust": 0.023255813953488372,
    "be robust against": 1.0,
    "robust against feature": 1.0,
    "against feature dependencies": 1.0,
    "feature dependencies .": 1.0,
    "<s> maximum entropy": 0.5,
    "maximum entropy has": 0.2,
    "entropy has also": 1.0,
    "has also been": 1.0,
    "also been applied": 0.5,
    "been applied successfully": 0.16666666666666666,
    "applied successfully for": 1.0,
    "successfully for summarization": 1.0,
    "for summarization in": 1.0,
    "in the broadcast": 0.006535947712418301,
    "the broadcast news": 1.0,
    "broadcast news domain": 1.0,
    "<s> aided summarization": 1.0,
    "aided summarization machine": 1.0,
    "summarization machine learning": 1.0,
    "machine learning techniques": 0.047619047619047616,
    "learning techniques from": 1.0,
    "techniques from closely": 1.0,
    "from closely related": 1.0,
    "closely related fields": 0.5,
    "related fields such": 1.0,
    "fields such as": 1.0,
    "such as information": 0.011111111111111112,
    "as information retrieval": 1.0,
    "information retrieval or": 0.16666666666666666,
    "retrieval or text": 1.0,
    "or text mining": 0.5,
    "text mining have": 0.5,
    "mining have been": 1.0,
    "have been successfully": 0.038461538461538464,
    "been successfully adapted": 1.0,
    "successfully adapted to": 1.0,
    "adapted to help": 1.0,
    "to help automatic": 0.5,
    "help automatic summarization": 1.0,
    "<s> apart from": 1.0,
    "apart from fully": 1.0,
    "from fully automated": 1.0,
    "fully automated summarizers": 1.0,
    "automated summarizers -lrb-": 1.0,
    "summarizers -lrb- fas": 1.0,
    "-lrb- fas -rrb-": 1.0,
    "fas -rrb- ,": 1.0,
    "-rrb- , there": 0.01282051282051282,
    ", there are": 0.2727272727272727,
    "there are systems": 0.09523809523809523,
    "are systems that": 1.0,
    "systems that aid": 0.09090909090909091,
    "that aid users": 1.0,
    "aid users with": 1.0,
    "users with the": 1.0,
    "with the task": 0.03333333333333333,
    "task of summarization": 0.1111111111111111,
    "of summarization -lrb-": 0.125,
    "summarization -lrb- mahs": 0.5,
    "-lrb- mahs =": 1.0,
    "mahs = machine": 1.0,
    "= machine aided": 1.0,
    "machine aided human": 1.0,
    "aided human summarization": 1.0,
    "human summarization -rrb-": 1.0,
    "summarization -rrb- ,": 0.3333333333333333,
    "-rrb- , for": 0.01282051282051282,
    "for example by": 0.03571428571428571,
    "example by highlighting": 0.5,
    "by highlighting candidate": 1.0,
    "highlighting candidate passages": 1.0,
    "candidate passages to": 1.0,
    "passages to be": 1.0,
    "to be included": 0.023255813953488372,
    "be included in": 1.0,
    "included in the": 1.0,
    "the summary ,": 0.125,
    "summary , and": 0.3333333333333333,
    ", and there": 0.015873015873015872,
    "and there are": 0.5,
    "systems that depend": 0.09090909090909091,
    "that depend on": 1.0,
    "depend on post-processing": 0.3333333333333333,
    "on post-processing by": 1.0,
    "post-processing by a": 1.0,
    "a human -lrb-": 0.09090909090909091,
    "human -lrb- hams": 0.5,
    "-lrb- hams =": 1.0,
    "hams = human": 1.0,
    "= human aided": 1.0,
    "human aided machine": 1.0,
    "aided machine summarization": 1.0,
    "machine summarization -rrb-": 1.0,
    "<s> evaluation an": 0.2,
    "evaluation an ongoing": 1.0,
    "an ongoing issue": 1.0,
    "ongoing issue in": 1.0,
    "issue in this": 1.0,
    "in this field": 0.13333333333333333,
    "this field is": 0.5,
    "field is that": 1.0,
    "is that of": 0.08333333333333333,
    "that of evaluation": 0.125,
    "of evaluation .": 0.2,
    "<s> evaluation techniques": 0.2,
    "evaluation techniques fall": 1.0,
    "techniques fall into": 1.0,
    "fall into intrinsic": 0.5,
    "into intrinsic and": 1.0,
    "intrinsic and extrinsic": 1.0,
    "and extrinsic ,": 1.0,
    "extrinsic , inter-texual": 1.0,
    ", inter-texual and": 1.0,
    "inter-texual and intra-texual": 1.0,
    "and intra-texual .": 1.0,
    "intrinsic evaluation tests": 0.3333333333333333,
    "evaluation tests the": 1.0,
    "tests the summarization": 1.0,
    "the summarization system": 0.3333333333333333,
    "summarization system in": 0.3333333333333333,
    "system in of": 0.5,
    "in of itself": 1.0,
    "of itself while": 1.0,
    "itself while an": 1.0,
    "while an extrinsic": 1.0,
    "extrinsic evaluation tests": 0.25,
    "the summarization based": 0.3333333333333333,
    "summarization based on": 1.0,
    "based on how": 0.021739130434782608,
    "on how it": 1.0,
    "how it affects": 0.5,
    "it affects the": 1.0,
    "affects the completion": 1.0,
    "the completion of": 1.0,
    "completion of some": 1.0,
    "some other task": 0.14285714285714285,
    "other task .": 1.0,
    "<s> intrinsic evaluations": 0.5,
    "intrinsic evaluations have": 1.0,
    "evaluations have assessed": 1.0,
    "have assessed mainly": 1.0,
    "assessed mainly the": 1.0,
    "mainly the coherence": 1.0,
    "the coherence and": 1.0,
    "coherence and informativeness": 0.5,
    "and informativeness of": 1.0,
    "informativeness of summaries": 0.5,
    "of summaries .": 0.25,
    "<s> extrinsic evaluations": 0.5,
    "extrinsic evaluations ,": 1.0,
    "evaluations , on": 1.0,
    ", on the": 0.8571428571428571,
    "hand , have": 0.14285714285714285,
    ", have tested": 0.5,
    "have tested the": 1.0,
    "tested the impact": 1.0,
    "the impact of": 0.5,
    "impact of summarization": 1.0,
    "of summarization on": 0.125,
    "summarization on tasks": 1.0,
    "tasks like relevance": 0.5,
    "like relevance assessment": 1.0,
    "relevance assessment ,": 1.0,
    "assessment , reading": 1.0,
    ", reading comprehension": 1.0,
    "reading comprehension ,": 0.5,
    "comprehension , etc.": 1.0,
    "<s> intra-texual methods": 1.0,
    "intra-texual methods assess": 1.0,
    "methods assess the": 1.0,
    "assess the output": 1.0,
    "output of a": 0.25,
    "of a specific": 0.010869565217391304,
    "a specific summarization": 0.2,
    "specific summarization system": 1.0,
    "summarization system ,": 0.3333333333333333,
    "system , and": 0.1,
    "and the inter-texual": 0.024390243902439025,
    "the inter-texual ones": 1.0,
    "inter-texual ones focus": 1.0,
    "ones focus on": 1.0,
    "focus on contrastive": 0.25,
    "on contrastive analysis": 1.0,
    "contrastive analysis of": 1.0,
    "analysis of outputs": 0.07692307692307693,
    "of outputs of": 1.0,
    "outputs of several": 1.0,
    "of several summarization": 0.3333333333333333,
    "several summarization systems": 1.0,
    "<s> human judgement": 0.25,
    "human judgement often": 1.0,
    "judgement often has": 1.0,
    "often has wide": 0.5,
    "has wide variance": 1.0,
    "wide variance on": 1.0,
    "variance on what": 1.0,
    "on what is": 0.3333333333333333,
    "what is considered": 0.16666666666666666,
    "is considered a": 0.5,
    "considered a ``": 1.0,
    "a `` good": 0.16666666666666666,
    "`` good ''": 1.0,
    "good '' summary": 1.0,
    "'' summary ,": 1.0,
    "summary , which": 0.16666666666666666,
    "means that making": 0.25,
    "that making the": 1.0,
    "making the evaluation": 0.5,
    "the evaluation process": 0.2,
    "evaluation process automatic": 1.0,
    "process automatic is": 1.0,
    "automatic is particularly": 1.0,
    "is particularly difficult": 0.5,
    "particularly difficult .": 1.0,
    "manual evaluation can": 0.3333333333333333,
    "used , but": 0.125,
    "but this is": 0.25,
    "this is both": 0.038461538461538464,
    "is both time": 1.0,
    "both time and": 1.0,
    "time and labor": 0.3333333333333333,
    "and labor intensive": 1.0,
    "labor intensive as": 1.0,
    "intensive as it": 1.0,
    "as it requires": 1.0,
    "it requires humans": 0.5,
    "requires humans to": 1.0,
    "humans to read": 1.0,
    "to read not": 1.0,
    "read not only": 1.0,
    "only the summaries": 0.25,
    "the summaries but": 0.25,
    "summaries but also": 1.0,
    "but also the": 0.3333333333333333,
    "also the source": 0.5,
    "the source documents": 0.16666666666666666,
    "source documents .": 0.6666666666666666,
    "<s> other issues": 0.14285714285714285,
    "other issues are": 1.0,
    "issues are those": 1.0,
    "are those concerning": 1.0,
    "those concerning coherence": 1.0,
    "concerning coherence and": 1.0,
    "coherence and coverage": 0.5,
    "and coverage .": 1.0,
    "<s> one of": 0.16666666666666666,
    "of the metrics": 0.005128205128205128,
    "the metrics used": 1.0,
    "metrics used in": 1.0,
    "used in nist": 0.043478260869565216,
    "in nist 's": 1.0,
    "nist 's annual": 1.0,
    "'s annual document": 1.0,
    "annual document understanding": 1.0,
    "document understanding conferences": 1.0,
    "understanding conferences ,": 1.0,
    "conferences , in": 1.0,
    ", in which": 0.029411764705882353,
    "in which research": 0.125,
    "which research groups": 1.0,
    "research groups submit": 1.0,
    "groups submit their": 1.0,
    "submit their systems": 1.0,
    "their systems for": 0.5,
    "systems for both": 0.5,
    "for both summarization": 1.0,
    "both summarization and": 1.0,
    "summarization and translation": 1.0,
    "and translation tasks": 0.3333333333333333,
    "translation tasks ,": 1.0,
    "tasks , is": 0.25,
    ", is the": 0.46153846153846156,
    "is the rouge": 0.022222222222222223,
    "the rouge metric": 1.0,
    "rouge metric -lrb-": 1.0,
    "metric -lrb- recall-oriented": 1.0,
    "evaluation -rrb- .": 0.5,
    "<s> it essentially": 0.029411764705882353,
    "it essentially calculates": 1.0,
    "essentially calculates n-gram": 1.0,
    "calculates n-gram overlaps": 1.0,
    "n-gram overlaps between": 1.0,
    "overlaps between automatically": 1.0,
    "between automatically generated": 1.0,
    "automatically generated summaries": 0.3333333333333333,
    "generated summaries and": 1.0,
    "summaries and previously-written": 0.5,
    "and previously-written human": 1.0,
    "previously-written human summaries": 1.0,
    "human summaries .": 1.0,
    "<s> a high": 0.022727272727272728,
    "a high level": 0.5,
    "high level of": 1.0,
    "level of overlap": 0.14285714285714285,
    "of overlap should": 1.0,
    "overlap should indicate": 1.0,
    "should indicate a": 1.0,
    "indicate a high": 1.0,
    "level of shared": 0.14285714285714285,
    "of shared concepts": 1.0,
    "shared concepts between": 1.0,
    "concepts between the": 1.0,
    "the two summaries": 0.14285714285714285,
    "two summaries .": 1.0,
    "note that overlap": 0.14285714285714285,
    "that overlap metrics": 1.0,
    "overlap metrics like": 1.0,
    "metrics like this": 1.0,
    "like this are": 1.0,
    "this are unable": 0.5,
    "are unable to": 1.0,
    "unable to provide": 0.5,
    "to provide any": 0.25,
    "provide any feedback": 1.0,
    "any feedback on": 1.0,
    "feedback on a": 1.0,
    "on a summary": 0.041666666666666664,
    "a summary 's": 0.1111111111111111,
    "summary 's coherence": 0.5,
    "'s coherence .": 1.0,
    "<s> anaphor resolution": 1.0,
    "anaphor resolution remains": 1.0,
    "resolution remains another": 1.0,
    "remains another problem": 1.0,
    "another problem yet": 0.5,
    "problem yet to": 1.0,
    "yet to be": 1.0,
    "to be fully": 0.023255813953488372,
    "be fully solved": 0.5,
    "fully solved .": 1.0,
    "<s> evaluating summaries": 1.0,
    "evaluating summaries ,": 0.25,
    "summaries , either": 0.3333333333333333,
    ", either manually": 0.5,
    "either manually or": 1.0,
    "manually or automatically": 1.0,
    "or automatically ,": 0.5,
    "automatically , is": 1.0,
    "is a hard": 0.037037037037037035,
    "a hard task": 0.5,
    "hard task .": 1.0,
    "difficulty in evaluation": 0.5,
    "in evaluation comes": 1.0,
    "evaluation comes from": 1.0,
    "comes from the": 0.5,
    "from the impossibility": 0.045454545454545456,
    "the impossibility of": 1.0,
    "impossibility of building": 1.0,
    "of building a": 1.0,
    "building a fair": 1.0,
    "a fair gold-standard": 1.0,
    "fair gold-standard against": 1.0,
    "gold-standard against which": 1.0,
    "against which the": 1.0,
    "which the results": 0.125,
    "the results of": 0.2,
    "results of the": 1.0,
    "of the systems": 0.005128205128205128,
    "the systems can": 0.25,
    "systems can be": 0.6666666666666666,
    "can be compared": 0.01098901098901099,
    "be compared .": 1.0,
    "furthermore , it": 0.16666666666666666,
    "it is also": 0.0425531914893617,
    "is also very": 0.2,
    "also very hard": 0.5,
    "very hard to": 1.0,
    "hard to determine": 0.3333333333333333,
    "to determine what": 0.09090909090909091,
    "determine what a": 1.0,
    "what a correct": 0.3333333333333333,
    "a correct summary": 0.5,
    "correct summary is": 1.0,
    "summary is ,": 0.5,
    "is , because": 0.1111111111111111,
    ", because there": 0.25,
    "because there is": 0.5,
    "there is always": 0.058823529411764705,
    "is always the": 0.5,
    "always the possibility": 1.0,
    "possibility of a": 0.3333333333333333,
    "a system to": 0.1,
    "system to generate": 0.2,
    "to generate a": 0.16666666666666666,
    "generate a good": 0.16666666666666666,
    "a good summary": 0.2,
    "good summary that": 0.5,
    "that is quite": 0.05263157894736842,
    "is quite different": 1.0,
    "quite different from": 0.6666666666666666,
    "different from any": 0.16666666666666666,
    "from any human": 1.0,
    "any human summary": 1.0,
    "human summary used": 1.0,
    "summary used as": 1.0,
    "used as an": 0.2,
    "as an approximation": 0.06666666666666667,
    "an approximation to": 0.5,
    "approximation to the": 1.0,
    "to the correct": 0.012987012987012988,
    "the correct output": 0.16666666666666666,
    "correct output .": 1.0,
    "<s> current difficulties": 0.3333333333333333,
    "current difficulties in": 1.0,
    "difficulties in evaluating": 1.0,
    "in evaluating summaries": 1.0,
    "evaluating summaries automatically": 0.25,
    "summaries automatically the": 1.0,
    "automatically the most": 0.5,
    "common way to": 0.5,
    "way to evaluate": 0.2,
    "to evaluate the": 0.5,
    "evaluate the informativeness": 0.5,
    "the informativeness of": 1.0,
    "informativeness of automatic": 0.5,
    "of automatic summaries": 1.0,
    "automatic summaries is": 0.3333333333333333,
    "summaries is to": 0.3333333333333333,
    "is to compare": 0.05263157894736842,
    "to compare them": 0.25,
    "compare them with": 1.0,
    "them with human-made": 1.0,
    "with human-made model": 1.0,
    "human-made model summaries": 1.0,
    "model summaries .": 0.5,
    "however , as": 0.022727272727272728,
    ", as content": 0.043478260869565216,
    "as content selection": 1.0,
    "content selection is": 1.0,
    "selection is not": 1.0,
    "is not a": 0.05263157894736842,
    "not a deterministic": 1.0,
    "a deterministic problem": 0.5,
    "deterministic problem ,": 1.0,
    "problem , different": 0.25,
    ", different people": 0.3333333333333333,
    "different people would": 1.0,
    "people would choose": 1.0,
    "would choose different": 1.0,
    "choose different sentences": 1.0,
    "different sentences ,": 0.3333333333333333,
    "and even ,": 0.16666666666666666,
    "even , the": 1.0,
    ", the same": 0.009523809523809525,
    "the same person": 0.041666666666666664,
    "same person may": 1.0,
    "person may chose": 1.0,
    "may chose different": 1.0,
    "chose different sentences": 1.0,
    "different sentences at": 0.3333333333333333,
    "sentences at different": 1.0,
    "at different times": 1.0,
    "different times ,": 1.0,
    "times , showing": 1.0,
    ", showing evidence": 1.0,
    "showing evidence of": 1.0,
    "evidence of low": 1.0,
    "of low agreement": 1.0,
    "low agreement among": 1.0,
    "agreement among humans": 1.0,
    "among humans as": 1.0,
    "humans as to": 1.0,
    "to which sentences": 0.2,
    "which sentences are": 1.0,
    "sentences are good": 0.14285714285714285,
    "are good summary": 1.0,
    "good summary sentences": 0.5,
    "summary sentences .": 1.0,
    "<s> besides the": 1.0,
    "besides the human": 1.0,
    "the human variability": 0.25,
    "human variability ,": 1.0,
    "variability , the": 1.0,
    ", the semantic": 0.009523809523809525,
    "the semantic equivalence": 0.5,
    "semantic equivalence is": 1.0,
    "equivalence is another": 1.0,
    "is another problem": 0.5,
    "another problem ,": 0.5,
    "problem , because": 0.25,
    ", because two": 0.125,
    "because two distinct": 1.0,
    "two distinct sentences": 1.0,
    "distinct sentences can": 1.0,
    "sentences can express": 0.3333333333333333,
    "express the same": 0.5,
    "the same meaning": 0.041666666666666664,
    "same meaning but": 1.0,
    "meaning but not": 1.0,
    "but not using": 0.25,
    "not using the": 1.0,
    "using the same": 0.14285714285714285,
    "the same words": 0.041666666666666664,
    "same words .": 1.0,
    "<s> this phenomenon": 0.038461538461538464,
    "this phenomenon is": 0.5,
    "phenomenon is known": 1.0,
    "is known as": 0.3333333333333333,
    "known as paraphrase": 0.1,
    "as paraphrase .": 1.0,
    "we can find": 0.2,
    "can find an": 1.0,
    "find an approach": 0.5,
    "an approach to": 0.25,
    "approach to automatically": 0.16666666666666666,
    "to automatically evaluating": 0.16666666666666666,
    "automatically evaluating summaries": 1.0,
    "evaluating summaries using": 0.25,
    "summaries using paraphrases": 1.0,
    "using paraphrases -lrb-": 1.0,
    "paraphrases -lrb- paraeval": 1.0,
    "-lrb- paraeval -rrb-": 1.0,
    "paraeval -rrb- .": 1.0,
    "<s> moreover ,": 1.0,
    "moreover , most": 0.25,
    ", most summarization": 0.125,
    "most summarization systems": 1.0,
    "summarization systems perform": 0.16666666666666666,
    "systems perform an": 1.0,
    "perform an extractive": 1.0,
    "an extractive approach": 0.5,
    "extractive approach ,": 1.0,
    "approach , selecting": 0.5,
    ", selecting and": 1.0,
    "selecting and copying": 1.0,
    "and copying important": 1.0,
    "copying important sentences": 1.0,
    "important sentences from": 0.5,
    "sentences from the": 0.5,
    "from the source": 0.045454545454545456,
    "<s> although humans": 0.14285714285714285,
    "although humans can": 1.0,
    "humans can also": 1.0,
    "can also cut": 0.125,
    "also cut and": 1.0,
    "cut and paste": 1.0,
    "and paste relevant": 1.0,
    "paste relevant information": 1.0,
    "relevant information of": 1.0,
    "information of a": 1.0,
    "text , most": 0.03333333333333333,
    ", most of": 0.125,
    "of the times": 0.005128205128205128,
    "the times they": 1.0,
    "times they rephrase": 1.0,
    "they rephrase sentences": 1.0,
    "rephrase sentences when": 1.0,
    "sentences when necessary": 1.0,
    "when necessary ,": 1.0,
    "necessary , or": 1.0,
    ", or they": 0.030303030303030304,
    "or they join": 1.0,
    "they join different": 1.0,
    "join different related": 1.0,
    "different related information": 1.0,
    "related information into": 1.0,
    "information into one": 0.5,
    "into one sentence": 0.5,
    "one sentence .": 0.5,
    "evaluating summaries qualitatively": 0.25,
    "summaries qualitatively the": 1.0,
    "qualitatively the main": 1.0,
    "the main drawback": 0.2,
    "main drawback of": 1.0,
    "drawback of the": 1.0,
    "of the evaluation": 0.005128205128205128,
    "the evaluation systems": 0.2,
    "evaluation systems existing": 1.0,
    "systems existing so": 1.0,
    "existing so far": 1.0,
    "so far is": 0.5,
    "far is that": 1.0,
    "is that we": 0.08333333333333333,
    "that we need": 0.3333333333333333,
    "we need at": 0.16666666666666666,
    "need at least": 1.0,
    "at least one": 0.2,
    "least one reference": 1.0,
    "one reference summary": 1.0,
    ", and for": 0.005291005291005291,
    "and for some": 1.0,
    "for some methods": 0.3333333333333333,
    "some methods more": 0.5,
    "methods more than": 1.0,
    "than one ,": 0.3333333333333333,
    "one , to": 0.25,
    ", to be": 0.07692307692307693,
    "able to compare": 0.0625,
    "to compare automatic": 0.25,
    "compare automatic summaries": 1.0,
    "automatic summaries with": 0.3333333333333333,
    "summaries with models": 0.5,
    "with models .": 1.0,
    "a hard and": 0.5,
    "hard and expensive": 1.0,
    "and expensive task": 0.5,
    "expensive task .": 1.0,
    "<s> much effort": 0.3333333333333333,
    "much effort has": 1.0,
    "effort has to": 1.0,
    "has to be": 0.8,
    "be done in": 0.4,
    "done in order": 0.2,
    "order to have": 0.125,
    "to have corpus": 0.1,
    "have corpus of": 1.0,
    "corpus of texts": 0.125,
    "of texts and": 0.5,
    "texts and their": 1.0,
    "and their corresponding": 0.16666666666666666,
    "their corresponding summaries": 1.0,
    "corresponding summaries .": 1.0,
    "furthermore , for": 0.16666666666666666,
    ", for some": 0.045454545454545456,
    "some methods presented": 0.5,
    "methods presented in": 1.0,
    "presented in the": 0.3333333333333333,
    "in the previous": 0.006535947712418301,
    "the previous section": 0.5,
    "previous section ,": 1.0,
    "section , not": 1.0,
    ", not only": 0.2857142857142857,
    "not only do": 0.14285714285714285,
    "only do we": 1.0,
    "do we need": 1.0,
    "to have human-made": 0.1,
    "have human-made summaries": 1.0,
    "human-made summaries available": 1.0,
    "summaries available for": 1.0,
    "available for comparison": 0.5,
    "for comparison ,": 1.0,
    "comparison , but": 1.0,
    "but also manual": 0.16666666666666666,
    "also manual annotation": 1.0,
    "manual annotation has": 1.0,
    "annotation has to": 1.0,
    "to be performed": 0.023255813953488372,
    "be performed in": 0.5,
    "performed in some": 0.5,
    "in some of": 0.125,
    "some of them": 0.058823529411764705,
    "of them -lrb-": 0.5,
    "them -lrb- e.g.": 1.0,
    "-lrb- e.g. scu": 0.02631578947368421,
    "e.g. scu in": 1.0,
    "scu in the": 1.0,
    "in the pyramid": 0.006535947712418301,
    "the pyramid method": 1.0,
    "pyramid method -rrb-": 1.0,
    "method -rrb- .": 1.0,
    "<s> in any": 0.020618556701030927,
    "any case ,": 0.6666666666666666,
    "case , what": 0.3333333333333333,
    ", what the": 0.5,
    "what the evaluation": 0.25,
    "the evaluation methods": 0.2,
    "evaluation methods need": 1.0,
    "methods need as": 0.5,
    "need as an": 1.0,
    "as an input": 0.06666666666666667,
    "an input ,": 0.3333333333333333,
    "input , is": 0.3333333333333333,
    "set of summaries": 0.03571428571428571,
    "of summaries to": 0.25,
    "summaries to serve": 0.5,
    "to serve as": 1.0,
    "serve as gold": 0.25,
    "as gold standards": 1.0,
    "gold standards and": 1.0,
    "standards and a": 1.0,
    "and a set": 0.0625,
    "set of automatic": 0.03571428571428571,
    "automatic summaries .": 0.3333333333333333,
    "moreover , they": 0.25,
    "they all perform": 0.5,
    "all perform a": 1.0,
    "perform a quantitative": 0.3333333333333333,
    "a quantitative evaluation": 0.5,
    "quantitative evaluation with": 0.5,
    "evaluation with regard": 1.0,
    "regard to different": 0.25,
    "to different similarity": 1.0,
    "different similarity metrics": 1.0,
    "similarity metrics .": 1.0,
    "<s> to overcome": 0.125,
    "to overcome these": 0.5,
    "overcome these problems": 1.0,
    "these problems ,": 1.0,
    "problems , we": 0.16666666666666666,
    ", we think": 0.058823529411764705,
    "we think that": 1.0,
    "think that the": 1.0,
    "that the quantitative": 0.043478260869565216,
    "the quantitative evaluation": 1.0,
    "quantitative evaluation might": 0.5,
    "evaluation might not": 1.0,
    "might not be": 0.5,
    "not be the": 0.08333333333333333,
    "be the only": 0.3333333333333333,
    "the only way": 0.3333333333333333,
    "only way to": 1.0,
    "to evaluate summaries": 0.25,
    "evaluate summaries ,": 1.0,
    "summaries , and": 0.3333333333333333,
    "and a qualitative": 0.0625,
    "a qualitative automatic": 0.5,
    "qualitative automatic evaluation": 1.0,
    "automatic evaluation would": 0.3333333333333333,
    "evaluation would be": 0.3333333333333333,
    "would be also": 0.1111111111111111,
    "be also important": 1.0,
    "also important .": 1.0,
    "<s> therefore ,": 1.0,
    "therefore , the": 0.5,
    ", the second": 0.009523809523809525,
    "the second aim": 0.3333333333333333,
    "second aim of": 1.0,
    "aim of this": 1.0,
    "of this paper": 0.09090909090909091,
    "this paper is": 1.0,
    "paper is to": 1.0,
    "is to suggest": 0.05263157894736842,
    "to suggest a": 1.0,
    "suggest a novel": 1.0,
    "a novel proposal": 1.0,
    "novel proposal for": 1.0,
    "proposal for evaluating": 1.0,
    "for evaluating automatically": 0.3333333333333333,
    "evaluating automatically the": 1.0,
    "automatically the quality": 0.5,
    "of a summary": 0.010869565217391304,
    "a summary in": 0.1111111111111111,
    "summary in a": 0.5,
    "in a qualitative": 0.019230769230769232,
    "a qualitative manner": 0.5,
    "qualitative manner rather": 1.0,
    "manner rather than": 1.0,
    "rather than in": 0.07142857142857142,
    "than in a": 1.0,
    "in a quantitative": 0.019230769230769232,
    "a quantitative one": 0.5,
    "quantitative one .": 1.0,
    "<s> our evaluation": 0.3333333333333333,
    "our evaluation approach": 1.0,
    "evaluation approach is": 1.0,
    "approach is a": 0.2,
    "is a preliminary": 0.018518518518518517,
    "a preliminary approach": 1.0,
    "preliminary approach which": 1.0,
    "approach which has": 0.5,
    "which has to": 0.14285714285714285,
    "to be studied": 0.023255813953488372,
    "be studied more": 1.0,
    "studied more deeply": 1.0,
    "more deeply ,": 1.0,
    "deeply , and": 1.0,
    ", and developed": 0.005291005291005291,
    "and developed in": 0.5,
    "in the future": 0.006535947712418301,
    "the future .": 0.3333333333333333,
    "<s> its main": 0.5,
    "its main underlying": 0.5,
    "main underlying idea": 1.0,
    "underlying idea is": 1.0,
    "idea is to": 1.0,
    "is to define": 0.05263157894736842,
    "to define several": 0.5,
    "define several quality": 1.0,
    "several quality criteria": 1.0,
    "quality criteria and": 1.0,
    "criteria and check": 1.0,
    "and check how": 1.0,
    "check how a": 1.0,
    "how a generated": 0.5,
    "a generated summary": 1.0,
    "generated summary tackles": 1.0,
    "summary tackles each": 1.0,
    "tackles each of": 1.0,
    "each of these": 0.2,
    "of these ,": 0.09090909090909091,
    "these , in": 0.5,
    ", in such": 0.029411764705882353,
    "such a way": 0.14285714285714285,
    "a way that": 0.2,
    "way that a": 0.3333333333333333,
    "that a reference": 0.3333333333333333,
    "a reference model": 0.5,
    "reference model would": 1.0,
    "model would not": 0.3333333333333333,
    "would not be": 1.0,
    "not be necessary": 0.08333333333333333,
    "be necessary anymore": 0.5,
    "necessary anymore ,": 1.0,
    "anymore , taking": 1.0,
    ", taking only": 1.0,
    "taking only into": 1.0,
    "only into consideration": 1.0,
    "into consideration the": 1.0,
    "consideration the automatic": 1.0,
    "the automatic summary": 0.5,
    "summary and the": 0.5,
    "and the original": 0.024390243902439025,
    "the original source": 0.1,
    "original source .": 1.0,
    "<s> once performed": 0.4,
    "once performed ,": 0.5,
    "performed , it": 0.5,
    ", it could": 0.041666666666666664,
    "it could be": 1.0,
    "be used together": 0.05263157894736842,
    "used together with": 1.0,
    "together with any": 1.0,
    "with any other": 1.0,
    "any other automatic": 0.5,
    "other automatic methodology": 1.0,
    "automatic methodology to": 1.0,
    "methodology to measure": 1.0,
    "to measure summary": 0.25,
    "measure summary 's": 1.0,
    "summary 's informativeness": 0.5,
    "'s informativeness .": 1.0,
    "language generation -lrb-": 0.16666666666666666,
    "generation -lrb- nlg": 1.0,
    "-lrb- nlg -rrb-": 0.3333333333333333,
    "nlg -rrb- is": 1.0,
    "-rrb- is the": 0.2727272727272727,
    "is the natural": 0.022222222222222223,
    "the natural language": 1.0,
    "language processing task": 0.027777777777777776,
    "processing task of": 1.0,
    "task of generating": 0.1111111111111111,
    "of generating natural": 1.0,
    "generating natural language": 1.0,
    "natural language from": 0.014492753623188406,
    "language from a": 1.0,
    "from a machine": 0.08333333333333333,
    "a machine representation": 0.125,
    "machine representation system": 0.5,
    "representation system such": 1.0,
    "system such as": 1.0,
    "as a knowledge": 0.027777777777777776,
    "a knowledge base": 1.0,
    "knowledge base or": 0.25,
    "base or a": 1.0,
    "or a logical": 0.05263157894736842,
    "a logical form": 1.0,
    "logical form .": 1.0,
    "<s> psycholinguists prefer": 1.0,
    "psycholinguists prefer the": 1.0,
    "prefer the term": 1.0,
    "the term language": 0.1111111111111111,
    "term language production": 1.0,
    "language production when": 1.0,
    "production when such": 1.0,
    "when such formal": 0.5,
    "such formal representations": 1.0,
    "formal representations are": 0.5,
    "representations are interpreted": 1.0,
    "are interpreted as": 1.0,
    "interpreted as models": 1.0,
    "as models for": 1.0,
    "models for mental": 0.16666666666666666,
    "for mental representations": 1.0,
    "mental representations .": 1.0,
    "<s> in a": 0.020618556701030927,
    "in a sense": 0.019230769230769232,
    "a sense ,": 1.0,
    "sense , one": 1.0,
    ", one can": 0.16666666666666666,
    "one can say": 0.5,
    "can say that": 1.0,
    "say that an": 1.0,
    "that an nlg": 1.0,
    "an nlg system": 1.0,
    "nlg system is": 0.5,
    "system is like": 0.1111111111111111,
    "like a translator": 0.5,
    "a translator that": 0.3333333333333333,
    "translator that converts": 1.0,
    "that converts a": 1.0,
    "converts a computer": 1.0,
    "a computer based": 0.0625,
    "computer based representation": 1.0,
    "based representation into": 1.0,
    "representation into a": 1.0,
    "into a natural": 0.058823529411764705,
    "natural language representation": 0.014492753623188406,
    "language representation .": 1.0,
    ", the methods": 0.009523809523809525,
    "the methods to": 0.3333333333333333,
    "methods to produce": 0.25,
    "to produce the": 0.2,
    "produce the final": 0.3333333333333333,
    "the final language": 0.2,
    "final language are": 1.0,
    "language are very": 1.0,
    "are very different": 0.25,
    "very different from": 0.3333333333333333,
    "different from those": 0.16666666666666666,
    "from those of": 0.5,
    "those of a": 1.0,
    "of a compiler": 0.021739130434782608,
    "a compiler due": 0.3333333333333333,
    "compiler due to": 1.0,
    "due to the": 0.6666666666666666,
    "to the inherent": 0.012987012987012988,
    "the inherent expressivity": 1.0,
    "inherent expressivity of": 1.0,
    "expressivity of natural": 1.0,
    "natural languages .": 0.2222222222222222,
    "<s> nlg may": 0.5,
    "nlg may be": 1.0,
    "may be viewed": 0.047619047619047616,
    "viewed as the": 0.25,
    "as the opposite": 0.03571428571428571,
    "opposite of natural": 0.5,
    "language understanding .": 0.13333333333333333,
    "<s> the difference": 0.006802721088435374,
    "the difference can": 1.0,
    "difference can be": 1.0,
    "can be put": 0.01098901098901099,
    "be put this": 1.0,
    "put this way": 1.0,
    "this way :": 0.3333333333333333,
    "way : whereas": 1.0,
    ": whereas in": 1.0,
    "whereas in natural": 1.0,
    "in natural language": 0.75,
    "language understanding the": 0.06666666666666667,
    "understanding the system": 0.25,
    "the system needs": 0.11538461538461539,
    "system needs to": 0.75,
    "needs to disambiguate": 0.25,
    "to disambiguate the": 0.3333333333333333,
    "disambiguate the input": 1.0,
    "the input sentence": 0.125,
    "input sentence to": 1.0,
    "sentence to produce": 1.0,
    "produce the machine": 0.3333333333333333,
    "the machine representation": 1.0,
    "machine representation language": 0.5,
    "representation language ,": 0.5,
    "language , in": 0.14285714285714285,
    ", in nlg": 0.029411764705882353,
    "in nlg the": 0.3333333333333333,
    "nlg the system": 1.0,
    "needs to make": 0.25,
    "to make decisions": 0.25,
    "make decisions about": 1.0,
    "decisions about how": 0.5,
    "about how to": 1.0,
    "how to put": 0.2,
    "to put a": 0.5,
    "put a concept": 1.0,
    "a concept into": 1.0,
    "concept into words": 1.0,
    "<s> the simplest": 0.006802721088435374,
    "the simplest -lrb-": 1.0,
    "simplest -lrb- and": 1.0,
    "-lrb- and perhaps": 0.2,
    "and perhaps trivial": 1.0,
    "perhaps trivial -rrb-": 1.0,
    "trivial -rrb- examples": 1.0,
    "-rrb- examples are": 1.0,
    "examples are systems": 0.3333333333333333,
    "systems that generate": 0.09090909090909091,
    "that generate form": 1.0,
    "generate form letters": 1.0,
    "form letters .": 1.0,
    "<s> such systems": 0.125,
    "such systems do": 0.5,
    "systems do not": 1.0,
    "do not typically": 0.07692307692307693,
    "not typically involve": 0.5,
    "typically involve grammar": 1.0,
    "involve grammar rules": 1.0,
    "grammar rules ,": 0.2,
    "rules , but": 0.2,
    ", but may": 0.020833333333333332,
    "but may generate": 0.5,
    "may generate a": 1.0,
    "generate a letter": 0.16666666666666666,
    "a letter to": 1.0,
    "letter to a": 1.0,
    "to a consumer": 0.03571428571428571,
    "a consumer ,": 1.0,
    "consumer , e.g.": 1.0,
    ", e.g. stating": 0.1,
    "e.g. stating that": 1.0,
    "stating that a": 1.0,
    "that a credit": 0.3333333333333333,
    "a credit card": 1.0,
    "credit card spending": 0.3333333333333333,
    "card spending limit": 1.0,
    "spending limit is": 1.0,
    "limit is about": 1.0,
    "is about to": 1.0,
    "about to be": 1.0,
    "to be reached": 0.023255813953488372,
    "be reached .": 1.0,
    "<s> more complex": 0.125,
    "more complex nlg": 0.1111111111111111,
    "complex nlg systems": 1.0,
    "nlg systems dynamically": 0.2,
    "systems dynamically create": 1.0,
    "dynamically create texts": 1.0,
    "create texts to": 1.0,
    "texts to meet": 0.5,
    "to meet a": 0.25,
    "meet a communicative": 1.0,
    "a communicative goal": 1.0,
    "communicative goal .": 0.5,
    "<s> as in": 0.21428571428571427,
    "as in other": 0.25,
    "in other areas": 0.2857142857142857,
    "other areas of": 0.6666666666666666,
    "areas of natural": 0.5,
    "processing , this": 0.1111111111111111,
    ", this can": 0.16666666666666666,
    "this can be": 1.0,
    "can be done": 0.02197802197802198,
    "be done using": 0.2,
    "done using either": 1.0,
    "using either explicit": 1.0,
    "either explicit models": 1.0,
    "explicit models of": 1.0,
    "models of language": 1.0,
    "of language -lrb-": 0.2,
    "language -lrb- e.g.": 0.5,
    "e.g. , grammars": 0.038461538461538464,
    ", grammars -rrb-": 1.0,
    "grammars -rrb- and": 0.5,
    "-rrb- and the": 0.25,
    "and the domain": 0.024390243902439025,
    "the domain ,": 0.5,
    "domain , or": 0.3333333333333333,
    "or using statistical": 0.5,
    "using statistical models": 0.5,
    "statistical models derived": 0.125,
    "models derived by": 1.0,
    "derived by analyzing": 1.0,
    "by analyzing human-written": 0.5,
    "analyzing human-written texts": 1.0,
    "human-written texts .": 1.0,
    "<s> nlg is": 0.5,
    "nlg is a": 0.5,
    "is a fast-evolving": 0.018518518518518517,
    "a fast-evolving field": 1.0,
    "fast-evolving field .": 1.0,
    "<s> the best": 0.006802721088435374,
    "the best single": 0.07142857142857142,
    "best single source": 1.0,
    "single source for": 0.5,
    "source for up-to-date": 1.0,
    "for up-to-date research": 1.0,
    "up-to-date research in": 1.0,
    "research in the": 0.2857142857142857,
    "in the area": 0.006535947712418301,
    "the area is": 0.5,
    "area is the": 0.5,
    "is the siggen": 0.022222222222222223,
    "the siggen portion": 1.0,
    "siggen portion of": 1.0,
    "portion of the": 1.0,
    "of the acl": 0.005128205128205128,
    "the acl anthology": 1.0,
    "acl anthology .": 1.0,
    "<s> perhaps the": 1.0,
    "perhaps the closest": 0.5,
    "the closest the": 1.0,
    "closest the field": 1.0,
    "the field comes": 0.058823529411764705,
    "field comes to": 1.0,
    "comes to a": 1.0,
    "to a specialist": 0.03571428571428571,
    "a specialist textbook": 1.0,
    "specialist textbook is": 1.0,
    "textbook is reiter": 1.0,
    "is reiter and": 1.0,
    "reiter and dale": 1.0,
    "and dale -lrb-": 1.0,
    "dale -lrb- 2000": 1.0,
    "-lrb- 2000 -rrb-": 1.0,
    "2000 -rrb- ,": 1.0,
    "but this book": 0.25,
    "this book does": 1.0,
    "book does not": 1.0,
    "does not describe": 0.2,
    "not describe developments": 1.0,
    "describe developments in": 1.0,
    "developments in the": 0.5,
    "the field since": 0.058823529411764705,
    "field since 2000": 1.0,
    "since 2000 .": 0.5,
    "<s> this system": 0.019230769230769232,
    "this system takes": 0.5,
    "system takes as": 1.0,
    "takes as input": 1.0,
    "as input six": 0.5,
    "input six numbers": 1.0,
    "six numbers ,": 1.0,
    "numbers , which": 0.5,
    ", which give": 0.017857142857142856,
    "which give predicted": 1.0,
    "give predicted pollen": 1.0,
    "predicted pollen levels": 1.0,
    "pollen levels in": 0.1111111111111111,
    "levels in different": 1.0,
    "in different parts": 0.3333333333333333,
    "parts of scotland": 0.0625,
    "of scotland .": 0.5,
    "<s> from these": 1.0,
    "from these numbers": 1.0,
    "these numbers ,": 0.5,
    "numbers , the": 0.5,
    "the system generates": 0.038461538461538464,
    "system generates a": 1.0,
    "generates a short": 0.5,
    "a short textual": 0.2,
    "short textual summary": 1.0,
    "textual summary of": 1.0,
    "summary of pollen": 0.3333333333333333,
    "of pollen levels": 0.5,
    "pollen levels as": 0.1111111111111111,
    "levels as its": 1.0,
    "as its output": 0.3333333333333333,
    "its output .": 0.3333333333333333,
    "example , using": 0.037037037037037035,
    ", using the": 0.1,
    "using the historical": 0.14285714285714285,
    "the historical data": 1.0,
    "historical data for": 1.0,
    "data for 1-july-2005": 1.0,
    "for 1-july-2005 ,": 1.0,
    "1-july-2005 , the": 1.0,
    ", the software": 0.009523809523809525,
    "the software produces": 0.25,
    "software produces grass": 1.0,
    "produces grass pollen": 1.0,
    "grass pollen levels": 1.0,
    "pollen levels for": 0.3333333333333333,
    "levels for friday": 1.0,
    "for friday have": 1.0,
    "friday have increased": 1.0,
    "have increased from": 1.0,
    "increased from the": 1.0,
    "from the moderate": 0.13636363636363635,
    "the moderate to": 1.0,
    "moderate to high": 1.0,
    "to high levels": 1.0,
    "high levels of": 1.0,
    "levels of yesterday": 0.42857142857142855,
    "of yesterday with": 0.6666666666666666,
    "yesterday with values": 1.0,
    "with values of": 1.0,
    "values of around": 0.5,
    "of around 6": 1.0,
    "around 6 to": 1.0,
    "6 to 7": 1.0,
    "to 7 across": 1.0,
    "7 across most": 1.0,
    "across most parts": 1.0,
    "most parts of": 1.0,
    "parts of the": 0.1875,
    "of the country": 0.015384615384615385,
    "the country .": 0.6666666666666666,
    ", in northern": 0.029411764705882353,
    "in northern areas": 1.0,
    "northern areas ,": 1.0,
    "areas , pollen": 1.0,
    ", pollen levels": 1.0,
    "pollen levels will": 0.2222222222222222,
    "levels will be": 1.0,
    "will be moderate": 0.1111111111111111,
    "be moderate with": 1.0,
    "moderate with values": 1.0,
    "values of 4": 0.25,
    "of 4 .": 1.0,
    "contrast , the": 0.2,
    ", the actual": 0.009523809523809525,
    "the actual forecast": 0.3333333333333333,
    "actual forecast -lrb-": 1.0,
    "forecast -lrb- written": 1.0,
    "-lrb- written by": 1.0,
    "a human meteorologist": 0.09090909090909091,
    "human meteorologist -rrb-": 1.0,
    "meteorologist -rrb- from": 1.0,
    "-rrb- from this": 1.0,
    "from this data": 1.0,
    "this data was": 1.0,
    "data was pollen": 1.0,
    "was pollen counts": 1.0,
    "pollen counts are": 1.0,
    "counts are expected": 1.0,
    "are expected to": 1.0,
    "expected to remain": 0.5,
    "to remain high": 1.0,
    "remain high at": 1.0,
    "high at level": 1.0,
    "at level 6": 1.0,
    "level 6 over": 1.0,
    "6 over most": 1.0,
    "over most of": 1.0,
    "most of scotland": 0.16666666666666666,
    "of scotland ,": 0.5,
    "scotland , and": 1.0,
    "and even level": 0.16666666666666666,
    "even level 7": 1.0,
    "level 7 in": 1.0,
    "7 in the": 1.0,
    "in the south": 0.013071895424836602,
    "the south east": 1.0,
    "south east .": 1.0,
    "the only relief": 0.3333333333333333,
    "only relief is": 1.0,
    "relief is in": 1.0,
    "is in the": 0.3333333333333333,
    "in the northern": 0.013071895424836602,
    "the northern isles": 1.0,
    "northern isles and": 1.0,
    "isles and far": 1.0,
    "and far northeast": 1.0,
    "far northeast of": 1.0,
    "northeast of mainland": 1.0,
    "of mainland scotland": 1.0,
    "mainland scotland with": 0.5,
    "scotland with medium": 1.0,
    "with medium levels": 1.0,
    "medium levels of": 1.0,
    "levels of pollen": 0.14285714285714285,
    "of pollen count": 0.5,
    "pollen count .": 1.0,
    "<s> comparing these": 1.0,
    "comparing these two": 1.0,
    "these two illustrates": 0.5,
    "two illustrates some": 1.0,
    "illustrates some of": 1.0,
    "of the choices": 0.005128205128205128,
    "the choices that": 1.0,
    "choices that nlg": 1.0,
    "that nlg systems": 0.5,
    "nlg systems must": 0.2,
    "systems must make": 1.0,
    "must make ;": 1.0,
    "make ; these": 1.0,
    "; these are": 0.5,
    "these are further": 0.25,
    "are further discussed": 1.0,
    "further discussed below": 1.0,
    "<s> stages the": 1.0,
    "stages the process": 1.0,
    "process to generate": 0.25,
    "to generate text": 0.16666666666666666,
    "generate text can": 1.0,
    "text can be": 1.0,
    "can be as": 0.02197802197802198,
    "simple as keeping": 0.5,
    "as keeping a": 1.0,
    "keeping a list": 1.0,
    "list of canned": 0.1,
    "of canned text": 1.0,
    "canned text that": 1.0,
    "text that is": 0.25,
    "that is copied": 0.05263157894736842,
    "is copied and": 1.0,
    "copied and pasted": 1.0,
    "and pasted ,": 1.0,
    "pasted , possibly": 1.0,
    ", possibly linked": 1.0,
    "possibly linked with": 1.0,
    "linked with some": 1.0,
    "with some glue": 0.25,
    "some glue text": 1.0,
    "glue text .": 1.0,
    "<s> the results": 0.006802721088435374,
    "the results may": 0.2,
    "results may be": 1.0,
    "may be satisfactory": 0.047619047619047616,
    "be satisfactory in": 1.0,
    "satisfactory in simple": 1.0,
    "in simple domains": 1.0,
    "simple domains such": 1.0,
    "domains such as": 1.0,
    "such as horoscope": 0.011111111111111112,
    "as horoscope machines": 1.0,
    "horoscope machines or": 1.0,
    "machines or generators": 1.0,
    "or generators of": 1.0,
    "generators of personalised": 1.0,
    "of personalised business": 1.0,
    "personalised business letters": 1.0,
    "business letters .": 1.0,
    "however , a": 0.022727272727272728,
    ", a sophisticated": 0.020833333333333332,
    "a sophisticated nlg": 1.0,
    "sophisticated nlg system": 1.0,
    "nlg system needs": 0.5,
    "needs to include": 0.25,
    "to include stages": 0.14285714285714285,
    "include stages of": 1.0,
    "stages of planning": 1.0,
    "of planning and": 1.0,
    "planning and merging": 1.0,
    "and merging of": 1.0,
    "merging of information": 0.5,
    "of information to": 0.2,
    "information to enable": 0.25,
    "to enable the": 1.0,
    "enable the generation": 0.5,
    "the generation of": 1.0,
    "generation of text": 1.0,
    "of text that": 0.041666666666666664,
    "text that looks": 0.25,
    "that looks natural": 1.0,
    "looks natural and": 1.0,
    "natural and does": 0.5,
    "and does not": 1.0,
    "does not become": 0.2,
    "not become repetitive": 1.0,
    "become repetitive .": 1.0,
    "<s> typical stages": 0.5,
    "typical stages are": 1.0,
    "stages are :": 1.0,
    "are : content": 0.5,
    ": content determination": 1.0,
    "content determination :": 1.0,
    "determination : deciding": 1.0,
    ": deciding what": 1.0,
    "deciding what information": 1.0,
    "what information to": 1.0,
    "information to mention": 0.25,
    "to mention in": 1.0,
    "mention in the": 1.0,
    "in the pollen": 0.006535947712418301,
    "the pollen example": 1.0,
    "pollen example above": 1.0,
    "example above ,": 1.0,
    "above , deciding": 0.25,
    ", deciding whether": 0.5,
    "deciding whether to": 0.5,
    "whether to explicitly": 1.0,
    "to explicitly mention": 0.5,
    "explicitly mention that": 1.0,
    "mention that pollen": 1.0,
    "that pollen level": 1.0,
    "pollen level is": 0.5,
    "level is 7": 1.0,
    "is 7 in": 1.0,
    "<s> document structuring": 0.5,
    "document structuring :": 1.0,
    "structuring : overall": 1.0,
    ": overall organization": 1.0,
    "overall organization of": 1.0,
    "organization of the": 0.5,
    "of the information": 0.010256410256410256,
    "the information to": 0.16666666666666666,
    "information to convey": 0.25,
    "to convey .": 0.3333333333333333,
    "example , deciding": 0.05555555555555555,
    ", deciding to": 0.5,
    "deciding to describe": 0.5,
    "to describe the": 0.5,
    "describe the areas": 0.5,
    "the areas with": 1.0,
    "areas with high": 0.5,
    "with high pollen": 0.5,
    "high pollen levels": 1.0,
    "pollen levels first": 0.1111111111111111,
    "levels first ,": 1.0,
    "first , instead": 1.0,
    ", instead of": 1.0,
    "instead of the": 0.14285714285714285,
    "of the areas": 0.005128205128205128,
    "areas with low": 0.5,
    "with low pollen": 1.0,
    "low pollen levels": 1.0,
    "pollen levels .": 0.1111111111111111,
    "<s> aggregation :": 1.0,
    "aggregation : merging": 1.0,
    ": merging of": 1.0,
    "merging of similar": 0.5,
    "of similar sentences": 0.5,
    "sentences to improve": 0.16666666666666666,
    "to improve readability": 0.1111111111111111,
    "improve readability and": 1.0,
    "readability and naturalness": 1.0,
    "and naturalness .": 1.0,
    "instance , merging": 0.1111111111111111,
    ", merging the": 1.0,
    "merging the two": 1.0,
    "the two sentences": 0.14285714285714285,
    "two sentences grass": 0.5,
    "sentences grass pollen": 1.0,
    "of yesterday and": 0.3333333333333333,
    "yesterday and grass": 1.0,
    "and grass pollen": 1.0,
    "will be around": 0.1111111111111111,
    "be around 6": 1.0,
    "the country into": 0.3333333333333333,
    "country into the": 1.0,
    "into the single": 0.125,
    "the single sentence": 1.0,
    "single sentence grass": 1.0,
    "sentence grass pollen": 1.0,
    "<s> lexical choice": 0.5,
    "lexical choice :": 1.0,
    "choice : putting": 1.0,
    ": putting words": 1.0,
    "putting words to": 1.0,
    "words to the": 1.0,
    "to the concepts": 0.012987012987012988,
    "the concepts .": 1.0,
    "deciding whether medium": 0.5,
    "whether medium or": 1.0,
    "medium or moderate": 1.0,
    "or moderate should": 1.0,
    "moderate should be": 1.0,
    "should be used": 0.2222222222222222,
    "be used when": 0.05263157894736842,
    "used when describing": 0.5,
    "when describing a": 0.5,
    "describing a pollen": 1.0,
    "a pollen level": 1.0,
    "pollen level of": 0.5,
    "level of 4": 0.14285714285714285,
    "<s> referring expression": 1.0,
    "referring expression generation": 0.5,
    "expression generation :": 1.0,
    "generation : creating": 0.5,
    ": creating referring": 0.5,
    "creating referring expressions": 1.0,
    "referring expressions that": 1.0,
    "expressions that identify": 1.0,
    "that identify objects": 1.0,
    "identify objects and": 1.0,
    "objects and regions": 1.0,
    "and regions .": 1.0,
    "deciding to use": 0.5,
    "to use in": 0.1,
    "use in the": 1.0,
    "mainland scotland to": 0.5,
    "scotland to refer": 1.0,
    "to refer to": 1.0,
    "refer to a": 0.3333333333333333,
    "to a certain": 0.03571428571428571,
    "a certain region": 1.0,
    "certain region in": 1.0,
    "region in scotland": 1.0,
    "in scotland .": 1.0,
    "<s> this task": 0.038461538461538464,
    "this task also": 0.16666666666666666,
    "task also includes": 1.0,
    "also includes making": 1.0,
    "includes making decisions": 1.0,
    "making decisions about": 1.0,
    "decisions about pronouns": 0.5,
    "about pronouns and": 1.0,
    "pronouns and other": 1.0,
    "and other types": 0.1111111111111111,
    "other types of": 1.0,
    "types of anaphora": 0.07142857142857142,
    "of anaphora .": 1.0,
    "<s> realisation :": 1.0,
    "realisation : creating": 1.0,
    ": creating the": 0.5,
    "creating the actual": 1.0,
    "the actual text": 0.3333333333333333,
    "actual text ,": 1.0,
    ", which should": 0.017857142857142856,
    "which should be": 1.0,
    "should be correct": 0.1111111111111111,
    "be correct according": 1.0,
    "correct according to": 1.0,
    "to the rules": 0.012987012987012988,
    "the rules of": 0.2,
    "rules of syntax": 0.25,
    "of syntax ,": 0.5,
    "syntax , morphology": 0.4,
    ", morphology ,": 1.0,
    ", and orthography": 0.005291005291005291,
    "and orthography .": 1.0,
    ", using will": 0.1,
    "using will be": 1.0,
    "will be for": 0.1111111111111111,
    "be for the": 1.0,
    "for the future": 0.03125,
    "the future tense": 0.3333333333333333,
    "future tense of": 1.0,
    "tense of to": 1.0,
    "of to be": 1.0,
    "to be .": 0.023255813953488372,
    "<s> applications the": 0.5,
    "applications the popular": 1.0,
    "the popular media": 1.0,
    "popular media has": 1.0,
    "media has been": 1.0,
    "has been especially": 0.03571428571428571,
    "been especially interested": 1.0,
    "especially interested in": 1.0,
    "interested in nlg": 1.0,
    "in nlg systems": 0.3333333333333333,
    "nlg systems which": 0.2,
    "systems which generate": 1.0,
    "which generate jokes": 0.3333333333333333,
    "generate jokes -lrb-": 1.0,
    "jokes -lrb- see": 1.0,
    "-lrb- see computational": 0.0625,
    "see computational humor": 1.0,
    "computational humor -rrb-": 1.0,
    "humor -rrb- .": 1.0,
    "<s> but from": 0.16666666666666666,
    "but from a": 1.0,
    "from a commercial": 0.08333333333333333,
    "a commercial perspective": 0.5,
    "commercial perspective ,": 1.0,
    "perspective , the": 1.0,
    ", the most": 0.01904761904761905,
    "the most successful": 0.041666666666666664,
    "most successful nlg": 0.5,
    "successful nlg applications": 1.0,
    "nlg applications have": 1.0,
    "applications have been": 0.5,
    "have been data-to-text": 0.038461538461538464,
    "been data-to-text systems": 1.0,
    "data-to-text systems which": 1.0,
    "which generate textual": 0.3333333333333333,
    "generate textual summaries": 1.0,
    "textual summaries of": 1.0,
    "summaries of databases": 0.25,
    "of databases and": 1.0,
    "databases and data": 1.0,
    "and data sets": 0.5,
    "data sets ;": 0.3333333333333333,
    "sets ; these": 1.0,
    "; these systems": 0.5,
    "these systems usually": 0.2222222222222222,
    "systems usually perform": 0.5,
    "usually perform data": 1.0,
    "perform data analysis": 1.0,
    "data analysis as": 1.0,
    "analysis as well": 1.0,
    "well as text": 0.07692307692307693,
    "as text generation": 1.0,
    "text generation .": 1.0,
    "particular , several": 0.3333333333333333,
    ", several systems": 1.0,
    "several systems have": 1.0,
    "systems have been": 0.6,
    "have been built": 0.038461538461538464,
    "been built that": 1.0,
    "built that produce": 1.0,
    "that produce textual": 1.0,
    "produce textual weather": 1.0,
    "textual weather forecasts": 1.0,
    "weather forecasts from": 0.25,
    "forecasts from weather": 1.0,
    "from weather data": 1.0,
    "weather data .": 1.0,
    "<s> the earliest": 0.006802721088435374,
    "the earliest such": 0.5,
    "earliest such system": 1.0,
    "such system to": 1.0,
    "system to be": 0.2,
    "to be deployed": 0.023255813953488372,
    "be deployed was": 1.0,
    "deployed was fog": 1.0,
    "was fog ,": 1.0,
    "fog , which": 1.0,
    "which was used": 0.2,
    "was used by": 0.25,
    "used by environment": 0.1111111111111111,
    "by environment canada": 1.0,
    "environment canada to": 1.0,
    "canada to generate": 1.0,
    "to generate weather": 0.16666666666666666,
    "generate weather forecasts": 1.0,
    "weather forecasts in": 0.25,
    "forecasts in french": 1.0,
    "in french and": 1.0,
    "french and english": 0.5,
    "and english in": 1.0,
    "english in the": 1.0,
    "in the early": 0.006535947712418301,
    "the early 1990s": 0.3333333333333333,
    "early 1990s .": 1.0,
    "<s> the success": 0.006802721088435374,
    "success of fog": 0.3333333333333333,
    "of fog triggered": 1.0,
    "fog triggered other": 1.0,
    "triggered other work": 1.0,
    "other work ,": 1.0,
    "work , both": 0.3333333333333333,
    ", both research": 0.3333333333333333,
    "both research and": 1.0,
    "research and commercial": 0.16666666666666666,
    "and commercial .": 1.0,
    "recent research in": 0.5,
    "research in this": 0.14285714285714285,
    "in this area": 0.2,
    "this area include": 0.3333333333333333,
    "area include an": 1.0,
    "include an experiment": 0.5,
    "an experiment which": 1.0,
    "experiment which showed": 1.0,
    "which showed that": 1.0,
    "showed that users": 0.3333333333333333,
    "that users sometimes": 1.0,
    "users sometimes preferred": 1.0,
    "sometimes preferred computer-generated": 1.0,
    "preferred computer-generated weather": 1.0,
    "computer-generated weather forecasts": 1.0,
    "weather forecasts to": 0.25,
    "forecasts to human-written": 1.0,
    "to human-written ones": 1.0,
    "human-written ones ,": 1.0,
    "ones , in": 0.3333333333333333,
    ", in part": 0.029411764705882353,
    "in part because": 1.0,
    "part because the": 1.0,
    "because the computer": 0.25,
    "the computer forecasts": 0.5,
    "computer forecasts used": 1.0,
    "forecasts used more": 1.0,
    "used more consistent": 1.0,
    "more consistent terminology": 1.0,
    "consistent terminology ,": 1.0,
    "terminology , and": 1.0,
    "a demonstration that": 0.3333333333333333,
    "demonstration that statistical": 1.0,
    "that statistical techniques": 1.0,
    "statistical techniques could": 0.3333333333333333,
    "techniques could be": 1.0,
    "be used to": 0.3157894736842105,
    "used to generate": 0.045454545454545456,
    "to generate high-quality": 0.16666666666666666,
    "generate high-quality weather": 1.0,
    "high-quality weather forecasts": 1.0,
    "weather forecasts .": 0.25,
    "<s> recent applications": 0.3333333333333333,
    "recent applications include": 1.0,
    "applications include the": 0.3333333333333333,
    "include the arns": 0.2,
    "the arns system": 1.0,
    "arns system used": 1.0,
    "system used to": 1.0,
    "used to summarise": 0.045454545454545456,
    "to summarise conditions": 0.3333333333333333,
    "summarise conditions in": 1.0,
    "conditions in us": 1.0,
    "in us ports": 1.0,
    "us ports .": 1.0,
    "in the 1990s": 0.013071895424836602,
    "the 1990s there": 0.5,
    "1990s there was": 1.0,
    "there was considerable": 0.3333333333333333,
    "was considerable interest": 1.0,
    "considerable interest in": 1.0,
    "interest in using": 0.42857142857142855,
    "in using nlg": 1.0,
    "using nlg to": 1.0,
    "nlg to summarise": 0.6666666666666666,
    "to summarise financial": 0.3333333333333333,
    "summarise financial and": 1.0,
    "financial and business": 1.0,
    "and business data": 1.0,
    "business data .": 1.0,
    "for example the": 0.017857142857142856,
    "example the spotlight": 0.5,
    "the spotlight system": 1.0,
    "spotlight system developed": 1.0,
    "system developed at": 1.0,
    "developed at a.c.": 0.5,
    "at a.c. nielsen": 1.0,
    "a.c. nielsen automatically": 1.0,
    "nielsen automatically generated": 1.0,
    "automatically generated readable": 0.3333333333333333,
    "generated readable english": 1.0,
    "readable english text": 1.0,
    "english text based": 1.0,
    "text based on": 1.0,
    "on the analysis": 0.029850746268656716,
    "of large amounts": 0.25,
    "large amounts of": 1.0,
    "amounts of retail": 0.5,
    "of retail sales": 1.0,
    "retail sales data": 1.0,
    "sales data .": 1.0,
    "<s> more recently": 0.125,
    "more recently there": 1.0,
    "recently there is": 1.0,
    "there is growing": 0.058823529411764705,
    "is growing interest": 1.0,
    "growing interest in": 1.0,
    "to summarise electronic": 0.3333333333333333,
    "summarise electronic medical": 1.0,
    "electronic medical records": 1.0,
    "medical records .": 0.3333333333333333,
    "<s> commercial applications": 0.5,
    "commercial applications in": 1.0,
    "applications in this": 0.5,
    "this area are": 0.3333333333333333,
    "area are starting": 1.0,
    "are starting to": 1.0,
    "starting to appear": 1.0,
    "to appear ,": 0.5,
    "appear , and": 1.0,
    ", and researchers": 0.005291005291005291,
    "and researchers have": 1.0,
    "researchers have shown": 0.3333333333333333,
    "have shown that": 1.0,
    "shown that nlg": 1.0,
    "that nlg summaries": 0.5,
    "nlg summaries of": 1.0,
    "summaries of medical": 0.5,
    "of medical data": 1.0,
    "medical data can": 1.0,
    "data can be": 1.0,
    "can be effective": 0.01098901098901099,
    "be effective decision-support": 0.5,
    "effective decision-support aids": 1.0,
    "decision-support aids for": 1.0,
    "aids for medical": 1.0,
    "for medical professionals": 1.0,
    "medical professionals .": 1.0,
    "<s> there is": 0.2222222222222222,
    "is also growing": 0.1,
    "also growing interest": 1.0,
    "nlg to enhance": 0.3333333333333333,
    "to enhance accessibility": 1.0,
    "enhance accessibility ,": 1.0,
    "accessibility , for": 1.0,
    "example by describing": 0.5,
    "by describing graphs": 1.0,
    "describing graphs and": 1.0,
    "graphs and data": 1.0,
    "data sets to": 0.3333333333333333,
    "sets to blind": 1.0,
    "to blind people": 1.0,
    "blind people .": 0.3333333333333333,
    "example for a": 0.5,
    "for a highly": 0.03225806451612903,
    "a highly interactive": 1.0,
    "highly interactive use": 1.0,
    "interactive use of": 1.0,
    "use of nlg": 0.045454545454545456,
    "of nlg is": 1.0,
    "nlg is the": 0.5,
    "is the wysiwym": 0.022222222222222223,
    "the wysiwym framework": 1.0,
    "wysiwym framework .": 1.0,
    "<s> it stands": 0.029411764705882353,
    "it stands for": 1.0,
    "stands for what": 1.0,
    "for what you": 0.3333333333333333,
    "what you see": 0.5,
    "you see is": 1.0,
    "see is what": 1.0,
    "is what you": 0.5,
    "what you meant": 0.5,
    "you meant and": 1.0,
    "meant and allows": 1.0,
    "and allows users": 0.5,
    "allows users to": 1.0,
    "users to see": 0.5,
    "to see and": 0.5,
    "see and manipulate": 1.0,
    "and manipulate the": 1.0,
    "manipulate the continuously": 1.0,
    "the continuously rendered": 1.0,
    "continuously rendered view": 1.0,
    "rendered view -lrb-": 1.0,
    "view -lrb- nlg": 1.0,
    "-lrb- nlg output": 0.3333333333333333,
    "nlg output -rrb-": 1.0,
    "output -rrb- of": 1.0,
    "-rrb- of an": 0.14285714285714285,
    "of an underlying": 0.07692307692307693,
    "an underlying formal": 1.0,
    "underlying formal language": 1.0,
    "formal language document": 0.5,
    "language document -lrb-": 1.0,
    "document -lrb- nlg": 0.5,
    "-lrb- nlg input": 0.3333333333333333,
    "nlg input -rrb-": 1.0,
    "input -rrb- ,": 0.5,
    "-rrb- , thereby": 0.01282051282051282,
    ", thereby editing": 1.0,
    "thereby editing the": 1.0,
    "editing the formal": 1.0,
    "the formal language": 0.5,
    "formal language without": 0.5,
    "language without having": 1.0,
    "without having to": 1.0,
    "having to learn": 1.0,
    "to learn it": 0.16666666666666666,
    "learn it .": 1.0,
    "<s> evaluation as": 0.2,
    "evaluation as in": 1.0,
    "in other scientific": 0.14285714285714285,
    "other scientific fields": 1.0,
    "scientific fields ,": 1.0,
    "fields , nlg": 0.5,
    ", nlg researchers": 1.0,
    "nlg researchers need": 1.0,
    "researchers need to": 1.0,
    "need to be": 0.1,
    "able to test": 0.0625,
    "to test how": 0.5,
    "test how well": 1.0,
    "how well their": 0.16666666666666666,
    "well their systems": 1.0,
    "their systems ,": 0.5,
    "systems , modules": 0.16666666666666666,
    ", modules ,": 1.0,
    "modules , and": 1.0,
    ", and algorithms": 0.005291005291005291,
    "and algorithms work": 1.0,
    "algorithms work .": 1.0,
    "this is called": 0.038461538461538464,
    "is called evaluation": 0.16666666666666666,
    "called evaluation .": 0.5,
    "there are three": 0.047619047619047616,
    "are three basic": 1.0,
    "three basic techniques": 1.0,
    "basic techniques for": 1.0,
    "techniques for evaluating": 0.5,
    "for evaluating nlg": 0.3333333333333333,
    "evaluating nlg systems": 1.0,
    "nlg systems :": 0.2,
    "systems : task-based": 1.0,
    ": task-based -lrb-": 1.0,
    "task-based -lrb- extrinsic": 1.0,
    "-lrb- extrinsic -rrb-": 1.0,
    "extrinsic -rrb- evaluation": 1.0,
    "-rrb- evaluation :": 1.0,
    "evaluation : give": 0.5,
    ": give the": 1.0,
    "give the generated": 1.0,
    "the generated text": 1.0,
    "generated text to": 1.0,
    "text to a": 0.2857142857142857,
    "to a person": 0.07142857142857142,
    "a person ,": 0.2727272727272727,
    "person , and": 0.5,
    ", and assess": 0.005291005291005291,
    "and assess how": 1.0,
    "assess how well": 1.0,
    "how well it": 0.3333333333333333,
    "well it helps": 0.5,
    "it helps him": 1.0,
    "helps him perform": 1.0,
    "him perform a": 1.0,
    "perform a task": 0.3333333333333333,
    "a task -lrb-": 0.3333333333333333,
    "task -lrb- or": 1.0,
    "-lrb- or otherwise": 0.1,
    "or otherwise achieves": 1.0,
    "otherwise achieves its": 1.0,
    "achieves its communicative": 1.0,
    "its communicative goal": 1.0,
    "communicative goal -rrb-": 0.5,
    "goal -rrb- .": 1.0,
    ", a system": 0.041666666666666664,
    "a system which": 0.1,
    "system which generates": 1.0,
    "which generates summaries": 1.0,
    "generates summaries of": 1.0,
    "be evaluated by": 0.5,
    "evaluated by giving": 1.0,
    "by giving these": 1.0,
    "giving these summaries": 1.0,
    "these summaries to": 0.5,
    "summaries to doctors": 0.5,
    "to doctors ,": 1.0,
    "doctors , and": 1.0,
    ", and assessing": 0.005291005291005291,
    "and assessing whether": 1.0,
    "assessing whether the": 1.0,
    "whether the summaries": 0.5,
    "the summaries helps": 0.25,
    "summaries helps doctors": 1.0,
    "helps doctors make": 1.0,
    "doctors make better": 1.0,
    "make better decisions": 1.0,
    "better decisions .": 1.0,
    "<s> human ratings": 0.25,
    "human ratings :": 0.25,
    "ratings : give": 1.0,
    ", and ask": 0.005291005291005291,
    "and ask him": 1.0,
    "ask him or": 1.0,
    "him or her": 1.0,
    "or her to": 0.5,
    "her to rate": 1.0,
    "to rate the": 0.5,
    "rate the quality": 1.0,
    "the quality and": 0.2,
    "quality and usefulness": 1.0,
    "and usefulness of": 1.0,
    "usefulness of the": 1.0,
    "<s> metrics :": 1.0,
    "metrics : compare": 1.0,
    ": compare generated": 1.0,
    "compare generated texts": 1.0,
    "generated texts to": 1.0,
    "texts to texts": 0.5,
    "to texts written": 1.0,
    "texts written by": 1.0,
    "written by people": 0.16666666666666666,
    "by people from": 0.5,
    "people from the": 1.0,
    "from the same": 0.045454545454545456,
    "input data ,": 0.16666666666666666,
    "data , using": 0.1,
    ", using an": 0.1,
    "using an automatic": 0.5,
    "an automatic metric": 0.5,
    "automatic metric such": 1.0,
    "metric such as": 1.0,
    "such as bleu": 0.011111111111111112,
    "as bleu .": 1.0,
    "<s> generally speaking": 0.4,
    "generally speaking ,": 1.0,
    "speaking , what": 0.2,
    ", what we": 0.5,
    "what we ultimately": 0.3333333333333333,
    "we ultimately want": 1.0,
    "ultimately want to": 1.0,
    "want to know": 0.2,
    "to know is": 1.0,
    "know is how": 1.0,
    "is how useful": 0.5,
    "how useful nlg": 1.0,
    "useful nlg systems": 1.0,
    "nlg systems are": 0.2,
    "systems are at": 0.07692307692307693,
    "are at helping": 0.5,
    "at helping people": 1.0,
    "helping people ,": 1.0,
    "people , which": 1.0,
    "is the first": 0.022222222222222223,
    "the first of": 0.045454545454545456,
    "first of the": 1.0,
    "of the above": 0.005128205128205128,
    "the above techniques": 0.5,
    "above techniques .": 1.0,
    "however , task-based": 0.022727272727272728,
    ", task-based evaluations": 1.0,
    "task-based evaluations are": 0.6666666666666666,
    "evaluations are time-consuming": 0.5,
    "are time-consuming and": 1.0,
    "time-consuming and expensive": 1.0,
    "and expensive ,": 0.5,
    "expensive , and": 0.3333333333333333,
    "can be difficult": 0.01098901098901099,
    "be difficult to": 1.0,
    "difficult to carry": 0.09090909090909091,
    "to carry out": 1.0,
    "carry out -lrb-": 1.0,
    "out -lrb- especially": 1.0,
    "-lrb- especially if": 0.5,
    "especially if they": 1.0,
    "if they require": 1.0,
    "they require subjects": 0.5,
    "require subjects with": 1.0,
    "subjects with specialised": 1.0,
    "with specialised expertise": 1.0,
    "specialised expertise ,": 1.0,
    "expertise , such": 1.0,
    "such as doctors": 0.011111111111111112,
    "as doctors -rrb-": 1.0,
    "doctors -rrb- .": 1.0,
    "<s> hence -lrb-": 0.5,
    "hence -lrb- as": 1.0,
    "areas of nlp": 0.5,
    "of nlp -rrb-": 0.2,
    "nlp -rrb- task-based": 0.25,
    "-rrb- task-based evaluations": 1.0,
    "evaluations are the": 0.5,
    "are the exception": 0.09090909090909091,
    "the exception ,": 1.0,
    "exception , not": 1.0,
    ", not the": 0.14285714285714285,
    "not the norm": 0.2,
    "the norm .": 1.0,
    "<s> in recent": 0.020618556701030927,
    "in recent years": 1.0,
    "recent years researchers": 0.25,
    "years researchers have": 1.0,
    "researchers have started": 0.3333333333333333,
    "have started trying": 1.0,
    "started trying to": 1.0,
    "trying to assess": 0.2,
    "to assess how": 1.0,
    "how well human-ratings": 0.16666666666666666,
    "well human-ratings and": 1.0,
    "human-ratings and metrics": 1.0,
    "and metrics correlate": 1.0,
    "metrics correlate with": 1.0,
    "correlate with -lrb-": 0.5,
    "with -lrb- predict": 1.0,
    "-lrb- predict -rrb-": 1.0,
    "predict -rrb- task-based": 1.0,
    "task-based evaluations .": 0.3333333333333333,
    "<s> much of": 0.3333333333333333,
    "much of this": 0.3333333333333333,
    "of this work": 0.09090909090909091,
    "this work is": 0.6666666666666666,
    "work is being": 0.3333333333333333,
    "is being conducted": 0.3333333333333333,
    "being conducted in": 1.0,
    "conducted in the": 0.5,
    "context of generation": 0.2,
    "of generation challenges": 1.0,
    "generation challenges shared-task": 1.0,
    "challenges shared-task events": 1.0,
    "shared-task events .": 1.0,
    "<s> initial results": 1.0,
    "initial results suggest": 1.0,
    "results suggest that": 1.0,
    "suggest that human": 1.0,
    "that human ratings": 0.5,
    "human ratings are": 0.5,
    "ratings are much": 0.5,
    "are much better": 0.5,
    "much better than": 1.0,
    "better than metrics": 1.0,
    "than metrics in": 1.0,
    "metrics in this": 1.0,
    "in this regard": 0.06666666666666667,
    "this regard .": 1.0,
    "<s> in other": 0.020618556701030927,
    "in other words": 0.14285714285714285,
    "other words ,": 0.5,
    "words , human": 0.0625,
    ", human ratings": 0.3333333333333333,
    "human ratings usually": 0.25,
    "ratings usually do": 1.0,
    "usually do predict": 1.0,
    "do predict task-effectiveness": 1.0,
    "predict task-effectiveness at": 0.5,
    "task-effectiveness at least": 1.0,
    "at least to": 0.2,
    "least to some": 1.0,
    "some degree -lrb-": 0.5,
    "degree -lrb- although": 1.0,
    "-lrb- although there": 0.5,
    "although there are": 1.0,
    "there are exceptions": 0.047619047619047616,
    "are exceptions -rrb-": 1.0,
    "exceptions -rrb- ,": 1.0,
    ", while ratings": 0.07142857142857142,
    "while ratings produced": 1.0,
    "ratings produced by": 1.0,
    "produced by metrics": 0.3333333333333333,
    "by metrics often": 1.0,
    "metrics often do": 1.0,
    "often do not": 1.0,
    "do not predict": 0.07692307692307693,
    "not predict task-effectiveness": 1.0,
    "predict task-effectiveness well": 0.5,
    "task-effectiveness well .": 1.0,
    "<s> these results": 0.0625,
    "these results are": 1.0,
    "results are very": 0.25,
    "are very preliminary": 0.25,
    "very preliminary ,": 1.0,
    "preliminary , hopefully": 1.0,
    ", hopefully better": 1.0,
    "hopefully better data": 1.0,
    "better data will": 1.0,
    "data will be": 1.0,
    "will be available": 0.1111111111111111,
    "be available soon": 1.0,
    "available soon .": 1.0,
    "case , human": 0.3333333333333333,
    "ratings are currently": 0.5,
    "are currently the": 0.5,
    "currently the most": 1.0,
    "the most popular": 0.125,
    "most popular evaluation": 0.3333333333333333,
    "popular evaluation technique": 1.0,
    "evaluation technique in": 1.0,
    "technique in nlg": 1.0,
    "in nlg ;": 0.3333333333333333,
    "nlg ; this": 1.0,
    "; this is": 0.5,
    "this is contrast": 0.038461538461538464,
    "is contrast to": 1.0,
    "contrast to machine": 0.5,
    "to machine translation": 0.3333333333333333,
    "translation , where": 0.125,
    ", where metrics": 0.06666666666666667,
    "where metrics are": 1.0,
    "metrics are very": 1.0,
    "are very widely": 0.25,
    "very widely used": 1.0,
    "widely used .": 0.14285714285714285,
    "understanding is a": 0.5,
    "is a subtopic": 0.018518518518518517,
    "a subtopic of": 1.0,
    "subtopic of natural": 1.0,
    "language processing in": 0.027777777777777776,
    "processing in artificial": 0.5,
    "in artificial intelligence": 1.0,
    "intelligence that deals": 0.5,
    "that deals with": 1.0,
    "deals with machine": 0.25,
    "with machine reading": 1.0,
    "machine reading comprehension": 1.0,
    "reading comprehension .": 0.5,
    "<s> the process": 0.013605442176870748,
    "process of disassembling": 0.08333333333333333,
    "of disassembling and": 1.0,
    "disassembling and parsing": 1.0,
    "and parsing input": 1.0,
    "parsing input is": 1.0,
    "input is more": 1.0,
    "is more complex": 0.3333333333333333,
    "more complex than": 0.2222222222222222,
    "complex than the": 1.0,
    "than the reverse": 0.25,
    "the reverse process": 1.0,
    "reverse process of": 1.0,
    "process of assembling": 0.08333333333333333,
    "of assembling output": 1.0,
    "assembling output in": 1.0,
    "output in natural": 1.0,
    "language generation because": 0.16666666666666666,
    "generation because of": 1.0,
    "because of the": 0.6666666666666666,
    "of the occurrence": 0.005128205128205128,
    "the occurrence of": 1.0,
    "occurrence of unknown": 1.0,
    "of unknown and": 1.0,
    "unknown and unexpected": 1.0,
    "and unexpected features": 1.0,
    "unexpected features in": 1.0,
    "features in the": 1.0,
    "in the input": 0.006535947712418301,
    "the input and": 0.25,
    "input and the": 0.5,
    "and the need": 0.024390243902439025,
    "the need to": 0.3333333333333333,
    "need to determine": 0.1,
    "to determine the": 0.36363636363636365,
    "determine the appropriate": 0.1,
    "the appropriate syntactic": 0.3333333333333333,
    "appropriate syntactic and": 1.0,
    "syntactic and semantic": 1.0,
    "and semantic schemes": 0.25,
    "semantic schemes to": 1.0,
    "schemes to apply": 1.0,
    "to apply to": 1.0,
    "apply to it": 0.5,
    "to it ,": 1.0,
    "it , factors": 0.5,
    ", factors which": 1.0,
    "factors which are": 1.0,
    "which are pre-determined": 0.08333333333333333,
    "are pre-determined when": 1.0,
    "pre-determined when outputting": 1.0,
    "when outputting language": 1.0,
    "outputting language .": 1.0,
    "there is considerable": 0.058823529411764705,
    "is considerable commercial": 1.0,
    "considerable commercial interest": 1.0,
    "commercial interest in": 1.0,
    "interest in the": 0.14285714285714285,
    "the field because": 0.058823529411764705,
    "field because of": 1.0,
    "because of its": 0.16666666666666666,
    "of its application": 0.125,
    "its application to": 1.0,
    "application to news-gathering": 1.0,
    "to news-gathering ,": 1.0,
    "news-gathering , text": 1.0,
    ", text categorization": 0.3333333333333333,
    "text categorization ,": 1.0,
    "categorization , voice-activation": 1.0,
    ", voice-activation ,": 1.0,
    "voice-activation , archiving": 1.0,
    ", archiving and": 1.0,
    "archiving and large-scale": 1.0,
    "and large-scale content-analysis": 1.0,
    "large-scale content-analysis .": 1.0,
    "<s> eight years": 1.0,
    "eight years after": 1.0,
    "years after john": 1.0,
    "after john mccarthy": 1.0,
    "john mccarthy coined": 1.0,
    "mccarthy coined the": 1.0,
    "coined the term": 1.0,
    "the term artificial": 0.1111111111111111,
    "term artificial intelligence": 1.0,
    "artificial intelligence ,": 0.125,
    "intelligence , bobrow": 1.0,
    ", bobrow 's": 1.0,
    "bobrow 's dissertation": 1.0,
    "'s dissertation -lrb-": 1.0,
    "dissertation -lrb- titled": 1.0,
    "-lrb- titled natural": 1.0,
    "titled natural language": 1.0,
    "language input for": 0.25,
    "input for a": 1.0,
    "a computer problem": 0.0625,
    "computer problem solving": 1.0,
    "problem solving system": 1.0,
    "solving system -rrb-": 1.0,
    "system -rrb- showed": 1.0,
    "-rrb- showed how": 1.0,
    "showed how a": 1.0,
    "how a computer": 0.5,
    "a computer can": 0.0625,
    "computer can understand": 1.0,
    "can understand simple": 1.0,
    "understand simple natural": 0.5,
    "simple natural language": 1.0,
    "language input to": 0.25,
    "input to solve": 0.3333333333333333,
    "to solve algebra": 0.25,
    "solve algebra word": 1.0,
    "algebra word problems": 1.0,
    "word problems .": 1.0,
    "<s> a year": 0.022727272727272728,
    "a year later": 0.5,
    "year later ,": 1.0,
    "later , in": 0.3333333333333333,
    ", in 1965": 0.029411764705882353,
    "in 1965 ,": 0.5,
    "1965 , joseph": 0.5,
    ", joseph weizenbaum": 1.0,
    "joseph weizenbaum at": 0.5,
    "weizenbaum at mit": 1.0,
    "at mit wrote": 0.5,
    "mit wrote eliza": 1.0,
    "wrote eliza ,": 1.0,
    "eliza , an": 0.3333333333333333,
    ", an interactive": 0.1,
    "an interactive program": 1.0,
    "interactive program that": 1.0,
    "program that carried": 0.5,
    "that carried on": 1.0,
    "carried on a": 1.0,
    "on a dialogue": 0.041666666666666664,
    "a dialogue in": 0.5,
    "dialogue in english": 1.0,
    "in english on": 0.14285714285714285,
    "english on any": 1.0,
    "on any topic": 0.5,
    "any topic ,": 0.5,
    "topic , the": 0.5,
    "most popular being": 0.3333333333333333,
    "popular being psychotherapy": 1.0,
    "being psychotherapy .": 1.0,
    "<s> eliza worked": 0.3333333333333333,
    "eliza worked by": 1.0,
    "worked by simple": 1.0,
    "by simple parsing": 1.0,
    "simple parsing and": 1.0,
    "parsing and substitution": 1.0,
    "and substitution of": 1.0,
    "substitution of key": 0.5,
    "of key words": 1.0,
    "key words into": 1.0,
    "words into canned": 0.25,
    "into canned phrases": 1.0,
    "canned phrases and": 1.0,
    "phrases and weizenbaum": 0.3333333333333333,
    "and weizenbaum sidestepped": 1.0,
    "weizenbaum sidestepped the": 1.0,
    "sidestepped the problem": 1.0,
    "problem of giving": 0.125,
    "of giving the": 1.0,
    "giving the program": 1.0,
    "the program a": 0.25,
    "program a database": 0.5,
    "a database of": 0.6666666666666666,
    "database of real-world": 0.5,
    "of real-world knowledge": 1.0,
    "real-world knowledge or": 1.0,
    "knowledge or a": 1.0,
    "or a rich": 0.05263157894736842,
    "a rich lexicon": 1.0,
    "rich lexicon .": 0.3333333333333333,
    "<s> yet eliza": 1.0,
    "yet eliza gained": 1.0,
    "eliza gained surprising": 1.0,
    "gained surprising popularity": 1.0,
    "surprising popularity as": 1.0,
    "popularity as a": 1.0,
    "as a toy": 0.027777777777777776,
    "a toy project": 0.5,
    "toy project and": 1.0,
    "project and can": 1.0,
    "can be seen": 0.03296703296703297,
    "be seen as": 0.6666666666666666,
    "seen as a": 0.6666666666666666,
    "as a very": 0.027777777777777776,
    "a very early": 0.08333333333333333,
    "very early precursor": 1.0,
    "early precursor to": 1.0,
    "precursor to current": 1.0,
    "to current commercial": 1.0,
    "current commercial systems": 1.0,
    "commercial systems such": 1.0,
    "systems such as": 1.0,
    "such as those": 0.05555555555555555,
    "as those used": 0.2,
    "those used by": 0.3333333333333333,
    "used by ask.com": 0.1111111111111111,
    "by ask.com .": 1.0,
    "<s> in 1969": 0.020618556701030927,
    "in 1969 roger": 0.5,
    "1969 roger schank": 1.0,
    "roger schank at": 0.3333333333333333,
    "schank at stanford": 1.0,
    "at stanford university": 0.5,
    "stanford university introduced": 1.0,
    "university introduced the": 1.0,
    "introduced the conceptual": 0.5,
    "the conceptual dependency": 1.0,
    "conceptual dependency theory": 1.0,
    "dependency theory for": 1.0,
    "theory for natural": 1.0,
    "for natural language": 0.75,
    "<s> this model": 0.038461538461538464,
    "this model ,": 0.5,
    "model , partially": 0.3333333333333333,
    ", partially influenced": 1.0,
    "partially influenced by": 1.0,
    "by the work": 0.03571428571428571,
    "the work of": 1.0,
    "work of sydney": 0.5,
    "of sydney lamb": 1.0,
    "sydney lamb ,": 1.0,
    "lamb , was": 1.0,
    ", was extensively": 0.25,
    "was extensively used": 1.0,
    "extensively used by": 1.0,
    "used by schank": 0.1111111111111111,
    "by schank 's": 1.0,
    "schank 's students": 1.0,
    "'s students at": 1.0,
    "students at yale": 0.5,
    "at yale university": 0.5,
    "yale university ,": 1.0,
    "university , such": 1.0,
    "such as robert": 0.011111111111111112,
    "as robert wilensky": 1.0,
    "robert wilensky ,": 1.0,
    "wilensky , wendy": 0.5,
    ", wendy lehnert": 1.0,
    "wendy lehnert ,": 1.0,
    "lehnert , and": 0.5,
    ", and janet": 0.005291005291005291,
    "and janet kolodner": 1.0,
    "janet kolodner .": 1.0,
    "<s> in 1970": 0.010309278350515464,
    "in 1970 ,": 1.0,
    "1970 , william": 1.0,
    ", william a.": 0.5,
    "william a. woods": 1.0,
    "a. woods introduced": 1.0,
    "woods introduced the": 1.0,
    "introduced the augmented": 0.5,
    "the augmented transition": 1.0,
    "augmented transition network": 1.0,
    "transition network -lrb-": 1.0,
    "network -lrb- atn": 1.0,
    "-lrb- atn -rrb-": 1.0,
    "atn -rrb- to": 1.0,
    "-rrb- to represent": 0.25,
    "to represent natural": 1.0,
    "represent natural language": 1.0,
    "language input .": 0.25,
    "instead of phrase": 0.14285714285714285,
    "of phrase structure": 1.0,
    "phrase structure rules": 0.5,
    "structure rules atns": 1.0,
    "rules atns used": 1.0,
    "atns used an": 1.0,
    "used an equivalent": 1.0,
    "an equivalent set": 1.0,
    "equivalent set of": 1.0,
    "set of finite": 0.03571428571428571,
    "of finite state": 1.0,
    "finite state automata": 0.25,
    "state automata that": 1.0,
    "automata that were": 1.0,
    "that were called": 0.25,
    "were called recursively": 1.0,
    "called recursively .": 1.0,
    "<s> atns and": 1.0,
    "atns and their": 1.0,
    "and their more": 0.16666666666666666,
    "their more general": 1.0,
    "more general format": 0.3333333333333333,
    "general format called": 1.0,
    "format called ``": 1.0,
    "called `` generalized": 0.2,
    "`` generalized atns": 1.0,
    "generalized atns ''": 1.0,
    "atns '' continued": 1.0,
    "'' continued to": 1.0,
    "continued to be": 0.6666666666666666,
    "to be used": 0.046511627906976744,
    "used for a": 0.13333333333333333,
    "number of years": 0.027777777777777776,
    "of years .": 1.0,
    "<s> in 1971": 0.010309278350515464,
    "in 1971 terry": 0.5,
    "1971 terry winograd": 1.0,
    "terry winograd finished": 1.0,
    "winograd finished writing": 1.0,
    "finished writing shrdlu": 1.0,
    "writing shrdlu for": 1.0,
    "shrdlu for his": 1.0,
    "for his phd": 0.5,
    "his phd thesis": 1.0,
    "phd thesis at": 1.0,
    "thesis at mit": 1.0,
    "at mit .": 0.5,
    "<s> shrdlu could": 0.5,
    "shrdlu could understand": 1.0,
    "could understand simple": 1.0,
    "understand simple english": 0.5,
    "simple english sentences": 1.0,
    "english sentences in": 1.0,
    "sentences in a": 0.125,
    "in a restricted": 0.019230769230769232,
    "a restricted world": 0.5,
    "restricted world of": 1.0,
    "world of children": 1.0,
    "of children 's": 1.0,
    "children 's blocks": 1.0,
    "'s blocks to": 1.0,
    "blocks to direct": 1.0,
    "to direct a": 1.0,
    "direct a robotic": 1.0,
    "a robotic arm": 1.0,
    "robotic arm to": 1.0,
    "arm to move": 1.0,
    "to move items": 1.0,
    "move items .": 1.0,
    "<s> the successful": 0.006802721088435374,
    "the successful demonstration": 0.5,
    "successful demonstration of": 1.0,
    "demonstration of shrdlu": 0.5,
    "of shrdlu provided": 1.0,
    "shrdlu provided significant": 1.0,
    "provided significant momentum": 1.0,
    "significant momentum for": 1.0,
    "momentum for continued": 1.0,
    "for continued research": 1.0,
    "continued research in": 0.5,
    "the field .": 0.11764705882352941,
    "<s> winograd continued": 1.0,
    "winograd continued to": 1.0,
    "be a major": 0.07692307692307693,
    "a major influence": 0.2,
    "major influence in": 1.0,
    "influence in the": 1.0,
    "the field with": 0.058823529411764705,
    "field with the": 1.0,
    "with the publication": 0.03333333333333333,
    "publication of his": 0.5,
    "of his book": 0.3333333333333333,
    "his book language": 1.0,
    "book language as": 1.0,
    "language as a": 0.5,
    "as a cognitive": 0.027777777777777776,
    "a cognitive process": 1.0,
    "cognitive process .": 1.0,
    "<s> at stanford": 0.3333333333333333,
    "at stanford ,": 0.5,
    "stanford , winograd": 1.0,
    ", winograd was": 1.0,
    "winograd was later": 1.0,
    "was later the": 1.0,
    "later the adviser": 1.0,
    "the adviser for": 1.0,
    "adviser for larry": 1.0,
    "for larry page": 1.0,
    "larry page ,": 1.0,
    "page , who": 0.25,
    ", who co-founded": 1.0,
    "who co-founded google": 1.0,
    "co-founded google .": 1.0,
    "in the 1970s": 0.006535947712418301,
    "the 1970s and": 1.0,
    "1970s and 1980s": 1.0,
    "and 1980s the": 0.5,
    "1980s the natural": 1.0,
    "language processing group": 0.027777777777777776,
    "processing group at": 1.0,
    "group at sri": 1.0,
    "at sri international": 1.0,
    "sri international continued": 1.0,
    "international continued research": 1.0,
    "continued research and": 0.5,
    "research and development": 0.3333333333333333,
    "and development in": 0.3333333333333333,
    "development in the": 1.0,
    "<s> a number": 0.06818181818181818,
    "number of commercial": 0.027777777777777776,
    "of commercial efforts": 1.0,
    "commercial efforts based": 0.5,
    "efforts based on": 1.0,
    "on the research": 0.014925373134328358,
    "the research were": 0.3333333333333333,
    "research were undertaken": 1.0,
    "were undertaken ,": 1.0,
    "undertaken , e.g.": 1.0,
    ", e.g. ,": 0.7,
    "e.g. , in": 0.038461538461538464,
    ", in 1982": 0.029411764705882353,
    "in 1982 gary": 0.5,
    "1982 gary hendrix": 1.0,
    "gary hendrix formed": 1.0,
    "hendrix formed symantec": 1.0,
    "formed symantec corporation": 1.0,
    "symantec corporation originally": 1.0,
    "corporation originally as": 1.0,
    "originally as a": 1.0,
    "as a company": 0.027777777777777776,
    "a company for": 1.0,
    "company for developing": 0.5,
    "for developing a": 0.5,
    "developing a natural": 1.0,
    "natural language interface": 0.014492753623188406,
    "language interface for": 1.0,
    "interface for database": 1.0,
    "for database queries": 1.0,
    "database queries on": 1.0,
    "queries on personal": 1.0,
    "on personal computers": 1.0,
    "personal computers .": 1.0,
    "however , with": 0.022727272727272728,
    ", with the": 0.125,
    "with the advent": 0.03333333333333333,
    "the advent of": 1.0,
    "advent of mouse": 1.0,
    "of mouse driven": 1.0,
    "mouse driven ,": 1.0,
    "driven , graphic": 1.0,
    ", graphic user": 1.0,
    "graphic user interfaces": 1.0,
    "user interfaces symantec": 0.5,
    "interfaces symantec changed": 1.0,
    "symantec changed direction": 1.0,
    "changed direction .": 1.0,
    "number of other": 0.027777777777777776,
    "of other commercial": 0.25,
    "other commercial efforts": 1.0,
    "commercial efforts were": 0.5,
    "efforts were started": 1.0,
    "were started around": 1.0,
    "started around the": 1.0,
    "around the same": 0.5,
    "time , e.g.": 0.09090909090909091,
    "e.g. , larry": 0.038461538461538464,
    ", larry r.": 1.0,
    "larry r. harris": 1.0,
    "r. harris at": 1.0,
    "harris at the": 1.0,
    "at the artificial": 0.0625,
    "the artificial intelligence": 1.0,
    "artificial intelligence corporation": 0.125,
    "intelligence corporation and": 1.0,
    "corporation and roger": 1.0,
    "and roger schank": 1.0,
    "roger schank and": 0.6666666666666666,
    "schank and his": 0.5,
    "and his students": 1.0,
    "his students at": 0.5,
    "students at cognitive": 0.5,
    "at cognitive systems": 1.0,
    "cognitive systems corp.": 1.0,
    "systems corp. .": 1.0,
    "<s> in 1983": 0.010309278350515464,
    "in 1983 ,": 1.0,
    "1983 , michael": 1.0,
    ", michael dyer": 0.25,
    "michael dyer developed": 1.0,
    "dyer developed the": 1.0,
    "developed the boris": 0.25,
    "the boris system": 1.0,
    "boris system at": 1.0,
    "system at yale": 1.0,
    "at yale which": 0.5,
    "yale which bore": 1.0,
    "which bore similarities": 1.0,
    "bore similarities to": 1.0,
    "similarities to the": 1.0,
    "to the work": 0.012987012987012988,
    "work of roger": 0.5,
    "of roger schank": 1.0,
    "schank and w.": 0.5,
    "and w. g.": 1.0,
    "w. g. lehnart": 1.0,
    "g. lehnart .": 1.0,
    "<s> scope and": 1.0,
    "scope and context": 1.0,
    "context the umbrella": 0.5,
    "the umbrella term": 1.0,
    "umbrella term ``": 1.0,
    "term `` natural": 0.5,
    "`` natural language": 0.25,
    "language understanding ''": 0.06666666666666667,
    "understanding '' can": 0.5,
    "can be applied": 0.02197802197802198,
    "to a diverse": 0.03571428571428571,
    "a diverse set": 1.0,
    "diverse set of": 1.0,
    "set of computer": 0.03571428571428571,
    "of computer applications": 0.25,
    "computer applications ,": 1.0,
    "applications , ranging": 0.25,
    ", ranging from": 1.0,
    "ranging from small": 0.5,
    "from small ,": 0.5,
    "small , relatively": 0.5,
    ", relatively simple": 1.0,
    "relatively simple tasks": 1.0,
    "simple tasks such": 1.0,
    "such as short": 0.011111111111111112,
    "as short commands": 1.0,
    "short commands issued": 1.0,
    "commands issued to": 1.0,
    "issued to robots": 1.0,
    "to robots ,": 1.0,
    "robots , to": 1.0,
    ", to highly": 0.07692307692307693,
    "to highly complex": 1.0,
    "highly complex endeavors": 1.0,
    "complex endeavors such": 1.0,
    "endeavors such as": 1.0,
    "as the full": 0.03571428571428571,
    "the full comprehension": 0.3333333333333333,
    "full comprehension of": 1.0,
    "comprehension of newspaper": 0.5,
    "of newspaper articles": 1.0,
    "newspaper articles or": 1.0,
    "articles or poetry": 0.5,
    "or poetry passages": 1.0,
    "poetry passages .": 1.0,
    "<s> many real": 0.09090909090909091,
    "many real world": 1.0,
    "real world applications": 0.3333333333333333,
    "world applications fall": 1.0,
    "applications fall between": 1.0,
    "fall between the": 1.0,
    "the two extremes": 0.14285714285714285,
    "two extremes ,": 1.0,
    "extremes , for": 1.0,
    ", for instance": 0.18181818181818182,
    "for instance text": 0.08333333333333333,
    "instance text classification": 1.0,
    "text classification for": 1.0,
    "classification for the": 0.5,
    "for the automatic": 0.03125,
    "the automatic analysis": 0.5,
    "automatic analysis of": 1.0,
    "analysis of emails": 0.07692307692307693,
    "of emails and": 1.0,
    "emails and their": 1.0,
    "and their routing": 0.16666666666666666,
    "their routing to": 1.0,
    "routing to a": 1.0,
    "to a suitable": 0.03571428571428571,
    "a suitable department": 0.3333333333333333,
    "suitable department in": 1.0,
    "department in a": 1.0,
    "in a corporation": 0.019230769230769232,
    "a corporation does": 1.0,
    "corporation does not": 1.0,
    "does not require": 0.2,
    "not require in": 1.0,
    "require in depth": 1.0,
    "in depth understanding": 1.0,
    "depth understanding of": 1.0,
    "understanding of the": 0.2,
    "text , but": 0.03333333333333333,
    ", but is": 0.041666666666666664,
    "but is far": 0.5,
    "is far more": 1.0,
    "far more complex": 0.5,
    "than the management": 0.25,
    "the management of": 1.0,
    "management of simple": 0.5,
    "of simple queries": 0.5,
    "simple queries to": 1.0,
    "queries to database": 1.0,
    "to database tables": 1.0,
    "database tables with": 1.0,
    "tables with fixed": 1.0,
    "with fixed schemata": 1.0,
    "fixed schemata .": 1.0,
    "<s> throughout the": 1.0,
    "throughout the years": 1.0,
    "the years various": 1.0,
    "years various attempts": 1.0,
    "various attempts at": 1.0,
    "attempts at processing": 0.5,
    "at processing natural": 1.0,
    "processing natural language": 1.0,
    "natural language or": 0.014492753623188406,
    "language or english-like": 0.5,
    "or english-like sentences": 1.0,
    "english-like sentences presented": 1.0,
    "sentences presented to": 1.0,
    "presented to computers": 1.0,
    "to computers have": 1.0,
    "computers have taken": 1.0,
    "have taken place": 1.0,
    "taken place at": 1.0,
    "place at varying": 1.0,
    "at varying degrees": 1.0,
    "varying degrees of": 1.0,
    "degrees of complexity": 1.0,
    "of complexity .": 1.0,
    "<s> some attempts": 0.0625,
    "some attempts have": 1.0,
    "attempts have not": 1.0,
    "have not resulted": 0.5,
    "not resulted in": 1.0,
    "resulted in systems": 0.5,
    "in systems with": 0.5,
    "systems with deep": 0.3333333333333333,
    "with deep understanding": 1.0,
    "understanding , but": 0.6666666666666666,
    ", but have": 0.041666666666666664,
    "but have helped": 0.5,
    "have helped overall": 1.0,
    "helped overall system": 1.0,
    "overall system usability": 1.0,
    "system usability .": 1.0,
    "example , wayne": 0.018518518518518517,
    ", wayne ratliff": 1.0,
    "wayne ratliff originally": 1.0,
    "ratliff originally developed": 1.0,
    "originally developed the": 1.0,
    "developed the vulcan": 0.25,
    "the vulcan program": 1.0,
    "vulcan program with": 1.0,
    "program with an": 1.0,
    "with an english-like": 0.2,
    "an english-like syntax": 1.0,
    "english-like syntax to": 1.0,
    "syntax to mimic": 0.5,
    "to mimic the": 1.0,
    "mimic the english": 1.0,
    "the english speaking": 0.25,
    "english speaking computer": 1.0,
    "speaking computer in": 1.0,
    "computer in star": 0.5,
    "in star trek": 1.0,
    "star trek .": 1.0,
    "<s> vulcan later": 1.0,
    "vulcan later became": 1.0,
    "later became the": 1.0,
    "became the dbase": 1.0,
    "the dbase system": 1.0,
    "dbase system whose": 1.0,
    "system whose easy-to-use": 1.0,
    "whose easy-to-use syntax": 1.0,
    "easy-to-use syntax effectively": 1.0,
    "syntax effectively launched": 1.0,
    "effectively launched the": 1.0,
    "launched the personal": 1.0,
    "the personal computer": 1.0,
    "personal computer database": 1.0,
    "computer database industry": 1.0,
    "database industry .": 1.0,
    "<s> systems with": 0.125,
    "systems with an": 0.3333333333333333,
    "with an easy": 0.2,
    "an easy to": 1.0,
    "easy to use": 0.3333333333333333,
    "to use or": 0.1,
    "use or english": 0.5,
    "or english like": 1.0,
    "english like syntax": 1.0,
    "like syntax are": 1.0,
    "syntax are ,": 1.0,
    "are , however": 1.0,
    "however , quite": 0.022727272727272728,
    ", quite distinct": 1.0,
    "quite distinct from": 1.0,
    "distinct from systems": 0.3333333333333333,
    "from systems that": 1.0,
    "systems that use": 0.18181818181818182,
    "that use a": 0.5,
    "use a rich": 0.25,
    "rich lexicon and": 0.3333333333333333,
    "lexicon and include": 1.0,
    "and include an": 0.5,
    "include an internal": 0.5,
    "an internal representation": 0.6666666666666666,
    "internal representation -lrb-": 0.3333333333333333,
    "representation -lrb- often": 0.5,
    "-lrb- often as": 0.5,
    "often as first": 0.5,
    "as first order": 1.0,
    "first order logic": 1.0,
    "order logic -rrb-": 1.0,
    "logic -rrb- of": 1.0,
    "of the semantics": 0.005128205128205128,
    "the semantics of": 0.5,
    "semantics of natural": 1.0,
    "natural language sentences": 0.014492753623188406,
    "language sentences .": 1.0,
    "<s> hence the": 0.5,
    "hence the breadth": 1.0,
    "the breadth and": 1.0,
    "breadth and depth": 1.0,
    "and depth of": 1.0,
    "depth of ``": 1.0,
    "of `` understanding": 0.125,
    "`` understanding ''": 1.0,
    "understanding '' aimed": 0.5,
    "'' aimed at": 1.0,
    "aimed at by": 0.5,
    "at by a": 1.0,
    "by a system": 0.05555555555555555,
    "a system determine": 0.1,
    "system determine both": 1.0,
    "determine both the": 1.0,
    "both the complexity": 0.5,
    "the system -lrb-": 0.038461538461538464,
    "system -lrb- and": 0.5,
    "-lrb- and the": 0.4,
    "and the implied": 0.024390243902439025,
    "the implied challenges": 1.0,
    "implied challenges -rrb-": 1.0,
    "challenges -rrb- and": 1.0,
    "and the types": 0.024390243902439025,
    "types of applications": 0.07142857142857142,
    "of applications it": 0.3333333333333333,
    "applications it can": 1.0,
    "it can deal": 0.16666666666666666,
    "can deal with": 1.0,
    "deal with .": 0.5,
    "<s> the ``": 0.013605442176870748,
    "the `` breadth": 0.14285714285714285,
    "`` breadth ''": 1.0,
    "breadth '' of": 1.0,
    "'' of a": 1.0,
    "a system is": 0.1,
    "system is measured": 0.1111111111111111,
    "is measured by": 0.6666666666666666,
    "measured by the": 0.6666666666666666,
    "by the sizes": 0.03571428571428571,
    "the sizes of": 1.0,
    "sizes of its": 0.5,
    "of its vocabulary": 0.125,
    "its vocabulary and": 1.0,
    "vocabulary and grammar": 0.5,
    "and grammar .": 0.5,
    "the `` depth": 0.14285714285714285,
    "`` depth ''": 1.0,
    "depth '' is": 1.0,
    "'' is measured": 0.1111111111111111,
    "by the degree": 0.03571428571428571,
    "the degree to": 1.0,
    "degree to which": 1.0,
    "to which its": 0.2,
    "which its understanding": 1.0,
    "its understanding approximates": 1.0,
    "understanding approximates that": 1.0,
    "approximates that of": 1.0,
    "of a fluent": 0.010869565217391304,
    "a fluent native": 1.0,
    "fluent native speaker": 1.0,
    "<s> at the": 0.3333333333333333,
    "at the narrowest": 0.0625,
    "the narrowest and": 1.0,
    "narrowest and shallowest": 1.0,
    "and shallowest ,": 1.0,
    "shallowest , english-like": 1.0,
    ", english-like command": 1.0,
    "english-like command interpreters": 1.0,
    "command interpreters require": 1.0,
    "interpreters require minimal": 1.0,
    "require minimal complexity": 1.0,
    "minimal complexity ,": 1.0,
    "complexity , but": 1.0,
    "but have a": 0.5,
    "have a small": 0.07692307692307693,
    "a small range": 0.5,
    "small range of": 1.0,
    "range of applications": 0.25,
    "of applications .": 0.3333333333333333,
    "<s> narrow but": 1.0,
    "narrow but deep": 1.0,
    "but deep systems": 1.0,
    "deep systems explore": 1.0,
    "systems explore and": 1.0,
    "explore and model": 1.0,
    "and model mechanisms": 1.0,
    "model mechanisms of": 1.0,
    "mechanisms of understanding": 1.0,
    "of understanding ,": 1.0,
    ", but they": 0.0625,
    "but they still": 0.3333333333333333,
    "they still have": 1.0,
    "still have limited": 1.0,
    "have limited application": 1.0,
    "limited application .": 1.0,
    "<s> systems that": 0.5,
    "systems that attempt": 0.09090909090909091,
    "that attempt to": 1.0,
    "attempt to understand": 0.16666666666666666,
    "to understand the": 0.6666666666666666,
    "understand the contents": 0.5,
    "the contents of": 1.0,
    "contents of a": 1.0,
    "of a document": 0.021739130434782608,
    "a document such": 0.125,
    "document such as": 1.0,
    "as a news": 0.027777777777777776,
    "a news release": 0.5,
    "news release beyond": 1.0,
    "release beyond simple": 1.0,
    "beyond simple keyword": 1.0,
    "simple keyword matching": 1.0,
    "keyword matching and": 1.0,
    "matching and to": 1.0,
    "and to judge": 0.09090909090909091,
    "to judge its": 0.5,
    "judge its suitability": 1.0,
    "its suitability for": 1.0,
    "suitability for a": 1.0,
    "for a user": 0.03225806451612903,
    "a user are": 0.5,
    "user are broader": 1.0,
    "are broader and": 1.0,
    "broader and require": 1.0,
    "and require significant": 0.3333333333333333,
    "require significant complexity": 1.0,
    "significant complexity ,": 1.0,
    "but they are": 0.3333333333333333,
    "they are still": 0.14285714285714285,
    "are still somewhat": 0.25,
    "still somewhat shallow": 1.0,
    "somewhat shallow .": 1.0,
    "systems that are": 0.18181818181818182,
    "are both very": 0.5,
    "both very broad": 1.0,
    "very broad and": 0.5,
    "broad and very": 1.0,
    "and very deep": 1.0,
    "very deep are": 1.0,
    "deep are beyond": 1.0,
    "are beyond the": 1.0,
    "beyond the current": 0.3333333333333333,
    "the current state": 0.5,
    "current state of": 1.0,
    "state of the": 0.8,
    "of the art": 0.010256410256410256,
    "the art .": 0.5,
    "<s> components and": 1.0,
    "components and architecture": 1.0,
    "and architecture regardless": 1.0,
    "architecture regardless of": 1.0,
    "regardless of the": 0.5,
    "of the approach": 0.005128205128205128,
    "the approach used": 1.0,
    "approach used ,": 1.0,
    "used , some": 0.125,
    ", some common": 0.1111111111111111,
    "some common components": 1.0,
    "common components can": 1.0,
    "components can be": 1.0,
    "can be identified": 0.01098901098901099,
    "be identified in": 0.5,
    "identified in most": 1.0,
    "in most natural": 0.5,
    "most natural language": 1.0,
    "language understanding systems": 0.06666666666666667,
    "understanding systems .": 1.0,
    "system needs a": 0.25,
    "needs a lexicon": 0.5,
    "a lexicon of": 1.0,
    "lexicon of the": 0.5,
    "the language and": 0.125,
    "language and a": 0.5,
    "and a parser": 0.0625,
    "a parser and": 0.25,
    "parser and grammar": 1.0,
    "and grammar rules": 0.5,
    "grammar rules to": 0.2,
    "rules to break": 0.3333333333333333,
    "to break sentences": 1.0,
    "break sentences into": 1.0,
    "sentences into an": 0.3333333333333333,
    "into an internal": 0.5,
    "internal representation .": 0.6666666666666666,
    "<s> the construction": 0.006802721088435374,
    "of a rich": 0.010869565217391304,
    "rich lexicon with": 0.3333333333333333,
    "lexicon with a": 1.0,
    "with a suitable": 0.05,
    "a suitable ontology": 0.3333333333333333,
    "suitable ontology requires": 1.0,
    "ontology requires significant": 1.0,
    "requires significant effort": 1.0,
    "significant effort ,": 1.0,
    "effort , e.g.": 1.0,
    "e.g. , the": 0.07692307692307693,
    ", the wordnet": 0.009523809523809525,
    "the wordnet lexicon": 1.0,
    "wordnet lexicon required": 1.0,
    "lexicon required many": 1.0,
    "required many person-years": 1.0,
    "many person-years of": 1.0,
    "person-years of effort": 1.0,
    "of effort .": 1.0,
    "the system also": 0.038461538461538464,
    "system also needs": 1.0,
    "also needs a": 1.0,
    "needs a semantic": 0.5,
    "a semantic theory": 0.5,
    "semantic theory to": 0.5,
    "theory to guide": 1.0,
    "to guide the": 1.0,
    "guide the comprehension": 0.5,
    "the comprehension .": 1.0,
    "<s> the interpretation": 0.006802721088435374,
    "the interpretation capabilities": 1.0,
    "interpretation capabilities of": 1.0,
    "capabilities of a": 1.0,
    "of a language": 0.021739130434782608,
    "a language understanding": 0.16666666666666666,
    "language understanding system": 0.06666666666666667,
    "understanding system depend": 1.0,
    "system depend on": 1.0,
    "depend on the": 0.3333333333333333,
    "on the semantic": 0.014925373134328358,
    "the semantic theory": 0.5,
    "semantic theory it": 0.5,
    "theory it uses": 1.0,
    "it uses .": 0.5,
    "<s> competing semantic": 1.0,
    "competing semantic theories": 1.0,
    "semantic theories of": 1.0,
    "theories of language": 0.3333333333333333,
    "of language have": 0.2,
    "language have specific": 1.0,
    "have specific trade": 1.0,
    "specific trade offs": 1.0,
    "trade offs in": 1.0,
    "offs in their": 1.0,
    "in their suitability": 0.25,
    "their suitability as": 1.0,
    "suitability as the": 1.0,
    "as the basis": 0.03571428571428571,
    "basis of computer": 0.25,
    "of computer automated": 0.25,
    "computer automated semantic": 1.0,
    "automated semantic interpretation": 1.0,
    "semantic interpretation .": 1.0,
    "<s> these range": 0.0625,
    "these range from": 1.0,
    "range from naive": 0.5,
    "from naive semantics": 1.0,
    "naive semantics or": 1.0,
    "semantics or stochastic": 0.5,
    "or stochastic semantic": 1.0,
    "stochastic semantic analysis": 1.0,
    "semantic analysis to": 0.3333333333333333,
    "analysis to the": 1.0,
    "to the use": 0.03896103896103896,
    "use of pragmatics": 0.045454545454545456,
    "of pragmatics to": 1.0,
    "pragmatics to derive": 1.0,
    "to derive meaning": 1.0,
    "derive meaning from": 1.0,
    "meaning from context": 1.0,
    "from context .": 1.0,
    "<s> advanced applications": 0.3333333333333333,
    "advanced applications of": 1.0,
    "applications of natural": 1.0,
    "language understanding also": 0.06666666666666667,
    "understanding also attempt": 1.0,
    "also attempt to": 1.0,
    "attempt to incorporate": 0.16666666666666666,
    "to incorporate logical": 1.0,
    "incorporate logical inference": 1.0,
    "logical inference within": 1.0,
    "inference within their": 1.0,
    "within their framework": 1.0,
    "their framework .": 1.0,
    "this is generally": 0.038461538461538464,
    "is generally achieved": 1.0,
    "generally achieved by": 1.0,
    "achieved by mapping": 0.5,
    "by mapping the": 1.0,
    "mapping the derived": 1.0,
    "the derived meaning": 1.0,
    "derived meaning into": 1.0,
    "meaning into a": 1.0,
    "into a set": 0.058823529411764705,
    "set of assertions": 0.03571428571428571,
    "of assertions in": 1.0,
    "assertions in predicate": 1.0,
    "in predicate logic": 1.0,
    "predicate logic ,": 1.0,
    "logic , then": 1.0,
    ", then using": 0.09090909090909091,
    "then using logical": 1.0,
    "using logical deduction": 1.0,
    "logical deduction to": 1.0,
    "deduction to arrive": 1.0,
    "to arrive at": 1.0,
    "arrive at conclusions": 1.0,
    "at conclusions .": 1.0,
    "based on functional": 0.021739130434782608,
    "on functional languages": 1.0,
    "functional languages such": 1.0,
    "such as lisp": 0.011111111111111112,
    "as lisp hence": 1.0,
    "lisp hence need": 1.0,
    "hence need to": 1.0,
    "need to include": 0.1,
    "to include a": 0.14285714285714285,
    "include a subsystem": 0.3333333333333333,
    "a subsystem for": 1.0,
    "subsystem for the": 1.0,
    "for the representation": 0.03125,
    "the representation of": 1.0,
    "representation of logical": 0.5,
    "of logical assertions": 1.0,
    "logical assertions ,": 1.0,
    "assertions , while": 1.0,
    ", while logic": 0.07142857142857142,
    "while logic oriented": 1.0,
    "logic oriented systems": 1.0,
    "oriented systems such": 1.0,
    "as those using": 0.2,
    "those using the": 1.0,
    "using the language": 0.14285714285714285,
    "the language prolog": 0.125,
    "language prolog generally": 1.0,
    "prolog generally rely": 1.0,
    "generally rely on": 1.0,
    "rely on an": 0.16666666666666666,
    "on an extension": 0.3333333333333333,
    "an extension of": 1.0,
    "extension of the": 1.0,
    "of the built": 0.005128205128205128,
    "the built in": 1.0,
    "built in logical": 1.0,
    "in logical representation": 1.0,
    "logical representation framework": 1.0,
    "representation framework .": 1.0,
    "<s> the management": 0.006802721088435374,
    "management of context": 0.5,
    "of context in": 0.5,
    "context in natural": 1.0,
    "language understanding can": 0.06666666666666667,
    "understanding can present": 1.0,
    "can present special": 1.0,
    "present special challenges": 1.0,
    "special challenges .": 1.0,
    "<s> a large": 0.022727272727272728,
    "a large variety": 0.1111111111111111,
    "large variety of": 1.0,
    "variety of examples": 0.125,
    "of examples and": 1.0,
    "examples and counter": 0.25,
    "and counter examples": 1.0,
    "counter examples have": 1.0,
    "examples have resulted": 1.0,
    "have resulted in": 1.0,
    "resulted in multiple": 0.5,
    "in multiple approaches": 1.0,
    "multiple approaches to": 1.0,
    "approaches to the": 0.2,
    "to the formal": 0.012987012987012988,
    "the formal modeling": 0.5,
    "formal modeling of": 1.0,
    "modeling of context": 1.0,
    "of context ,": 0.5,
    "context , each": 0.25,
    ", each with": 0.16666666666666666,
    "each with specific": 1.0,
    "with specific strengths": 1.0,
    "specific strengths and": 1.0,
    "strengths and weaknesses": 1.0,
    "and weaknesses .": 1.0,
    "character recognition ,": 0.3076923076923077,
    "recognition , usually": 0.07142857142857142,
    ", usually abbreviated": 0.2,
    "usually abbreviated to": 1.0,
    "abbreviated to ocr": 1.0,
    "to ocr ,": 1.0,
    "ocr , is": 0.14285714285714285,
    "is the mechanical": 0.022222222222222223,
    "the mechanical or": 1.0,
    "mechanical or electronic": 1.0,
    "or electronic conversion": 1.0,
    "electronic conversion of": 1.0,
    "conversion of scanned": 0.5,
    "of scanned images": 1.0,
    "scanned images of": 1.0,
    "images of handwritten": 0.5,
    "of handwritten ,": 1.0,
    "handwritten , typewritten": 1.0,
    ", typewritten or": 0.5,
    "typewritten or printed": 1.0,
    "or printed text": 1.0,
    "printed text into": 0.3333333333333333,
    "text into machine-encoded": 0.14285714285714285,
    "into machine-encoded text": 1.0,
    "machine-encoded text .": 1.0,
    "it is widely": 0.02127659574468085,
    "is widely used": 1.0,
    "widely used as": 0.14285714285714285,
    "used as a": 0.4,
    "as a form": 0.027777777777777776,
    "a form of": 1.0,
    "form of data": 0.14285714285714285,
    "of data entry": 0.14285714285714285,
    "data entry from": 0.3333333333333333,
    "entry from some": 1.0,
    "from some sort": 1.0,
    "some sort of": 1.0,
    "sort of original": 0.5,
    "of original paper": 1.0,
    "original paper data": 1.0,
    "paper data source": 1.0,
    "data source ,": 1.0,
    "source , whether": 1.0,
    ", whether documents": 1.0,
    "whether documents ,": 1.0,
    "documents , sales": 0.1111111111111111,
    ", sales receipts": 1.0,
    "sales receipts ,": 1.0,
    "receipts , mail": 1.0,
    ", mail ,": 1.0,
    "mail , or": 1.0,
    ", or any": 0.030303030303030304,
    "or any number": 0.3333333333333333,
    "any number of": 1.0,
    "number of printed": 0.027777777777777776,
    "of printed records": 0.5,
    "printed records .": 1.0,
    "it is crucial": 0.02127659574468085,
    "is crucial to": 1.0,
    "crucial to the": 1.0,
    "to the computerization": 0.012987012987012988,
    "the computerization of": 1.0,
    "computerization of printed": 1.0,
    "of printed texts": 0.5,
    "printed texts so": 1.0,
    "texts so that": 1.0,
    "so that they": 0.16666666666666666,
    "can be electronically": 0.01098901098901099,
    "be electronically searched": 1.0,
    "electronically searched ,": 1.0,
    "searched , stored": 0.5,
    ", stored more": 1.0,
    "stored more compactly": 1.0,
    "more compactly ,": 1.0,
    "compactly , displayed": 1.0,
    ", displayed on-line": 1.0,
    "displayed on-line ,": 1.0,
    "on-line , and": 1.0,
    ", and used": 0.005291005291005291,
    "and used in": 1.0,
    "used in machine": 0.043478260869565216,
    "in machine processes": 0.2,
    "machine processes such": 1.0,
    "processes such as": 1.0,
    "such as machine": 0.011111111111111112,
    "as machine translation": 1.0,
    "translation , text-to-speech": 0.125,
    "text-to-speech and text": 0.5,
    "and text mining": 0.25,
    "text mining .": 0.5,
    "<s> ocr is": 0.5,
    "ocr is a": 0.3333333333333333,
    "field of research": 0.08333333333333333,
    "of research in": 0.25,
    "research in pattern": 0.14285714285714285,
    "in pattern recognition": 1.0,
    "pattern recognition ,": 0.25,
    "recognition , artificial": 0.07142857142857142,
    "artificial intelligence and": 0.125,
    "intelligence and computer": 0.5,
    "and computer vision": 1.0,
    "computer vision .": 1.0,
    "<s> early versions": 0.5,
    "early versions needed": 1.0,
    "versions needed to": 1.0,
    "needed to be": 0.5,
    "to be programmed": 0.023255813953488372,
    "be programmed with": 0.5,
    "programmed with images": 1.0,
    "with images of": 1.0,
    "images of each": 0.5,
    "of each character": 0.14285714285714285,
    "each character ,": 1.0,
    "character , and": 0.5,
    ", and worked": 0.005291005291005291,
    "and worked on": 1.0,
    "worked on one": 0.5,
    "on one font": 0.5,
    "one font at": 1.0,
    "font at a": 1.0,
    "at a time": 0.5,
    "a time .": 1.0,
    "<s> `` intelligent": 0.2,
    "`` intelligent ''": 1.0,
    "intelligent '' systems": 1.0,
    "'' systems with": 0.3333333333333333,
    "systems with a": 0.3333333333333333,
    "a high degree": 0.25,
    "high degree of": 1.0,
    "degree of recognition": 0.3333333333333333,
    "of recognition accuracy": 0.5,
    "recognition accuracy for": 0.14285714285714285,
    "accuracy for most": 0.3333333333333333,
    "for most fonts": 0.3333333333333333,
    "most fonts are": 1.0,
    "fonts are now": 1.0,
    "are now common": 0.25,
    "now common .": 1.0,
    "systems are capable": 0.07692307692307693,
    "are capable of": 1.0,
    "capable of reproducing": 0.5,
    "of reproducing formatted": 1.0,
    "reproducing formatted output": 1.0,
    "formatted output that": 1.0,
    "output that closely": 0.5,
    "that closely approximates": 1.0,
    "closely approximates the": 1.0,
    "approximates the original": 1.0,
    "the original scanned": 0.1,
    "original scanned page": 1.0,
    "scanned page including": 1.0,
    "page including images": 1.0,
    "including images ,": 1.0,
    "images , columns": 0.5,
    ", columns and": 1.0,
    "columns and other": 1.0,
    "and other non-textual": 0.1111111111111111,
    "other non-textual components": 1.0,
    "non-textual components .": 1.0,
    "<s> in 1914": 0.010309278350515464,
    "in 1914 ,": 1.0,
    "1914 , emanuel": 1.0,
    ", emanuel goldberg": 0.5,
    "emanuel goldberg developed": 1.0,
    "goldberg developed a": 1.0,
    "developed a machine": 0.3333333333333333,
    "a machine that": 0.125,
    "machine that read": 1.0,
    "that read characters": 1.0,
    "read characters and": 1.0,
    "characters and converted": 1.0,
    "and converted them": 1.0,
    "converted them into": 1.0,
    "them into standard": 1.0,
    "into standard telegraph": 1.0,
    "standard telegraph code": 1.0,
    "telegraph code .": 1.0,
    "needed -rrb- around": 0.07692307692307693,
    "-rrb- around the": 1.0,
    "time , edmund": 0.09090909090909091,
    ", edmund fournier": 1.0,
    "edmund fournier d'albe": 1.0,
    "fournier d'albe developed": 1.0,
    "d'albe developed the": 1.0,
    "developed the optophone": 0.25,
    "the optophone ,": 1.0,
    "optophone , a": 1.0,
    ", a handheld": 0.020833333333333332,
    "a handheld scanner": 1.0,
    "handheld scanner that": 1.0,
    "scanner that when": 1.0,
    "that when moved": 1.0,
    "when moved across": 1.0,
    "moved across a": 1.0,
    "across a printed": 1.0,
    "a printed page": 1.0,
    "printed page ,": 1.0,
    "page , produced": 0.25,
    ", produced tones": 0.3333333333333333,
    "produced tones that": 1.0,
    "tones that corresponded": 1.0,
    "that corresponded to": 1.0,
    "corresponded to specific": 1.0,
    "to specific letters": 1.0,
    "specific letters or": 1.0,
    "letters or characters": 1.0,
    "or characters .": 1.0,
    "<s> goldberg continued": 1.0,
    "goldberg continued to": 1.0,
    "continued to develop": 0.3333333333333333,
    "to develop ocr": 0.2,
    "develop ocr technology": 1.0,
    "ocr technology for": 0.1111111111111111,
    "technology for data": 0.5,
    "for data entry": 0.5,
    "data entry .": 0.3333333333333333,
    "<s> later ,": 1.0,
    "later , he": 0.16666666666666666,
    ", he proposed": 0.5,
    "he proposed photographing": 1.0,
    "proposed photographing data": 1.0,
    "photographing data records": 1.0,
    "data records and": 1.0,
    "records and then": 1.0,
    "and then ,": 0.14285714285714285,
    "then , using": 0.2,
    ", using photocells": 0.1,
    "using photocells ,": 1.0,
    "photocells , matching": 1.0,
    ", matching the": 1.0,
    "matching the photos": 1.0,
    "the photos against": 1.0,
    "photos against a": 1.0,
    "against a template": 1.0,
    "a template containing": 0.5,
    "template containing the": 1.0,
    "containing the desired": 0.3333333333333333,
    "the desired identification": 0.25,
    "desired identification pattern": 1.0,
    "identification pattern .": 1.0,
    "<s> in 1929": 0.010309278350515464,
    "in 1929 gustav": 1.0,
    "1929 gustav tauschek": 1.0,
    "gustav tauschek had": 1.0,
    "tauschek had similar": 1.0,
    "had similar ideas": 1.0,
    "similar ideas ,": 1.0,
    "ideas , and": 1.0,
    ", and obtained": 0.005291005291005291,
    "and obtained a": 1.0,
    "obtained a patent": 0.5,
    "a patent on": 0.5,
    "patent on ocr": 0.3333333333333333,
    "on ocr in": 1.0,
    "ocr in germany": 0.5,
    "in germany .": 0.5,
    "<s> paul w.": 1.0,
    "paul w. handel": 1.0,
    "w. handel also": 1.0,
    "handel also obtained": 1.0,
    "also obtained a": 1.0,
    "obtained a us": 0.5,
    "a us patent": 1.0,
    "us patent on": 1.0,
    "patent on such": 0.3333333333333333,
    "on such template-matching": 1.0,
    "such template-matching ocr": 1.0,
    "template-matching ocr technology": 1.0,
    "ocr technology in": 0.1111111111111111,
    "technology in usa": 1.0,
    "in usa in": 1.0,
    "usa in 1933": 1.0,
    "in 1933 -lrb-": 1.0,
    "1933 -lrb- u.s.": 1.0,
    "-lrb- u.s. patent": 1.0,
    "u.s. patent 1,915,993": 0.3333333333333333,
    "patent 1,915,993 -rrb-": 1.0,
    "1,915,993 -rrb- .": 1.0,
    "<s> in 1935": 0.010309278350515464,
    "in 1935 tauschek": 1.0,
    "1935 tauschek was": 1.0,
    "tauschek was also": 1.0,
    "was also granted": 0.5,
    "also granted a": 1.0,
    "granted a us": 1.0,
    "patent on his": 0.3333333333333333,
    "on his method": 1.0,
    "his method -lrb-": 1.0,
    "method -lrb- u.s.": 1.0,
    "u.s. patent 2,026,329": 0.3333333333333333,
    "patent 2,026,329 -rrb-": 1.0,
    "2,026,329 -rrb- .": 1.0,
    "<s> in 1949": 0.010309278350515464,
    "in 1949 rca": 0.5,
    "1949 rca engineers": 1.0,
    "rca engineers worked": 1.0,
    "engineers worked on": 1.0,
    "worked on the": 0.5,
    "on the first": 0.014925373134328358,
    "the first primitive": 0.045454545454545456,
    "first primitive computer-type": 1.0,
    "primitive computer-type ocr": 1.0,
    "computer-type ocr to": 1.0,
    "ocr to help": 0.3333333333333333,
    "to help blind": 0.5,
    "help blind people": 1.0,
    "blind people for": 0.3333333333333333,
    "people for the": 1.0,
    "for the us": 0.03125,
    "the us veterans": 0.5,
    "us veterans administration": 1.0,
    "veterans administration ,": 1.0,
    "administration , but": 1.0,
    ", but instead": 0.020833333333333332,
    "but instead of": 1.0,
    "instead of converting": 0.14285714285714285,
    "of converting the": 0.5,
    "converting the printed": 1.0,
    "the printed characters": 1.0,
    "printed characters to": 1.0,
    "characters to machine": 1.0,
    "to machine language": 0.6666666666666666,
    "machine language ,": 0.3333333333333333,
    "language , their": 0.14285714285714285,
    ", their device": 1.0,
    "their device converted": 1.0,
    "device converted it": 1.0,
    "converted it to": 1.0,
    "it to machine": 0.2,
    "machine language and": 0.3333333333333333,
    "language and then": 0.5,
    "and then spoke": 0.14285714285714285,
    "then spoke the": 1.0,
    "spoke the letters": 1.0,
    "the letters :": 1.0,
    "letters : an": 1.0,
    ": an early": 1.0,
    "an early text-to-speech": 1.0,
    "early text-to-speech technology": 1.0,
    "text-to-speech technology .": 1.0,
    "<s> it proved": 0.029411764705882353,
    "it proved far": 0.5,
    "proved far too": 1.0,
    "far too expensive": 1.0,
    "too expensive and": 0.5,
    "expensive and was": 1.0,
    "and was not": 1.0,
    "was not pursued": 0.5,
    "not pursued after": 1.0,
    "pursued after testing": 1.0,
    "after testing .": 1.0,
    "1950 , david": 0.5,
    ", david h.": 0.3333333333333333,
    "david h. shepard": 1.0,
    "h. shepard ,": 1.0,
    "shepard , a": 1.0,
    ", a cryptanalyst": 0.020833333333333332,
    "a cryptanalyst at": 1.0,
    "cryptanalyst at the": 1.0,
    "at the armed": 0.0625,
    "the armed forces": 1.0,
    "armed forces security": 1.0,
    "forces security agency": 1.0,
    "security agency in": 1.0,
    "agency in the": 1.0,
    "in the united": 0.006535947712418301,
    "united states ,": 0.14285714285714285,
    "states , addressed": 1.0,
    ", addressed the": 1.0,
    "addressed the problem": 1.0,
    "problem of converting": 0.125,
    "of converting printed": 0.5,
    "converting printed messages": 1.0,
    "printed messages into": 1.0,
    "messages into machine": 1.0,
    "into machine language": 1.0,
    "machine language for": 0.3333333333333333,
    "language for computer": 0.3333333333333333,
    "for computer processing": 0.3333333333333333,
    "computer processing and": 1.0,
    "processing and built": 1.0,
    "and built a": 1.0,
    "built a machine": 1.0,
    "a machine to": 0.125,
    "machine to do": 1.0,
    "to do this": 0.3333333333333333,
    "do this ,": 0.5,
    "this , called": 0.25,
    ", called ``": 1.0,
    "called `` gismo": 0.2,
    "`` gismo .": 0.5,
    "gismo . ''": 1.0,
    ". '' .": 0.5,
    "<s> he received": 0.14285714285714285,
    "he received a": 1.0,
    "received a patent": 1.0,
    "a patent for": 0.5,
    "patent for his": 1.0,
    "for his ``": 0.5,
    "his `` apparatus": 1.0,
    "`` apparatus for": 1.0,
    "apparatus for reading": 1.0,
    "for reading ''": 0.3333333333333333,
    "reading '' in": 1.0,
    "'' in 1953": 0.14285714285714285,
    "in 1953 u.s.": 1.0,
    "1953 u.s. patent": 1.0,
    "u.s. patent 2,663,758": 0.3333333333333333,
    "patent 2,663,758 .": 1.0,
    "<s> `` gismo": 0.2,
    "`` gismo ''": 0.5,
    "gismo '' could": 1.0,
    "'' could read": 1.0,
    "could read 23": 1.0,
    "read 23 letters": 1.0,
    "23 letters of": 1.0,
    "letters of the": 1.0,
    "of the english": 0.010256410256410256,
    "the english alphabet": 0.5,
    "english alphabet ,": 0.5,
    "alphabet , comprehend": 0.5,
    ", comprehend morse": 1.0,
    "comprehend morse code": 1.0,
    "morse code ,": 1.0,
    "code , read": 0.5,
    ", read musical": 0.5,
    "read musical notations": 1.0,
    "musical notations ,": 1.0,
    "notations , read": 1.0,
    ", read aloud": 0.5,
    "read aloud from": 1.0,
    "aloud from printed": 1.0,
    "from printed pages": 1.0,
    "printed pages ,": 1.0,
    ", and duplicate": 0.005291005291005291,
    "and duplicate typewritten": 1.0,
    "duplicate typewritten pages": 1.0,
    "typewritten pages .": 1.0,
    "<s> shepard went": 1.0,
    "shepard went on": 1.0,
    "went on to": 1.0,
    "on to found": 0.5,
    "to found intelligent": 1.0,
    "found intelligent machines": 1.0,
    "intelligent machines research": 1.0,
    "machines research corporation": 1.0,
    "research corporation -lrb-": 1.0,
    "corporation -lrb- imr": 0.5,
    "-lrb- imr -rrb-": 1.0,
    "imr -rrb- ,": 1.0,
    ", which soon": 0.017857142857142856,
    "which soon developed": 1.0,
    "soon developed the": 1.0,
    "developed the world": 0.25,
    "the world 's": 0.125,
    "world 's first": 1.0,
    "'s first commercial": 1.0,
    "first commercial ocr": 0.5,
    "commercial ocr systems": 0.5,
    "ocr systems .": 0.25,
    "<s> in 1955": 0.010309278350515464,
    "in 1955 ,": 1.0,
    "1955 , the": 0.5,
    "the first commercial": 0.045454545454545456,
    "first commercial system": 0.5,
    "commercial system was": 1.0,
    "system was installed": 0.2,
    "was installed at": 1.0,
    "installed at the": 0.5,
    "at the reader": 0.0625,
    "the reader 's": 0.16666666666666666,
    "reader 's digest": 1.0,
    "'s digest ,": 0.3333333333333333,
    "digest , which": 1.0,
    ", which used": 0.017857142857142856,
    "which used ocr": 1.0,
    "used ocr to": 1.0,
    "ocr to input": 0.3333333333333333,
    "to input sales": 0.5,
    "input sales reports": 1.0,
    "sales reports into": 1.0,
    "reports into a": 0.5,
    "into a computer": 0.058823529411764705,
    "a computer .": 0.125,
    "<s> it converted": 0.029411764705882353,
    "it converted the": 1.0,
    "converted the typewritten": 1.0,
    "the typewritten reports": 1.0,
    "typewritten reports into": 1.0,
    "reports into punched": 0.5,
    "into punched cards": 1.0,
    "punched cards for": 1.0,
    "cards for input": 1.0,
    "for input into": 1.0,
    "input into the": 1.0,
    "into the computer": 0.125,
    "the computer in": 0.5,
    "computer in the": 0.5,
    "in the magazine": 0.006535947712418301,
    "the magazine 's": 1.0,
    "magazine 's subscription": 1.0,
    "'s subscription department": 1.0,
    "subscription department ,": 1.0,
    "department , for": 1.0,
    ", for help": 0.045454545454545456,
    "for help in": 1.0,
    "help in processing": 1.0,
    "in processing the": 1.0,
    "processing the shipment": 0.5,
    "the shipment of": 1.0,
    "shipment of 15-20": 1.0,
    "of 15-20 million": 1.0,
    "15-20 million books": 1.0,
    "million books a": 1.0,
    "books a year": 1.0,
    "a year .": 0.5,
    "<s> the second": 0.006802721088435374,
    "the second system": 0.3333333333333333,
    "second system was": 1.0,
    "system was sold": 0.2,
    "was sold to": 1.0,
    "sold to the": 1.0,
    "to the standard": 0.012987012987012988,
    "the standard oil": 0.3333333333333333,
    "standard oil company": 1.0,
    "oil company for": 1.0,
    "company for reading": 0.5,
    "for reading credit": 0.3333333333333333,
    "reading credit card": 1.0,
    "credit card imprints": 0.3333333333333333,
    "card imprints for": 1.0,
    "imprints for billing": 1.0,
    "for billing purposes": 1.0,
    "billing purposes .": 1.0,
    "<s> other systems": 0.14285714285714285,
    "other systems sold": 0.3333333333333333,
    "systems sold by": 1.0,
    "sold by imr": 1.0,
    "by imr during": 1.0,
    "imr during the": 1.0,
    "during the late": 0.16666666666666666,
    "the late 1950s": 0.1111111111111111,
    "late 1950s included": 1.0,
    "1950s included a": 1.0,
    "included a bill": 1.0,
    "a bill stub": 1.0,
    "bill stub reader": 1.0,
    "stub reader to": 1.0,
    "reader to the": 1.0,
    "to the ohio": 0.012987012987012988,
    "the ohio bell": 1.0,
    "ohio bell telephone": 1.0,
    "bell telephone company": 1.0,
    "telephone company and": 1.0,
    "company and a": 1.0,
    "and a page": 0.0625,
    "a page scanner": 1.0,
    "page scanner to": 1.0,
    "scanner to the": 1.0,
    "to the united": 0.012987012987012988,
    "united states air": 0.14285714285714285,
    "states air force": 1.0,
    "air force for": 0.5,
    "force for reading": 1.0,
    "for reading and": 0.3333333333333333,
    "reading and transmitting": 0.5,
    "and transmitting by": 1.0,
    "transmitting by teletype": 1.0,
    "by teletype typewritten": 1.0,
    "teletype typewritten messages": 1.0,
    "typewritten messages .": 1.0,
    "<s> ibm and": 1.0,
    "ibm and others": 1.0,
    "and others were": 0.5,
    "others were later": 1.0,
    "were later licensed": 1.0,
    "later licensed on": 1.0,
    "licensed on shepard": 1.0,
    "on shepard 's": 1.0,
    "shepard 's ocr": 1.0,
    "'s ocr patents": 1.0,
    "ocr patents .": 1.0,
    "<s> in about": 0.010309278350515464,
    "in about 1965": 1.0,
    "about 1965 ,": 1.0,
    "1965 , reader": 0.5,
    ", reader 's": 1.0,
    "'s digest and": 0.3333333333333333,
    "digest and rca": 1.0,
    "and rca collaborated": 1.0,
    "rca collaborated to": 1.0,
    "collaborated to build": 1.0,
    "to build an": 1.0,
    "build an ocr": 0.5,
    "an ocr document": 1.0,
    "ocr document reader": 1.0,
    "document reader designed": 0.5,
    "reader designed to": 1.0,
    "designed to digitize": 0.2,
    "to digitize the": 1.0,
    "digitize the serial": 0.5,
    "the serial numbers": 1.0,
    "serial numbers on": 1.0,
    "numbers on reader": 1.0,
    "on reader 's": 1.0,
    "'s digest coupons": 0.3333333333333333,
    "digest coupons returned": 1.0,
    "coupons returned from": 1.0,
    "returned from advertisements": 0.5,
    "from advertisements .": 1.0,
    "<s> the fonts": 0.006802721088435374,
    "the fonts used": 1.0,
    "fonts used on": 1.0,
    "used on the": 1.0,
    "on the documents": 0.014925373134328358,
    "the documents were": 0.3333333333333333,
    "documents were printed": 1.0,
    "were printed by": 1.0,
    "printed by an": 1.0,
    "by an rca": 0.5,
    "an rca drum": 0.5,
    "rca drum printer": 1.0,
    "drum printer using": 1.0,
    "printer using the": 1.0,
    "using the ocr-a": 0.14285714285714285,
    "the ocr-a font": 1.0,
    "ocr-a font .": 1.0,
    "<s> the reader": 0.006802721088435374,
    "the reader was": 0.16666666666666666,
    "reader was connected": 0.5,
    "was connected directly": 1.0,
    "connected directly to": 1.0,
    "directly to an": 0.5,
    "to an rca": 1.0,
    "an rca 301": 0.5,
    "rca 301 computer": 1.0,
    "301 computer -lrb-": 1.0,
    "computer -lrb- one": 1.0,
    "-lrb- one of": 1.0,
    "the first solid": 0.045454545454545456,
    "first solid state": 1.0,
    "solid state computers": 1.0,
    "state computers -rrb-": 1.0,
    "computers -rrb- .": 1.0,
    "<s> this reader": 0.019230769230769232,
    "this reader was": 1.0,
    "reader was followed": 0.5,
    "was followed by": 1.0,
    "followed by a": 0.5,
    "by a specialised": 0.05555555555555555,
    "a specialised document": 1.0,
    "specialised document reader": 1.0,
    "document reader installed": 0.5,
    "reader installed at": 1.0,
    "installed at twa": 0.5,
    "at twa where": 1.0,
    "twa where the": 1.0,
    "where the reader": 0.07692307692307693,
    "the reader processed": 0.16666666666666666,
    "reader processed airline": 1.0,
    "processed airline ticket": 1.0,
    "airline ticket stock": 1.0,
    "ticket stock .": 1.0,
    "<s> the readers": 0.006802721088435374,
    "the readers processed": 1.0,
    "readers processed documents": 1.0,
    "processed documents at": 1.0,
    "documents at a": 1.0,
    "at a rate": 0.25,
    "a rate of": 1.0,
    "rate of 1,500": 0.3333333333333333,
    "of 1,500 documents": 1.0,
    "1,500 documents per": 1.0,
    "documents per minute": 1.0,
    "per minute ,": 1.0,
    "minute , and": 1.0,
    ", and checked": 0.005291005291005291,
    "and checked each": 1.0,
    "checked each document": 1.0,
    "each document ,": 1.0,
    "document , rejecting": 0.2,
    ", rejecting those": 1.0,
    "rejecting those it": 1.0,
    "those it was": 1.0,
    "it was not": 0.2,
    "was not able": 0.5,
    "not able to": 1.0,
    "able to process": 0.0625,
    "to process correctly": 0.3333333333333333,
    "process correctly .": 1.0,
    "the product became": 0.5,
    "product became part": 1.0,
    "became part of": 1.0,
    "of the rca": 0.005128205128205128,
    "the rca product": 1.0,
    "rca product line": 1.0,
    "product line as": 1.0,
    "line as a": 1.0,
    "as a reader": 0.027777777777777776,
    "a reader designed": 1.0,
    "designed to process": 0.2,
    "to process ``": 0.3333333333333333,
    "process `` turn": 1.0,
    "`` turn around": 1.0,
    "turn around documents": 1.0,
    "around documents ''": 1.0,
    "documents '' such": 1.0,
    "'' such as": 1.0,
    "as those utility": 0.2,
    "those utility and": 1.0,
    "utility and insurance": 1.0,
    "and insurance bills": 1.0,
    "insurance bills returned": 1.0,
    "bills returned with": 1.0,
    "returned with payments": 1.0,
    "with payments .": 1.0,
    "<s> the united": 0.006802721088435374,
    "united states postal": 0.14285714285714285,
    "states postal service": 1.0,
    "postal service has": 1.0,
    "service has been": 1.0,
    "has been using": 0.07142857142857142,
    "been using ocr": 1.0,
    "using ocr machines": 0.3333333333333333,
    "ocr machines to": 1.0,
    "machines to sort": 1.0,
    "to sort mail": 1.0,
    "sort mail since": 1.0,
    "mail since 1965": 1.0,
    "since 1965 based": 1.0,
    "1965 based on": 1.0,
    "based on technology": 0.021739130434782608,
    "on technology devised": 1.0,
    "technology devised primarily": 1.0,
    "devised primarily by": 1.0,
    "primarily by the": 1.0,
    "by the prolific": 0.03571428571428571,
    "the prolific inventor": 1.0,
    "prolific inventor jacob": 1.0,
    "inventor jacob rabinow": 1.0,
    "jacob rabinow .": 1.0,
    "the first use": 0.045454545454545456,
    "first use of": 1.0,
    "use of ocr": 0.045454545454545456,
    "of ocr in": 0.25,
    "ocr in europe": 0.5,
    "in europe was": 0.25,
    "europe was by": 1.0,
    "was by the": 0.5,
    "by the british": 0.03571428571428571,
    "the british general": 1.0,
    "british general post": 1.0,
    "general post office": 1.0,
    "post office -lrb-": 1.0,
    "office -lrb- gpo": 1.0,
    "-lrb- gpo -rrb-": 1.0,
    "gpo -rrb- .": 1.0,
    "<s> in 1965": 0.010309278350515464,
    "in 1965 it": 0.5,
    "1965 it began": 1.0,
    "it began planning": 1.0,
    "began planning an": 1.0,
    "planning an entire": 1.0,
    "an entire banking": 1.0,
    "entire banking system": 1.0,
    "banking system ,": 1.0,
    ", the national": 0.009523809523809525,
    "the national giro": 0.5,
    "national giro ,": 1.0,
    "giro , using": 1.0,
    ", using ocr": 0.1,
    "using ocr technology": 0.3333333333333333,
    "ocr technology ,": 0.1111111111111111,
    "technology , a": 0.3333333333333333,
    "process that revolutionized": 0.5,
    "that revolutionized bill": 1.0,
    "revolutionized bill payment": 1.0,
    "bill payment systems": 1.0,
    "payment systems in": 1.0,
    "systems in the": 1.0,
    "in the uk": 0.0196078431372549,
    "the uk .": 0.5,
    "<s> canada post": 1.0,
    "canada post has": 1.0,
    "post has been": 1.0,
    "using ocr systems": 0.3333333333333333,
    "ocr systems since": 0.25,
    "systems since 1971": 1.0,
    "since 1971 -lrb-": 1.0,
    "1971 -lrb- citation": 1.0,
    "needed -rrb- .": 0.46153846153846156,
    "<s> ocr systems": 0.25,
    "ocr systems read": 0.25,
    "systems read the": 1.0,
    "read the name": 1.0,
    "the name and": 0.5,
    "name and address": 1.0,
    "and address of": 1.0,
    "address of the": 1.0,
    "of the addressee": 0.005128205128205128,
    "the addressee at": 1.0,
    "addressee at the": 1.0,
    "at the first": 0.125,
    "the first mechanized": 0.045454545454545456,
    "first mechanized sorting": 1.0,
    "mechanized sorting center": 1.0,
    "sorting center ,": 1.0,
    "center , and": 0.5,
    ", and print": 0.005291005291005291,
    "and print a": 1.0,
    "print a routing": 1.0,
    "a routing bar": 1.0,
    "routing bar code": 1.0,
    "bar code on": 0.5,
    "code on the": 1.0,
    "on the envelope": 0.014925373134328358,
    "the envelope based": 1.0,
    "envelope based on": 1.0,
    "on the postal": 0.014925373134328358,
    "the postal code": 1.0,
    "postal code .": 1.0,
    "<s> to avoid": 0.125,
    "to avoid confusion": 1.0,
    "avoid confusion with": 1.0,
    "confusion with the": 1.0,
    "with the human-readable": 0.03333333333333333,
    "the human-readable address": 1.0,
    "human-readable address field": 1.0,
    "address field which": 1.0,
    "field which can": 1.0,
    "can be located": 0.01098901098901099,
    "be located anywhere": 1.0,
    "located anywhere on": 1.0,
    "anywhere on the": 1.0,
    "on the letter": 0.014925373134328358,
    "the letter ,": 1.0,
    "letter , special": 1.0,
    ", special ink": 1.0,
    "special ink -lrb-": 1.0,
    "ink -lrb- orange": 1.0,
    "-lrb- orange in": 1.0,
    "orange in visible": 1.0,
    "in visible light": 1.0,
    "visible light -rrb-": 1.0,
    "light -rrb- is": 1.0,
    "-rrb- is used": 0.09090909090909091,
    "is used that": 0.07692307692307693,
    "used that is": 1.0,
    "that is clearly": 0.05263157894736842,
    "is clearly visible": 0.5,
    "clearly visible under": 1.0,
    "visible under ultraviolet": 1.0,
    "under ultraviolet light": 1.0,
    "ultraviolet light .": 1.0,
    "<s> envelopes may": 1.0,
    "envelopes may then": 1.0,
    "may then be": 1.0,
    "then be processed": 1.0,
    "be processed with": 1.0,
    "processed with equipment": 0.5,
    "with equipment based": 1.0,
    "equipment based on": 1.0,
    "based on simple": 0.021739130434782608,
    "on simple bar": 1.0,
    "simple bar code": 1.0,
    "bar code readers": 0.5,
    "code readers .": 1.0,
    "<s> importance of": 1.0,
    "importance of ocr": 0.25,
    "of ocr to": 0.25,
    "ocr to the": 0.3333333333333333,
    "to the blind": 0.012987012987012988,
    "the blind in": 0.3333333333333333,
    "blind in 1974": 1.0,
    "in 1974 ray": 1.0,
    "1974 ray kurzweil": 1.0,
    "ray kurzweil started": 1.0,
    "kurzweil started the": 1.0,
    "started the company": 1.0,
    "the company kurzweil": 1.0,
    "company kurzweil computer": 1.0,
    "kurzweil computer products": 1.0,
    "computer products ,": 0.5,
    "products , inc.": 0.5,
    ", inc. and": 0.5,
    "inc. and continued": 1.0,
    "and continued development": 1.0,
    "continued development of": 1.0,
    "development of omni-font": 0.14285714285714285,
    "of omni-font ocr": 1.0,
    "omni-font ocr ,": 1.0,
    "ocr , which": 0.14285714285714285,
    ", which could": 0.017857142857142856,
    "which could recognize": 1.0,
    "could recognize text": 1.0,
    "recognize text printed": 1.0,
    "text printed in": 1.0,
    "printed in virtually": 1.0,
    "in virtually any": 1.0,
    "virtually any font": 0.5,
    "any font .": 1.0,
    "<s> he decided": 0.14285714285714285,
    "he decided that": 1.0,
    "decided that the": 1.0,
    "that the best": 0.043478260869565216,
    "the best application": 0.07142857142857142,
    "best application of": 1.0,
    "application of this": 0.25,
    "of this technology": 0.09090909090909091,
    "this technology would": 1.0,
    "technology would be": 1.0,
    "would be to": 0.1111111111111111,
    "be to create": 0.5,
    "create a reading": 0.14285714285714285,
    "a reading machine": 1.0,
    "reading machine for": 1.0,
    "machine for the": 1.0,
    "for the blind": 0.03125,
    "the blind ,": 0.3333333333333333,
    "blind , which": 1.0,
    ", which would": 0.03571428571428571,
    "which would allow": 0.5,
    "would allow blind": 1.0,
    "allow blind people": 1.0,
    "blind people to": 0.3333333333333333,
    "people to have": 0.5,
    "have a computer": 0.07692307692307693,
    "a computer read": 0.0625,
    "computer read text": 1.0,
    "read text to": 1.0,
    "text to them": 0.14285714285714285,
    "to them out": 0.5,
    "them out loud": 1.0,
    "out loud .": 1.0,
    "<s> this device": 0.019230769230769232,
    "this device required": 1.0,
    "device required the": 1.0,
    "required the invention": 1.0,
    "the invention of": 1.0,
    "invention of two": 1.0,
    "of two enabling": 0.5,
    "two enabling technologies": 1.0,
    "enabling technologies --": 1.0,
    "technologies -- the": 1.0,
    "-- the ccd": 0.3333333333333333,
    "the ccd flatbed": 1.0,
    "ccd flatbed scanner": 1.0,
    "flatbed scanner and": 1.0,
    "scanner and the": 1.0,
    "and the text-to-speech": 0.024390243902439025,
    "the text-to-speech synthesizer": 1.0,
    "text-to-speech synthesizer .": 1.0,
    "<s> on january": 0.2,
    "on january 13": 1.0,
    "january 13 ,": 1.0,
    "13 , 1976": 1.0,
    ", 1976 the": 0.5,
    "1976 the successful": 1.0,
    "the successful finished": 0.5,
    "successful finished product": 1.0,
    "finished product was": 1.0,
    "product was unveiled": 1.0,
    "was unveiled during": 1.0,
    "unveiled during a": 1.0,
    "during a widely-reported": 0.5,
    "a widely-reported news": 1.0,
    "widely-reported news conference": 1.0,
    "news conference headed": 1.0,
    "conference headed by": 1.0,
    "headed by kurzweil": 1.0,
    "by kurzweil and": 1.0,
    "kurzweil and the": 1.0,
    "and the leaders": 0.024390243902439025,
    "the leaders of": 1.0,
    "leaders of the": 1.0,
    "of the national": 0.005128205128205128,
    "the national federation": 0.5,
    "national federation of": 1.0,
    "federation of the": 1.0,
    "of the blind": 0.005128205128205128,
    "the blind -lrb-": 0.3333333333333333,
    "blind -lrb- citation": 1.0,
    "<s> in 1978": 0.010309278350515464,
    "in 1978 kurzweil": 1.0,
    "1978 kurzweil computer": 1.0,
    "computer products began": 0.5,
    "products began selling": 1.0,
    "began selling a": 1.0,
    "selling a commercial": 1.0,
    "a commercial version": 0.5,
    "commercial version of": 1.0,
    "version of the": 0.5,
    "of the optical": 0.005128205128205128,
    "the optical character": 1.0,
    "character recognition computer": 0.07692307692307693,
    "recognition computer program": 0.5,
    "<s> lexisnexis was": 1.0,
    "lexisnexis was one": 1.0,
    "was one of": 1.0,
    "the first customers": 0.045454545454545456,
    "first customers ,": 1.0,
    "customers , and": 1.0,
    ", and bought": 0.005291005291005291,
    "and bought the": 1.0,
    "bought the program": 1.0,
    "the program to": 0.25,
    "program to upload": 0.5,
    "to upload paper": 1.0,
    "upload paper legal": 1.0,
    "paper legal and": 1.0,
    "legal and news": 1.0,
    "and news documents": 1.0,
    "news documents onto": 1.0,
    "documents onto its": 1.0,
    "onto its nascent": 1.0,
    "its nascent online": 1.0,
    "nascent online databases": 1.0,
    "online databases .": 1.0,
    "<s> two years": 0.42857142857142855,
    "two years later": 1.0,
    "years later ,": 1.0,
    "later , kurzweil": 0.16666666666666666,
    ", kurzweil sold": 0.3333333333333333,
    "kurzweil sold his": 1.0,
    "sold his company": 1.0,
    "his company to": 1.0,
    "company to xerox": 1.0,
    "to xerox ,": 1.0,
    "xerox , which": 1.0,
    ", which had": 0.017857142857142856,
    "which had an": 1.0,
    "had an interest": 1.0,
    "an interest in": 1.0,
    "interest in further": 0.14285714285714285,
    "in further commercializing": 1.0,
    "further commercializing paper-to-computer": 1.0,
    "commercializing paper-to-computer text": 1.0,
    "paper-to-computer text conversion": 1.0,
    "text conversion .": 1.0,
    "<s> xerox eventually": 1.0,
    "xerox eventually spun": 1.0,
    "eventually spun it": 1.0,
    "spun it off": 1.0,
    "it off as": 1.0,
    "off as scansoft": 1.0,
    "as scansoft ,": 1.0,
    "scansoft , which": 1.0,
    ", which merged": 0.017857142857142856,
    "which merged with": 1.0,
    "merged with nuance": 1.0,
    "with nuance communications": 1.0,
    "nuance communications -lrb-": 1.0,
    "communications -lrb- citation": 0.5,
    "<s> ocr software": 0.25,
    "ocr software desktop": 0.2,
    "software desktop &": 1.0,
    "desktop & server": 1.0,
    "& server ocr": 1.0,
    "server ocr software": 1.0,
    "ocr software ocr": 0.2,
    "software ocr software": 1.0,
    "ocr software and": 0.2,
    "software and icr": 1.0,
    "and icr software": 0.5,
    "icr software technology": 1.0,
    "software technology are": 1.0,
    "technology are analytical": 1.0,
    "are analytical artificial": 1.0,
    "analytical artificial intelligence": 1.0,
    "artificial intelligence systems": 0.125,
    "intelligence systems that": 1.0,
    "systems that consider": 0.09090909090909091,
    "that consider sequences": 1.0,
    "consider sequences of": 1.0,
    "sequences of characters": 0.3333333333333333,
    "of characters rather": 0.5,
    "characters rather than": 1.0,
    "rather than whole": 0.07142857142857142,
    "than whole words": 1.0,
    "whole words or": 1.0,
    "or phrases .": 0.5,
    "<s> based on": 1.0,
    "analysis of sequential": 0.07692307692307693,
    "of sequential lines": 1.0,
    "sequential lines and": 1.0,
    "lines and curves": 1.0,
    "and curves ,": 1.0,
    "curves , ocr": 1.0,
    ", ocr and": 0.5,
    "ocr and icr": 1.0,
    "and icr make": 0.5,
    "icr make `": 1.0,
    "make ` best": 1.0,
    "` best guesses": 1.0,
    "best guesses '": 1.0,
    "guesses ' at": 1.0,
    "' at characters": 1.0,
    "at characters using": 1.0,
    "characters using database": 1.0,
    "using database look-up": 1.0,
    "database look-up tables": 1.0,
    "look-up tables to": 1.0,
    "tables to closely": 1.0,
    "to closely associate": 1.0,
    "closely associate or": 1.0,
    "associate or match": 1.0,
    "or match the": 1.0,
    "match the strings": 0.5,
    "the strings of": 1.0,
    "strings of characters": 0.5,
    "of characters that": 0.5,
    "characters that form": 1.0,
    "that form words": 1.0,
    "form words .": 1.0,
    "<s> webocr &": 0.5,
    "webocr & onlineocr": 0.6666666666666666,
    "& onlineocr with": 0.5,
    "onlineocr with it": 1.0,
    "with it technology": 0.3333333333333333,
    "it technology development": 1.0,
    "technology development ,": 1.0,
    "development , the": 0.5,
    ", the platform": 0.009523809523809525,
    "the platform for": 1.0,
    "platform for people": 1.0,
    "for people to": 0.5,
    "people to use": 0.5,
    "to use software": 0.1,
    "use software has": 1.0,
    "software has been": 1.0,
    "has been changed": 0.03571428571428571,
    "been changed from": 1.0,
    "changed from single": 1.0,
    "from single pc": 1.0,
    "single pc platform": 1.0,
    "pc platform to": 1.0,
    "platform to multi-platforms": 1.0,
    "to multi-platforms such": 1.0,
    "multi-platforms such as": 1.0,
    "such as pc": 0.011111111111111112,
    "as pc +": 1.0,
    "pc + web-based": 1.0,
    "+ web-based +": 1.0,
    "web-based + cloud": 1.0,
    "+ cloud computing": 1.0,
    "cloud computing +": 1.0,
    "computing + mobile": 1.0,
    "+ mobile devices": 1.0,
    "mobile devices .": 1.0,
    "<s> after 30": 0.3333333333333333,
    "after 30 years": 1.0,
    "30 years development": 1.0,
    "years development ,": 0.5,
    "development , ocr": 0.5,
    ", ocr software": 0.5,
    "ocr software started": 0.2,
    "software started to": 1.0,
    "started to adapt": 1.0,
    "to adapt to": 1.0,
    "adapt to new": 1.0,
    "to new application": 0.25,
    "new application requirements": 1.0,
    "application requirements .": 1.0,
    "<s> webocr also": 0.5,
    "webocr also known": 1.0,
    "known as onlineocr": 0.1,
    "as onlineocr or": 1.0,
    "onlineocr or web-based": 1.0,
    "or web-based ocr": 1.0,
    "web-based ocr service": 1.0,
    "ocr service ,": 1.0,
    "service , has": 0.5,
    ", has been": 1.0,
    "has been a": 0.03571428571428571,
    "been a new": 0.5,
    "a new trend": 0.16666666666666666,
    "new trend to": 1.0,
    "trend to meet": 0.5,
    "to meet larger": 0.25,
    "meet larger volume": 1.0,
    "larger volume and": 1.0,
    "volume and larger": 1.0,
    "and larger group": 0.5,
    "larger group of": 1.0,
    "group of users": 0.5,
    "of users after": 0.5,
    "users after 30": 1.0,
    "years development of": 0.5,
    "development of the": 0.14285714285714285,
    "of the desktop": 0.005128205128205128,
    "the desktop ocr": 1.0,
    "desktop ocr .": 1.0,
    "<s> internet and": 1.0,
    "internet and broadband": 1.0,
    "and broadband technologies": 1.0,
    "broadband technologies have": 1.0,
    "technologies have made": 1.0,
    "have made webocr": 1.0,
    "made webocr &": 1.0,
    "& onlineocr practically": 0.5,
    "onlineocr practically available": 1.0,
    "practically available to": 1.0,
    "available to both": 1.0,
    "to both individual": 0.3333333333333333,
    "both individual users": 1.0,
    "individual users and": 1.0,
    "users and enterprise": 1.0,
    "and enterprise customers": 1.0,
    "enterprise customers .": 1.0,
    "<s> since 2000": 0.25,
    "since 2000 ,": 0.5,
    "2000 , some": 1.0,
    ", some major": 0.1111111111111111,
    "some major ocr": 1.0,
    "major ocr vendors": 0.5,
    "ocr vendors began": 1.0,
    "vendors began offering": 1.0,
    "began offering webocr": 1.0,
    "offering webocr &": 1.0,
    "webocr & online": 0.3333333333333333,
    "& online software": 1.0,
    "online software ,": 1.0,
    "software , a": 1.0,
    "number of new": 0.027777777777777776,
    "of new entrants": 1.0,
    "new entrants companies": 1.0,
    "entrants companies to": 1.0,
    "companies to seize": 1.0,
    "to seize the": 1.0,
    "seize the opportunity": 1.0,
    "the opportunity to": 1.0,
    "opportunity to develop": 1.0,
    "to develop innovative": 0.2,
    "develop innovative web-based": 1.0,
    "innovative web-based ocr": 1.0,
    "service , some": 0.5,
    ", some of": 0.1111111111111111,
    "which are free": 0.08333333333333333,
    "are free of": 1.0,
    "free of charge": 1.0,
    "of charge services": 1.0,
    "charge services .": 1.0,
    "<s> application-oriented ocr": 1.0,
    "application-oriented ocr since": 0.5,
    "ocr since ocr": 1.0,
    "since ocr technology": 1.0,
    "ocr technology has": 0.1111111111111111,
    "technology has been": 1.0,
    "has been more": 0.03571428571428571,
    "been more and": 0.5,
    "and more widely": 0.2,
    "more widely applied": 1.0,
    "widely applied to": 1.0,
    "applied to paper-intensive": 0.09090909090909091,
    "to paper-intensive industry": 1.0,
    "paper-intensive industry ,": 1.0,
    "industry , it": 1.0,
    "it is facing": 0.02127659574468085,
    "is facing more": 1.0,
    "facing more complex": 1.0,
    "more complex images": 0.1111111111111111,
    "complex images environment": 1.0,
    "images environment in": 1.0,
    "environment in the": 1.0,
    "in the real": 0.006535947712418301,
    "real world .": 0.3333333333333333,
    "for example :": 0.03571428571428571,
    "example : complicated": 0.5,
    ": complicated backgrounds": 1.0,
    "complicated backgrounds ,": 1.0,
    "backgrounds , degraded-images": 1.0,
    ", degraded-images ,": 1.0,
    "degraded-images , heavy-noise": 1.0,
    ", heavy-noise ,": 1.0,
    "heavy-noise , paper": 1.0,
    ", paper skew": 1.0,
    "paper skew ,": 1.0,
    "skew , picture": 1.0,
    ", picture distortion": 1.0,
    "picture distortion ,": 1.0,
    "distortion , low-resolution": 1.0,
    ", low-resolution ,": 1.0,
    "low-resolution , disturbed": 1.0,
    ", disturbed by": 1.0,
    "disturbed by grid": 1.0,
    "by grid &": 1.0,
    "grid & lines": 1.0,
    "& lines ,": 1.0,
    "lines , text": 1.0,
    ", text image": 0.3333333333333333,
    "text image consisting": 1.0,
    "image consisting of": 1.0,
    "consisting of special": 0.5,
    "of special fonts": 1.0,
    "special fonts ,": 1.0,
    "fonts , symbols": 1.0,
    ", symbols ,": 1.0,
    "symbols , glossary": 1.0,
    ", glossary words": 0.5,
    "glossary words and": 1.0,
    "words and etc.": 0.125,
    "and etc. .": 1.0,
    "<s> all the": 1.0,
    "all the factors": 0.14285714285714285,
    "the factors affect": 1.0,
    "factors affect ocr": 1.0,
    "affect ocr products": 1.0,
    "ocr products '": 1.0,
    "products ' stability": 1.0,
    "' stability in": 1.0,
    "stability in recognition": 1.0,
    "in recognition accuracy": 1.0,
    "recognition accuracy .": 0.42857142857142855,
    "recent years ,": 0.25,
    "years , the": 0.2,
    ", the major": 0.009523809523809525,
    "the major ocr": 0.5,
    "major ocr technology": 0.5,
    "ocr technology providers": 0.1111111111111111,
    "technology providers began": 1.0,
    "providers began to": 1.0,
    "to develop dedicated": 0.2,
    "develop dedicated ocr": 1.0,
    "dedicated ocr systems": 1.0,
    "ocr systems ,": 0.25,
    "systems , each": 0.16666666666666666,
    ", each for": 0.16666666666666666,
    "each for special": 1.0,
    "for special types": 1.0,
    "special types of": 1.0,
    "types of images": 0.07142857142857142,
    "of images .": 1.0,
    "<s> they combine": 0.3333333333333333,
    "they combine various": 1.0,
    "combine various optimization": 0.5,
    "various optimization methods": 1.0,
    "optimization methods related": 1.0,
    "methods related to": 1.0,
    "to the special": 0.012987012987012988,
    "the special image": 1.0,
    "special image ,": 1.0,
    "image , such": 1.0,
    "such as business": 0.011111111111111112,
    "as business rules": 1.0,
    "business rules ,": 1.0,
    "rules , standard": 0.2,
    ", standard expression": 0.5,
    "standard expression ,": 1.0,
    "expression , glossary": 0.5,
    ", glossary or": 0.5,
    "glossary or dictionary": 1.0,
    "or dictionary and": 1.0,
    "dictionary and rich": 1.0,
    "and rich information": 1.0,
    "rich information contained": 1.0,
    "information contained in": 1.0,
    "contained in color": 1.0,
    "in color images": 1.0,
    "color images ,": 1.0,
    "images , to": 0.5,
    ", to improve": 0.15384615384615385,
    "to improve the": 0.1111111111111111,
    "improve the recognition": 1.0,
    "the recognition accuracy": 0.3333333333333333,
    "<s> such strategy": 0.125,
    "such strategy to": 1.0,
    "strategy to customize": 0.3333333333333333,
    "to customize ocr": 0.5,
    "customize ocr technology": 1.0,
    "ocr technology is": 0.2222222222222222,
    "technology is called": 0.3333333333333333,
    "is called ``": 0.16666666666666666,
    "called `` application-oriented": 0.2,
    "`` application-oriented ocr": 1.0,
    "application-oriented ocr ''": 0.5,
    "ocr '' or": 0.5,
    "or `` customized": 0.25,
    "`` customized ocr": 1.0,
    "customized ocr ''": 1.0,
    "ocr '' ,": 0.5,
    "'' , widely": 0.03333333333333333,
    ", widely used": 1.0,
    "widely used in": 0.42857142857142855,
    "used in the": 0.2608695652173913,
    "in the fields": 0.006535947712418301,
    "the fields of": 1.0,
    "fields of business-card": 0.5,
    "of business-card ocr": 1.0,
    "business-card ocr ,": 1.0,
    "ocr , invoice": 0.14285714285714285,
    ", invoice ocr": 1.0,
    "invoice ocr ,": 1.0,
    "ocr , screenshot": 0.14285714285714285,
    ", screenshot ocr": 1.0,
    "screenshot ocr ,": 1.0,
    "ocr , id": 0.14285714285714285,
    ", id card": 1.0,
    "id card ocr": 1.0,
    "card ocr ,": 1.0,
    "ocr , driver-license": 0.14285714285714285,
    ", driver-license ocr": 1.0,
    "driver-license ocr or": 1.0,
    "ocr or auto": 1.0,
    "or auto plant": 1.0,
    "auto plant ocr": 1.0,
    "plant ocr ,": 1.0,
    "ocr , and": 0.14285714285714285,
    "<s> see also": 1.0,
    "see also :": 0.6666666666666666,
    "also : list": 0.5,
    ": list of": 1.0,
    "list of optical": 0.1,
    "of optical character": 1.0,
    "character recognition software": 0.07692307692307693,
    "recognition software current": 0.3333333333333333,
    "software current state": 1.0,
    "state of ocr": 0.2,
    "of ocr technology": 0.25,
    "ocr technology this": 0.1111111111111111,
    "technology this section": 1.0,
    "this section needs": 0.5,
    "section needs additional": 1.0,
    "needs additional citations": 1.0,
    "additional citations for": 1.0,
    "citations for verification": 1.0,
    "for verification .": 1.0,
    "please help improve": 0.5,
    "help improve this": 1.0,
    "this article by": 0.2,
    "article by adding": 1.0,
    "by adding citations": 0.5,
    "adding citations to": 1.0,
    "citations to reliable": 0.5,
    "to reliable sources": 1.0,
    "reliable sources .": 1.0,
    "<s> unsourced material": 1.0,
    "unsourced material may": 1.0,
    "material may be": 1.0,
    "may be challenged": 0.047619047619047616,
    "be challenged and": 1.0,
    "challenged and removed": 1.0,
    "and removed .": 1.0,
    "-lrb- may 2009": 0.5,
    "may 2009 -rrb-": 1.0,
    "2009 -rrb- commissioned": 1.0,
    "-rrb- commissioned by": 1.0,
    "commissioned by the": 1.0,
    "by the u.s.": 0.07142857142857142,
    "the u.s. department": 0.25,
    "u.s. department of": 1.0,
    "department of energy": 1.0,
    "of energy -lrb-": 1.0,
    "energy -lrb- doe": 1.0,
    "-lrb- doe -rrb-": 1.0,
    "doe -rrb- ,": 1.0,
    ", the information": 0.009523809523809525,
    "the information science": 0.16666666666666666,
    "information science research": 1.0,
    "science research institute": 1.0,
    "research institute -lrb-": 1.0,
    "institute -lrb- isri": 1.0,
    "-lrb- isri -rrb-": 1.0,
    "isri -rrb- had": 1.0,
    "-rrb- had the": 1.0,
    "had the mission": 1.0,
    "the mission to": 1.0,
    "mission to foster": 1.0,
    "to foster the": 1.0,
    "foster the improvement": 1.0,
    "the improvement of": 1.0,
    "improvement of automated": 0.5,
    "of automated technologies": 1.0,
    "automated technologies for": 1.0,
    "technologies for understanding": 1.0,
    "for understanding machine": 1.0,
    "understanding machine printed": 1.0,
    "machine printed documents": 1.0,
    "printed documents -lrb-": 1.0,
    "documents -lrb- citation": 0.2,
    "needed -rrb- ,": 0.07692307692307693,
    "and it conducted": 0.2,
    "it conducted the": 1.0,
    "conducted the most": 1.0,
    "the most authoritative": 0.041666666666666664,
    "most authoritative of": 1.0,
    "authoritative of the": 1.0,
    "of the annual": 0.005128205128205128,
    "the annual test": 0.5,
    "annual test of": 1.0,
    "test of ocr": 1.0,
    "of ocr accuracy": 0.25,
    "ocr accuracy for": 1.0,
    "accuracy for 5": 0.3333333333333333,
    "for 5 consecutive": 1.0,
    "5 consecutive years": 1.0,
    "consecutive years in": 1.0,
    "years in the": 1.0,
    "in the mid-90s": 0.006535947712418301,
    "the mid-90s .": 1.0,
    "<s> recognition of": 1.0,
    "recognition of latin-script": 0.09090909090909091,
    "of latin-script ,": 1.0,
    "latin-script , typewritten": 1.0,
    ", typewritten text": 0.5,
    "typewritten text is": 1.0,
    "text is still": 0.25,
    "is still not": 0.25,
    "still not 100": 1.0,
    "not 100 %": 1.0,
    "100 % accurate": 0.5,
    "% accurate even": 0.5,
    "accurate even where": 1.0,
    "even where clear": 1.0,
    "where clear imaging": 1.0,
    "clear imaging is": 1.0,
    "imaging is available": 1.0,
    "is available .": 1.0,
    "<s> one study": 0.08333333333333333,
    "one study based": 1.0,
    "study based on": 1.0,
    "based on recognition": 0.021739130434782608,
    "on recognition of": 1.0,
    "recognition of 19th": 0.09090909090909091,
    "of 19th -": 1.0,
    "19th - and": 1.0,
    "- and early": 0.5,
    "and early 20th-century": 1.0,
    "early 20th-century newspaper": 1.0,
    "20th-century newspaper pages": 1.0,
    "newspaper pages concluded": 1.0,
    "pages concluded that": 1.0,
    "concluded that character-by-character": 0.5,
    "that character-by-character ocr": 1.0,
    "character-by-character ocr accuracy": 1.0,
    "accuracy for commercial": 0.3333333333333333,
    "for commercial ocr": 1.0,
    "commercial ocr software": 0.5,
    "ocr software varied": 0.2,
    "software varied from": 1.0,
    "varied from 71": 1.0,
    "from 71 %": 1.0,
    "71 % to": 1.0,
    "% to 98": 0.5,
    "to 98 %": 1.0,
    "98 % ;": 0.3333333333333333,
    "% ; total": 1.0,
    "; total accuracy": 1.0,
    "total accuracy can": 1.0,
    "accuracy can be": 1.0,
    "be achieved only": 0.2,
    "achieved only by": 1.0,
    "only by human": 0.5,
    "by human review": 0.3333333333333333,
    "human review .": 1.0,
    "<s> other areas": 0.14285714285714285,
    "other areas --": 0.3333333333333333,
    "areas -- including": 1.0,
    "-- including recognition": 1.0,
    "including recognition of": 1.0,
    "recognition of hand": 0.09090909090909091,
    "of hand printing": 1.0,
    "hand printing ,": 1.0,
    "printing , cursive": 1.0,
    ", cursive handwriting": 1.0,
    "cursive handwriting ,": 1.0,
    "handwriting , and": 1.0,
    ", and printed": 0.005291005291005291,
    "and printed text": 1.0,
    "printed text in": 0.3333333333333333,
    "text in other": 0.125,
    "in other scripts": 0.14285714285714285,
    "other scripts -lrb-": 1.0,
    "scripts -lrb- especially": 0.5,
    "-lrb- especially those": 0.5,
    "especially those east": 0.3333333333333333,
    "those east asian": 1.0,
    "east asian language": 1.0,
    "asian language characters": 1.0,
    "language characters which": 1.0,
    "characters which have": 0.5,
    "which have many": 0.5,
    "have many strokes": 0.2,
    "many strokes for": 1.0,
    "strokes for a": 1.0,
    "for a single": 0.03225806451612903,
    "a single character": 0.1111111111111111,
    "single character -rrb-": 1.0,
    "character -rrb- --": 1.0,
    "-rrb- -- are": 1.0,
    "-- are still": 0.5,
    "are still the": 0.25,
    "still the subject": 1.0,
    "the subject of": 0.4,
    "subject of active": 0.5,
    "of active research": 1.0,
    "active research .": 1.0,
    "<s> accuracy rates": 0.4,
    "accuracy rates can": 0.5,
    "rates can be": 1.0,
    "can be measured": 0.01098901098901099,
    "be measured in": 1.0,
    "measured in several": 1.0,
    "in several ways": 0.5,
    "several ways ,": 1.0,
    "ways , and": 0.5,
    ", and how": 0.005291005291005291,
    "and how they": 0.6666666666666666,
    "how they are": 0.6666666666666666,
    "they are measured": 0.14285714285714285,
    "are measured can": 1.0,
    "measured can greatly": 1.0,
    "can greatly affect": 1.0,
    "greatly affect the": 1.0,
    "affect the reported": 1.0,
    "the reported accuracy": 1.0,
    "reported accuracy rate": 1.0,
    "accuracy rate .": 0.5,
    ", if word": 0.1,
    "if word context": 1.0,
    "word context -lrb-": 1.0,
    "context -lrb- basically": 0.5,
    "-lrb- basically a": 1.0,
    "basically a lexicon": 1.0,
    "lexicon of words": 0.5,
    "words -rrb- is": 0.3333333333333333,
    "-rrb- is not": 0.09090909090909091,
    "is not used": 0.10526315789473684,
    "not used to": 0.5,
    "used to correct": 0.045454545454545456,
    "to correct software": 1.0,
    "correct software finding": 1.0,
    "software finding non-existent": 1.0,
    "finding non-existent words": 1.0,
    "non-existent words ,": 1.0,
    "words , a": 0.0625,
    ", a character": 0.020833333333333332,
    "a character error": 1.0,
    "character error rate": 1.0,
    "error rate of": 0.3333333333333333,
    "rate of 1": 0.3333333333333333,
    "of 1 %": 1.0,
    "1 % -lrb-": 0.5,
    "% -lrb- 99": 0.3333333333333333,
    "-lrb- 99 %": 1.0,
    "99 % accuracy": 1.0,
    "% accuracy -rrb-": 0.5,
    "accuracy -rrb- may": 0.5,
    "-rrb- may result": 1.0,
    "may result in": 1.0,
    "result in an": 1.0,
    "in an error": 0.125,
    "an error rate": 1.0,
    "rate of 5": 0.3333333333333333,
    "of 5 %": 1.0,
    "5 % -lrb-": 1.0,
    "% -lrb- 95": 0.3333333333333333,
    "-lrb- 95 %": 1.0,
    "95 % accuracy": 0.25,
    "accuracy -rrb- or": 0.5,
    "-rrb- or worse": 0.25,
    "or worse if": 1.0,
    "worse if the": 1.0,
    "if the measurement": 0.07142857142857142,
    "the measurement is": 1.0,
    "measurement is based": 1.0,
    "based on whether": 0.021739130434782608,
    "on whether each": 1.0,
    "whether each whole": 1.0,
    "each whole word": 1.0,
    "whole word was": 1.0,
    "word was recognized": 1.0,
    "was recognized with": 1.0,
    "recognized with no": 1.0,
    "with no incorrect": 0.5,
    "no incorrect letters": 1.0,
    "incorrect letters .": 1.0,
    "<s> on-line character": 0.6666666666666666,
    "on-line character recognition": 1.0,
    "character recognition is": 0.15384615384615385,
    "recognition is sometimes": 0.1,
    "is sometimes confused": 0.3333333333333333,
    "sometimes confused with": 1.0,
    "confused with optical": 0.5,
    "with optical character": 1.0,
    "-lrb- see handwriting": 0.0625,
    "see handwriting recognition": 1.0,
    "handwriting recognition -rrb-": 1.0,
    "recognition -rrb- .": 1.0,
    "ocr is an": 0.3333333333333333,
    "is an instance": 0.1,
    "an instance of": 1.0,
    "instance of off-line": 0.5,
    "of off-line character": 1.0,
    "off-line character recognition": 1.0,
    "recognition , where": 0.07142857142857142,
    "where the system": 0.07692307692307693,
    "the system recognizes": 0.038461538461538464,
    "system recognizes the": 1.0,
    "recognizes the fixed": 0.3333333333333333,
    "the fixed static": 1.0,
    "fixed static shape": 1.0,
    "static shape of": 1.0,
    "shape of the": 1.0,
    "of the character": 0.005128205128205128,
    "the character ,": 1.0,
    "character , while": 0.5,
    ", while on-line": 0.07142857142857142,
    "while on-line character": 1.0,
    "character recognition instead": 0.07692307692307693,
    "recognition instead recognizes": 1.0,
    "instead recognizes the": 1.0,
    "recognizes the dynamic": 0.3333333333333333,
    "the dynamic motion": 1.0,
    "dynamic motion during": 1.0,
    "motion during handwriting": 1.0,
    "during handwriting .": 1.0,
    "example , on-line": 0.018518518518518517,
    ", on-line recognition": 1.0,
    "on-line recognition ,": 1.0,
    "recognition , such": 0.07142857142857142,
    "such as that": 0.011111111111111112,
    "as that used": 1.0,
    "that used for": 1.0,
    "used for gestures": 0.06666666666666667,
    "for gestures in": 1.0,
    "gestures in the": 1.0,
    "in the penpoint": 0.006535947712418301,
    "the penpoint os": 1.0,
    "penpoint os or": 1.0,
    "os or the": 1.0,
    "or the tablet": 0.1111111111111111,
    "the tablet pc": 1.0,
    "tablet pc can": 0.5,
    "pc can tell": 1.0,
    "can tell whether": 1.0,
    "tell whether a": 1.0,
    "whether a horizontal": 0.3333333333333333,
    "a horizontal mark": 1.0,
    "horizontal mark was": 1.0,
    "mark was drawn": 1.0,
    "was drawn right-to-left": 1.0,
    "drawn right-to-left ,": 1.0,
    "right-to-left , or": 1.0,
    ", or left-to-right": 0.030303030303030304,
    "or left-to-right .": 1.0,
    "recognition is also": 0.2,
    "is also referred": 0.1,
    "also referred to": 1.0,
    "to by other": 0.5,
    "by other terms": 1.0,
    "other terms such": 1.0,
    "terms such as": 1.0,
    "such as dynamic": 0.011111111111111112,
    "as dynamic character": 1.0,
    "dynamic character recognition": 1.0,
    "recognition , real-time": 0.07142857142857142,
    ", real-time character": 1.0,
    "real-time character recognition": 1.0,
    "recognition , and": 0.21428571428571427,
    ", and intelligent": 0.005291005291005291,
    "and intelligent character": 1.0,
    "intelligent character recognition": 1.0,
    "character recognition or": 0.07692307692307693,
    "recognition or icr": 1.0,
    "or icr .": 1.0,
    "<s> on-line systems": 0.3333333333333333,
    "on-line systems for": 1.0,
    "systems for recognizing": 0.5,
    "for recognizing hand-printed": 1.0,
    "recognizing hand-printed text": 1.0,
    "hand-printed text on": 0.5,
    "text on the": 1.0,
    "on the fly": 0.014925373134328358,
    "the fly have": 1.0,
    "fly have become": 1.0,
    "have become well": 1.0,
    "become well known": 1.0,
    "well known as": 1.0,
    "known as commercial": 0.1,
    "as commercial products": 1.0,
    "commercial products in": 1.0,
    "products in recent": 1.0,
    "recent years -lrb-": 0.25,
    "years -lrb- see": 1.0,
    "-lrb- see tablet": 0.0625,
    "see tablet pc": 1.0,
    "tablet pc history": 0.5,
    "pc history -rrb-": 1.0,
    "history -rrb- .": 1.0,
    "<s> among these": 1.0,
    "among these are": 1.0,
    "these are the": 0.25,
    "are the input": 0.09090909090909091,
    "the input devices": 0.125,
    "input devices for": 0.5,
    "devices for personal": 1.0,
    "for personal digital": 1.0,
    "personal digital assistants": 1.0,
    "digital assistants such": 1.0,
    "assistants such as": 1.0,
    "as those running": 0.2,
    "those running palm": 1.0,
    "running palm os": 1.0,
    "palm os .": 1.0,
    "<s> the apple": 0.006802721088435374,
    "the apple newton": 0.3333333333333333,
    "apple newton pioneered": 1.0,
    "newton pioneered this": 1.0,
    "pioneered this product": 1.0,
    "this product .": 1.0,
    "the algorithms used": 0.25,
    "algorithms used in": 1.0,
    "used in these": 0.043478260869565216,
    "in these devices": 0.25,
    "these devices take": 1.0,
    "devices take advantage": 1.0,
    "advantage of the": 0.5,
    "of the fact": 0.010256410256410256,
    "that the order": 0.043478260869565216,
    "the order ,": 0.5,
    "order , speed": 0.5,
    ", speed ,": 1.0,
    "speed , and": 0.5,
    ", and direction": 0.005291005291005291,
    "and direction of": 1.0,
    "direction of individual": 1.0,
    "of individual lines": 0.5,
    "individual lines segments": 1.0,
    "lines segments at": 1.0,
    "segments at input": 1.0,
    "at input are": 1.0,
    "input are known": 1.0,
    "are known .": 0.3333333333333333,
    "also , the": 0.3333333333333333,
    ", the user": 0.009523809523809525,
    "the user can": 0.16666666666666666,
    "user can be": 1.0,
    "can be retrained": 0.01098901098901099,
    "be retrained to": 1.0,
    "retrained to use": 1.0,
    "to use only": 0.1,
    "use only specific": 0.5,
    "only specific letter": 1.0,
    "specific letter shapes": 1.0,
    "letter shapes .": 0.5,
    "these methods can": 0.3333333333333333,
    "methods can not": 1.0,
    "can not be": 0.26666666666666666,
    "not be used": 0.08333333333333333,
    "be used in": 0.05263157894736842,
    "used in software": 0.043478260869565216,
    "in software that": 1.0,
    "software that scans": 1.0,
    "that scans paper": 1.0,
    "scans paper documents": 1.0,
    "paper documents ,": 1.0,
    "documents , so": 0.1111111111111111,
    ", so accurate": 0.08333333333333333,
    "so accurate recognition": 1.0,
    "accurate recognition of": 1.0,
    "recognition of hand-printed": 0.09090909090909091,
    "of hand-printed documents": 0.5,
    "hand-printed documents is": 1.0,
    "documents is still": 1.0,
    "is still largely": 0.25,
    "still largely an": 1.0,
    "largely an open": 1.0,
    "an open problem": 0.5,
    "open problem .": 1.0,
    "accuracy rates of": 0.5,
    "rates of 80": 0.3333333333333333,
    "of 80 %": 1.0,
    "80 % to": 1.0,
    "% to 90": 0.5,
    "to 90 %": 1.0,
    "90 % on": 0.25,
    "% on neat": 1.0,
    "on neat ,": 1.0,
    "neat , clean": 1.0,
    ", clean hand-printed": 1.0,
    "clean hand-printed characters": 1.0,
    "hand-printed characters can": 1.0,
    "be achieved ,": 0.2,
    "achieved , but": 0.5,
    "but that accuracy": 0.3333333333333333,
    "that accuracy rate": 1.0,
    "accuracy rate still": 0.5,
    "rate still translates": 1.0,
    "still translates to": 1.0,
    "translates to dozens": 1.0,
    "to dozens of": 1.0,
    "dozens of errors": 1.0,
    "of errors per": 1.0,
    "errors per page": 1.0,
    "per page ,": 1.0,
    "page , making": 0.25,
    ", making the": 1.0,
    "making the technology": 0.5,
    "the technology useful": 0.5,
    "technology useful only": 1.0,
    "useful only in": 1.0,
    "only in very": 1.0,
    "in very limited": 0.3333333333333333,
    "very limited applications": 0.5,
    "limited applications .": 1.0,
    "recognition of cursive": 0.09090909090909091,
    "of cursive text": 1.0,
    "cursive text is": 1.0,
    "text is an": 0.25,
    "is an active": 0.1,
    "an active area": 1.0,
    "active area of": 1.0,
    "area of research": 0.6,
    "of research ,": 0.125,
    "research , with": 0.25,
    ", with recognition": 0.125,
    "with recognition rates": 1.0,
    "recognition rates even": 0.5,
    "rates even lower": 1.0,
    "even lower than": 1.0,
    "lower than that": 1.0,
    "than that of": 1.0,
    "that of hand-printed": 0.125,
    "of hand-printed text": 0.5,
    "hand-printed text .": 0.5,
    "<s> higher rates": 1.0,
    "higher rates of": 1.0,
    "rates of recognition": 0.3333333333333333,
    "of recognition of": 0.5,
    "recognition of general": 0.09090909090909091,
    "of general cursive": 1.0,
    "general cursive script": 1.0,
    "cursive script will": 0.5,
    "script will likely": 1.0,
    "will likely not": 0.5,
    "likely not be": 1.0,
    "not be possible": 0.08333333333333333,
    "be possible without": 0.5,
    "possible without the": 1.0,
    "without the use": 1.0,
    "use of contextual": 0.045454545454545456,
    "of contextual or": 1.0,
    "contextual or grammatical": 1.0,
    "or grammatical information": 1.0,
    "grammatical information .": 1.0,
    "example , recognizing": 0.018518518518518517,
    ", recognizing entire": 1.0,
    "recognizing entire words": 1.0,
    "entire words from": 1.0,
    "words from a": 0.5,
    "a dictionary is": 0.3333333333333333,
    "dictionary is easier": 1.0,
    "is easier than": 0.5,
    "easier than trying": 0.5,
    "than trying to": 1.0,
    "trying to parse": 0.2,
    "to parse individual": 0.25,
    "parse individual characters": 1.0,
    "individual characters from": 1.0,
    "characters from script": 1.0,
    "from script .": 1.0,
    "<s> reading the": 1.0,
    "reading the amount": 1.0,
    "the amount line": 1.0,
    "amount line of": 1.0,
    "line of a": 1.0,
    "of a cheque": 0.010869565217391304,
    "a cheque -lrb-": 1.0,
    "cheque -lrb- which": 1.0,
    "-lrb- which is": 0.3333333333333333,
    "which is always": 0.07692307692307693,
    "is always a": 0.5,
    "always a written-out": 1.0,
    "a written-out number": 1.0,
    "written-out number -rrb-": 1.0,
    "number -rrb- is": 0.5,
    "-rrb- is an": 0.09090909090909091,
    "is an example": 0.1,
    "an example where": 0.125,
    "example where using": 1.0,
    "where using a": 1.0,
    "using a smaller": 0.1,
    "a smaller dictionary": 1.0,
    "smaller dictionary can": 1.0,
    "dictionary can increase": 1.0,
    "can increase recognition": 1.0,
    "increase recognition rates": 1.0,
    "recognition rates greatly": 0.5,
    "rates greatly .": 1.0,
    "<s> knowledge of": 1.0,
    "the grammar of": 0.09090909090909091,
    "grammar of the": 0.5,
    "language being scanned": 0.5,
    "being scanned can": 1.0,
    "scanned can also": 1.0,
    "can also help": 0.125,
    "also help determine": 1.0,
    "help determine if": 1.0,
    "determine if a": 0.2,
    "if a word": 0.5,
    "a word is": 0.16666666666666666,
    "word is likely": 0.25,
    "be a verb": 0.15384615384615385,
    "a verb or": 0.3333333333333333,
    "verb or a": 0.6666666666666666,
    "or a noun": 0.10526315789473684,
    "noun , for": 0.14285714285714285,
    "example , allowing": 0.018518518518518517,
    ", allowing greater": 1.0,
    "allowing greater accuracy": 1.0,
    "greater accuracy .": 1.0,
    "<s> the shapes": 0.006802721088435374,
    "the shapes of": 1.0,
    "shapes of individual": 0.5,
    "of individual cursive": 0.5,
    "individual cursive characters": 1.0,
    "cursive characters themselves": 1.0,
    "characters themselves simply": 1.0,
    "themselves simply do": 1.0,
    "simply do not": 1.0,
    "do not contain": 0.07692307692307693,
    "not contain enough": 1.0,
    "contain enough information": 1.0,
    "enough information to": 1.0,
    "information to accurately": 0.25,
    "to accurately -lrb-": 1.0,
    "accurately -lrb- greater": 1.0,
    "-lrb- greater than": 1.0,
    "greater than 98": 1.0,
    "than 98 %": 1.0,
    "98 % -rrb-": 0.3333333333333333,
    "% -rrb- recognize": 1.0,
    "-rrb- recognize all": 1.0,
    "recognize all handwritten": 1.0,
    "all handwritten cursive": 1.0,
    "handwritten cursive script": 1.0,
    "cursive script .": 0.5,
    "it is necessary": 0.02127659574468085,
    "is necessary to": 0.5,
    "necessary to understand": 0.5,
    "to understand that": 0.3333333333333333,
    "understand that ocr": 1.0,
    "that ocr technology": 1.0,
    "technology is a": 0.3333333333333333,
    "is a basic": 0.018518518518518517,
    "a basic technology": 0.5,
    "basic technology also": 1.0,
    "technology also used": 1.0,
    "also used in": 0.5,
    "used in advanced": 0.043478260869565216,
    "in advanced scanning": 1.0,
    "advanced scanning applications": 0.5,
    "scanning applications .": 1.0,
    "<s> due to": 1.0,
    "due to this": 0.3333333333333333,
    "to this ,": 0.16666666666666666,
    "this , an": 0.25,
    ", an advanced": 0.1,
    "an advanced scanning": 1.0,
    "advanced scanning solution": 0.5,
    "scanning solution can": 1.0,
    "solution can be": 1.0,
    "can be unique": 0.01098901098901099,
    "be unique and": 1.0,
    "unique and patented": 1.0,
    "and patented and": 1.0,
    "patented and not": 1.0,
    "and not easily": 0.125,
    "not easily copied": 0.3333333333333333,
    "easily copied despite": 1.0,
    "copied despite being": 1.0,
    "despite being based": 1.0,
    "being based on": 1.0,
    "based on this": 0.021739130434782608,
    "on this basic": 0.3333333333333333,
    "this basic ocr": 1.0,
    "basic ocr technology": 1.0,
    "ocr technology .": 0.1111111111111111,
    "<s> for more": 0.03508771929824561,
    "for more complex": 0.25,
    "more complex recognition": 0.1111111111111111,
    "complex recognition problems": 1.0,
    "recognition problems ,": 1.0,
    "problems , intelligent": 0.16666666666666666,
    ", intelligent character": 1.0,
    "character recognition systems": 0.07692307692307693,
    "recognition systems are": 0.2,
    "systems are generally": 0.07692307692307693,
    "are generally used": 0.25,
    "generally used ,": 1.0,
    "used , as": 0.125,
    ", as artificial": 0.043478260869565216,
    "as artificial neural": 1.0,
    "artificial neural networks": 0.5,
    "neural networks can": 0.09090909090909091,
    "networks can be": 1.0,
    "be made indifferent": 0.25,
    "made indifferent to": 1.0,
    "indifferent to both": 1.0,
    "to both affine": 0.3333333333333333,
    "both affine and": 1.0,
    "affine and non-linear": 1.0,
    "and non-linear transformations": 1.0,
    "non-linear transformations .": 1.0,
    "<s> a technique": 0.022727272727272728,
    "a technique which": 0.5,
    "technique which is": 1.0,
    "which is having": 0.07692307692307693,
    "is having considerable": 1.0,
    "having considerable success": 1.0,
    "considerable success in": 1.0,
    "success in recognizing": 1.0,
    "in recognizing difficult": 0.5,
    "recognizing difficult words": 1.0,
    "difficult words and": 1.0,
    "words and character": 0.125,
    "and character groups": 1.0,
    "character groups within": 1.0,
    "groups within documents": 1.0,
    "within documents generally": 1.0,
    "documents generally amenable": 1.0,
    "generally amenable to": 1.0,
    "amenable to computer": 1.0,
    "to computer ocr": 1.0,
    "computer ocr is": 1.0,
    "ocr is to": 0.3333333333333333,
    "is to submit": 0.05263157894736842,
    "to submit them": 1.0,
    "submit them automatically": 1.0,
    "them automatically to": 1.0,
    "automatically to humans": 1.0,
    "to humans in": 1.0,
    "humans in the": 1.0,
    "in the recaptcha": 0.006535947712418301,
    "the recaptcha system": 1.0,
    "recaptcha system .": 1.0,
    "<s> in corpus": 0.010309278350515464,
    "in corpus linguistics": 1.0,
    "corpus linguistics ,": 0.3333333333333333,
    "linguistics , part-of-speech": 0.125,
    ", part-of-speech tagging": 1.0,
    "part-of-speech tagging -lrb-": 0.1111111111111111,
    "tagging -lrb- pos": 1.0,
    "-lrb- pos tagging": 0.5,
    "pos tagging or": 0.2,
    "tagging or post": 0.5,
    "or post -rrb-": 1.0,
    "post -rrb- ,": 1.0,
    "-rrb- , also": 0.02564102564102564,
    "also called grammatical": 0.3333333333333333,
    "called grammatical tagging": 1.0,
    "grammatical tagging or": 0.5,
    "tagging or word-category": 0.5,
    "or word-category disambiguation": 1.0,
    "word-category disambiguation ,": 1.0,
    "disambiguation , is": 1.0,
    "process of marking": 0.08333333333333333,
    "of marking up": 1.0,
    "marking up a": 1.0,
    "up a word": 0.5,
    "a text -lrb-": 0.07142857142857142,
    "text -lrb- corpus": 0.16666666666666666,
    "-lrb- corpus -rrb-": 1.0,
    "corpus -rrb- as": 0.14285714285714285,
    "-rrb- as corresponding": 0.3333333333333333,
    "as corresponding to": 1.0,
    "corresponding to a": 0.5,
    "to a particular": 0.03571428571428571,
    "a particular part": 0.25,
    "particular part of": 1.0,
    "of speech ,": 0.1276595744680851,
    "speech , based": 0.09090909090909091,
    "based on both": 0.021739130434782608,
    "on both its": 1.0,
    "both its definition": 1.0,
    "its definition ,": 1.0,
    "definition , as": 0.5,
    "well as its": 0.07692307692307693,
    "as its context": 0.3333333333333333,
    "its context --": 1.0,
    "context -- i.e.": 1.0,
    "-- i.e. relationship": 1.0,
    "i.e. relationship with": 1.0,
    "relationship with adjacent": 1.0,
    "with adjacent and": 1.0,
    "adjacent and related": 1.0,
    "and related words": 0.3333333333333333,
    "related words in": 1.0,
    "words in a": 0.2727272727272727,
    "in a phrase": 0.019230769230769232,
    "a phrase ,": 0.5,
    "phrase , sentence": 1.0,
    ", sentence ,": 1.0,
    "sentence , or": 0.16666666666666666,
    ", or paragraph": 0.030303030303030304,
    "or paragraph .": 1.0,
    "<s> a simplified": 0.022727272727272728,
    "a simplified form": 1.0,
    "simplified form of": 1.0,
    "form of this": 0.14285714285714285,
    "of this is": 0.09090909090909091,
    "this is commonly": 0.038461538461538464,
    "is commonly taught": 0.5,
    "commonly taught to": 1.0,
    "taught to school-age": 1.0,
    "to school-age children": 1.0,
    "school-age children ,": 1.0,
    "children , in": 1.0,
    "in the identification": 0.006535947712418301,
    "identification of words": 0.5,
    "of words as": 0.06666666666666667,
    "words as nouns": 1.0,
    "as nouns ,": 1.0,
    "nouns , verbs": 0.3333333333333333,
    ", verbs ,": 1.0,
    "verbs , adjectives": 0.3333333333333333,
    ", adjectives ,": 1.0,
    "adjectives , adverbs": 1.0,
    ", adverbs ,": 1.0,
    "adverbs , etc.": 1.0,
    "once performed by": 0.5,
    "performed by hand": 0.5,
    "by hand ,": 0.3333333333333333,
    "hand , pos": 0.14285714285714285,
    ", pos tagging": 1.0,
    "pos tagging is": 0.2,
    "tagging is now": 0.5,
    "is now done": 0.3333333333333333,
    "now done in": 1.0,
    "done in the": 0.2,
    "context of computational": 0.2,
    "computational linguistics ,": 0.3333333333333333,
    "linguistics , using": 0.125,
    ", using algorithms": 0.1,
    "using algorithms which": 1.0,
    "algorithms which associate": 0.5,
    "which associate discrete": 1.0,
    "associate discrete terms": 1.0,
    "discrete terms ,": 1.0,
    "terms , as": 1.0,
    "well as hidden": 0.07692307692307693,
    "as hidden parts": 1.0,
    "hidden parts of": 1.0,
    "speech , in": 0.09090909090909091,
    ", in accordance": 0.029411764705882353,
    "in accordance with": 1.0,
    "accordance with a": 1.0,
    "with a set": 0.05,
    "set of descriptive": 0.03571428571428571,
    "of descriptive tags": 1.0,
    "descriptive tags .": 1.0,
    "<s> pos-tagging algorithms": 1.0,
    "pos-tagging algorithms fall": 1.0,
    "algorithms fall into": 1.0,
    "fall into two": 0.5,
    "into two distinctive": 1.0,
    "two distinctive groups": 1.0,
    "distinctive groups :": 1.0,
    "groups : rule-based": 1.0,
    ": rule-based and": 0.5,
    "rule-based and stochastic": 1.0,
    "and stochastic .": 1.0,
    "<s> e. brill": 1.0,
    "e. brill 's": 1.0,
    "brill 's tagger": 1.0,
    "'s tagger ,": 1.0,
    "tagger , one": 0.2,
    ", one of": 0.16666666666666666,
    "the first and": 0.045454545454545456,
    "first and widely": 1.0,
    "and widely used": 1.0,
    "widely used english": 0.14285714285714285,
    "used english pos-taggers": 1.0,
    "english pos-taggers ,": 1.0,
    "pos-taggers , employs": 1.0,
    ", employs rule-based": 1.0,
    "employs rule-based algorithms": 1.0,
    "rule-based algorithms .": 1.0,
    "is not rare": 0.05263157894736842,
    "not rare --": 1.0,
    "rare -- in": 1.0,
    "-- in natural": 1.0,
    "in natural languages": 0.125,
    "natural languages -lrb-": 0.1111111111111111,
    "languages -lrb- as": 0.5,
    "-lrb- as opposed": 0.14285714285714285,
    "as opposed to": 1.0,
    "opposed to many": 1.0,
    "to many artificial": 0.25,
    "many artificial languages": 1.0,
    "artificial languages -rrb-": 1.0,
    "languages -rrb- ,": 0.5,
    "-rrb- , a": 0.038461538461538464,
    ", a large": 0.020833333333333332,
    "a large percentage": 0.1111111111111111,
    "large percentage of": 1.0,
    "percentage of word-forms": 1.0,
    "of word-forms are": 1.0,
    "word-forms are ambiguous": 1.0,
    "are ambiguous .": 1.0,
    "example , even": 0.018518518518518517,
    ", even ``": 0.14285714285714285,
    "even `` dogs": 1.0,
    "`` dogs ''": 1.0,
    "dogs '' ,": 0.25,
    "which is usually": 0.07692307692307693,
    "is usually thought": 0.125,
    "usually thought of": 1.0,
    "thought of as": 1.0,
    "of as just": 0.5,
    "as just a": 1.0,
    "just a plural": 0.5,
    "a plural noun": 1.0,
    "plural noun ,": 1.0,
    "noun , can": 0.14285714285714285,
    ", can also": 0.16666666666666666,
    "also be a": 0.14285714285714285,
    "a verb :": 0.16666666666666666,
    "verb : the": 1.0,
    ": the sailor": 0.16666666666666666,
    "the sailor dogs": 1.0,
    "sailor dogs the": 1.0,
    "dogs the barmaid": 1.0,
    "the barmaid .": 1.0,
    "<s> performing grammatical": 1.0,
    "performing grammatical tagging": 1.0,
    "grammatical tagging will": 0.5,
    "tagging will indicate": 1.0,
    "will indicate that": 1.0,
    "indicate that ``": 1.0,
    "that `` dogs": 0.16666666666666666,
    "dogs '' is": 0.5,
    "is a verb": 0.018518518518518517,
    "a verb ,": 0.5,
    "verb , and": 0.6,
    "and not the": 0.125,
    "not the more": 0.2,
    "the more common": 0.16666666666666666,
    "more common plural": 1.0,
    "common plural noun": 1.0,
    "noun , since": 0.14285714285714285,
    ", since one": 0.2,
    "since one of": 1.0,
    "the words must": 0.16666666666666666,
    "words must be": 1.0,
    "must be the": 0.16666666666666666,
    "be the main": 0.3333333333333333,
    "the main verb": 0.2,
    "main verb ,": 1.0,
    "and the noun": 0.024390243902439025,
    "the noun reading": 1.0,
    "noun reading is": 1.0,
    "reading is less": 1.0,
    "is less likely": 1.0,
    "less likely following": 0.5,
    "likely following ``": 1.0,
    "following `` sailor": 1.0,
    "`` sailor ''": 1.0,
    "sailor '' -lrb-": 0.5,
    "'' -lrb- sailor": 0.1111111111111111,
    "-lrb- sailor !": 0.5,
    "<s> \u2192 dogs": 1.0,
    "\u2192 dogs -rrb-": 1.0,
    "dogs -rrb- .": 1.0,
    "<s> semantic analysis": 1.0,
    "semantic analysis can": 0.3333333333333333,
    "analysis can then": 0.5,
    "can then extrapolate": 1.0,
    "then extrapolate that": 1.0,
    "extrapolate that ``": 1.0,
    "that `` sailor": 0.16666666666666666,
    "sailor '' and": 0.5,
    "and `` barmaid": 0.05,
    "`` barmaid ''": 1.0,
    "barmaid '' implicate": 0.5,
    "'' implicate ``": 1.0,
    "implicate `` dogs": 1.0,
    "dogs '' as": 0.25,
    "'' as 1": 0.2,
    "as 1 -rrb-": 1.0,
    "1 -rrb- in": 1.0,
    "-rrb- in the": 0.75,
    "in the nautical": 0.006535947712418301,
    "the nautical context": 1.0,
    "nautical context -lrb-": 1.0,
    "context -lrb- sailor": 0.5,
    "-lrb- sailor \u2192": 0.5,
    "sailor \u2192 <verb>": 1.0,
    "\u2192 <verb> \u2190": 1.0,
    "<verb> \u2190 barmaid": 1.0,
    "\u2190 barmaid -rrb-": 1.0,
    "barmaid -rrb- and": 0.3333333333333333,
    "-rrb- and 2": 0.05,
    "and 2 -rrb-": 1.0,
    "2 -rrb- an": 1.0,
    "-rrb- an action": 1.0,
    "an action applied": 1.0,
    "action applied to": 1.0,
    "applied to the": 0.18181818181818182,
    "to the object": 0.012987012987012988,
    "the object ``": 1.0,
    "object `` barmaid": 1.0,
    "barmaid '' -lrb-": 0.5,
    "'' -lrb- -lrb-": 0.1111111111111111,
    "-lrb- -lrb- subject": 1.0,
    "-lrb- subject -rrb-": 1.0,
    "subject -rrb- dogs": 1.0,
    "-rrb- dogs \u2192": 1.0,
    "dogs \u2192 barmaid": 1.0,
    "\u2192 barmaid -rrb-": 1.0,
    "barmaid -rrb- .": 0.3333333333333333,
    "in this context": 0.13333333333333333,
    "this context ,": 1.0,
    "context , ``": 0.25,
    ", `` dogs": 0.04,
    "is a nautical": 0.018518518518518517,
    "a nautical term": 1.0,
    "nautical term meaning": 1.0,
    "term meaning ``": 1.0,
    "meaning `` fastens": 1.0,
    "`` fastens -lrb-": 1.0,
    "fastens -lrb- a": 1.0,
    "-lrb- a watertight": 0.2,
    "a watertight barmaid": 1.0,
    "watertight barmaid -rrb-": 1.0,
    "barmaid -rrb- securely": 0.3333333333333333,
    "-rrb- securely ;": 1.0,
    "securely ; applies": 1.0,
    "; applies a": 1.0,
    "applies a dog": 0.5,
    "a dog to": 1.0,
    "dog to ''": 1.0,
    "to '' .": 0.5,
    "<s> `` dogged": 0.2,
    "`` dogged ''": 1.0,
    "dogged '' ,": 1.0,
    "'' , on": 0.03333333333333333,
    "hand , can": 0.14285714285714285,
    ", can be": 0.3333333333333333,
    "can be either": 0.01098901098901099,
    "be either an": 1.0,
    "either an adjective": 1.0,
    "an adjective or": 0.6,
    "adjective or a": 1.0,
    "or a past-tense": 0.05263157894736842,
    "a past-tense verb": 1.0,
    "past-tense verb .": 1.0,
    "<s> just which": 1.0,
    "just which parts": 1.0,
    "which parts of": 1.0,
    "of speech a": 0.02127659574468085,
    "speech a word": 1.0,
    "word can represent": 0.5,
    "can represent varies": 0.5,
    "represent varies greatly": 1.0,
    "varies greatly .": 0.5,
    "<s> trained linguists": 1.0,
    "trained linguists can": 1.0,
    "linguists can identify": 1.0,
    "can identify the": 1.0,
    "identify the grammatical": 0.16666666666666666,
    "the grammatical parts": 0.3333333333333333,
    "grammatical parts of": 1.0,
    "of speech to": 0.02127659574468085,
    "speech to various": 0.3333333333333333,
    "to various fine": 1.0,
    "various fine degrees": 1.0,
    "fine degrees depending": 1.0,
    "degrees depending on": 1.0,
    "on the tagging": 0.014925373134328358,
    "the tagging system": 0.5,
    "tagging system .": 1.0,
    "<s> schools commonly": 1.0,
    "schools commonly teach": 1.0,
    "commonly teach that": 1.0,
    "teach that there": 1.0,
    "there are 9": 0.047619047619047616,
    "are 9 parts": 1.0,
    "9 parts of": 1.0,
    "of speech in": 0.02127659574468085,
    "speech in english": 0.5,
    "in english :": 0.14285714285714285,
    "english : noun": 1.0,
    ": noun ,": 1.0,
    ", verb ,": 0.5,
    "verb , article": 0.2,
    ", article ,": 0.6666666666666666,
    "article , adjective": 0.3333333333333333,
    ", adjective ,": 1.0,
    "adjective , preposition": 1.0,
    ", preposition ,": 1.0,
    "preposition , pronoun": 0.3333333333333333,
    ", pronoun ,": 1.0,
    "pronoun , adverb": 1.0,
    ", adverb ,": 1.0,
    "adverb , conjunction": 1.0,
    ", conjunction ,": 1.0,
    "conjunction , and": 1.0,
    ", and interjection": 0.005291005291005291,
    "and interjection .": 1.0,
    "there are clearly": 0.047619047619047616,
    "are clearly many": 1.0,
    "clearly many more": 1.0,
    "many more categories": 1.0,
    "more categories and": 1.0,
    "categories and sub-categories": 0.5,
    "and sub-categories .": 1.0,
    "<s> for nouns": 0.017543859649122806,
    "for nouns ,": 1.0,
    "nouns , plural": 0.16666666666666666,
    ", plural ,": 1.0,
    "plural , possessive": 0.5,
    ", possessive ,": 1.0,
    "possessive , and": 1.0,
    ", and singular": 0.005291005291005291,
    "and singular forms": 1.0,
    "singular forms can": 1.0,
    "forms can be": 1.0,
    "can be distinguished": 0.01098901098901099,
    "be distinguished .": 1.0,
    "<s> in many": 0.010309278350515464,
    "in many languages": 0.1,
    "many languages words": 1.0,
    "languages words are": 1.0,
    "words are also": 0.1,
    "are also marked": 0.125,
    "also marked for": 1.0,
    "marked for their": 0.5,
    "for their ``": 0.5,
    "their `` case": 1.0,
    "`` case ''": 1.0,
    "case '' -lrb-": 1.0,
    "'' -lrb- role": 0.1111111111111111,
    "-lrb- role as": 1.0,
    "role as subject": 1.0,
    "as subject ,": 1.0,
    "subject , object": 0.5,
    ", object ,": 1.0,
    "object , etc.": 1.0,
    "-rrb- , grammatical": 0.01282051282051282,
    ", grammatical gender": 1.0,
    "grammatical gender ,": 1.0,
    "gender , and": 1.0,
    "so on ;": 0.2,
    "on ; while": 1.0,
    "; while verbs": 1.0,
    "while verbs are": 1.0,
    "verbs are marked": 1.0,
    "are marked for": 1.0,
    "marked for tense": 0.5,
    "for tense ,": 1.0,
    "tense , aspect": 1.0,
    ", aspect ,": 1.0,
    "aspect , and": 1.0,
    "and other things": 0.1111111111111111,
    "other things .": 0.3333333333333333,
    "<s> in part-of-speech": 0.010309278350515464,
    "in part-of-speech tagging": 1.0,
    "part-of-speech tagging by": 0.1111111111111111,
    "tagging by computer": 1.0,
    "by computer ,": 0.3333333333333333,
    "computer , it": 1.0,
    "it is typical": 0.02127659574468085,
    "is typical to": 1.0,
    "typical to distinguish": 1.0,
    "to distinguish from": 0.2,
    "distinguish from 50": 1.0,
    "from 50 to": 1.0,
    "50 to 150": 1.0,
    "to 150 separate": 1.0,
    "150 separate parts": 1.0,
    "separate parts of": 1.0,
    "speech for english": 0.25,
    "for english ,": 1.0,
    "english , for": 0.16666666666666666,
    "example , nn": 0.018518518518518517,
    ", nn for": 1.0,
    "nn for singular": 1.0,
    "for singular common": 0.5,
    "singular common nouns": 1.0,
    "common nouns ,": 1.0,
    "nouns , nns": 0.16666666666666666,
    ", nns for": 1.0,
    "nns for plural": 1.0,
    "for plural common": 1.0,
    "plural common nouns": 1.0,
    "nouns , np": 0.16666666666666666,
    ", np for": 1.0,
    "np for singular": 1.0,
    "for singular proper": 0.5,
    "singular proper nouns": 1.0,
    "proper nouns -lrb-": 1.0,
    "nouns -lrb- see": 1.0,
    "-lrb- see the": 0.0625,
    "see the pos": 0.5,
    "the pos tags": 0.3333333333333333,
    "pos tags used": 1.0,
    "tags used in": 0.5,
    "in the brown": 0.0196078431372549,
    "brown corpus -rrb-": 0.25,
    "corpus -rrb- .": 0.2857142857142857,
    "<s> work on": 0.5,
    "work on stochastic": 1.0,
    "on stochastic methods": 1.0,
    "stochastic methods for": 1.0,
    "methods for tagging": 0.25,
    "for tagging koine": 1.0,
    "tagging koine greek": 1.0,
    "koine greek -lrb-": 1.0,
    "greek -lrb- derose": 1.0,
    "-lrb- derose 1990": 1.0,
    "derose 1990 -rrb-": 1.0,
    "1990 -rrb- has": 0.5,
    "-rrb- has used": 0.3333333333333333,
    "has used over": 1.0,
    "used over 1,000": 1.0,
    "over 1,000 parts": 1.0,
    "1,000 parts of": 1.0,
    "speech , and": 0.09090909090909091,
    ", and found": 0.005291005291005291,
    "and found that": 1.0,
    "found that about": 0.2,
    "that about as": 1.0,
    "about as many": 1.0,
    "as many words": 0.5,
    "many words were": 0.25,
    "words were ambiguous": 0.5,
    "were ambiguous there": 1.0,
    "ambiguous there as": 1.0,
    "there as in": 1.0,
    "as in english": 0.08333333333333333,
    "in english .": 0.14285714285714285,
    "<s> a morphosyntactic": 0.022727272727272728,
    "a morphosyntactic descriptor": 1.0,
    "morphosyntactic descriptor in": 1.0,
    "descriptor in the": 1.0,
    "case of morphologically": 0.16666666666666666,
    "of morphologically rich": 1.0,
    "morphologically rich languages": 1.0,
    "rich languages can": 1.0,
    "languages can be": 1.0,
    "can be expressed": 0.03296703296703297,
    "be expressed like": 0.3333333333333333,
    "expressed like ncmsan": 1.0,
    "like ncmsan ,": 1.0,
    "ncmsan , which": 1.0,
    "which means category": 0.25,
    "means category =": 1.0,
    "category = noun": 1.0,
    "= noun ,": 1.0,
    "noun , type": 0.14285714285714285,
    ", type =": 1.0,
    "type = common": 1.0,
    "= common ,": 1.0,
    "common , gender": 0.5,
    ", gender =": 1.0,
    "gender = masculine": 1.0,
    "= masculine ,": 1.0,
    "masculine , number": 1.0,
    ", number =": 1.0,
    "number = singular": 1.0,
    "= singular ,": 1.0,
    "singular , case": 1.0,
    ", case =": 1.0,
    "case = accusative": 1.0,
    "= accusative ,": 1.0,
    "accusative , animate": 1.0,
    ", animate =": 1.0,
    "animate = no.": 1.0,
    "= no. .": 1.0,
    "<s> history the": 0.5,
    "history the brown": 1.0,
    "brown corpus research": 0.08333333333333333,
    "corpus research on": 1.0,
    "research on part-of-speech": 1.0,
    "on part-of-speech tagging": 1.0,
    "part-of-speech tagging has": 0.1111111111111111,
    "tagging has been": 1.0,
    "has been closely": 0.03571428571428571,
    "been closely tied": 1.0,
    "closely tied to": 1.0,
    "tied to corpus": 1.0,
    "to corpus linguistics": 1.0,
    "corpus linguistics .": 0.3333333333333333,
    "the first major": 0.09090909090909091,
    "first major corpus": 0.5,
    "major corpus of": 1.0,
    "corpus of english": 0.125,
    "of english for": 0.3333333333333333,
    "english for computer": 1.0,
    "for computer analysis": 0.3333333333333333,
    "computer analysis was": 1.0,
    "analysis was the": 0.5,
    "was the brown": 0.25,
    "brown corpus developed": 0.08333333333333333,
    "corpus developed at": 1.0,
    "developed at brown": 0.5,
    "at brown university": 1.0,
    "brown university by": 0.5,
    "university by henry": 1.0,
    "by henry kucera": 1.0,
    "henry kucera and": 1.0,
    "kucera and nelson": 1.0,
    "and nelson francis": 1.0,
    "nelson francis ,": 1.0,
    "francis , in": 1.0,
    "in the mid-1960s": 0.006535947712418301,
    "the mid-1960s .": 1.0,
    "<s> it consists": 0.029411764705882353,
    "it consists of": 1.0,
    "consists of about": 0.5,
    "of about 1,000,000": 1.0,
    "about 1,000,000 words": 1.0,
    "1,000,000 words of": 1.0,
    "words of running": 0.3333333333333333,
    "of running english": 1.0,
    "running english prose": 1.0,
    "english prose text": 1.0,
    "prose text ,": 1.0,
    "text , made": 0.06666666666666667,
    ", made up": 0.5,
    "made up of": 1.0,
    "up of 500": 1.0,
    "of 500 samples": 0.5,
    "500 samples from": 1.0,
    "samples from randomly": 1.0,
    "from randomly chosen": 1.0,
    "randomly chosen publications": 1.0,
    "chosen publications .": 1.0,
    "<s> each sample": 0.2,
    "each sample is": 1.0,
    "sample is 2,000": 1.0,
    "is 2,000 or": 1.0,
    "2,000 or more": 1.0,
    "or more words": 0.25,
    "more words -lrb-": 1.0,
    "words -lrb- ending": 0.3333333333333333,
    "-lrb- ending at": 1.0,
    "ending at the": 1.0,
    "the first sentence-end": 0.045454545454545456,
    "first sentence-end after": 1.0,
    "sentence-end after 2,000": 1.0,
    "after 2,000 words": 1.0,
    "2,000 words ,": 1.0,
    "words , so": 0.0625,
    ", so that": 0.16666666666666666,
    "that the corpus": 0.043478260869565216,
    "the corpus contains": 1.0,
    "corpus contains only": 0.5,
    "contains only complete": 1.0,
    "only complete sentences": 1.0,
    "complete sentences -rrb-": 1.0,
    "sentences -rrb- .": 0.5,
    "<s> the brown": 0.013605442176870748,
    "brown corpus was": 0.16666666666666666,
    "corpus was painstakingly": 0.5,
    "was painstakingly ``": 1.0,
    "painstakingly `` tagged": 1.0,
    "`` tagged ''": 1.0,
    "tagged '' with": 0.5,
    "'' with part-of-speech": 0.25,
    "with part-of-speech markers": 1.0,
    "part-of-speech markers over": 1.0,
    "markers over many": 1.0,
    "over many years": 1.0,
    "many years .": 1.0,
    "<s> a first": 0.022727272727272728,
    "a first approximation": 0.3333333333333333,
    "first approximation was": 1.0,
    "approximation was done": 1.0,
    "was done with": 1.0,
    "done with a": 0.5,
    "with a program": 0.05,
    "a program by": 0.25,
    "program by greene": 1.0,
    "by greene and": 1.0,
    "greene and rubin": 1.0,
    "and rubin ,": 1.0,
    "rubin , which": 1.0,
    ", which consisted": 0.017857142857142856,
    "which consisted of": 1.0,
    "consisted of a": 1.0,
    "of a huge": 0.010869565217391304,
    "a huge handmade": 1.0,
    "huge handmade list": 1.0,
    "handmade list of": 1.0,
    "list of what": 0.1,
    "of what categories": 0.25,
    "what categories could": 1.0,
    "categories could co-occur": 1.0,
    "could co-occur at": 1.0,
    "co-occur at all": 1.0,
    "at all .": 0.2,
    "example , article": 0.018518518518518517,
    ", article then": 0.3333333333333333,
    "article then noun": 1.0,
    "then noun can": 1.0,
    "noun can occur": 1.0,
    "can occur ,": 1.0,
    "occur , but": 1.0,
    ", but article": 0.020833333333333332,
    "but article verb": 1.0,
    "article verb -lrb-": 1.0,
    "verb -lrb- arguably": 0.5,
    "-lrb- arguably -rrb-": 1.0,
    "arguably -rrb- can": 1.0,
    "-rrb- can not": 0.3333333333333333,
    "can not .": 0.13333333333333333,
    "<s> the program": 0.006802721088435374,
    "the program got": 0.25,
    "program got about": 1.0,
    "got about 70": 1.0,
    "about 70 %": 1.0,
    "70 % correct": 0.3333333333333333,
    "% correct .": 1.0,
    "<s> its results": 0.5,
    "its results were": 1.0,
    "results were repeatedly": 1.0,
    "were repeatedly reviewed": 1.0,
    "repeatedly reviewed and": 1.0,
    "reviewed and corrected": 1.0,
    "and corrected by": 1.0,
    "corrected by hand": 1.0,
    "hand , and": 0.14285714285714285,
    ", and later": 0.005291005291005291,
    "and later users": 1.0,
    "later users sent": 1.0,
    "users sent in": 1.0,
    "sent in errata": 1.0,
    "in errata ,": 1.0,
    "errata , so": 1.0,
    "so that by": 0.16666666666666666,
    "that by the": 1.0,
    "by the late": 0.03571428571428571,
    "the late 70s": 0.1111111111111111,
    "late 70s the": 1.0,
    "70s the tagging": 1.0,
    "the tagging was": 0.5,
    "tagging was nearly": 0.5,
    "was nearly perfect": 1.0,
    "nearly perfect -lrb-": 1.0,
    "perfect -lrb- allowing": 1.0,
    "-lrb- allowing for": 1.0,
    "allowing for some": 1.0,
    "for some cases": 0.16666666666666666,
    "some cases on": 0.25,
    "cases on which": 1.0,
    "on which even": 0.3333333333333333,
    "which even human": 1.0,
    "even human speakers": 1.0,
    "human speakers might": 1.0,
    "speakers might not": 1.0,
    "might not agree": 0.5,
    "not agree -rrb-": 1.0,
    "agree -rrb- .": 1.0,
    "this corpus has": 0.5,
    "corpus has been": 1.0,
    "been used for": 0.2,
    "used for innumerable": 0.06666666666666667,
    "for innumerable studies": 1.0,
    "innumerable studies of": 1.0,
    "studies of word-frequency": 1.0,
    "of word-frequency and": 1.0,
    "word-frequency and of": 1.0,
    "and of part-of-speech": 1.0,
    "of part-of-speech ,": 0.5,
    "part-of-speech , and": 1.0,
    ", and inspired": 0.005291005291005291,
    "and inspired the": 1.0,
    "inspired the development": 1.0,
    "development of similar": 0.14285714285714285,
    "of similar ``": 0.5,
    "similar `` tagged": 1.0,
    "tagged '' corpora": 0.5,
    "'' corpora in": 1.0,
    "corpora in many": 1.0,
    "in many other": 0.1,
    "other languages .": 0.2,
    "<s> statistics derived": 0.3333333333333333,
    "statistics derived by": 1.0,
    "by analyzing it": 0.5,
    "analyzing it formed": 1.0,
    "it formed the": 1.0,
    "formed the basis": 1.0,
    "the basis for": 0.25,
    "basis for most": 0.5,
    "for most later": 0.3333333333333333,
    "most later part-of-speech": 1.0,
    "later part-of-speech tagging": 1.0,
    "part-of-speech tagging systems": 0.1111111111111111,
    "tagging systems ,": 1.0,
    "systems , such": 0.16666666666666666,
    "such as claws": 0.011111111111111112,
    "as claws -lrb-": 1.0,
    "claws -lrb- linguistics": 1.0,
    "linguistics -rrb- and": 0.5,
    "-rrb- and volsunga": 0.05,
    "and volsunga .": 1.0,
    "however , by": 0.022727272727272728,
    ", by this": 0.2,
    "by this time": 1.0,
    "this time -lrb-": 0.3333333333333333,
    "time -lrb- 2005": 0.5,
    "-lrb- 2005 -rrb-": 1.0,
    "2005 -rrb- it": 1.0,
    "-rrb- it has": 1.0,
    "has been superseded": 0.03571428571428571,
    "been superseded by": 1.0,
    "superseded by larger": 1.0,
    "by larger corpora": 1.0,
    "larger corpora such": 1.0,
    "corpora such as": 1.0,
    "as the 100": 0.03571428571428571,
    "the 100 million": 1.0,
    "100 million word": 1.0,
    "million word british": 1.0,
    "word british national": 1.0,
    "british national corpus": 1.0,
    "national corpus .": 1.0,
    "<s> for some": 0.017543859649122806,
    "for some time": 0.3333333333333333,
    "some time ,": 0.5,
    "time , part-of-speech": 0.09090909090909091,
    "part-of-speech tagging was": 0.1111111111111111,
    "tagging was considered": 0.5,
    "was considered an": 1.0,
    "considered an inseparable": 1.0,
    "an inseparable part": 1.0,
    "inseparable part of": 1.0,
    "part of natural": 0.045454545454545456,
    "processing , because": 0.1111111111111111,
    "because there are": 0.5,
    "there are certain": 0.047619047619047616,
    "are certain cases": 1.0,
    "certain cases where": 1.0,
    "cases where the": 0.3333333333333333,
    "where the correct": 0.07692307692307693,
    "of speech can": 0.02127659574468085,
    "speech can not": 0.3333333333333333,
    "not be decided": 0.08333333333333333,
    "be decided without": 1.0,
    "decided without understanding": 1.0,
    "without understanding the": 1.0,
    "understanding the semantics": 0.25,
    "the semantics or": 0.5,
    "semantics or even": 0.5,
    "or even the": 0.2,
    "even the pragmatics": 0.5,
    "the pragmatics of": 1.0,
    "pragmatics of the": 1.0,
    "of the context": 0.005128205128205128,
    "the context .": 0.14285714285714285,
    "this is extremely": 0.038461538461538464,
    "is extremely expensive": 0.5,
    "extremely expensive ,": 1.0,
    "expensive , especially": 0.3333333333333333,
    ", especially because": 0.1111111111111111,
    "especially because analyzing": 1.0,
    "because analyzing the": 1.0,
    "analyzing the higher": 1.0,
    "the higher levels": 1.0,
    "higher levels is": 0.5,
    "levels is much": 1.0,
    "is much harder": 0.5,
    "much harder when": 1.0,
    "harder when multiple": 1.0,
    "when multiple part-of-speech": 1.0,
    "multiple part-of-speech possibilities": 1.0,
    "part-of-speech possibilities must": 1.0,
    "possibilities must be": 1.0,
    "must be considered": 0.16666666666666666,
    "be considered for": 0.5,
    "considered for each": 1.0,
    "<s> use of": 1.0,
    "use of hidden": 0.045454545454545456,
    "of hidden markov": 1.0,
    "hidden markov models": 0.5384615384615384,
    "markov models in": 0.1111111111111111,
    "models in the": 1.0,
    "in the mid": 0.006535947712418301,
    "the mid 1980s": 1.0,
    "mid 1980s ,": 1.0,
    "1980s , researchers": 0.2,
    ", researchers in": 0.5,
    "researchers in europe": 1.0,
    "in europe began": 0.25,
    "europe began to": 1.0,
    "began to use": 0.25,
    "to use hidden": 0.1,
    "use hidden markov": 1.0,
    "markov models -lrb-": 0.2222222222222222,
    "models -lrb- hmms": 0.6666666666666666,
    "-lrb- hmms -rrb-": 1.0,
    "hmms -rrb- to": 0.5,
    "-rrb- to disambiguate": 0.25,
    "to disambiguate parts": 0.3333333333333333,
    "disambiguate parts of": 1.0,
    "speech , when": 0.18181818181818182,
    ", when working": 0.16666666666666666,
    "when working to": 1.0,
    "working to tag": 1.0,
    "to tag the": 1.0,
    "tag the lancaster-oslo-bergen": 1.0,
    "the lancaster-oslo-bergen corpus": 1.0,
    "lancaster-oslo-bergen corpus of": 1.0,
    "corpus of british": 0.125,
    "of british english": 1.0,
    "british english .": 1.0,
    "<s> hmms involve": 0.3333333333333333,
    "hmms involve counting": 1.0,
    "involve counting cases": 1.0,
    "counting cases -lrb-": 1.0,
    "cases -lrb- such": 1.0,
    "such as from": 0.011111111111111112,
    "as from the": 1.0,
    ", and making": 0.010582010582010581,
    "and making a": 0.5,
    "making a table": 1.0,
    "a table of": 1.0,
    "table of the": 0.3333333333333333,
    "of the probabilities": 0.005128205128205128,
    "the probabilities of": 0.75,
    "probabilities of certain": 0.3333333333333333,
    "of certain sequences": 1.0,
    "certain sequences .": 1.0,
    "example , once": 0.018518518518518517,
    ", once you": 1.0,
    "once you 've": 1.0,
    "you 've seen": 0.5,
    "'ve seen an": 1.0,
    "seen an article": 1.0,
    "an article such": 0.5,
    "article such as": 1.0,
    "such as `": 0.011111111111111112,
    "as ` the": 1.0,
    "` the '": 1.0,
    "the ' ,": 1.0,
    "' , perhaps": 0.16666666666666666,
    ", perhaps the": 0.3333333333333333,
    "perhaps the next": 0.5,
    "the next word": 0.2857142857142857,
    "next word is": 0.5,
    "word is a": 0.25,
    "is a noun": 0.018518518518518517,
    "a noun 40": 0.16666666666666666,
    "noun 40 %": 1.0,
    "40 % of": 0.5,
    "% of the": 0.625,
    "of the time": 0.020512820512820513,
    "time , an": 0.09090909090909091,
    ", an adjective": 0.1,
    "an adjective 40": 0.2,
    "adjective 40 %": 1.0,
    "40 % ,": 0.5,
    "% , and": 0.5,
    "and a number": 0.0625,
    "a number 20": 0.043478260869565216,
    "number 20 %": 1.0,
    "20 % .": 1.0,
    "<s> knowing this": 1.0,
    "knowing this ,": 1.0,
    "this , a": 0.25,
    ", a program": 0.020833333333333332,
    "a program can": 0.25,
    "program can decide": 1.0,
    "can decide that": 1.0,
    "decide that ``": 1.0,
    "that `` can": 0.16666666666666666,
    "`` can ''": 1.0,
    "can '' in": 0.5,
    "'' in ``": 0.14285714285714285,
    "in `` the": 0.3333333333333333,
    "`` the can": 0.125,
    "the can ''": 1.0,
    "can '' is": 0.5,
    "'' is far": 0.1111111111111111,
    "far more likely": 0.5,
    "more likely to": 1.0,
    "a noun than": 0.16666666666666666,
    "noun than a": 1.0,
    "than a verb": 0.2,
    "or a modal": 0.05263157894736842,
    "a modal .": 1.0,
    "<s> the same": 0.006802721088435374,
    "the same method": 0.041666666666666664,
    "same method can": 1.0,
    "method can of": 1.0,
    "can of course": 1.0,
    "of course be": 0.5,
    "course be used": 1.0,
    "used to benefit": 0.045454545454545456,
    "to benefit from": 1.0,
    "benefit from knowledge": 0.3333333333333333,
    "from knowledge about": 1.0,
    "knowledge about following": 0.3333333333333333,
    "about following words": 1.0,
    "following words .": 1.0,
    "<s> more advanced": 0.125,
    "more advanced -lrb-": 1.0,
    "advanced -lrb- ``": 1.0,
    "-lrb- `` higher": 0.125,
    "`` higher order": 1.0,
    "higher order ''": 1.0,
    "order '' -rrb-": 1.0,
    "'' -rrb- hmms": 0.07142857142857142,
    "-rrb- hmms learn": 1.0,
    "hmms learn the": 1.0,
    "learn the probabilities": 1.0,
    "the probabilities not": 0.25,
    "probabilities not only": 1.0,
    "not only of": 0.14285714285714285,
    "only of pairs": 1.0,
    "of pairs ,": 1.0,
    "pairs , but": 0.5,
    ", but triples": 0.020833333333333332,
    "but triples or": 1.0,
    "triples or even": 1.0,
    "or even larger": 0.2,
    "even larger sequences": 1.0,
    "larger sequences .": 1.0,
    "<s> so ,": 0.3333333333333333,
    "so , for": 1.0,
    "if you 've": 0.5,
    "you 've just": 0.5,
    "'ve just seen": 1.0,
    "just seen an": 1.0,
    "an article and": 0.5,
    "article and a": 0.5,
    "and a verb": 0.0625,
    "verb , the": 0.2,
    ", the next": 0.009523809523809525,
    "the next item": 0.14285714285714285,
    "next item may": 1.0,
    "item may be": 1.0,
    "may be very": 0.047619047619047616,
    "be very likely": 0.3333333333333333,
    "very likely a": 1.0,
    "likely a preposition": 1.0,
    "a preposition ,": 1.0,
    "preposition , article": 0.3333333333333333,
    "article , or": 0.3333333333333333,
    ", or noun": 0.030303030303030304,
    "or noun ,": 1.0,
    "noun , but": 0.14285714285714285,
    ", but much": 0.020833333333333332,
    "but much less": 1.0,
    "much less likely": 1.0,
    "less likely another": 0.5,
    "likely another verb": 1.0,
    "another verb .": 1.0,
    "<s> when several": 0.16666666666666666,
    "when several ambiguous": 1.0,
    "several ambiguous words": 1.0,
    "ambiguous words occur": 0.5,
    "words occur together": 1.0,
    "occur together ,": 1.0,
    "together , the": 1.0,
    ", the possibilities": 0.009523809523809525,
    "the possibilities multiply": 1.0,
    "possibilities multiply .": 1.0,
    "however , it": 0.022727272727272728,
    "it is easy": 0.02127659574468085,
    "is easy to": 1.0,
    "easy to enumerate": 0.3333333333333333,
    "to enumerate every": 1.0,
    "enumerate every combination": 1.0,
    "every combination and": 1.0,
    "combination and to": 1.0,
    "and to assign": 0.09090909090909091,
    "to assign a": 0.3333333333333333,
    "assign a relative": 0.5,
    "a relative probability": 1.0,
    "relative probability to": 1.0,
    "probability to each": 1.0,
    "to each one": 0.2,
    "each one ,": 0.5,
    "one , by": 0.25,
    ", by multiplying": 0.2,
    "by multiplying together": 1.0,
    "multiplying together the": 1.0,
    "together the probabilities": 1.0,
    "probabilities of each": 0.3333333333333333,
    "of each choice": 0.14285714285714285,
    "each choice in": 1.0,
    "choice in turn": 1.0,
    "in turn .": 0.2,
    "<s> the combination": 0.006802721088435374,
    "the combination with": 1.0,
    "combination with highest": 0.5,
    "with highest probability": 0.5,
    "highest probability is": 1.0,
    "probability is then": 1.0,
    "is then chosen": 0.2,
    "then chosen .": 1.0,
    "<s> the european": 0.006802721088435374,
    "the european group": 0.3333333333333333,
    "european group developed": 1.0,
    "group developed claws": 1.0,
    "developed claws ,": 1.0,
    "claws , a": 0.5,
    ", a tagging": 0.020833333333333332,
    "a tagging program": 1.0,
    "tagging program that": 1.0,
    "program that did": 0.5,
    "that did exactly": 0.5,
    "did exactly this": 1.0,
    "exactly this ,": 1.0,
    "this , and": 0.25,
    ", and achieved": 0.005291005291005291,
    "and achieved accuracy": 1.0,
    "achieved accuracy in": 0.5,
    "accuracy in the": 1.0,
    "in the 93-95": 0.006535947712418301,
    "the 93-95 %": 1.0,
    "93-95 % range": 1.0,
    "% range .": 1.0,
    "is worth remembering": 0.5,
    "worth remembering ,": 1.0,
    "remembering , as": 1.0,
    ", as eugene": 0.043478260869565216,
    "as eugene charniak": 1.0,
    "eugene charniak points": 1.0,
    "charniak points out": 1.0,
    "points out in": 1.0,
    "out in statistical": 0.5,
    "in statistical techniques": 0.3333333333333333,
    "statistical techniques for": 0.3333333333333333,
    "techniques for natural": 0.5,
    "natural language parsing": 0.028985507246376812,
    "language parsing ,": 0.5,
    "parsing , that": 0.5,
    ", that merely": 0.25,
    "that merely assigning": 1.0,
    "merely assigning the": 1.0,
    "assigning the most": 1.0,
    "most common tag": 0.16666666666666666,
    "common tag to": 1.0,
    "tag to each": 1.0,
    "to each known": 0.2,
    "each known word": 1.0,
    "known word and": 0.5,
    "word and the": 1.0,
    "and the tag": 0.024390243902439025,
    "the tag ``": 0.5,
    "tag `` proper": 1.0,
    "`` proper noun": 1.0,
    "proper noun ''": 1.0,
    "noun '' to": 1.0,
    "'' to all": 0.3333333333333333,
    "to all unknowns": 0.3333333333333333,
    "all unknowns ,": 1.0,
    "unknowns , will": 1.0,
    ", will approach": 0.5,
    "will approach 90": 1.0,
    "approach 90 %": 1.0,
    "90 % accuracy": 0.25,
    "% accuracy because": 0.25,
    "accuracy because many": 1.0,
    "because many words": 1.0,
    "many words are": 0.25,
    "words are unambiguous": 0.1,
    "are unambiguous .": 1.0,
    "<s> claws pioneered": 0.5,
    "claws pioneered the": 1.0,
    "pioneered the field": 1.0,
    "field of hmm-based": 0.08333333333333333,
    "of hmm-based part": 1.0,
    "hmm-based part of": 1.0,
    "tagging , but": 0.5,
    ", but was": 0.020833333333333332,
    "but was quite": 1.0,
    "was quite expensive": 1.0,
    "quite expensive since": 1.0,
    "expensive since it": 1.0,
    "since it enumerated": 0.5,
    "it enumerated all": 1.0,
    "enumerated all possibilities": 1.0,
    "all possibilities .": 1.0,
    "<s> it sometimes": 0.029411764705882353,
    "it sometimes had": 1.0,
    "sometimes had to": 1.0,
    "had to resort": 1.0,
    "to resort to": 1.0,
    "resort to backup": 1.0,
    "to backup methods": 1.0,
    "backup methods when": 1.0,
    "methods when there": 1.0,
    "when there were": 1.0,
    "there were simply": 0.3333333333333333,
    "were simply too": 1.0,
    "simply too many": 1.0,
    "too many -lrb-": 0.5,
    "many -lrb- the": 1.0,
    "-lrb- the brown": 0.25,
    "brown corpus contains": 0.08333333333333333,
    "corpus contains a": 0.5,
    "contains a case": 1.0,
    "a case with": 1.0,
    "case with 17": 1.0,
    "with 17 ambiguous": 1.0,
    "17 ambiguous words": 1.0,
    "ambiguous words in": 0.5,
    "in a row": 0.019230769230769232,
    "a row ,": 1.0,
    "row , and": 1.0,
    "there are words": 0.047619047619047616,
    "are words such": 1.0,
    "words such as": 1.0,
    "as `` still": 0.07142857142857142,
    "`` still ''": 1.0,
    "still '' that": 1.0,
    "'' that can": 0.25,
    "that can represent": 0.07692307692307693,
    "can represent as": 0.5,
    "represent as many": 1.0,
    "as many as": 0.5,
    "many as 7": 1.0,
    "as 7 distinct": 1.0,
    "7 distinct parts": 1.0,
    "distinct parts of": 1.0,
    "of speech -rrb-": 0.06382978723404255,
    "speech -rrb- .": 0.75,
    "<s> hmms underlie": 0.3333333333333333,
    "hmms underlie the": 1.0,
    "underlie the functioning": 1.0,
    "the functioning of": 1.0,
    "functioning of stochastic": 1.0,
    "of stochastic taggers": 1.0,
    "stochastic taggers and": 1.0,
    "taggers and are": 0.5,
    "and are used": 0.2,
    "are used in": 0.25,
    "used in various": 0.043478260869565216,
    "in various algorithms": 0.3333333333333333,
    "various algorithms one": 1.0,
    "algorithms one of": 1.0,
    "the most widely": 0.041666666666666664,
    "most widely used": 1.0,
    "widely used being": 0.14285714285714285,
    "used being the": 1.0,
    "being the bi-directional": 1.0,
    "the bi-directional inference": 1.0,
    "bi-directional inference algorithm": 1.0,
    "inference algorithm .": 1.0,
    "<s> dynamic programming": 0.3333333333333333,
    "dynamic programming methods": 0.5,
    "programming methods in": 1.0,
    "methods in 1987": 1.0,
    "in 1987 ,": 0.6666666666666666,
    "1987 , steven": 0.5,
    ", steven derose": 1.0,
    "steven derose and": 1.0,
    "derose and ken": 1.0,
    "and ken church": 1.0,
    "ken church independently": 1.0,
    "church independently developed": 1.0,
    "independently developed dynamic": 1.0,
    "developed dynamic programming": 1.0,
    "dynamic programming algorithms": 0.5,
    "programming algorithms to": 1.0,
    "algorithms to solve": 0.3333333333333333,
    "to solve the": 0.25,
    "solve the same": 1.0,
    "the same problem": 0.041666666666666664,
    "same problem in": 1.0,
    "problem in vastly": 0.25,
    "in vastly less": 1.0,
    "vastly less time": 1.0,
    "less time .": 1.0,
    "<s> their methods": 0.5,
    "their methods were": 1.0,
    "methods were similar": 0.5,
    "were similar to": 1.0,
    "to the viterbi": 0.012987012987012988,
    "the viterbi algorithm": 1.0,
    "viterbi algorithm known": 0.25,
    "algorithm known for": 1.0,
    "known for some": 1.0,
    "some time in": 0.5,
    "time in other": 1.0,
    "in other fields": 0.14285714285714285,
    "other fields .": 1.0,
    "<s> derose used": 0.5,
    "derose used a": 1.0,
    "used a table": 0.6666666666666666,
    "table of pairs": 0.3333333333333333,
    "pairs , while": 0.5,
    ", while church": 0.07142857142857142,
    "while church used": 1.0,
    "church used a": 1.0,
    "table of triples": 0.3333333333333333,
    "of triples and": 1.0,
    "triples and a": 1.0,
    "and a method": 0.0625,
    "a method of": 0.25,
    "method of estimating": 0.5,
    "of estimating the": 1.0,
    "estimating the values": 1.0,
    "the values for": 1.0,
    "values for triples": 1.0,
    "for triples that": 1.0,
    "triples that were": 1.0,
    "that were rare": 0.25,
    "were rare or": 1.0,
    "rare or nonexistent": 1.0,
    "or nonexistent in": 1.0,
    "nonexistent in the": 1.0,
    "brown corpus -lrb-": 0.08333333333333333,
    "corpus -lrb- actual": 0.5,
    "-lrb- actual measurement": 1.0,
    "actual measurement of": 1.0,
    "measurement of triple": 1.0,
    "of triple probabilities": 1.0,
    "triple probabilities would": 1.0,
    "probabilities would require": 1.0,
    "require a much": 0.2,
    "a much larger": 0.6666666666666666,
    "much larger corpus": 0.5,
    "<s> both methods": 0.5,
    "both methods achieved": 1.0,
    "methods achieved accuracy": 1.0,
    "achieved accuracy over": 0.5,
    "accuracy over 95": 1.0,
    "over 95 %": 1.0,
    "95 % .": 0.5,
    "<s> derose 's": 0.5,
    "derose 's 1990": 0.5,
    "'s 1990 dissertation": 1.0,
    "1990 dissertation at": 1.0,
    "dissertation at brown": 1.0,
    "brown university included": 0.5,
    "university included analyses": 1.0,
    "included analyses of": 1.0,
    "analyses of the": 1.0,
    "the specific error": 0.3333333333333333,
    "specific error types": 1.0,
    "error types ,": 1.0,
    "types , probabilities": 1.0,
    ", probabilities ,": 1.0,
    "probabilities , and": 1.0,
    "and other related": 0.1111111111111111,
    "other related data": 1.0,
    "related data ,": 1.0,
    ", and replicated": 0.005291005291005291,
    "and replicated his": 1.0,
    "replicated his work": 1.0,
    "his work for": 1.0,
    "work for greek": 1.0,
    "for greek ,": 1.0,
    "greek , where": 1.0,
    ", where it": 0.06666666666666667,
    "where it proved": 1.0,
    "it proved similarly": 0.5,
    "proved similarly effective": 1.0,
    "similarly effective .": 1.0,
    "<s> these findings": 0.0625,
    "these findings were": 1.0,
    "findings were surprisingly": 1.0,
    "were surprisingly disruptive": 1.0,
    "surprisingly disruptive to": 1.0,
    "disruptive to the": 1.0,
    "to the field": 0.025974025974025976,
    "field of natural": 0.16666666666666666,
    "<s> the accuracy": 0.006802721088435374,
    "the accuracy reported": 0.3333333333333333,
    "accuracy reported was": 1.0,
    "reported was higher": 1.0,
    "was higher than": 1.0,
    "higher than the": 1.0,
    "than the typical": 0.25,
    "the typical accuracy": 1.0,
    "typical accuracy of": 1.0,
    "accuracy of very": 0.14285714285714285,
    "of very sophisticated": 0.5,
    "very sophisticated algorithms": 1.0,
    "sophisticated algorithms that": 0.5,
    "algorithms that integrated": 0.5,
    "that integrated part": 1.0,
    "integrated part of": 1.0,
    "of speech choice": 0.02127659574468085,
    "speech choice with": 1.0,
    "choice with many": 1.0,
    "with many higher": 1.0,
    "many higher levels": 1.0,
    "higher levels of": 0.5,
    "levels of linguistic": 0.14285714285714285,
    "of linguistic analysis": 0.5,
    "linguistic analysis :": 1.0,
    "analysis : syntax": 0.25,
    ": syntax ,": 1.0,
    "morphology , semantics": 0.2,
    "semantics , and": 0.5,
    "<s> claws ,": 0.5,
    "claws , derose": 0.5,
    ", derose 's": 1.0,
    "derose 's and": 0.5,
    "'s and church": 1.0,
    "and church 's": 1.0,
    "church 's methods": 1.0,
    "'s methods did": 1.0,
    "methods did fail": 1.0,
    "did fail for": 1.0,
    "fail for some": 1.0,
    "for some of": 0.16666666666666666,
    "of the known": 0.005128205128205128,
    "the known cases": 0.2,
    "known cases where": 1.0,
    "cases where semantics": 0.3333333333333333,
    "where semantics is": 1.0,
    "semantics is required": 1.0,
    "is required ,": 0.5,
    "required , but": 1.0,
    ", but those": 0.020833333333333332,
    "but those proved": 1.0,
    "those proved negligibly": 1.0,
    "proved negligibly rare": 1.0,
    "negligibly rare .": 1.0,
    "<s> this convinced": 0.019230769230769232,
    "this convinced many": 1.0,
    "convinced many in": 1.0,
    "many in the": 1.0,
    "the field that": 0.058823529411764705,
    "field that part-of-speech": 0.5,
    "that part-of-speech tagging": 1.0,
    "part-of-speech tagging could": 0.1111111111111111,
    "tagging could usefully": 1.0,
    "could usefully be": 1.0,
    "usefully be separated": 1.0,
    "be separated out": 1.0,
    "separated out from": 1.0,
    "out from the": 1.0,
    "from the other": 0.045454545454545456,
    "the other levels": 0.125,
    "other levels of": 1.0,
    "levels of processing": 0.14285714285714285,
    "of processing ;": 1.0,
    "processing ; this": 1.0,
    "; this in": 0.25,
    "this in turn": 1.0,
    "in turn simplified": 0.2,
    "turn simplified the": 1.0,
    "simplified the theory": 1.0,
    "the theory and": 0.3333333333333333,
    "theory and practice": 1.0,
    "and practice of": 1.0,
    "practice of computerized": 1.0,
    "of computerized language": 0.5,
    "computerized language analysis": 1.0,
    "language analysis ,": 1.0,
    ", and encouraged": 0.005291005291005291,
    "and encouraged researchers": 1.0,
    "encouraged researchers to": 1.0,
    "researchers to find": 1.0,
    "to find ways": 0.1111111111111111,
    "find ways to": 1.0,
    "ways to separate": 1.0,
    "to separate out": 1.0,
    "separate out other": 1.0,
    "out other pieces": 1.0,
    "other pieces as": 1.0,
    "pieces as well": 1.0,
    "as well .": 0.06666666666666667,
    "<s> markov models": 1.0,
    "markov models are": 0.1111111111111111,
    "models are now": 0.5,
    "are now the": 0.25,
    "now the standard": 1.0,
    "the standard method": 0.3333333333333333,
    "standard method for": 1.0,
    "method for part-of-speech": 0.5,
    "for part-of-speech assignment": 0.5,
    "part-of-speech assignment .": 1.0,
    "<s> unsupervised taggers": 0.2,
    "unsupervised taggers the": 1.0,
    "taggers the methods": 1.0,
    "the methods already": 0.3333333333333333,
    "methods already discussed": 1.0,
    "already discussed involve": 1.0,
    "discussed involve working": 1.0,
    "involve working from": 1.0,
    "working from a": 1.0,
    "from a pre-existing": 0.08333333333333333,
    "a pre-existing corpus": 1.0,
    "pre-existing corpus to": 1.0,
    "corpus to learn": 1.0,
    "to learn tag": 0.16666666666666666,
    "learn tag probabilities": 1.0,
    "tag probabilities .": 1.0,
    "it is ,": 0.02127659574468085,
    "is , however": 0.1111111111111111,
    "however , also": 0.022727272727272728,
    ", also possible": 0.2,
    "also possible to": 0.3333333333333333,
    "possible to bootstrap": 0.3333333333333333,
    "to bootstrap using": 1.0,
    "bootstrap using ``": 1.0,
    "using `` unsupervised": 1.0,
    "`` unsupervised ''": 1.0,
    "unsupervised '' tagging": 1.0,
    "'' tagging .": 1.0,
    "<s> unsupervised tagging": 0.2,
    "unsupervised tagging techniques": 1.0,
    "tagging techniques use": 1.0,
    "techniques use an": 1.0,
    "use an untagged": 1.0,
    "an untagged corpus": 1.0,
    "untagged corpus for": 1.0,
    "corpus for their": 1.0,
    "for their training": 0.5,
    "their training data": 1.0,
    "training data and": 0.1,
    "data and produce": 0.5,
    "and produce the": 0.5,
    "produce the tagset": 0.3333333333333333,
    "the tagset by": 1.0,
    "tagset by induction": 1.0,
    "by induction .": 1.0,
    "<s> that is": 1.0,
    "that is ,": 0.2631578947368421,
    "is , they": 0.3333333333333333,
    ", they observe": 0.125,
    "they observe patterns": 1.0,
    "observe patterns in": 1.0,
    "patterns in word": 1.0,
    "in word use": 1.0,
    "word use ,": 1.0,
    ", and derive": 0.005291005291005291,
    "and derive part-of-speech": 1.0,
    "derive part-of-speech categories": 1.0,
    "part-of-speech categories themselves": 1.0,
    "categories themselves .": 1.0,
    "example , statistics": 0.018518518518518517,
    ", statistics readily": 0.5,
    "statistics readily reveal": 1.0,
    "readily reveal that": 1.0,
    "reveal that ``": 1.0,
    "that `` the": 0.16666666666666666,
    "`` the ''": 0.125,
    "the '' ,": 1.0,
    ", `` a": 0.04,
    "`` a ''": 0.5,
    "a '' ,": 1.0,
    "and `` an": 0.05,
    "`` an ''": 1.0,
    "an '' occur": 1.0,
    "'' occur in": 1.0,
    "occur in similar": 0.5,
    "in similar contexts": 1.0,
    "similar contexts ,": 1.0,
    "contexts , while": 0.5,
    ", while ``": 0.07142857142857142,
    "while `` eat": 1.0,
    "`` eat ''": 1.0,
    "eat '' occurs": 1.0,
    "'' occurs in": 1.0,
    "occurs in very": 0.3333333333333333,
    "in very different": 0.3333333333333333,
    "very different ones": 0.3333333333333333,
    "different ones .": 1.0,
    "<s> with sufficient": 0.2,
    "with sufficient iteration": 1.0,
    "sufficient iteration ,": 1.0,
    "iteration , similarity": 1.0,
    ", similarity classes": 1.0,
    "similarity classes of": 1.0,
    "classes of words": 0.5,
    "of words emerge": 0.06666666666666667,
    "words emerge that": 1.0,
    "emerge that are": 1.0,
    "that are remarkably": 0.06666666666666667,
    "are remarkably similar": 1.0,
    "remarkably similar to": 1.0,
    "similar to those": 0.13333333333333333,
    "to those human": 0.5,
    "those human linguists": 1.0,
    "human linguists would": 1.0,
    "linguists would expect": 1.0,
    "would expect ;": 1.0,
    "expect ; and": 1.0,
    "; and the": 0.25,
    "and the differences": 0.024390243902439025,
    "the differences themselves": 1.0,
    "differences themselves sometimes": 1.0,
    "themselves sometimes suggest": 1.0,
    "sometimes suggest valuable": 1.0,
    "suggest valuable new": 1.0,
    "valuable new insights": 1.0,
    "new insights .": 1.0,
    "<s> these two": 0.0625,
    "these two categories": 0.5,
    "two categories can": 1.0,
    "categories can be": 1.0,
    "can be further": 0.01098901098901099,
    "be further subdivided": 1.0,
    "further subdivided into": 1.0,
    "subdivided into rule-based": 1.0,
    "into rule-based ,": 1.0,
    "rule-based , stochastic": 1.0,
    ", stochastic ,": 1.0,
    "stochastic , and": 0.5,
    ", and neural": 0.010582010582010581,
    "and neural approaches": 0.5,
    "neural approaches .": 1.0,
    "<s> other taggers": 0.14285714285714285,
    "other taggers and": 1.0,
    "taggers and methods": 0.5,
    "and methods some": 1.0,
    "methods some current": 1.0,
    "some current major": 0.5,
    "current major algorithms": 1.0,
    "major algorithms for": 1.0,
    "algorithms for part-of-speech": 0.25,
    "for part-of-speech tagging": 0.5,
    "part-of-speech tagging include": 0.1111111111111111,
    "tagging include the": 1.0,
    "include the viterbi": 0.2,
    "viterbi algorithm ,": 0.25,
    "algorithm , brill": 0.3333333333333333,
    ", brill tagger": 1.0,
    "brill tagger ,": 0.5,
    "tagger , constraint": 0.2,
    ", constraint grammar": 1.0,
    "constraint grammar ,": 1.0,
    "grammar , and": 0.4,
    "and the baum-welch": 0.024390243902439025,
    "the baum-welch algorithm": 1.0,
    "baum-welch algorithm -lrb-": 1.0,
    "algorithm -lrb- also": 1.0,
    "known as the": 0.1,
    "as the forward-backward": 0.03571428571428571,
    "the forward-backward algorithm": 1.0,
    "forward-backward algorithm -rrb-": 1.0,
    "algorithm -rrb- .": 0.5,
    "<s> hidden markov": 1.0,
    "hidden markov model": 0.46153846153846156,
    "markov model and": 0.125,
    "model and visible": 1.0,
    "and visible markov": 1.0,
    "visible markov model": 1.0,
    "markov model taggers": 0.125,
    "model taggers can": 1.0,
    "taggers can both": 1.0,
    "can both be": 1.0,
    "both be implemented": 1.0,
    "be implemented using": 0.5,
    "implemented using the": 1.0,
    "using the viterbi": 0.14285714285714285,
    "viterbi algorithm .": 0.25,
    "<s> the brill": 0.006802721088435374,
    "the brill tagger": 1.0,
    "brill tagger is": 0.5,
    "tagger is unusual": 1.0,
    "is unusual in": 1.0,
    "unusual in that": 1.0,
    "in that it": 0.5,
    "that it learns": 0.3333333333333333,
    "it learns a": 1.0,
    "learns a set": 1.0,
    "set of patterns": 0.03571428571428571,
    "of patterns ,": 1.0,
    "patterns , and": 1.0,
    "and then applies": 0.14285714285714285,
    "then applies those": 1.0,
    "applies those patterns": 1.0,
    "those patterns rather": 1.0,
    "patterns rather than": 1.0,
    "rather than optimizing": 0.07142857142857142,
    "than optimizing a": 1.0,
    "optimizing a statistical": 1.0,
    "a statistical quantity": 0.3333333333333333,
    "statistical quantity .": 1.0,
    "<s> many machine": 0.09090909090909091,
    "many machine learning": 1.0,
    "machine learning methods": 0.047619047619047616,
    "learning methods have": 1.0,
    "methods have also": 0.5,
    "have also been": 1.0,
    "to the problem": 0.012987012987012988,
    "problem of pos": 0.125,
    "of pos tagging": 0.5,
    "pos tagging .": 0.2,
    "<s> methods such": 0.3333333333333333,
    "methods such as": 1.0,
    "such as svm": 0.011111111111111112,
    "as svm ,": 1.0,
    "svm , maximum": 1.0,
    ", maximum entropy": 1.0,
    "maximum entropy classifier": 0.2,
    "entropy classifier ,": 1.0,
    "classifier , perceptron": 1.0,
    ", perceptron ,": 1.0,
    "perceptron , and": 1.0,
    ", and nearest-neighbor": 0.005291005291005291,
    "and nearest-neighbor have": 1.0,
    "nearest-neighbor have all": 1.0,
    "have all been": 1.0,
    "all been tried": 1.0,
    "been tried ,": 0.5,
    "tried , and": 1.0,
    ", and most": 0.005291005291005291,
    "and most can": 1.0,
    "most can achieve": 1.0,
    "can achieve accuracy": 1.0,
    "achieve accuracy above": 1.0,
    "accuracy above 95": 1.0,
    "above 95 %": 1.0,
    "<s> a direct": 0.022727272727272728,
    "a direct comparison": 1.0,
    "direct comparison of": 1.0,
    "comparison of several": 1.0,
    "of several methods": 0.3333333333333333,
    "several methods is": 1.0,
    "methods is reported": 1.0,
    "is reported -lrb-": 1.0,
    "reported -lrb- with": 1.0,
    "-lrb- with references": 0.3333333333333333,
    "with references -rrb-": 1.0,
    "references -rrb- at": 0.5,
    "-rrb- at .": 1.0,
    "<s> this comparison": 0.019230769230769232,
    "this comparison uses": 1.0,
    "comparison uses the": 1.0,
    "uses the penn": 1.0,
    "the penn tag": 0.25,
    "penn tag set": 1.0,
    "tag set on": 0.2,
    "set on some": 1.0,
    "on some of": 0.1111111111111111,
    "of the penn": 0.005128205128205128,
    "penn treebank data": 0.16666666666666666,
    "treebank data ,": 1.0,
    "data , so": 0.1,
    "so the results": 0.14285714285714285,
    "the results are": 0.2,
    "results are directly": 0.25,
    "are directly comparable": 1.0,
    "directly comparable .": 1.0,
    "however , many": 0.022727272727272728,
    ", many significant": 0.14285714285714285,
    "many significant taggers": 1.0,
    "significant taggers are": 1.0,
    "taggers are not": 1.0,
    "are not included": 0.2,
    "not included -lrb-": 1.0,
    "included -lrb- perhaps": 1.0,
    "-lrb- perhaps because": 1.0,
    "perhaps because of": 1.0,
    "of the labor": 0.005128205128205128,
    "the labor involved": 1.0,
    "labor involved in": 1.0,
    "involved in reconfiguring": 1.0,
    "in reconfiguring them": 1.0,
    "reconfiguring them for": 1.0,
    "them for this": 1.0,
    "for this particular": 0.125,
    "this particular dataset": 1.0,
    "particular dataset -rrb-": 1.0,
    "dataset -rrb- .": 1.0,
    "thus , it": 0.18181818181818182,
    ", it should": 0.041666666666666664,
    "it should not": 1.0,
    "should not be": 1.0,
    "not be assumed": 0.08333333333333333,
    "be assumed that": 1.0,
    "assumed that the": 1.0,
    "that the results": 0.043478260869565216,
    "the results reported": 0.2,
    "results reported there": 1.0,
    "reported there are": 1.0,
    "there are the": 0.047619047619047616,
    "are the best": 0.09090909090909091,
    "the best that": 0.14285714285714285,
    "best that can": 0.5,
    "be achieved with": 0.2,
    "achieved with a": 1.0,
    "with a given": 0.1,
    "a given approach": 0.16666666666666666,
    "given approach ;": 0.5,
    "approach ; nor": 1.0,
    "; nor even": 1.0,
    "nor even the": 1.0,
    "even the best": 0.5,
    "best that have": 0.5,
    "have been achieved": 0.07692307692307693,
    "been achieved with": 0.5,
    "given approach .": 0.5,
    "<s> issues while": 0.5,
    "issues while there": 1.0,
    "while there is": 1.0,
    "there is broad": 0.058823529411764705,
    "is broad agreement": 1.0,
    "broad agreement about": 1.0,
    "agreement about basic": 1.0,
    "about basic categories": 1.0,
    "basic categories ,": 1.0,
    "categories , a": 1.0,
    "number of edge": 0.027777777777777776,
    "of edge cases": 1.0,
    "edge cases make": 1.0,
    "cases make it": 1.0,
    "make it difficult": 0.5,
    "it difficult to": 0.5,
    "difficult to settle": 0.09090909090909091,
    "to settle on": 1.0,
    "settle on a": 1.0,
    "a single ``": 0.1111111111111111,
    "single `` correct": 1.0,
    "`` correct ''": 1.0,
    "correct '' set": 1.0,
    "'' set of": 1.0,
    "set of tags": 0.03571428571428571,
    "of tags ,": 1.0,
    "tags , even": 0.5,
    ", even in": 0.14285714285714285,
    "even in a": 0.5,
    "in a single": 0.019230769230769232,
    "a single language": 0.1111111111111111,
    "single language such": 1.0,
    "language such as": 1.0,
    "as english .": 0.3333333333333333,
    "example , it": 0.018518518518518517,
    "it is hard": 0.02127659574468085,
    "is hard to": 1.0,
    "hard to say": 0.3333333333333333,
    "to say whether": 0.3333333333333333,
    "say whether ``": 1.0,
    "whether `` fire": 1.0,
    "`` fire ''": 1.0,
    "fire '' is": 1.0,
    "'' is functioning": 0.1111111111111111,
    "is functioning as": 1.0,
    "functioning as an": 1.0,
    "as an adjective": 0.2,
    "a noun in": 0.16666666666666666,
    "noun in the": 1.0,
    "in the big": 0.006535947712418301,
    "the big green": 1.0,
    "big green fire": 1.0,
    "green fire truck": 1.0,
    "fire truck a": 1.0,
    "truck a second": 1.0,
    "a second important": 0.25,
    "second important example": 1.0,
    "important example is": 1.0,
    "example is the": 1.0,
    "is the use\\/mention": 0.022222222222222223,
    "the use\\/mention distinction": 1.0,
    "use\\/mention distinction ,": 1.0,
    "distinction , as": 1.0,
    ", as in": 0.043478260869565216,
    "the following example": 0.18181818181818182,
    "following example ,": 0.5,
    "example , where": 0.018518518518518517,
    ", where ``": 0.06666666666666667,
    "where `` blue": 1.0,
    "`` blue ''": 1.0,
    "blue '' is": 0.5,
    "'' is clearly": 0.1111111111111111,
    "is clearly not": 0.5,
    "clearly not functioning": 1.0,
    "not functioning as": 1.0,
    "an adjective -lrb-": 0.2,
    "adjective -lrb- the": 1.0,
    "brown corpus tag": 0.08333333333333333,
    "corpus tag set": 0.5,
    "tag set appends": 0.2,
    "set appends the": 1.0,
    "appends the suffix": 1.0,
    "the suffix ''": 1.0,
    "suffix '' -": 1.0,
    "'' - nc": 0.5,
    "- nc ''": 1.0,
    "nc '' in": 1.0,
    "'' in such": 0.14285714285714285,
    "in such cases": 0.5,
    "such cases -rrb-": 0.5,
    "cases -rrb- :": 1.0,
    "-rrb- : the": 0.1111111111111111,
    ": the word": 0.16666666666666666,
    "the word ``": 0.125,
    "word `` blue": 1.0,
    "blue '' has": 0.5,
    "'' has 4": 0.5,
    "has 4 letters": 1.0,
    "4 letters .": 1.0,
    "<s> words in": 0.5,
    "in a language": 0.019230769230769232,
    "a language other": 0.16666666666666666,
    "language other than": 1.0,
    "other than that": 1.0,
    "that of the": 0.125,
    "of the ``": 0.005128205128205128,
    "the `` main": 0.14285714285714285,
    "`` main ''": 1.0,
    "main '' text": 1.0,
    "'' text ,": 1.0,
    "text , are": 0.03333333333333333,
    ", are commonly": 0.5,
    "are commonly tagged": 1.0,
    "commonly tagged as": 1.0,
    "tagged as ``": 1.0,
    "as `` foreign": 0.07142857142857142,
    "`` foreign ''": 1.0,
    "foreign '' ,": 1.0,
    "'' , usually": 0.03333333333333333,
    ", usually in": 0.2,
    "usually in addition": 0.3333333333333333,
    "addition to a": 0.3333333333333333,
    "to a tag": 0.03571428571428571,
    "a tag for": 1.0,
    "tag for the": 1.0,
    "for the role": 0.03125,
    "the role the": 0.5,
    "role the foreign": 1.0,
    "the foreign word": 1.0,
    "foreign word is": 1.0,
    "word is actually": 0.25,
    "is actually playing": 0.5,
    "actually playing in": 1.0,
    "playing in context": 1.0,
    "there are also": 0.047619047619047616,
    "are also many": 0.125,
    "also many cases": 1.0,
    "many cases where": 0.5,
    "cases where pos": 0.3333333333333333,
    "where pos categories": 1.0,
    "pos categories and": 1.0,
    "categories and ``": 0.5,
    "and `` words": 0.05,
    "`` words ''": 1.0,
    "words '' do": 0.5,
    "'' do not": 1.0,
    "do not map": 0.07692307692307693,
    "not map one": 1.0,
    "map one to": 1.0,
    "one to one": 0.5,
    "to one ,": 0.5,
    "one , for": 0.25,
    "example : david": 0.5,
    ": david 's": 1.0,
    "david 's gonna": 1.0,
    "'s gonna do": 1.0,
    "gonna do n't": 1.0,
    "do n't vice": 0.5,
    "n't vice versa": 1.0,
    "vice versa first-cut": 1.0,
    "versa first-cut can": 1.0,
    "first-cut can not": 1.0,
    "can not pre": 0.06666666666666667,
    "not pre -": 1.0,
    "pre - and": 1.0,
    "- and post-secondary": 0.5,
    "and post-secondary look": 1.0,
    "post-secondary look -lrb-": 1.0,
    "look -lrb- a": 1.0,
    "-lrb- a word": 0.2,
    "a word -rrb-": 0.08333333333333333,
    "word -rrb- up": 1.0,
    "-rrb- up in": 1.0,
    "up in the": 0.3333333333333333,
    "in the last": 0.0196078431372549,
    "the last example": 0.3333333333333333,
    "last example ,": 1.0,
    ", `` look": 0.04,
    "`` look ''": 1.0,
    "look '' and": 1.0,
    "and `` up": 0.05,
    "`` up ''": 1.0,
    "up '' arguably": 1.0,
    "'' arguably function": 1.0,
    "arguably function as": 1.0,
    "function as a": 1.0,
    "as a single": 0.027777777777777776,
    "a single verbal": 0.1111111111111111,
    "single verbal unit": 1.0,
    "verbal unit ,": 1.0,
    "unit , despite": 1.0,
    ", despite the": 1.0,
    "despite the possibility": 0.5,
    "possibility of other": 0.3333333333333333,
    "of other words": 0.25,
    "other words coming": 0.5,
    "words coming between": 1.0,
    "coming between them": 1.0,
    "between them .": 0.5,
    "<s> some tag": 0.0625,
    "some tag sets": 1.0,
    "tag sets -lrb-": 0.25,
    "sets -lrb- such": 1.0,
    "such as penn": 0.011111111111111112,
    "as penn -rrb-": 1.0,
    "penn -rrb- break": 1.0,
    "-rrb- break hyphenated": 1.0,
    "break hyphenated words": 1.0,
    "hyphenated words ,": 1.0,
    "words , contractions": 0.0625,
    ", contractions ,": 1.0,
    "contractions , and": 1.0,
    ", and possessives": 0.005291005291005291,
    "and possessives into": 1.0,
    "possessives into separate": 1.0,
    "into separate tokens": 0.5,
    "separate tokens ,": 1.0,
    "tokens , thus": 1.0,
    ", thus avoiding": 0.5,
    "thus avoiding some": 1.0,
    "avoiding some but": 1.0,
    "some but far": 1.0,
    "but far from": 1.0,
    "far from all": 1.0,
    "from all such": 1.0,
    "all such problems": 1.0,
    "such problems .": 1.0,
    "it is unclear": 0.02127659574468085,
    "is unclear whether": 1.0,
    "unclear whether it": 1.0,
    "whether it is": 1.0,
    "it is best": 0.02127659574468085,
    "is best to": 1.0,
    "best to treat": 0.5,
    "to treat words": 1.0,
    "treat words such": 1.0,
    "as `` be": 0.07142857142857142,
    "`` be ''": 1.0,
    "be '' ,": 0.5,
    ", `` have": 0.04,
    "`` have ''": 1.0,
    "have '' ,": 1.0,
    "and `` do": 0.05,
    "`` do ''": 1.0,
    "do '' as": 1.0,
    "'' as categories": 0.2,
    "as categories in": 1.0,
    "categories in their": 1.0,
    "in their own": 0.25,
    "their own right": 1.0,
    "own right -lrb-": 1.0,
    "right -lrb- as": 1.0,
    ", or as": 0.030303030303030304,
    "or as simply": 0.5,
    "as simply verbs": 1.0,
    "simply verbs -lrb-": 1.0,
    "verbs -lrb- as": 1.0,
    "in the lob": 0.006535947712418301,
    "the lob corpus": 1.0,
    "lob corpus and": 0.5,
    "corpus and the": 0.3333333333333333,
    "and the penn": 0.024390243902439025,
    "penn treebank -rrb-": 0.16666666666666666,
    "treebank -rrb- .": 1.0,
    "<s> `` be": 0.2,
    "be '' has": 0.5,
    "'' has more": 0.5,
    "has more forms": 1.0,
    "more forms than": 1.0,
    "forms than other": 1.0,
    "than other english": 1.0,
    "other english verbs": 1.0,
    "english verbs ,": 1.0,
    "verbs , and": 0.3333333333333333,
    ", and occurs": 0.005291005291005291,
    "and occurs in": 1.0,
    "occurs in quite": 0.3333333333333333,
    "in quite different": 1.0,
    "quite different grammatical": 0.3333333333333333,
    "different grammatical contexts": 1.0,
    "grammatical contexts ,": 1.0,
    "contexts , complicating": 0.5,
    ", complicating the": 1.0,
    "complicating the issue": 1.0,
    "the issue .": 0.5,
    "most popular ``": 0.3333333333333333,
    "popular `` tag": 1.0,
    "`` tag set": 0.5,
    "tag set ''": 0.2,
    "set '' for": 0.5,
    "'' for pos": 1.0,
    "for pos tagging": 1.0,
    "pos tagging for": 0.2,
    "tagging for american": 1.0,
    "for american english": 1.0,
    "american english is": 1.0,
    "english is probably": 1.0,
    "is probably the": 1.0,
    "probably the penn": 1.0,
    "tag set ,": 0.4,
    "set , developed": 0.5,
    ", developed in": 1.0,
    "in the penn": 0.013071895424836602,
    "penn treebank project": 0.3333333333333333,
    "treebank project .": 0.5,
    "it is largely": 0.02127659574468085,
    "is largely similar": 1.0,
    "largely similar to": 1.0,
    "to the earlier": 0.012987012987012988,
    "the earlier brown": 1.0,
    "earlier brown corpus": 1.0,
    "brown corpus and": 0.08333333333333333,
    "corpus and lob": 0.3333333333333333,
    "and lob corpus": 1.0,
    "lob corpus tag": 0.5,
    "corpus tag sets": 0.5,
    "tag sets ,": 0.25,
    "sets , though": 1.0,
    ", though much": 0.16666666666666666,
    "though much smaller": 1.0,
    "much smaller .": 1.0,
    "europe , tag": 0.3333333333333333,
    ", tag sets": 1.0,
    "tag sets from": 0.25,
    "sets from the": 1.0,
    "from the eagles": 0.045454545454545456,
    "the eagles guidelines": 1.0,
    "eagles guidelines see": 1.0,
    "guidelines see wide": 1.0,
    "see wide use": 1.0,
    "wide use ,": 1.0,
    ", and include": 0.005291005291005291,
    "and include versions": 0.5,
    "include versions for": 1.0,
    "versions for multiple": 1.0,
    "for multiple languages": 1.0,
    "multiple languages .": 1.0,
    "<s> pos tagging": 1.0,
    "pos tagging work": 0.2,
    "tagging work has": 1.0,
    "done in a": 0.2,
    "variety of languages": 0.125,
    "of languages ,": 1.0,
    "languages , and": 0.18181818181818182,
    "and the set": 0.024390243902439025,
    "the set of": 1.0,
    "set of pos": 0.03571428571428571,
    "of pos tags": 0.5,
    "tags used varies": 0.5,
    "used varies greatly": 1.0,
    "varies greatly with": 0.5,
    "greatly with language": 1.0,
    "with language .": 1.0,
    "<s> tags usually": 1.0,
    "tags usually are": 1.0,
    "usually are designed": 1.0,
    "are designed to": 1.0,
    "designed to include": 0.2,
    "to include overt": 0.14285714285714285,
    "include overt morphological": 1.0,
    "overt morphological distinctions": 1.0,
    "morphological distinctions -lrb-": 1.0,
    "distinctions -lrb- this": 1.0,
    "-lrb- this makes": 1.0,
    "this makes the": 0.5,
    "makes the tag": 0.5,
    "the tag sets": 0.5,
    "tag sets for": 0.25,
    "sets for heavily": 1.0,
    "for heavily inflected": 1.0,
    "heavily inflected languages": 1.0,
    "inflected languages such": 0.5,
    "such as greek": 0.011111111111111112,
    "as greek and": 1.0,
    "greek and latin": 1.0,
    "and latin very": 1.0,
    "latin very large": 1.0,
    "very large ;": 1.0,
    "large ; and": 1.0,
    "; and makes": 0.25,
    "and makes tagging": 1.0,
    "makes tagging words": 1.0,
    "tagging words in": 1.0,
    "words in agglutinative": 0.09090909090909091,
    "in agglutinative languages": 1.0,
    "agglutinative languages such": 1.0,
    "languages such an": 0.2,
    "such an inuit": 0.5,
    "an inuit virtually": 1.0,
    "inuit virtually impossible": 1.0,
    "virtually impossible .": 1.0,
    "however , petrov": 0.022727272727272728,
    ", petrov ,": 1.0,
    "petrov , d.": 1.0,
    ", d. das": 1.0,
    "d. das ,": 1.0,
    "das , and": 1.0,
    ", and r.": 0.005291005291005291,
    "and r. mcdonald": 1.0,
    "r. mcdonald -lrb-": 1.0,
    "mcdonald -lrb- ``": 1.0,
    "-lrb- `` a": 0.125,
    "`` a universal": 0.5,
    "a universal part-of-speech": 0.5,
    "universal part-of-speech tagset": 1.0,
    "part-of-speech tagset ''": 1.0,
    "tagset '' http:\\/\\/arxiv.org\\/abs\\/1104.2086": 1.0,
    "'' http:\\/\\/arxiv.org\\/abs\\/1104.2086 -rrb-": 1.0,
    "http:\\/\\/arxiv.org\\/abs\\/1104.2086 -rrb- have": 1.0,
    "-rrb- have proposed": 0.5,
    "have proposed a": 1.0,
    "proposed a ``": 0.5,
    "`` universal ''": 0.5,
    "universal '' tag": 1.0,
    "'' tag set": 1.0,
    "set , with": 0.5,
    ", with 12": 0.125,
    "with 12 categories": 1.0,
    "12 categories -lrb-": 1.0,
    "categories -lrb- for": 1.0,
    "example , no": 0.018518518518518517,
    ", no subtypes": 0.3333333333333333,
    "no subtypes of": 1.0,
    "subtypes of nouns": 1.0,
    "of nouns ,": 1.0,
    "verbs , punctuation": 0.3333333333333333,
    ", punctuation ,": 1.0,
    "punctuation , etc.": 0.5,
    ", etc. ;": 0.05,
    "etc. ; no": 1.0,
    "; no distinction": 1.0,
    "no distinction of": 1.0,
    "distinction of ``": 1.0,
    "of `` to": 0.125,
    "`` to ''": 0.5,
    "to '' as": 0.5,
    "'' as an": 0.2,
    "as an infinitive": 0.06666666666666667,
    "an infinitive marker": 1.0,
    "infinitive marker vs.": 1.0,
    "marker vs. preposition": 1.0,
    "vs. preposition ,": 1.0,
    "preposition , etc.": 0.3333333333333333,
    "<s> whether a": 0.5,
    "whether a very": 0.3333333333333333,
    "a very small": 0.08333333333333333,
    "very small set": 0.5,
    "small set of": 1.0,
    "set of very": 0.03571428571428571,
    "of very broad": 0.5,
    "very broad tags": 0.5,
    "broad tags ,": 1.0,
    "tags , or": 0.5,
    ", or a": 0.06060606060606061,
    "or a much": 0.05263157894736842,
    "much larger set": 0.5,
    "larger set of": 1.0,
    "set of more": 0.07142857142857142,
    "of more precise": 0.25,
    "more precise ones": 1.0,
    "precise ones ,": 1.0,
    "ones , is": 0.3333333333333333,
    ", is preferable": 0.07692307692307693,
    "is preferable ,": 1.0,
    "preferable , depends": 1.0,
    ", depends on": 1.0,
    "on the purpose": 0.014925373134328358,
    "the purpose at": 0.5,
    "purpose at hand": 1.0,
    "at hand .": 1.0,
    "<s> automatic tagging": 0.14285714285714285,
    "automatic tagging is": 1.0,
    "tagging is easier": 0.5,
    "is easier on": 0.5,
    "easier on smaller": 1.0,
    "on smaller tag-sets": 1.0,
    "smaller tag-sets .": 1.0,
    "<s> a different": 0.045454545454545456,
    "a different issue": 0.2,
    "different issue is": 1.0,
    "issue is that": 1.0,
    "is that some": 0.08333333333333333,
    "that some cases": 0.25,
    "some cases are": 0.25,
    "cases are in": 1.0,
    "are in fact": 0.3333333333333333,
    "in fact ambiguous": 0.2,
    "fact ambiguous .": 1.0,
    "<s> beatrice santorini": 1.0,
    "beatrice santorini gives": 1.0,
    "santorini gives examples": 1.0,
    "gives examples in": 1.0,
    "examples in ``": 1.0,
    "in `` part-of-speech": 0.3333333333333333,
    "`` part-of-speech tagging": 1.0,
    "part-of-speech tagging guidelines": 0.1111111111111111,
    "tagging guidelines for": 1.0,
    "guidelines for the": 1.0,
    "for the penn": 0.03125,
    "treebank project ,": 0.5,
    "project , ''": 0.16666666666666666,
    ", '' -lrb-": 0.3333333333333333,
    "'' -lrb- 3rd": 0.1111111111111111,
    "-lrb- 3rd rev": 1.0,
    "3rd rev ,": 1.0,
    "rev , june": 1.0,
    ", june 1990": 1.0,
    "june 1990 -rrb-": 1.0,
    "1990 -rrb- ,": 0.5,
    "-rrb- , including": 0.01282051282051282,
    ", including the": 0.125,
    "including the following": 1.0,
    "the following -lrb-": 0.09090909090909091,
    "following -lrb- p.": 1.0,
    "-lrb- p. 32": 1.0,
    "p. 32 -rrb-": 1.0,
    "32 -rrb- case": 1.0,
    "-rrb- case in": 1.0,
    "case in which": 1.0,
    "in which entertaining": 0.125,
    "which entertaining can": 1.0,
    "entertaining can function": 1.0,
    "can function either": 1.0,
    "function either as": 1.0,
    "or a verb": 0.05263157894736842,
    "and there is": 0.25,
    "there is no": 0.058823529411764705,
    "is no evident": 1.0,
    "no evident way": 1.0,
    "evident way to": 1.0,
    "way to decide": 0.1,
    "to decide :": 0.5,
    "decide : the": 1.0,
    ": the duchess": 0.16666666666666666,
    "the duchess was": 1.0,
    "duchess was entertaining": 1.0,
    "was entertaining last": 1.0,
    "entertaining last night": 1.0,
    "last night .": 1.0,
    "<s> in computer": 0.010309278350515464,
    "in computer science": 1.0,
    "computer science and": 0.2,
    "science and linguistics": 1.0,
    "and linguistics ,": 0.5,
    "linguistics , parsing": 0.125,
    ", parsing ,": 0.3333333333333333,
    "parsing , or": 0.5,
    ", or ,": 0.030303030303030304,
    "or , more": 1.0,
    ", more formally": 0.25,
    "more formally ,": 1.0,
    "formally , syntactic": 1.0,
    ", syntactic analysis": 0.3333333333333333,
    "syntactic analysis ,": 1.0,
    "analysis , is": 0.14285714285714285,
    "process of analyzing": 0.08333333333333333,
    "of analyzing a": 1.0,
    "analyzing a text": 1.0,
    ", made of": 0.5,
    "made of a": 0.3333333333333333,
    "of a sequence": 0.010869565217391304,
    "a sequence of": 1.0,
    "sequence of tokens": 0.14285714285714285,
    "of tokens -lrb-": 0.5,
    "tokens -lrb- for": 1.0,
    "example , words": 0.018518518518518517,
    ", words -rrb-": 0.3333333333333333,
    "words -rrb- ,": 0.3333333333333333,
    "-rrb- , to": 0.01282051282051282,
    ", to determine": 0.15384615384615385,
    "to determine its": 0.09090909090909091,
    "determine its grammatical": 0.5,
    "its grammatical structure": 1.0,
    "grammatical structure with": 1.0,
    "structure with respect": 1.0,
    "a given -lrb-": 0.08333333333333333,
    "given -lrb- more": 1.0,
    "-lrb- more or": 0.5,
    "or less -rrb-": 0.25,
    "less -rrb- formal": 1.0,
    "-rrb- formal grammar": 1.0,
    "formal grammar .": 0.5,
    "<s> parsing can": 0.25,
    "parsing can also": 0.3333333333333333,
    "also be used": 0.2857142857142857,
    "as a linguistic": 0.027777777777777776,
    "a linguistic term": 0.5,
    "linguistic term ,": 1.0,
    "term , for": 1.0,
    "for instance when": 0.08333333333333333,
    "instance when discussing": 1.0,
    "when discussing how": 0.5,
    "discussing how phrases": 1.0,
    "how phrases are": 1.0,
    "phrases are divided": 1.0,
    "are divided up": 1.0,
    "divided up in": 1.0,
    "up in garden": 0.3333333333333333,
    "in garden path": 1.0,
    "garden path sentences": 1.0,
    "path sentences .": 1.0,
    "<s> parsing is": 0.5,
    "parsing is also": 0.5,
    "is also an": 0.1,
    "also an earlier": 1.0,
    "an earlier term": 1.0,
    "earlier term for": 1.0,
    "term for the": 0.3333333333333333,
    "for the diagramming": 0.0625,
    "the diagramming of": 1.0,
    "diagramming of sentences": 0.5,
    "of sentences of": 0.14285714285714285,
    "sentences of natural": 0.5,
    "natural languages ,": 0.2222222222222222,
    "and is still": 0.16666666666666666,
    "is still used": 0.25,
    "still used for": 1.0,
    "used for the": 0.06666666666666667,
    "diagramming of inflected": 0.5,
    "of inflected languages": 1.0,
    "inflected languages ,": 0.5,
    "languages , such": 0.09090909090909091,
    "as the romance": 0.03571428571428571,
    "the romance languages": 1.0,
    "romance languages or": 1.0,
    "languages or latin": 1.0,
    "or latin .": 1.0,
    "<s> the term": 0.027210884353741496,
    "the term parsing": 0.1111111111111111,
    "term parsing comes": 1.0,
    "parsing comes from": 1.0,
    "comes from latin": 0.5,
    "from latin pars": 1.0,
    "latin pars -lrb-": 1.0,
    "pars -lrb- \u014dr\u0101ti\u014dnis": 1.0,
    "-lrb- \u014dr\u0101ti\u014dnis -rrb-": 1.0,
    "\u014dr\u0101ti\u014dnis -rrb- ,": 1.0,
    "-rrb- , meaning": 0.01282051282051282,
    ", meaning part": 1.0,
    "meaning part -lrb-": 1.0,
    "part -lrb- of": 1.0,
    "-lrb- of speech": 0.5,
    "parsing is a": 0.5,
    "is a common": 0.037037037037037035,
    "a common term": 0.5,
    "common term used": 1.0,
    "term used in": 0.5,
    "used in psycholinguistics": 0.043478260869565216,
    "in psycholinguistics when": 1.0,
    "psycholinguistics when describing": 1.0,
    "when describing language": 0.5,
    "describing language comprehension": 1.0,
    "language comprehension .": 1.0,
    "context , parsing": 0.25,
    ", parsing refers": 0.3333333333333333,
    "parsing refers to": 1.0,
    "refers to the": 0.6,
    "to the way": 0.012987012987012988,
    "the way that": 0.25,
    "way that human": 0.3333333333333333,
    "that human beings": 0.5,
    "human beings ,": 1.0,
    "beings , rather": 1.0,
    ", rather than": 1.0,
    "rather than computers": 0.07142857142857142,
    "than computers ,": 1.0,
    "computers , analyze": 0.5,
    ", analyze a": 1.0,
    "analyze a sentence": 1.0,
    "sentence or phrase": 0.5,
    "or phrase -lrb-": 1.0,
    "phrase -lrb- in": 1.0,
    "-lrb- in spoken": 0.5,
    "in spoken language": 0.5,
    "spoken language or": 0.3333333333333333,
    "language or text": 0.5,
    "or text -rrb-": 0.5,
    "text -rrb- ``": 1.0,
    "-rrb- `` in": 1.0,
    "`` in terms": 0.5,
    "terms of grammatical": 0.14285714285714285,
    "of grammatical constituents": 1.0,
    "grammatical constituents ,": 1.0,
    "constituents , identifying": 1.0,
    ", identifying the": 0.6666666666666666,
    "identifying the parts": 0.25,
    "the parts of": 1.0,
    "speech , syntactic": 0.09090909090909091,
    ", syntactic relations": 0.3333333333333333,
    "syntactic relations ,": 1.0,
    "relations , etc.": 0.5,
    ", etc. ''": 0.05,
    "etc. '' this": 1.0,
    "'' this term": 1.0,
    "this term is": 1.0,
    "term is especially": 1.0,
    "is especially common": 0.5,
    "especially common when": 0.5,
    "common when discussing": 1.0,
    "when discussing what": 0.5,
    "discussing what linguistic": 1.0,
    "what linguistic cues": 1.0,
    "linguistic cues help": 1.0,
    "cues help speakers": 1.0,
    "help speakers to": 1.0,
    "speakers to parse": 1.0,
    "to parse garden-path": 0.25,
    "parse garden-path sentences": 1.0,
    "garden-path sentences .": 1.0,
    "<s> the parser": 0.006802721088435374,
    "the parser often": 0.2,
    "parser often uses": 1.0,
    "often uses a": 1.0,
    "uses a separate": 0.25,
    "a separate lexical": 0.5,
    "separate lexical analyser": 1.0,
    "lexical analyser to": 1.0,
    "analyser to create": 1.0,
    "to create tokens": 0.1111111111111111,
    "create tokens from": 1.0,
    "tokens from the": 1.0,
    "from the sequence": 0.045454545454545456,
    "the sequence of": 1.0,
    "sequence of input": 0.14285714285714285,
    "of input characters": 0.3333333333333333,
    "input characters .": 1.0,
    "<s> parsers may": 0.5,
    "parsers may be": 1.0,
    "may be programmed": 0.047619047619047616,
    "be programmed by": 0.5,
    "programmed by hand": 1.0,
    "by hand or": 0.3333333333333333,
    "hand or may": 0.5,
    "or may be": 0.5,
    "may be -lrb-": 0.047619047619047616,
    "be -lrb- semi": 1.0,
    "-lrb- semi -": 1.0,
    "semi - -rrb-": 1.0,
    "- -rrb- automatically": 1.0,
    "-rrb- automatically generated": 1.0,
    "automatically generated -lrb-": 0.3333333333333333,
    "generated -lrb- in": 1.0,
    "-lrb- in some": 0.5,
    "in some programming": 0.125,
    "some programming languages": 1.0,
    "programming languages -rrb-": 0.2,
    "languages -rrb- by": 0.5,
    "-rrb- by a": 1.0,
    "by a tool": 0.05555555555555555,
    "a tool .": 0.5,
    "<s> human languages": 0.25,
    "human languages see": 0.5,
    "languages see also": 1.0,
    "also : category": 0.5,
    ": category :": 1.0,
    "category : natural": 1.0,
    ": natural language": 1.0,
    "language parsing in": 0.5,
    "parsing in some": 1.0,
    "in some machine": 0.125,
    "some machine translation": 1.0,
    "translation and natural": 0.3333333333333333,
    "processing systems ,": 0.3333333333333333,
    "systems , human": 0.16666666666666666,
    ", human languages": 0.16666666666666666,
    "human languages are": 0.5,
    "languages are parsed": 1.0,
    "are parsed by": 1.0,
    "parsed by computer": 0.3333333333333333,
    "by computer programs": 0.3333333333333333,
    "computer programs .": 0.5,
    "<s> human sentences": 0.25,
    "human sentences are": 1.0,
    "sentences are not": 0.14285714285714285,
    "are not easily": 0.2,
    "not easily parsed": 0.3333333333333333,
    "easily parsed by": 1.0,
    "parsed by programs": 0.3333333333333333,
    "by programs ,": 1.0,
    "programs , as": 0.5,
    ", as there": 0.043478260869565216,
    "as there is": 1.0,
    "there is substantial": 0.058823529411764705,
    "is substantial ambiguity": 1.0,
    "substantial ambiguity in": 1.0,
    "ambiguity in the": 1.0,
    "in the structure": 0.006535947712418301,
    "structure of human": 0.25,
    "of human language": 0.2,
    "human language ,": 0.3333333333333333,
    "language , whose": 0.14285714285714285,
    ", whose usage": 0.5,
    "whose usage is": 1.0,
    "usage is to": 1.0,
    "is to convey": 0.05263157894736842,
    "to convey meaning": 0.3333333333333333,
    "convey meaning -lrb-": 1.0,
    "meaning -lrb- or": 1.0,
    "-lrb- or semantics": 0.1,
    "or semantics -rrb-": 1.0,
    "semantics -rrb- amongst": 1.0,
    "-rrb- amongst a": 1.0,
    "amongst a potentially": 1.0,
    "a potentially unlimited": 1.0,
    "potentially unlimited range": 1.0,
    "unlimited range of": 1.0,
    "range of possibilities": 0.25,
    "of possibilities but": 1.0,
    "possibilities but only": 1.0,
    "but only some": 1.0,
    "which are germane": 0.08333333333333333,
    "are germane to": 1.0,
    "germane to the": 1.0,
    "to the particular": 0.012987012987012988,
    "the particular case": 0.5,
    "particular case .": 1.0,
    "<s> so an": 0.3333333333333333,
    "so an utterance": 1.0,
    "an utterance ``": 0.5,
    "utterance `` man": 1.0,
    "`` man bites": 0.5,
    "man bites dog": 1.0,
    "bites dog ''": 1.0,
    "dog '' versus": 1.0,
    "'' versus ``": 1.0,
    "versus `` dog": 1.0,
    "`` dog bites": 1.0,
    "dog bites man": 0.5,
    "bites man ''": 1.0,
    "man '' is": 1.0,
    "'' is definite": 0.1111111111111111,
    "is definite on": 1.0,
    "definite on one": 1.0,
    "on one detail": 0.5,
    "one detail but": 1.0,
    "detail but in": 1.0,
    "but in another": 0.5,
    "in another language": 0.5,
    "another language might": 0.3333333333333333,
    "language might appear": 1.0,
    "might appear as": 1.0,
    "appear as ``": 1.0,
    "as `` man": 0.07142857142857142,
    "`` man dog": 0.5,
    "man dog bites": 1.0,
    "dog bites ''": 0.5,
    "bites '' with": 1.0,
    "'' with a": 0.25,
    "with a reliance": 0.05,
    "a reliance on": 1.0,
    "reliance on the": 1.0,
    "on the larger": 0.014925373134328358,
    "the larger context": 1.0,
    "larger context to": 1.0,
    "context to distinguish": 1.0,
    "distinguish between those": 0.5,
    "between those two": 1.0,
    "those two possibilities": 1.0,
    "two possibilities ,": 1.0,
    "possibilities , if": 1.0,
    ", if indeed": 0.1,
    "if indeed that": 1.0,
    "indeed that difference": 1.0,
    "that difference was": 1.0,
    "difference was of": 1.0,
    "was of concern": 1.0,
    "of concern .": 1.0,
    "it is difficult": 0.0425531914893617,
    "is difficult to": 0.75,
    "difficult to prepare": 0.09090909090909091,
    "to prepare formal": 1.0,
    "prepare formal rules": 1.0,
    "formal rules to": 1.0,
    "rules to describe": 0.3333333333333333,
    "to describe informal": 0.5,
    "describe informal behavior": 1.0,
    "informal behavior even": 1.0,
    "behavior even though": 1.0,
    "even though it": 0.3333333333333333,
    "though it is": 0.5,
    "it is clear": 0.02127659574468085,
    "is clear that": 1.0,
    "clear that some": 1.0,
    "that some rules": 0.25,
    "some rules are": 1.0,
    "rules are being": 0.3333333333333333,
    "are being followed": 0.5,
    "being followed .": 1.0,
    "<s> in order": 0.020618556701030927,
    "order to parse": 0.125,
    "to parse natural": 0.25,
    "parse natural language": 1.0,
    "natural language data": 0.014492753623188406,
    "language data ,": 1.0,
    "data , researchers": 0.1,
    ", researchers must": 0.5,
    "researchers must first": 1.0,
    "must first agree": 1.0,
    "first agree on": 1.0,
    "agree on the": 1.0,
    "on the grammar": 0.029850746268656716,
    "the grammar to": 0.09090909090909091,
    "grammar to be": 1.0,
    "<s> the choice": 0.006802721088435374,
    "the choice of": 1.0,
    "choice of syntax": 0.5,
    "of syntax is": 0.5,
    "syntax is affected": 1.0,
    "is affected by": 1.0,
    "affected by both": 1.0,
    "by both linguistic": 1.0,
    "both linguistic and": 1.0,
    "linguistic and computational": 1.0,
    "and computational concerns": 1.0,
    "computational concerns ;": 1.0,
    "concerns ; for": 1.0,
    "; for instance": 0.5,
    "for instance some": 0.08333333333333333,
    "instance some parsing": 1.0,
    "some parsing systems": 1.0,
    "parsing systems use": 1.0,
    "systems use lexical": 0.3333333333333333,
    "use lexical functional": 0.5,
    "lexical functional grammar": 1.0,
    "functional grammar ,": 0.5,
    "grammar , but": 0.2,
    ", but in": 0.020833333333333332,
    "but in general": 0.5,
    "general , parsing": 0.16666666666666666,
    ", parsing for": 0.3333333333333333,
    "parsing for grammars": 1.0,
    "for grammars of": 1.0,
    "grammars of this": 1.0,
    "of this type": 0.09090909090909091,
    "this type is": 0.3333333333333333,
    "type is known": 0.5,
    "to be np-complete": 0.023255813953488372,
    "be np-complete .": 1.0,
    "<s> head-driven phrase": 1.0,
    "head-driven phrase structure": 1.0,
    "phrase structure grammar": 0.5,
    "structure grammar is": 1.0,
    "grammar is another": 0.5,
    "is another linguistic": 0.5,
    "another linguistic formalism": 1.0,
    "linguistic formalism which": 1.0,
    "formalism which has": 1.0,
    "has been popular": 0.03571428571428571,
    "been popular in": 1.0,
    "popular in the": 1.0,
    "in the parsing": 0.006535947712418301,
    "the parsing community": 0.5,
    "parsing community ,": 1.0,
    "community , but": 1.0,
    ", but other": 0.020833333333333332,
    "but other research": 1.0,
    "other research efforts": 1.0,
    "research efforts have": 1.0,
    "efforts have focused": 0.5,
    "have focused on": 1.0,
    "focused on less": 0.1,
    "on less complex": 1.0,
    "less complex formalisms": 1.0,
    "complex formalisms such": 1.0,
    "formalisms such as": 1.0,
    "as the one": 0.03571428571428571,
    "the one used": 1.0,
    "one used in": 1.0,
    "<s> shallow parsing": 0.5,
    "shallow parsing aims": 1.0,
    "parsing aims to": 1.0,
    "aims to find": 0.5,
    "to find only": 0.1111111111111111,
    "find only the": 1.0,
    "only the boundaries": 0.25,
    "the boundaries of": 0.3333333333333333,
    "boundaries of major": 1.0,
    "of major constituents": 1.0,
    "major constituents such": 1.0,
    "constituents such as": 1.0,
    "such as noun": 0.011111111111111112,
    "as noun phrases": 1.0,
    "noun phrases .": 1.0,
    "<s> another popular": 0.07692307692307693,
    "another popular strategy": 1.0,
    "popular strategy for": 1.0,
    "strategy for avoiding": 1.0,
    "for avoiding linguistic": 1.0,
    "avoiding linguistic controversy": 1.0,
    "linguistic controversy is": 1.0,
    "controversy is dependency": 1.0,
    "is dependency grammar": 1.0,
    "dependency grammar parsing": 1.0,
    "grammar parsing .": 1.0,
    "<s> most modern": 0.5,
    "most modern parsers": 1.0,
    "modern parsers are": 1.0,
    "parsers are at": 0.3333333333333333,
    "are at least": 0.5,
    "at least partly": 0.2,
    "least partly statistical": 1.0,
    "partly statistical ;": 1.0,
    "statistical ; that": 1.0,
    "; that is": 1.0,
    ", they rely": 0.125,
    "they rely on": 1.0,
    "rely on a": 0.16666666666666666,
    "on a corpus": 0.041666666666666664,
    "training data which": 0.1,
    "data which has": 1.0,
    "which has already": 0.14285714285714285,
    "has already been": 1.0,
    "already been annotated": 0.5,
    "been annotated -lrb-": 1.0,
    "annotated -lrb- parsed": 1.0,
    "-lrb- parsed by": 1.0,
    "parsed by hand": 0.3333333333333333,
    "by hand -rrb-": 0.16666666666666666,
    "hand -rrb- .": 1.0,
    "this approach allows": 0.25,
    "approach allows the": 1.0,
    "allows the system": 0.3333333333333333,
    "system to gather": 0.2,
    "to gather information": 1.0,
    "gather information about": 1.0,
    "information about the": 0.5,
    "about the frequency": 0.125,
    "the frequency with": 1.0,
    "frequency with which": 1.0,
    "with which various": 1.0,
    "which various constructions": 1.0,
    "various constructions occur": 1.0,
    "constructions occur in": 1.0,
    "occur in specific": 0.5,
    "in specific contexts": 0.5,
    "specific contexts .": 1.0,
    "<s> -lrb- see": 0.15789473684210525,
    "-lrb- see machine": 0.0625,
    "see machine learning": 1.0,
    "learning . -rrb-": 1.0,
    "<s> approaches which": 0.3333333333333333,
    "approaches which have": 1.0,
    "which have been": 0.5,
    "been used include": 0.2,
    "used include straightforward": 1.0,
    "include straightforward pcfgs": 1.0,
    "straightforward pcfgs -lrb-": 1.0,
    "pcfgs -lrb- probabilistic": 1.0,
    "-lrb- probabilistic context-free": 1.0,
    "probabilistic context-free grammars": 1.0,
    "context-free grammars -rrb-": 0.2,
    "grammars -rrb- ,": 0.5,
    "-rrb- , maximum": 0.01282051282051282,
    "maximum entropy ,": 0.2,
    "entropy , and": 1.0,
    "and neural nets": 0.5,
    "neural nets .": 1.0,
    "<s> most of": 0.5,
    "of the more": 0.005128205128205128,
    "the more successful": 0.3333333333333333,
    "more successful systems": 0.3333333333333333,
    "successful systems use": 1.0,
    "use lexical statistics": 0.5,
    "lexical statistics -lrb-": 1.0,
    "statistics -lrb- that": 1.0,
    "-lrb- that is": 1.0,
    ", they consider": 0.125,
    "they consider the": 1.0,
    "consider the identities": 0.25,
    "the identities of": 1.0,
    "identities of the": 1.0,
    "the words involved": 0.16666666666666666,
    "words involved ,": 1.0,
    "involved , as": 1.0,
    "well as their": 0.07692307692307693,
    "as their part": 0.5,
    "their part of": 1.0,
    "<s> however such": 0.02702702702702703,
    "however such systems": 1.0,
    "such systems are": 0.5,
    "systems are vulnerable": 0.07692307692307693,
    "are vulnerable to": 1.0,
    "vulnerable to overfitting": 1.0,
    "to overfitting and": 1.0,
    "overfitting and require": 1.0,
    "and require some": 0.3333333333333333,
    "require some kind": 1.0,
    "kind of smoothing": 0.125,
    "of smoothing to": 1.0,
    "smoothing to be": 1.0,
    "to be effective": 0.023255813953488372,
    "be effective .": 0.5,
    "needed -rrb- parsing": 0.07692307692307693,
    "-rrb- parsing algorithms": 1.0,
    "parsing algorithms for": 1.0,
    "algorithms for natural": 0.25,
    "natural language can": 0.014492753623188406,
    "language can not": 1.0,
    "can not rely": 0.06666666666666667,
    "rely on the": 0.16666666666666666,
    "the grammar having": 0.09090909090909091,
    "grammar having `": 1.0,
    "having ` nice": 1.0,
    "` nice '": 1.0,
    "nice ' properties": 1.0,
    "' properties as": 1.0,
    "properties as with": 1.0,
    "as with manually": 0.3333333333333333,
    "with manually designed": 1.0,
    "manually designed grammars": 1.0,
    "designed grammars for": 1.0,
    "grammars for programming": 1.0,
    "for programming languages": 1.0,
    "programming languages .": 0.2,
    "<s> as mentioned": 0.07142857142857142,
    "as mentioned earlier": 0.5,
    "mentioned earlier some": 0.5,
    "earlier some grammar": 1.0,
    "some grammar formalisms": 1.0,
    "grammar formalisms are": 1.0,
    "formalisms are very": 1.0,
    "are very difficult": 0.25,
    "very difficult to": 0.5,
    "difficult to parse": 0.09090909090909091,
    "to parse computationally": 0.25,
    "parse computationally ;": 1.0,
    "computationally ; in": 1.0,
    "; in general": 1.0,
    "general , even": 0.16666666666666666,
    ", even if": 0.2857142857142857,
    "even if the": 0.3333333333333333,
    "if the desired": 0.07142857142857142,
    "the desired structure": 0.25,
    "desired structure is": 1.0,
    "structure is not": 1.0,
    "is not context-free": 0.05263157894736842,
    "not context-free ,": 1.0,
    "context-free , some": 1.0,
    ", some kind": 0.1111111111111111,
    "kind of context-free": 0.125,
    "of context-free approximation": 1.0,
    "context-free approximation to": 1.0,
    "to the grammar": 0.025974025974025976,
    "the grammar is": 0.09090909090909091,
    "grammar is used": 0.5,
    "used to perform": 0.045454545454545456,
    "to perform a": 0.2,
    "perform a first": 0.3333333333333333,
    "a first pass": 0.3333333333333333,
    "first pass .": 1.0,
    "<s> algorithms which": 0.5,
    "algorithms which use": 0.5,
    "which use context-free": 1.0,
    "use context-free grammars": 1.0,
    "context-free grammars often": 0.2,
    "grammars often rely": 1.0,
    "often rely on": 1.0,
    "rely on some": 0.16666666666666666,
    "on some variant": 0.1111111111111111,
    "some variant of": 1.0,
    "variant of the": 1.0,
    "of the cky": 0.005128205128205128,
    "the cky algorithm": 1.0,
    "cky algorithm ,": 1.0,
    "algorithm , usually": 0.3333333333333333,
    ", usually with": 0.4,
    "usually with some": 0.5,
    "with some heuristic": 0.25,
    "some heuristic to": 1.0,
    "heuristic to prune": 1.0,
    "to prune away": 1.0,
    "prune away unlikely": 1.0,
    "away unlikely analyses": 1.0,
    "unlikely analyses to": 1.0,
    "analyses to save": 1.0,
    "to save time": 1.0,
    "save time .": 1.0,
    "-lrb- see chart": 0.0625,
    "see chart parsing": 1.0,
    "chart parsing .": 1.0,
    "parsing . -rrb-": 1.0,
    "<s> however some": 0.02702702702702703,
    "however some systems": 1.0,
    "some systems trade": 0.25,
    "systems trade speed": 1.0,
    "trade speed for": 1.0,
    "speed for accuracy": 1.0,
    "for accuracy using": 1.0,
    "accuracy using ,": 1.0,
    "using , e.g.": 1.0,
    "e.g. , linear-time": 0.038461538461538464,
    ", linear-time versions": 1.0,
    "linear-time versions of": 1.0,
    "versions of the": 1.0,
    "of the shift-reduce": 0.005128205128205128,
    "the shift-reduce algorithm": 1.0,
    "shift-reduce algorithm .": 1.0,
    "<s> a somewhat": 0.022727272727272728,
    "a somewhat recent": 1.0,
    "somewhat recent development": 1.0,
    "recent development has": 1.0,
    "development has been": 1.0,
    "has been parse": 0.03571428571428571,
    "been parse reranking": 1.0,
    "parse reranking in": 1.0,
    "reranking in which": 1.0,
    "in which the": 0.125,
    "which the parser": 0.125,
    "the parser proposes": 0.2,
    "parser proposes some": 1.0,
    "proposes some large": 1.0,
    "some large number": 1.0,
    "number of analyses": 0.027777777777777776,
    "of analyses ,": 1.0,
    "analyses , and": 1.0,
    "and a more": 0.0625,
    "more complex system": 0.1111111111111111,
    "complex system selects": 0.5,
    "system selects the": 1.0,
    "selects the best": 1.0,
    "the best option": 0.07142857142857142,
    "best option .": 1.0,
    "<s> programming languages": 1.0,
    "programming languages the": 0.2,
    "languages the most": 1.0,
    "most common use": 0.16666666666666666,
    "common use of": 0.5,
    "of a parser": 0.010869565217391304,
    "a parser is": 0.25,
    "parser is as": 0.3333333333333333,
    "is as a": 1.0,
    "a compiler or": 0.3333333333333333,
    "compiler or interpreter": 1.0,
    "or interpreter .": 0.5,
    "<s> this parses": 0.019230769230769232,
    "this parses the": 1.0,
    "parses the source": 1.0,
    "the source code": 0.08333333333333333,
    "source code of": 1.0,
    "code of a": 1.0,
    "a computer programming": 0.0625,
    "computer programming language": 1.0,
    "programming language to": 1.0,
    "language to create": 0.25,
    "to create some": 0.1111111111111111,
    "create some form": 1.0,
    "form of internal": 0.14285714285714285,
    "of internal representation": 1.0,
    "programming languages tend": 0.2,
    "languages tend to": 1.0,
    "tend to be": 0.5,
    "to be specified": 0.023255813953488372,
    "be specified in": 1.0,
    "specified in terms": 1.0,
    "terms of a": 0.14285714285714285,
    "of a context-free": 0.010869565217391304,
    "a context-free grammar": 1.0,
    "context-free grammar because": 0.2,
    "grammar because fast": 1.0,
    "because fast and": 1.0,
    "fast and efficient": 1.0,
    "and efficient parsers": 0.5,
    "efficient parsers can": 1.0,
    "parsers can be": 1.0,
    "can be written": 0.01098901098901099,
    "be written for": 1.0,
    "written for them": 1.0,
    "for them .": 0.5,
    "<s> parsers are": 0.5,
    "parsers are written": 0.3333333333333333,
    "are written by": 1.0,
    "written by hand": 0.16666666666666666,
    "hand or generated": 0.5,
    "or generated by": 1.0,
    "generated by parser": 1.0,
    "by parser generators": 1.0,
    "parser generators .": 1.0,
    "<s> context-free grammars": 1.0,
    "context-free grammars are": 0.2,
    "grammars are limited": 1.0,
    "are limited in": 1.0,
    "limited in the": 1.0,
    "in the extent": 0.006535947712418301,
    "the extent to": 0.5,
    "extent to which": 1.0,
    "to which they": 0.2,
    "which they can": 0.5,
    "can express all": 0.25,
    "express all of": 1.0,
    "of the requirements": 0.005128205128205128,
    "the requirements of": 1.0,
    "requirements of a": 1.0,
    "a language .": 0.16666666666666666,
    "<s> informally ,": 1.0,
    "informally , the": 1.0,
    ", the reason": 0.009523809523809525,
    "the reason is": 1.0,
    "reason is that": 1.0,
    "that the memory": 0.043478260869565216,
    "the memory of": 1.0,
    "memory of such": 1.0,
    "such a language": 0.14285714285714285,
    "a language is": 0.16666666666666666,
    "language is limited": 0.2,
    "is limited .": 1.0,
    "the grammar can": 0.09090909090909091,
    "grammar can not": 1.0,
    "can not remember": 0.06666666666666667,
    "not remember the": 1.0,
    "remember the presence": 1.0,
    "the presence of": 1.0,
    "presence of a": 1.0,
    "of a construct": 0.010869565217391304,
    "a construct over": 1.0,
    "construct over an": 1.0,
    "over an arbitrarily": 1.0,
    "an arbitrarily long": 1.0,
    "arbitrarily long input": 1.0,
    "long input ;": 1.0,
    "input ; this": 1.0,
    "this is necessary": 0.038461538461538464,
    "is necessary for": 0.5,
    "necessary for a": 0.3333333333333333,
    "a language in": 0.16666666666666666,
    "language in which": 1.0,
    "in which ,": 0.125,
    "which , for": 1.0,
    ", a name": 0.020833333333333332,
    "a name must": 0.5,
    "name must be": 1.0,
    "must be declared": 0.16666666666666666,
    "be declared before": 1.0,
    "declared before it": 1.0,
    "before it may": 1.0,
    "it may be": 0.5,
    "may be referenced": 0.047619047619047616,
    "be referenced .": 1.0,
    "<s> more powerful": 0.125,
    "more powerful grammars": 1.0,
    "powerful grammars that": 1.0,
    "grammars that can": 1.0,
    "that can express": 0.07692307692307693,
    "can express this": 0.25,
    "express this constraint": 1.0,
    "this constraint ,": 1.0,
    "constraint , however": 1.0,
    "however , can": 0.022727272727272728,
    ", can not": 0.16666666666666666,
    "not be parsed": 0.08333333333333333,
    "be parsed efficiently": 1.0,
    "parsed efficiently .": 1.0,
    "a common strategy": 0.5,
    "common strategy to": 1.0,
    "strategy to create": 0.3333333333333333,
    "create a relaxed": 0.14285714285714285,
    "a relaxed parser": 1.0,
    "relaxed parser for": 1.0,
    "parser for a": 1.0,
    "for a context-free": 0.03225806451612903,
    "context-free grammar which": 0.4,
    "grammar which accepts": 0.5,
    "which accepts a": 1.0,
    "accepts a superset": 1.0,
    "a superset of": 1.0,
    "superset of the": 1.0,
    "of the desired": 0.005128205128205128,
    "the desired language": 0.25,
    "desired language constructs": 1.0,
    "language constructs -lrb-": 1.0,
    "constructs -lrb- that": 1.0,
    "is , it": 0.1111111111111111,
    ", it accepts": 0.041666666666666664,
    "it accepts some": 1.0,
    "accepts some invalid": 1.0,
    "some invalid constructs": 1.0,
    "invalid constructs -rrb-": 1.0,
    "constructs -rrb- ;": 1.0,
    "-rrb- ; later": 0.125,
    "; later ,": 1.0,
    "later , the": 0.3333333333333333,
    ", the unwanted": 0.009523809523809525,
    "the unwanted constructs": 1.0,
    "unwanted constructs can": 1.0,
    "constructs can be": 1.0,
    "be filtered out": 0.3333333333333333,
    "filtered out .": 1.0,
    "overview of process": 0.5,
    "of process flow": 1.0,
    "process flow of": 1.0,
    "flow of data": 1.0,
    "of data in": 0.14285714285714285,
    "data in a": 0.5,
    "in a typical": 0.019230769230769232,
    "a typical parser": 0.25,
    "typical parser the": 1.0,
    "parser the following": 0.5,
    "following example demonstrates": 0.5,
    "example demonstrates the": 1.0,
    "demonstrates the common": 1.0,
    "the common case": 0.5,
    "common case of": 1.0,
    "case of parsing": 0.16666666666666666,
    "of parsing a": 0.5,
    "parsing a computer": 1.0,
    "a computer language": 0.0625,
    "computer language with": 1.0,
    "language with two": 1.0,
    "with two levels": 0.5,
    "two levels of": 1.0,
    "levels of grammar": 0.14285714285714285,
    "of grammar :": 0.5,
    "grammar : lexical": 1.0,
    ": lexical and": 1.0,
    "lexical and syntactic": 1.0,
    "and syntactic .": 0.5,
    "the first stage": 0.045454545454545456,
    "first stage is": 1.0,
    "stage is the": 0.5,
    "is the token": 0.022222222222222223,
    "the token generation": 1.0,
    "token generation ,": 1.0,
    "generation , or": 1.0,
    ", or lexical": 0.030303030303030304,
    "or lexical analysis": 0.5,
    "lexical analysis ,": 1.0,
    "analysis , by": 0.14285714285714285,
    ", by which": 0.2,
    "by which the": 1.0,
    "which the input": 0.125,
    "the input character": 0.125,
    "input character stream": 1.0,
    "character stream is": 1.0,
    "stream is split": 1.0,
    "is split into": 1.0,
    "split into meaningful": 0.5,
    "into meaningful symbols": 0.5,
    "meaningful symbols defined": 1.0,
    "symbols defined by": 1.0,
    "defined by a": 1.0,
    "by a grammar": 0.1111111111111111,
    "a grammar of": 0.5,
    "grammar of regular": 0.5,
    "of regular expressions": 1.0,
    "regular expressions .": 1.0,
    ", a calculator": 0.020833333333333332,
    "a calculator program": 0.5,
    "calculator program would": 1.0,
    "program would look": 1.0,
    "look at an": 0.5,
    "at an input": 1.0,
    "an input such": 0.3333333333333333,
    "input such as": 1.0,
    "as `` 12": 0.07142857142857142,
    "`` 12 \\*": 1.0,
    "12 \\* -lrb-": 0.5,
    "\\* -lrb- 3": 1.0,
    "-lrb- 3 +4": 0.5,
    "3 +4 -rrb-": 1.0,
    "+4 -rrb- ^": 1.0,
    "-rrb- ^ 2": 1.0,
    "^ 2 ''": 1.0,
    "2 '' and": 1.0,
    "'' and split": 0.07692307692307693,
    "and split it": 1.0,
    "split it into": 1.0,
    "it into the": 0.2,
    "into the tokens": 0.125,
    "the tokens 12": 0.5,
    "tokens 12 ,": 1.0,
    "12 , \\*": 1.0,
    ", \\* ,": 1.0,
    "\\* , -lrb-": 0.5,
    ", -lrb- ,": 0.3333333333333333,
    "-lrb- , 3": 1.0,
    ", 3 ,": 1.0,
    "3 , +": 1.0,
    ", + ,": 1.0,
    "+ , 4": 0.5,
    ", 4 ,": 1.0,
    "4 , -rrb-": 1.0,
    ", -rrb- ,": 1.0,
    "-rrb- , ^": 0.01282051282051282,
    ", ^ ,": 1.0,
    "^ , 2": 0.5,
    ", 2 ,": 1.0,
    "2 , each": 1.0,
    "is a meaningful": 0.018518518518518517,
    "a meaningful symbol": 0.5,
    "meaningful symbol in": 1.0,
    "symbol in the": 1.0,
    "context of an": 0.2,
    "of an arithmetic": 0.07692307692307693,
    "an arithmetic expression": 1.0,
    "arithmetic expression .": 1.0,
    "<s> the lexer": 0.006802721088435374,
    "the lexer would": 1.0,
    "lexer would contain": 1.0,
    "would contain rules": 1.0,
    "contain rules to": 1.0,
    "rules to tell": 0.3333333333333333,
    "to tell it": 1.0,
    "tell it that": 1.0,
    "it that the": 1.0,
    "that the characters": 0.043478260869565216,
    "the characters \\*": 1.0,
    "characters \\* ,": 1.0,
    "\\* , +": 0.5,
    "+ , ^": 0.5,
    "^ , -lrb-": 0.5,
    ", -lrb- and": 0.3333333333333333,
    "-lrb- and -rrb-": 0.2,
    "and -rrb- mark": 1.0,
    "-rrb- mark the": 1.0,
    "mark the start": 1.0,
    "start of a": 0.5,
    "of a new": 0.010869565217391304,
    "a new token": 0.16666666666666666,
    "new token ,": 1.0,
    "token , so": 1.0,
    ", so meaningless": 0.08333333333333333,
    "so meaningless tokens": 1.0,
    "meaningless tokens like": 1.0,
    "tokens like ``": 1.0,
    "like `` 12": 0.3333333333333333,
    "12 \\* ''": 0.5,
    "\\* '' or": 1.0,
    "'' or ''": 0.2,
    "or '' -lrb-": 1.0,
    "'' -lrb- 3": 0.1111111111111111,
    "-lrb- 3 ''": 0.5,
    "3 '' will": 1.0,
    "'' will not": 1.0,
    "will not be": 0.5,
    "not be generated": 0.08333333333333333,
    "be generated .": 1.0,
    "<s> the next": 0.006802721088435374,
    "the next stage": 0.2857142857142857,
    "next stage is": 0.5,
    "stage is parsing": 0.5,
    "is parsing or": 1.0,
    "parsing or syntactic": 0.5,
    "or syntactic analysis": 1.0,
    "analysis , which": 0.2857142857142857,
    "which is checking": 0.07692307692307693,
    "is checking that": 1.0,
    "checking that the": 1.0,
    "that the tokens": 0.043478260869565216,
    "the tokens form": 0.5,
    "tokens form an": 1.0,
    "form an allowable": 1.0,
    "an allowable expression": 1.0,
    "allowable expression .": 1.0,
    "this is usually": 0.07692307692307693,
    "is usually done": 0.25,
    "usually done with": 0.5,
    "done with reference": 0.5,
    "with reference to": 1.0,
    "reference to a": 0.5,
    "to a context-free": 0.03571428571428571,
    "grammar which recursively": 0.5,
    "which recursively defines": 1.0,
    "recursively defines components": 1.0,
    "defines components that": 1.0,
    "components that can": 1.0,
    "can make up": 0.3333333333333333,
    "make up an": 0.5,
    "up an expression": 1.0,
    "an expression and": 1.0,
    "and the order": 0.024390243902439025,
    "the order in": 0.5,
    "order in which": 1.0,
    "in which they": 0.125,
    "which they must": 0.5,
    "they must appear": 1.0,
    "must appear .": 1.0,
    "however , not": 0.022727272727272728,
    ", not all": 0.2857142857142857,
    "not all rules": 0.5,
    "all rules defining": 1.0,
    "rules defining programming": 1.0,
    "defining programming languages": 1.0,
    "programming languages can": 0.2,
    "be expressed by": 0.3333333333333333,
    "expressed by context-free": 1.0,
    "by context-free grammars": 1.0,
    "context-free grammars alone": 0.2,
    "grammars alone ,": 1.0,
    "alone , for": 1.0,
    "for example type": 0.017857142857142856,
    "example type validity": 1.0,
    "type validity and": 1.0,
    "validity and proper": 1.0,
    "and proper declaration": 1.0,
    "proper declaration of": 1.0,
    "declaration of identifiers": 1.0,
    "of identifiers .": 1.0,
    "<s> these rules": 0.0625,
    "these rules can": 1.0,
    "can be formally": 0.01098901098901099,
    "be formally expressed": 1.0,
    "formally expressed with": 1.0,
    "expressed with attribute": 1.0,
    "with attribute grammars": 1.0,
    "attribute grammars .": 0.5,
    "<s> the final": 0.006802721088435374,
    "the final phase": 0.2,
    "final phase is": 1.0,
    "phase is semantic": 1.0,
    "is semantic parsing": 1.0,
    "semantic parsing or": 1.0,
    "parsing or analysis": 0.5,
    "or analysis ,": 1.0,
    "which is working": 0.07692307692307693,
    "is working out": 0.5,
    "working out the": 1.0,
    "out the implications": 0.3333333333333333,
    "the implications of": 1.0,
    "implications of the": 1.0,
    "of the expression": 0.005128205128205128,
    "the expression just": 0.5,
    "expression just validated": 1.0,
    "just validated and": 1.0,
    "validated and taking": 1.0,
    "and taking the": 1.0,
    "taking the appropriate": 0.3333333333333333,
    "the appropriate action": 0.3333333333333333,
    "appropriate action .": 1.0,
    "case of a": 0.16666666666666666,
    "of a calculator": 0.010869565217391304,
    "a calculator or": 0.5,
    "calculator or interpreter": 1.0,
    "or interpreter ,": 0.5,
    "interpreter , the": 1.0,
    ", the action": 0.009523809523809525,
    "the action is": 1.0,
    "action is to": 1.0,
    "is to evaluate": 0.05263157894736842,
    "evaluate the expression": 0.5,
    "the expression or": 0.5,
    "expression or program": 1.0,
    "or program ,": 1.0,
    "program , a": 1.0,
    ", a compiler": 0.020833333333333332,
    "a compiler ,": 0.3333333333333333,
    "compiler , on": 1.0,
    "hand , would": 0.14285714285714285,
    ", would generate": 0.3333333333333333,
    "would generate some": 1.0,
    "generate some kind": 1.0,
    "kind of code": 0.125,
    "of code .": 1.0,
    "<s> attribute grammars": 1.0,
    "attribute grammars can": 0.5,
    "grammars can also": 1.0,
    "used to define": 0.045454545454545456,
    "to define these": 0.5,
    "define these actions": 1.0,
    "these actions .": 1.0,
    "types of parser": 0.07142857142857142,
    "of parser the": 0.5,
    "parser the task": 0.5,
    "of the parser": 0.005128205128205128,
    "the parser is": 0.2,
    "parser is essentially": 0.3333333333333333,
    "is essentially to": 0.3333333333333333,
    "essentially to determine": 1.0,
    "to determine if": 0.18181818181818182,
    "determine if and": 0.2,
    "if and how": 1.0,
    "and how the": 0.3333333333333333,
    "how the input": 1.0,
    "the input can": 0.125,
    "input can be": 1.0,
    "derived from the": 0.3333333333333333,
    "from the start": 0.045454545454545456,
    "the start symbol": 0.5,
    "start symbol of": 0.5,
    "symbol of the": 1.0,
    "the grammar .": 0.09090909090909091,
    "<s> this can": 0.019230769230769232,
    "done in essentially": 0.2,
    "in essentially two": 1.0,
    "essentially two ways": 1.0,
    "two ways :": 1.0,
    "ways : top-down": 0.5,
    ": top-down parsing": 1.0,
    "top-down parsing -": 0.25,
    "parsing - top-down": 0.5,
    "- top-down parsing": 1.0,
    "top-down parsing can": 0.5,
    "parsing can be": 0.3333333333333333,
    "as an attempt": 0.06666666666666667,
    "attempt to find": 0.16666666666666666,
    "to find left-most": 0.1111111111111111,
    "find left-most derivations": 1.0,
    "left-most derivations of": 1.0,
    "derivations of an": 1.0,
    "of an input-stream": 0.07692307692307693,
    "an input-stream by": 1.0,
    "input-stream by searching": 1.0,
    "by searching for": 1.0,
    "searching for parse": 1.0,
    "for parse trees": 1.0,
    "parse trees using": 0.5,
    "trees using a": 1.0,
    "using a top-down": 0.1,
    "a top-down expansion": 1.0,
    "top-down expansion of": 1.0,
    "expansion of the": 1.0,
    "of the given": 0.010256410256410256,
    "the given formal": 0.5,
    "given formal grammar": 1.0,
    "formal grammar rules": 0.5,
    "grammar rules .": 0.4,
    "<s> tokens are": 1.0,
    "tokens are consumed": 1.0,
    "are consumed from": 1.0,
    "consumed from left": 1.0,
    "from left to": 1.0,
    "left to right": 1.0,
    "to right .": 1.0,
    "<s> inclusive choice": 1.0,
    "inclusive choice is": 1.0,
    "choice is used": 0.5,
    "used to accommodate": 0.045454545454545456,
    "to accommodate ambiguity": 0.5,
    "accommodate ambiguity by": 0.5,
    "ambiguity by expanding": 1.0,
    "by expanding all": 1.0,
    "expanding all alternative": 1.0,
    "all alternative right-hand-sides": 1.0,
    "alternative right-hand-sides of": 1.0,
    "right-hand-sides of grammar": 1.0,
    "of grammar rules": 0.5,
    "<s> bottom-up parsing": 1.0,
    "bottom-up parsing -": 1.0,
    "parsing - a": 0.5,
    "- a parser": 1.0,
    "a parser can": 0.25,
    "parser can start": 1.0,
    "can start with": 1.0,
    "start with the": 1.0,
    "with the input": 0.03333333333333333,
    "input and attempt": 0.5,
    "and attempt to": 1.0,
    "attempt to rewrite": 0.16666666666666666,
    "to rewrite it": 1.0,
    "rewrite it to": 1.0,
    "it to the": 0.2,
    "to the start": 0.012987012987012988,
    "start symbol .": 0.5,
    "<s> intuitively ,": 1.0,
    "intuitively , the": 1.0,
    ", the parser": 0.009523809523809525,
    "the parser attempts": 0.2,
    "parser attempts to": 1.0,
    "attempts to locate": 0.3333333333333333,
    "to locate the": 1.0,
    "locate the most": 1.0,
    "the most basic": 0.041666666666666664,
    "most basic elements": 1.0,
    "basic elements ,": 1.0,
    "elements , then": 1.0,
    ", then the": 0.18181818181818182,
    "then the elements": 0.25,
    "the elements containing": 1.0,
    "elements containing these": 1.0,
    "containing these ,": 1.0,
    "these , and": 0.5,
    "<s> lr parsers": 1.0,
    "lr parsers are": 0.5,
    "parsers are examples": 0.3333333333333333,
    "examples of bottom-up": 0.2,
    "of bottom-up parsers": 1.0,
    "bottom-up parsers .": 1.0,
    "<s> another term": 0.07692307692307693,
    "another term used": 1.0,
    "term used for": 0.5,
    "used for this": 0.06666666666666667,
    "for this type": 0.125,
    "type of parser": 0.125,
    "of parser is": 0.5,
    "parser is shift-reduce": 0.3333333333333333,
    "is shift-reduce parsing": 1.0,
    "shift-reduce parsing .": 1.0,
    "<s> ll parsers": 1.0,
    "ll parsers and": 0.5,
    "parsers and recursive-descent": 1.0,
    "and recursive-descent parser": 1.0,
    "recursive-descent parser are": 1.0,
    "parser are examples": 1.0,
    "examples of top-down": 0.2,
    "of top-down parsers": 0.5,
    "top-down parsers which": 1.0,
    "parsers which can": 1.0,
    "which can not": 0.2,
    "can not accommodate": 0.13333333333333333,
    "not accommodate left": 0.5,
    "accommodate left recursive": 1.0,
    "left recursive productions": 1.0,
    "recursive productions .": 1.0,
    "<s> although it": 0.14285714285714285,
    "although it has": 1.0,
    "has been believed": 0.03571428571428571,
    "been believed that": 1.0,
    "believed that simple": 1.0,
    "that simple implementations": 1.0,
    "simple implementations of": 1.0,
    "implementations of top-down": 0.5,
    "of top-down parsing": 0.5,
    "parsing can not": 0.3333333333333333,
    "not accommodate direct": 0.5,
    "accommodate direct and": 1.0,
    "direct and indirect": 1.0,
    "and indirect left-recursion": 1.0,
    "indirect left-recursion and": 1.0,
    "left-recursion and may": 1.0,
    "and may require": 0.5,
    "may require exponential": 0.5,
    "require exponential time": 1.0,
    "exponential time and": 1.0,
    "time and space": 0.3333333333333333,
    "and space complexity": 1.0,
    "space complexity while": 1.0,
    "complexity while parsing": 1.0,
    "while parsing ambiguous": 1.0,
    "parsing ambiguous context-free": 1.0,
    "ambiguous context-free grammars": 1.0,
    "context-free grammars ,": 0.2,
    "grammars , more": 0.5,
    ", more sophisticated": 0.25,
    "more sophisticated algorithms": 0.2,
    "sophisticated algorithms for": 0.5,
    "algorithms for top-down": 0.25,
    "for top-down parsing": 1.0,
    "top-down parsing have": 0.25,
    "parsing have been": 1.0,
    "been created by": 0.5,
    "created by frost": 0.5,
    "by frost ,": 1.0,
    "frost , hafiz": 1.0,
    ", hafiz ,": 1.0,
    "hafiz , and": 1.0,
    ", and callaghan": 0.005291005291005291,
    "and callaghan which": 1.0,
    "callaghan which accommodate": 1.0,
    "which accommodate ambiguity": 1.0,
    "accommodate ambiguity and": 0.5,
    "ambiguity and left": 1.0,
    "and left recursion": 1.0,
    "left recursion in": 1.0,
    "recursion in polynomial": 1.0,
    "in polynomial time": 1.0,
    "polynomial time and": 1.0,
    "time and which": 0.3333333333333333,
    "and which generate": 1.0,
    "which generate polynomial-size": 0.3333333333333333,
    "generate polynomial-size representations": 1.0,
    "polynomial-size representations of": 1.0,
    "representations of the": 1.0,
    "of the potentially": 0.005128205128205128,
    "the potentially exponential": 1.0,
    "potentially exponential number": 1.0,
    "exponential number of": 1.0,
    "number of parse": 0.027777777777777776,
    "of parse trees": 1.0,
    "parse trees .": 0.5,
    "<s> their algorithm": 0.5,
    "their algorithm is": 1.0,
    "algorithm is able": 0.2,
    "is able to": 1.0,
    "to produce both": 0.1,
    "produce both left-most": 1.0,
    "both left-most and": 1.0,
    "left-most and right-most": 1.0,
    "and right-most derivations": 1.0,
    "right-most derivations of": 1.0,
    "of an input": 0.07692307692307693,
    "an input with": 0.3333333333333333,
    "input with regard": 1.0,
    "regard to a": 0.25,
    "a given cfg": 0.08333333333333333,
    "given cfg -lrb-": 1.0,
    "cfg -lrb- context-free": 1.0,
    "-lrb- context-free grammar": 1.0,
    "context-free grammar -rrb-": 0.4,
    "grammar -rrb- .": 0.6666666666666666,
    "an important distinction": 0.25,
    "important distinction with": 0.5,
    "distinction with regard": 1.0,
    "regard to parsers": 0.25,
    "to parsers is": 1.0,
    "parsers is whether": 1.0,
    "is whether a": 1.0,
    "whether a parser": 0.3333333333333333,
    "a parser generates": 0.25,
    "parser generates a": 1.0,
    "generates a leftmost": 0.5,
    "a leftmost derivation": 1.0,
    "leftmost derivation or": 0.5,
    "derivation or a": 1.0,
    "or a rightmost": 0.05263157894736842,
    "a rightmost derivation": 1.0,
    "rightmost derivation -lrb-": 1.0,
    "derivation -lrb- see": 0.5,
    "-lrb- see context-free": 0.0625,
    "see context-free grammar": 1.0,
    "ll parsers will": 0.5,
    "parsers will generate": 1.0,
    "generate a leftmost": 0.16666666666666666,
    "leftmost derivation and": 0.5,
    "derivation and lr": 1.0,
    "and lr parsers": 1.0,
    "lr parsers will": 0.5,
    "generate a rightmost": 0.16666666666666666,
    "derivation -lrb- although": 0.5,
    "-lrb- although usually": 0.5,
    "although usually in": 1.0,
    "usually in reverse": 0.3333333333333333,
    "in reverse -rrb-": 1.0,
    "reverse -rrb- .": 1.0,
    "<s> in information": 0.010309278350515464,
    "information retrieval and": 0.3333333333333333,
    "retrieval and natural": 0.5,
    "nlp -rrb- ,": 0.25,
    "-rrb- , question": 0.01282051282051282,
    ", question answering": 0.5,
    "question answering -lrb-": 0.08333333333333333,
    "answering -lrb- qa": 1.0,
    "-lrb- qa -rrb-": 1.0,
    "qa -rrb- is": 1.0,
    "is the task": 0.022222222222222223,
    "task of automatically": 0.1111111111111111,
    "of automatically answering": 0.5,
    "automatically answering a": 1.0,
    "answering a question": 1.0,
    "a question posed": 0.2857142857142857,
    "question posed in": 1.0,
    "posed in natural": 0.5,
    "natural language .": 0.014492753623188406,
    "<s> to find": 0.125,
    "to find the": 0.3333333333333333,
    "find the answer": 0.5,
    "the answer to": 0.2857142857142857,
    "answer to a": 0.4,
    "to a question": 0.07142857142857142,
    "a question ,": 0.2857142857142857,
    "question , a": 0.09090909090909091,
    ", a qa": 0.020833333333333332,
    "a qa computer": 0.25,
    "qa computer program": 1.0,
    "computer program may": 0.2,
    "program may use": 1.0,
    "may use either": 1.0,
    "use either a": 1.0,
    "either a pre-structured": 0.5,
    "a pre-structured database": 1.0,
    "pre-structured database or": 1.0,
    "database or a": 0.5,
    "or a collection": 0.05263157894736842,
    "collection of natural": 0.3333333333333333,
    "natural language documents": 0.014492753623188406,
    "language documents -lrb-": 1.0,
    "documents -lrb- a": 0.2,
    "-lrb- a text": 0.2,
    "a text corpus": 0.07142857142857142,
    "text corpus such": 0.5,
    "corpus such as": 1.0,
    "as the world": 0.03571428571428571,
    "wide web or": 0.25,
    "web or some": 1.0,
    "or some local": 0.3333333333333333,
    "some local collection": 1.0,
    "local collection -rrb-": 1.0,
    "collection -rrb- .": 1.0,
    "<s> qa research": 1.0,
    "qa research attempts": 1.0,
    "research attempts to": 1.0,
    "attempts to deal": 0.3333333333333333,
    "to deal with": 1.0,
    "deal with a": 0.5,
    "with a wide": 0.05,
    "a wide range": 1.0,
    "wide range of": 1.0,
    "range of question": 0.25,
    "of question types": 0.25,
    "question types including": 1.0,
    "types including :": 1.0,
    "including : fact": 0.5,
    ": fact ,": 1.0,
    "fact , list": 0.2,
    ", list ,": 1.0,
    "list , definition": 1.0,
    ", definition ,": 1.0,
    "definition , how": 0.5,
    ", how ,": 0.5,
    "how , why": 1.0,
    ", why ,": 0.3333333333333333,
    "why , hypothetical": 1.0,
    ", hypothetical ,": 1.0,
    "hypothetical , semantically": 1.0,
    ", semantically constrained": 1.0,
    "semantically constrained ,": 1.0,
    "constrained , and": 1.0,
    ", and cross-lingual": 0.005291005291005291,
    "and cross-lingual questions": 1.0,
    "cross-lingual questions .": 1.0,
    "<s> search collections": 0.5,
    "search collections vary": 1.0,
    "collections vary from": 1.0,
    "vary from small": 1.0,
    "from small local": 0.5,
    "small local document": 1.0,
    "local document collections": 1.0,
    "document collections ,": 1.0,
    "collections , to": 0.5,
    ", to internal": 0.07692307692307693,
    "to internal organization": 1.0,
    "internal organization documents": 1.0,
    "organization documents ,": 1.0,
    "documents , to": 0.1111111111111111,
    ", to compiled": 0.07692307692307693,
    "to compiled newswire": 1.0,
    "compiled newswire reports": 1.0,
    "newswire reports ,": 1.0,
    "reports , to": 1.0,
    "to the world": 0.012987012987012988,
    "wide web .": 0.25,
    "<s> closed-domain question": 1.0,
    "closed-domain question answering": 1.0,
    "question answering deals": 0.16666666666666666,
    "answering deals with": 1.0,
    "deals with questions": 0.5,
    "with questions under": 0.5,
    "questions under a": 1.0,
    "under a specific": 1.0,
    "specific domain -lrb-": 0.3333333333333333,
    "domain -lrb- for": 1.0,
    "example , medicine": 0.018518518518518517,
    ", medicine or": 1.0,
    "medicine or automotive": 1.0,
    "or automotive maintenance": 1.0,
    "automotive maintenance -rrb-": 1.0,
    "maintenance -rrb- ,": 1.0,
    "seen as an": 0.3333333333333333,
    "as an easier": 0.06666666666666667,
    "an easier task": 1.0,
    "easier task because": 1.0,
    "task because nlp": 1.0,
    "because nlp systems": 1.0,
    "nlp systems can": 0.3333333333333333,
    "systems can exploit": 0.3333333333333333,
    "can exploit domain-specific": 1.0,
    "exploit domain-specific knowledge": 1.0,
    "domain-specific knowledge frequently": 1.0,
    "knowledge frequently formalized": 1.0,
    "frequently formalized in": 1.0,
    "formalized in ontologies": 1.0,
    "in ontologies .": 1.0,
    "<s> alternatively ,": 1.0,
    "alternatively , closed-domain": 0.5,
    ", closed-domain might": 1.0,
    "closed-domain might refer": 1.0,
    "might refer to": 1.0,
    "to a situation": 0.03571428571428571,
    "a situation where": 1.0,
    "situation where only": 1.0,
    "where only a": 1.0,
    "only a limited": 0.5,
    "a limited type": 0.5,
    "limited type of": 1.0,
    "type of questions": 0.125,
    "of questions are": 0.2,
    "questions are accepted": 0.3333333333333333,
    "are accepted ,": 1.0,
    "accepted , such": 1.0,
    "such as questions": 0.011111111111111112,
    "as questions asking": 1.0,
    "questions asking for": 1.0,
    "asking for descriptive": 1.0,
    "for descriptive rather": 1.0,
    "descriptive rather than": 1.0,
    "rather than procedural": 0.07142857142857142,
    "than procedural information": 1.0,
    "procedural information .": 1.0,
    "<s> open-domain question": 1.0,
    "open-domain question answering": 1.0,
    "with questions about": 0.5,
    "questions about nearly": 0.25,
    "about nearly anything": 1.0,
    "nearly anything ,": 1.0,
    "anything , and": 1.0,
    "and can only": 0.125,
    "can only rely": 0.5,
    "only rely on": 1.0,
    "rely on general": 0.16666666666666666,
    "on general ontologies": 1.0,
    "general ontologies and": 1.0,
    "ontologies and world": 1.0,
    "and world knowledge": 1.0,
    "world knowledge .": 0.5,
    "hand , these": 0.14285714285714285,
    ", these systems": 0.5,
    "systems usually have": 0.5,
    "usually have much": 1.0,
    "have much more": 1.0,
    "much more data": 0.25,
    "more data available": 0.5,
    "data available from": 0.3333333333333333,
    "available from which": 1.0,
    "from which to": 0.3333333333333333,
    "which to extract": 1.0,
    "to extract the": 0.3333333333333333,
    "extract the answer": 1.0,
    "the answer .": 0.21428571428571427,
    "contrast , current": 0.2,
    ", current qa": 1.0,
    "current qa systems": 1.0,
    "qa systems use": 0.16666666666666666,
    "systems use text": 0.16666666666666666,
    "use text documents": 1.0,
    "text documents as": 1.0,
    "documents as their": 1.0,
    "as their underlying": 0.5,
    "their underlying knowledge": 1.0,
    "underlying knowledge source": 1.0,
    "knowledge source and": 1.0,
    "source and combine": 1.0,
    "and combine various": 1.0,
    "combine various natural": 0.5,
    "various natural language": 1.0,
    "language processing techniques": 0.05555555555555555,
    "processing techniques to": 1.0,
    "techniques to search": 0.25,
    "to search for": 1.0,
    "search for the": 1.0,
    "for the answers": 0.03125,
    "the answers .": 1.0,
    "<s> current qa": 0.3333333333333333,
    "qa systems typically": 0.16666666666666666,
    "systems typically include": 1.0,
    "typically include a": 1.0,
    "include a question": 0.3333333333333333,
    "a question classifier": 0.14285714285714285,
    "question classifier module": 1.0,
    "classifier module that": 1.0,
    "module that determines": 1.0,
    "that determines the": 0.5,
    "determines the type": 0.5,
    "type of question": 0.125,
    "of question and": 0.25,
    "question and the": 1.0,
    "and the type": 0.024390243902439025,
    "type of answer": 0.125,
    "of answer .": 1.0,
    "<s> after the": 0.3333333333333333,
    "after the question": 0.3333333333333333,
    "the question is": 0.1875,
    "question is analyzed": 0.25,
    "is analyzed ,": 0.3333333333333333,
    "analyzed , the": 1.0,
    "the system typically": 0.038461538461538464,
    "system typically uses": 1.0,
    "typically uses several": 1.0,
    "uses several modules": 1.0,
    "several modules that": 1.0,
    "modules that apply": 1.0,
    "that apply increasingly": 1.0,
    "apply increasingly complex": 1.0,
    "increasingly complex nlp": 1.0,
    "complex nlp techniques": 1.0,
    "nlp techniques on": 0.5,
    "techniques on a": 1.0,
    "on a gradually": 0.041666666666666664,
    "a gradually reduced": 1.0,
    "gradually reduced amount": 1.0,
    "reduced amount of": 1.0,
    "amount of text": 0.2,
    "thus , a": 0.18181818181818182,
    ", a document": 0.020833333333333332,
    "a document retrieval": 0.125,
    "document retrieval module": 1.0,
    "retrieval module uses": 1.0,
    "module uses search": 1.0,
    "uses search engines": 1.0,
    "search engines to": 0.5,
    "engines to identify": 1.0,
    "identify the documents": 0.16666666666666666,
    "the documents or": 0.3333333333333333,
    "documents or paragraphs": 1.0,
    "or paragraphs in": 0.5,
    "paragraphs in the": 1.0,
    "the document set": 0.16666666666666666,
    "document set that": 1.0,
    "set that are": 1.0,
    "that are likely": 0.06666666666666667,
    "likely to contain": 0.14285714285714285,
    "to contain the": 1.0,
    "contain the answer": 0.5,
    "<s> subsequently a": 1.0,
    "subsequently a filter": 1.0,
    "a filter preselects": 1.0,
    "filter preselects small": 1.0,
    "preselects small text": 1.0,
    "small text fragments": 1.0,
    "text fragments that": 1.0,
    "fragments that contain": 1.0,
    "that contain strings": 0.3333333333333333,
    "contain strings of": 1.0,
    "strings of the": 0.5,
    "of the same": 0.005128205128205128,
    "the same type": 0.041666666666666664,
    "same type as": 1.0,
    "type as the": 1.0,
    "as the expected": 0.03571428571428571,
    "the expected answer": 0.5,
    "expected answer .": 1.0,
    "if the question": 0.14285714285714285,
    "question is ``": 0.25,
    "is `` who": 0.5,
    "`` who invented": 0.3333333333333333,
    "who invented penicillin": 1.0,
    "invented penicillin ''": 1.0,
    "penicillin '' the": 1.0,
    "'' the filter": 1.0,
    "the filter returns": 1.0,
    "filter returns text": 1.0,
    "returns text that": 1.0,
    "text that contain": 0.25,
    "that contain names": 0.3333333333333333,
    "contain names of": 1.0,
    "names of people": 1.0,
    "of people .": 1.0,
    "<s> finally ,": 1.0,
    "finally , an": 1.0,
    ", an answer": 0.1,
    "an answer extraction": 0.5,
    "answer extraction module": 0.25,
    "extraction module looks": 1.0,
    "module looks for": 1.0,
    "looks for further": 1.0,
    "for further clues": 0.3333333333333333,
    "further clues in": 1.0,
    "clues in the": 1.0,
    "text to determine": 0.14285714285714285,
    "if the answer": 0.14285714285714285,
    "the answer candidate": 0.07142857142857142,
    "answer candidate can": 1.0,
    "candidate can indeed": 1.0,
    "can indeed answer": 1.0,
    "indeed answer the": 1.0,
    "answer the question": 1.0,
    "the question .": 0.125,
    "question answering methods": 0.08333333333333333,
    "answering methods qa": 1.0,
    "methods qa is": 1.0,
    "qa is very": 1.0,
    "is very dependent": 0.16666666666666666,
    "very dependent on": 1.0,
    "dependent on a": 0.5,
    "on a good": 0.041666666666666664,
    "a good search": 0.2,
    "good search corpus": 1.0,
    "search corpus -": 1.0,
    "corpus - for": 1.0,
    "- for without": 1.0,
    "for without documents": 1.0,
    "without documents containing": 1.0,
    "documents containing the": 1.0,
    "containing the answer": 0.3333333333333333,
    "the answer ,": 0.07142857142857142,
    "answer , there": 1.0,
    "there is little": 0.058823529411764705,
    "is little any": 1.0,
    "little any qa": 1.0,
    "any qa system": 1.0,
    "qa system can": 0.2,
    "system can do": 1.0,
    "can do .": 0.5,
    "<s> it thus": 0.029411764705882353,
    "it thus makes": 1.0,
    "thus makes sense": 1.0,
    "makes sense that": 1.0,
    "sense that larger": 1.0,
    "that larger collection": 1.0,
    "larger collection sizes": 1.0,
    "collection sizes generally": 1.0,
    "sizes generally lend": 1.0,
    "generally lend well": 1.0,
    "lend well to": 1.0,
    "well to better": 1.0,
    "to better qa": 0.3333333333333333,
    "better qa performance": 1.0,
    "qa performance ,": 1.0,
    "performance , unless": 0.5,
    ", unless the": 1.0,
    "unless the question": 1.0,
    "the question domain": 0.0625,
    "question domain is": 1.0,
    "domain is orthogonal": 1.0,
    "is orthogonal to": 1.0,
    "orthogonal to the": 1.0,
    "to the collection": 0.012987012987012988,
    "the collection .": 1.0,
    "<s> the notion": 0.013605442176870748,
    "notion of data": 0.3333333333333333,
    "of data redundancy": 0.14285714285714285,
    "data redundancy in": 1.0,
    "redundancy in massive": 0.5,
    "in massive collections": 1.0,
    "massive collections ,": 1.0,
    "collections , such": 0.5,
    "as the web": 0.03571428571428571,
    "the web ,": 0.25,
    "web , means": 1.0,
    ", means that": 1.0,
    "means that nuggets": 0.25,
    "that nuggets of": 1.0,
    "nuggets of information": 1.0,
    "of information are": 0.2,
    "information are likely": 1.0,
    "to be phrased": 0.023255813953488372,
    "be phrased in": 1.0,
    "phrased in many": 1.0,
    "in many different": 0.1,
    "many different ways": 0.16666666666666666,
    "different ways in": 1.0,
    "ways in differing": 1.0,
    "in differing contexts": 1.0,
    "differing contexts and": 0.5,
    "contexts and documents": 1.0,
    "and documents ,": 1.0,
    "documents , leading": 0.1111111111111111,
    ", leading to": 1.0,
    "leading to two": 0.5,
    "to two benefits": 1.0,
    "two benefits :": 1.0,
    "benefits : by": 1.0,
    ": by having": 1.0,
    "by having the": 1.0,
    "having the right": 1.0,
    "the right information": 0.3333333333333333,
    "right information appear": 1.0,
    "information appear in": 1.0,
    "appear in many": 0.14285714285714285,
    "in many forms": 0.1,
    "many forms ,": 1.0,
    "forms , the": 1.0,
    ", the burden": 0.009523809523809525,
    "the burden on": 1.0,
    "burden on the": 1.0,
    "on the qa": 0.014925373134328358,
    "the qa system": 1.0,
    "qa system to": 0.2,
    "system to perform": 0.2,
    "to perform complex": 0.2,
    "perform complex nlp": 1.0,
    "nlp techniques to": 0.5,
    "techniques to understand": 0.25,
    "understand the text": 0.5,
    "the text is": 0.038461538461538464,
    "text is lessened": 0.25,
    "is lessened .": 1.0,
    "<s> correct answers": 1.0,
    "correct answers can": 1.0,
    "answers can be": 1.0,
    "be filtered from": 0.3333333333333333,
    "filtered from false": 1.0,
    "from false positives": 1.0,
    "false positives by": 1.0,
    "positives by relying": 1.0,
    "by relying on": 1.0,
    "relying on the": 1.0,
    "on the correct": 0.014925373134328358,
    "the correct answer": 0.16666666666666666,
    "correct answer to": 1.0,
    "answer to appear": 0.2,
    "to appear more": 0.5,
    "appear more times": 1.0,
    "more times in": 1.0,
    "times in the": 1.0,
    "in the documents": 0.006535947712418301,
    "the documents than": 0.3333333333333333,
    "documents than instances": 1.0,
    "than instances of": 1.0,
    "instances of incorrect": 0.5,
    "of incorrect ones": 1.0,
    "incorrect ones .": 1.0,
    "<s> issues in": 0.5,
    "issues in 2002": 1.0,
    "in 2002 a": 1.0,
    "2002 a group": 1.0,
    "a group of": 1.0,
    "group of researchers": 0.5,
    "of researchers wrote": 1.0,
    "researchers wrote a": 1.0,
    "wrote a roadmap": 1.0,
    "a roadmap of": 1.0,
    "roadmap of research": 1.0,
    "research in question": 0.14285714285714285,
    "in question answering": 0.5,
    "question answering .": 0.16666666666666666,
    "<s> the following": 0.006802721088435374,
    "the following issues": 0.09090909090909091,
    "following issues were": 1.0,
    "issues were identified": 1.0,
    "were identified .": 1.0,
    "<s> question classes": 0.4,
    "question classes different": 0.5,
    "classes different types": 1.0,
    "types of questions": 0.07142857142857142,
    "of questions -lrb-": 0.2,
    "questions -lrb- e.g.": 1.0,
    "e.g. , ``": 0.11538461538461539,
    ", `` what": 0.04,
    "capital of lichtenstein": 0.5,
    "of lichtenstein ?": 1.0,
    "lichtenstein ? ''": 1.0,
    "<s> vs. ``": 1.0,
    "vs. `` why": 0.5,
    "`` why does": 0.3333333333333333,
    "does a rainbow": 0.5,
    "a rainbow form": 1.0,
    "rainbow form ?": 1.0,
    "form ? ''": 1.0,
    "vs. `` did": 0.5,
    "`` did marilyn": 1.0,
    "did marilyn monroe": 1.0,
    "marilyn monroe and": 1.0,
    "monroe and cary": 1.0,
    "and cary grant": 1.0,
    "cary grant ever": 1.0,
    "grant ever appear": 1.0,
    "ever appear in": 1.0,
    "appear in a": 0.14285714285714285,
    "in a movie": 0.019230769230769232,
    "a movie together": 0.5,
    "movie together ?": 1.0,
    "together ? ''": 1.0,
    "<s> require the": 1.0,
    "use of different": 0.045454545454545456,
    "of different strategies": 0.5,
    "different strategies to": 1.0,
    "strategies to find": 1.0,
    "question classes are": 0.5,
    "classes are arranged": 1.0,
    "are arranged hierarchically": 1.0,
    "arranged hierarchically in": 1.0,
    "hierarchically in taxonomies": 1.0,
    "in taxonomies .": 1.0,
    "<s> question processing": 0.2,
    "question processing the": 0.25,
    "processing the same": 0.5,
    "the same information": 0.041666666666666664,
    "same information request": 1.0,
    "information request can": 1.0,
    "request can be": 1.0,
    "be expressed in": 0.3333333333333333,
    "expressed in various": 1.0,
    "in various ways": 0.6666666666666666,
    "various ways ,": 0.5,
    "ways , some": 0.5,
    ", some interrogative": 0.1111111111111111,
    "some interrogative -lrb-": 1.0,
    "interrogative -lrb- ``": 1.0,
    "-lrb- `` who": 0.125,
    "`` who is": 0.3333333333333333,
    "is the president": 0.022222222222222223,
    "the president of": 1.0,
    "president of the": 1.0,
    "united states ?": 0.14285714285714285,
    "states ? ''": 1.0,
    "<s> and some": 1.0,
    "and some assertive": 0.5,
    "some assertive -lrb-": 1.0,
    "assertive -lrb- ``": 1.0,
    "-lrb- `` tell": 0.125,
    "`` tell me": 1.0,
    "tell me the": 1.0,
    "me the name": 1.0,
    "the name of": 0.5,
    "name of the": 1.0,
    "of the president": 0.005128205128205128,
    "states . ''": 1.0,
    ". '' -rrb-": 0.5,
    "<s> a semantic": 0.022727272727272728,
    "a semantic model": 0.5,
    "semantic model of": 1.0,
    "model of question": 1.0,
    "of question understanding": 0.25,
    "question understanding and": 1.0,
    "understanding and processing": 1.0,
    "and processing would": 1.0,
    "processing would recognize": 1.0,
    "would recognize equivalent": 1.0,
    "recognize equivalent questions": 1.0,
    "equivalent questions ,": 1.0,
    "questions , regardless": 0.125,
    "regardless of how": 0.25,
    "of how they": 1.0,
    "they are presented": 0.14285714285714285,
    "are presented .": 1.0,
    "this model would": 0.5,
    "model would enable": 0.3333333333333333,
    "would enable the": 1.0,
    "enable the translation": 0.5,
    "of a complex": 0.021739130434782608,
    "a complex question": 0.2,
    "complex question into": 1.0,
    "question into a": 1.0,
    "into a series": 0.058823529411764705,
    "series of simpler": 0.14285714285714285,
    "of simpler questions": 0.5,
    "simpler questions ,": 1.0,
    "questions , would": 0.125,
    ", would identify": 0.3333333333333333,
    "would identify ambiguities": 1.0,
    "identify ambiguities and": 1.0,
    "ambiguities and treat": 1.0,
    "and treat them": 1.0,
    "treat them in": 1.0,
    "them in context": 1.0,
    "in context or": 0.25,
    "context or by": 1.0,
    "or by interactive": 1.0,
    "by interactive clarification": 1.0,
    "interactive clarification .": 1.0,
    "<s> context and": 1.0,
    "context and qa": 0.2,
    "and qa questions": 1.0,
    "qa questions are": 1.0,
    "questions are usually": 0.3333333333333333,
    "are usually asked": 0.3333333333333333,
    "usually asked within": 1.0,
    "asked within a": 1.0,
    "within a context": 0.2,
    "a context and": 0.5,
    "context and answers": 0.2,
    "and answers are": 1.0,
    "answers are provided": 1.0,
    "are provided within": 1.0,
    "provided within that": 1.0,
    "within that specific": 1.0,
    "that specific context": 1.0,
    "specific context .": 1.0,
    "<s> the context": 0.006802721088435374,
    "the context can": 0.14285714285714285,
    "context can be": 1.0,
    "used to clarify": 0.045454545454545456,
    "to clarify a": 1.0,
    "clarify a question": 1.0,
    "question , resolve": 0.09090909090909091,
    ", resolve ambiguities": 1.0,
    "resolve ambiguities or": 0.5,
    "ambiguities or keep": 1.0,
    "or keep track": 1.0,
    "keep track of": 1.0,
    "track of an": 1.0,
    "of an investigation": 0.07692307692307693,
    "an investigation performed": 1.0,
    "investigation performed through": 1.0,
    "performed through a": 1.0,
    "through a series": 0.5,
    "series of questions": 0.14285714285714285,
    "of questions .": 0.2,
    "<s> -lrb- for": 0.10526315789473684,
    ", the question": 0.009523809523809525,
    "the question ,": 0.3125,
    "question , ``": 0.18181818181818182,
    ", `` why": 0.04,
    "`` why did": 0.3333333333333333,
    "why did joe": 1.0,
    "did joe biden": 1.0,
    "joe biden visit": 1.0,
    "biden visit iraq": 1.0,
    "visit iraq in": 1.0,
    "iraq in january": 1.0,
    "in january 2010": 1.0,
    "january 2010 ?": 0.5,
    "2010 ? ''": 1.0,
    "<s> might be": 1.0,
    "might be asking": 0.16666666666666666,
    "be asking why": 1.0,
    "asking why vice": 1.0,
    "why vice president": 1.0,
    "vice president biden": 1.0,
    "president biden visited": 1.0,
    "biden visited and": 1.0,
    "visited and not": 1.0,
    "and not president": 0.125,
    "not president obama": 1.0,
    "president obama ,": 1.0,
    "obama , why": 1.0,
    ", why he": 0.6666666666666666,
    "why he went": 1.0,
    "he went to": 0.5,
    "went to iraq": 0.5,
    "to iraq and": 1.0,
    "iraq and not": 1.0,
    "and not afghanistan": 0.125,
    "not afghanistan or": 1.0,
    "afghanistan or some": 1.0,
    "or some other": 0.6666666666666666,
    "some other country": 0.14285714285714285,
    "other country ,": 1.0,
    "country , why": 1.0,
    "he went in": 0.5,
    "went in january": 1.0,
    "january 2010 and": 0.5,
    "2010 and not": 1.0,
    "and not before": 0.125,
    "not before or": 1.0,
    "before or after": 1.0,
    "or after ,": 1.0,
    "after , or": 1.0,
    ", or what": 0.06060606060606061,
    "or what biden": 0.5,
    "what biden was": 1.0,
    "biden was hoping": 1.0,
    "was hoping to": 1.0,
    "hoping to accomplish": 1.0,
    "to accomplish with": 1.0,
    "accomplish with his": 1.0,
    "with his visit": 1.0,
    "his visit .": 1.0,
    "<s> if the": 0.25,
    "question is one": 0.25,
    "one of a": 0.0625,
    "series of related": 0.14285714285714285,
    "of related questions": 0.3333333333333333,
    "related questions ,": 1.0,
    "questions , the": 0.125,
    ", the previous": 0.009523809523809525,
    "the previous questions": 0.5,
    "previous questions and": 1.0,
    "questions and their": 1.0,
    "and their answers": 0.16666666666666666,
    "their answers might": 1.0,
    "answers might shed": 1.0,
    "might shed light": 1.0,
    "shed light on": 1.0,
    "light on the": 1.0,
    "on the questioner": 0.014925373134328358,
    "the questioner 's": 0.25,
    "questioner 's intent": 1.0,
    "'s intent .": 1.0,
    "intent . -rrb-": 1.0,
    "<s> data sources": 1.0,
    "data sources for": 0.3333333333333333,
    "sources for qa": 1.0,
    "for qa before": 0.3333333333333333,
    "qa before a": 1.0,
    "before a question": 1.0,
    "a question can": 0.14285714285714285,
    "question can be": 1.0,
    "can be answered": 0.01098901098901099,
    "be answered ,": 1.0,
    "answered , it": 1.0,
    ", it must": 0.041666666666666664,
    "it must be": 1.0,
    "must be known": 0.16666666666666666,
    "be known what": 1.0,
    "known what knowledge": 1.0,
    "what knowledge sources": 1.0,
    "knowledge sources are": 1.0,
    "sources are available": 1.0,
    "are available and": 0.5,
    "available and relevant": 1.0,
    "and relevant .": 1.0,
    "a question is": 0.14285714285714285,
    "question is not": 0.25,
    "is not present": 0.05263157894736842,
    "not present in": 1.0,
    "in the data": 0.006535947712418301,
    "the data sources": 0.5,
    "data sources ,": 0.3333333333333333,
    "sources , no": 1.0,
    ", no matter": 0.3333333333333333,
    "no matter how": 1.0,
    "matter how well": 1.0,
    "how well the": 0.16666666666666666,
    "well the question": 1.0,
    "the question processing": 0.125,
    "question processing ,": 0.5,
    "processing , information": 0.1111111111111111,
    ", information retrieval": 0.5,
    "retrieval and answer": 0.5,
    "and answer extraction": 1.0,
    "answer extraction is": 0.25,
    "extraction is performed": 0.5,
    "is performed ,": 0.5,
    "performed , a": 0.5,
    ", a correct": 0.020833333333333332,
    "a correct result": 0.5,
    "correct result will": 1.0,
    "result will not": 1.0,
    "not be obtained": 0.08333333333333333,
    "be obtained .": 1.0,
    "<s> answer extraction": 0.5,
    "answer extraction answer": 0.25,
    "extraction answer extraction": 1.0,
    "answer extraction depends": 0.25,
    "extraction depends on": 1.0,
    "of the question": 0.015384615384615385,
    "question , on": 0.09090909090909091,
    "on the answer": 0.014925373134328358,
    "the answer type": 0.14285714285714285,
    "answer type provided": 0.5,
    "type provided by": 1.0,
    "provided by question": 0.5,
    "by question processing": 1.0,
    "processing , on": 0.1111111111111111,
    "on the actual": 0.014925373134328358,
    "the actual data": 0.3333333333333333,
    "actual data where": 1.0,
    "data where the": 1.0,
    "where the answer": 0.07692307692307693,
    "the answer is": 0.14285714285714285,
    "answer is searched": 0.5,
    "is searched ,": 1.0,
    "searched , on": 0.5,
    "on the search": 0.014925373134328358,
    "the search method": 1.0,
    "search method and": 1.0,
    "method and on": 1.0,
    "and on the": 0.5,
    "on the question": 0.014925373134328358,
    "the question focus": 0.0625,
    "question focus and": 1.0,
    "focus and context": 1.0,
    "and context .": 0.3333333333333333,
    "<s> answer formulation": 0.5,
    "answer formulation the": 1.0,
    "formulation the result": 1.0,
    "the result of": 0.4,
    "result of a": 0.3333333333333333,
    "of a qa": 0.010869565217391304,
    "a qa system": 0.75,
    "qa system should": 0.2,
    "system should be": 1.0,
    "should be presented": 0.1111111111111111,
    "be presented in": 1.0,
    "presented in a": 0.6666666666666666,
    "in a way": 0.019230769230769232,
    "a way as": 0.2,
    "way as natural": 1.0,
    "as natural as": 1.0,
    "natural as possible": 1.0,
    "as possible .": 0.2,
    "cases , simple": 0.14285714285714285,
    ", simple extraction": 0.5,
    "simple extraction is": 1.0,
    "extraction is sufficient": 0.5,
    "is sufficient .": 1.0,
    "example , when": 0.037037037037037035,
    "when the question": 0.2,
    "the question classification": 0.0625,
    "question classification indicates": 1.0,
    "classification indicates that": 1.0,
    "indicates that the": 1.0,
    "that the answer": 0.043478260869565216,
    "answer type is": 0.5,
    "type is a": 0.5,
    "is a name": 0.018518518518518517,
    "a name -lrb-": 0.5,
    "name -lrb- of": 1.0,
    "-lrb- of a": 0.5,
    "person , organization": 0.25,
    ", organization ,": 0.5,
    "organization , shop": 0.5,
    ", shop or": 1.0,
    "shop or disease": 1.0,
    "or disease ,": 1.0,
    "disease , etc.": 1.0,
    ", a quantity": 0.020833333333333332,
    "a quantity -lrb-": 1.0,
    "quantity -lrb- monetary": 1.0,
    "-lrb- monetary value": 1.0,
    "monetary value ,": 1.0,
    "value , length": 1.0,
    ", length ,": 1.0,
    "length , size": 0.5,
    ", size ,": 1.0,
    "size , distance": 1.0,
    ", distance ,": 1.0,
    "distance , etc.": 0.5,
    "etc. -rrb- or": 0.1111111111111111,
    "-rrb- or a": 0.25,
    "or a date": 0.05263157894736842,
    "a date -lrb-": 1.0,
    "date -lrb- e.g.": 0.5,
    "e.g. the answer": 0.2,
    "answer to the": 0.2,
    "to the question": 0.012987012987012988,
    ", `` on": 0.04,
    "`` on what": 1.0,
    "on what day": 0.3333333333333333,
    "what day did": 1.0,
    "day did christmas": 1.0,
    "did christmas fall": 1.0,
    "christmas fall in": 1.0,
    "fall in 1989": 1.0,
    "in 1989 ?": 1.0,
    "1989 ? ''": 1.0,
    "<s> the extraction": 0.006802721088435374,
    "extraction of a": 0.3333333333333333,
    "of a single": 0.010869565217391304,
    "a single datum": 0.1111111111111111,
    "single datum is": 1.0,
    "datum is sufficient": 1.0,
    "<s> for other": 0.017543859649122806,
    "for other cases": 1.0,
    "other cases ,": 0.5,
    "cases , the": 0.2857142857142857,
    ", the presentation": 0.009523809523809525,
    "the presentation of": 1.0,
    "presentation of the": 1.0,
    "of the answer": 0.005128205128205128,
    "the answer may": 0.07142857142857142,
    "answer may require": 1.0,
    "may require the": 0.5,
    "use of fusion": 0.045454545454545456,
    "of fusion techniques": 1.0,
    "fusion techniques that": 1.0,
    "techniques that combine": 0.5,
    "that combine the": 1.0,
    "combine the partial": 1.0,
    "the partial answers": 1.0,
    "partial answers from": 1.0,
    "answers from multiple": 0.5,
    "from multiple documents": 1.0,
    "multiple documents .": 0.5,
    "<s> real time": 0.5,
    "real time question": 0.5,
    "time question answering": 1.0,
    "question answering there": 0.08333333333333333,
    "answering there is": 1.0,
    "there is need": 0.058823529411764705,
    "is need for": 1.0,
    "need for developing": 0.3333333333333333,
    "for developing q&a": 0.5,
    "developing q&a systems": 1.0,
    "q&a systems that": 1.0,
    "that are capable": 0.06666666666666667,
    "capable of extracting": 0.5,
    "of extracting answers": 1.0,
    "extracting answers from": 1.0,
    "answers from large": 0.5,
    "from large data": 1.0,
    "large data sets": 1.0,
    "data sets in": 0.3333333333333333,
    "sets in several": 1.0,
    "in several seconds": 0.5,
    "several seconds ,": 1.0,
    "seconds , regardless": 1.0,
    "of the complexity": 0.005128205128205128,
    ", the size": 0.009523809523809525,
    "the size and": 0.5,
    "size and multitude": 0.5,
    "and multitude of": 1.0,
    "multitude of the": 1.0,
    "of the data": 0.005128205128205128,
    "data sources or": 0.3333333333333333,
    "sources or the": 1.0,
    "or the ambiguity": 0.1111111111111111,
    "the ambiguity of": 1.0,
    "ambiguity of the": 1.0,
    "<s> multilingual -lrb-": 1.0,
    "multilingual -lrb- or": 1.0,
    "-lrb- or cross-lingual": 0.1,
    "or cross-lingual -rrb-": 1.0,
    "cross-lingual -rrb- question": 1.0,
    "-rrb- question answering": 1.0,
    "question answering the": 0.08333333333333333,
    "answering the ability": 1.0,
    "ability to answer": 0.3333333333333333,
    "to answer a": 0.3333333333333333,
    "answer a question": 1.0,
    "posed in one": 0.5,
    "in one language": 0.2,
    "one language using": 0.5,
    "language using an": 1.0,
    "using an answer": 0.5,
    "an answer corpus": 0.5,
    "answer corpus in": 1.0,
    "corpus in another": 0.5,
    "another language -lrb-": 0.3333333333333333,
    "language -lrb- or": 0.5,
    "-lrb- or even": 0.1,
    "or even several": 0.2,
    "even several -rrb-": 1.0,
    "several -rrb- .": 1.0,
    "<s> this allows": 0.038461538461538464,
    "this allows users": 0.5,
    "users to consult": 0.5,
    "to consult information": 1.0,
    "consult information that": 1.0,
    "information that they": 1.0,
    "they can not": 0.14285714285714285,
    "can not use": 0.06666666666666667,
    "not use directly": 0.5,
    "use directly .": 1.0,
    "-lrb- see also": 0.0625,
    "see also machine": 0.3333333333333333,
    "also machine translation": 1.0,
    "translation . -rrb-": 1.0,
    "<s> interactive qa": 1.0,
    "interactive qa it": 1.0,
    "qa it is": 1.0,
    "is often the": 0.09090909090909091,
    "often the case": 0.5,
    "the case that": 0.125,
    "case that the": 1.0,
    "that the information": 0.043478260869565216,
    "the information need": 0.16666666666666666,
    "information need is": 1.0,
    "need is not": 1.0,
    "is not well": 0.05263157894736842,
    "not well captured": 1.0,
    "well captured by": 1.0,
    "captured by a": 1.0,
    "by a qa": 0.05555555555555555,
    "qa system ,": 0.2,
    "system , as": 0.1,
    ", as the": 0.043478260869565216,
    "as the question": 0.03571428571428571,
    "question processing part": 0.25,
    "processing part may": 1.0,
    "part may fail": 1.0,
    "may fail to": 1.0,
    "fail to classify": 1.0,
    "to classify properly": 1.0,
    "classify properly the": 1.0,
    "properly the question": 1.0,
    "the question or": 0.0625,
    "question or the": 1.0,
    "or the information": 0.1111111111111111,
    "the information needed": 0.16666666666666666,
    "information needed for": 1.0,
    "needed for extracting": 0.5,
    "for extracting and": 1.0,
    "extracting and generating": 1.0,
    "and generating the": 1.0,
    "generating the answer": 1.0,
    "answer is not": 0.5,
    "is not easily": 0.05263157894736842,
    "not easily retrieved": 0.3333333333333333,
    "easily retrieved .": 1.0,
    "<s> in such": 0.010309278350515464,
    "such cases ,": 0.5,
    ", the questioner": 0.009523809523809525,
    "the questioner might": 0.25,
    "questioner might want": 1.0,
    "might want not": 1.0,
    "want not only": 1.0,
    "not only to": 0.14285714285714285,
    "only to reformulate": 1.0,
    "to reformulate the": 1.0,
    "reformulate the question": 1.0,
    "question , but": 0.09090909090909091,
    ", but to": 0.020833333333333332,
    "but to have": 1.0,
    "have a dialogue": 0.07692307692307693,
    "a dialogue with": 0.5,
    "dialogue with the": 1.0,
    "with the system": 0.03333333333333333,
    "the system .": 0.07692307692307693,
    "the system might": 0.038461538461538464,
    "system might ask": 1.0,
    "might ask for": 1.0,
    "ask for a": 1.0,
    "for a clarification": 0.03225806451612903,
    "a clarification of": 1.0,
    "clarification of what": 0.5,
    "of what sense": 0.25,
    "what sense a": 1.0,
    "sense a word": 1.0,
    "word is being": 0.25,
    "is being used": 0.3333333333333333,
    "being used ,": 1.0,
    "used , or": 0.125,
    "or what type": 0.5,
    "what type of": 1.0,
    "type of information": 0.125,
    "of information is": 0.2,
    "information is being": 0.5,
    "is being asked": 0.3333333333333333,
    "being asked for": 1.0,
    "asked for .": 1.0,
    "for . -rrb-": 1.0,
    "<s> advanced reasoning": 0.3333333333333333,
    "advanced reasoning for": 1.0,
    "reasoning for qa": 1.0,
    "for qa more": 0.3333333333333333,
    "qa more sophisticated": 1.0,
    "more sophisticated questioners": 0.2,
    "sophisticated questioners expect": 1.0,
    "questioners expect answers": 1.0,
    "expect answers that": 1.0,
    "answers that are": 1.0,
    "that are outside": 0.06666666666666667,
    "are outside the": 1.0,
    "outside the scope": 1.0,
    "scope of written": 0.5,
    "of written texts": 0.25,
    "written texts or": 0.5,
    "texts or structured": 1.0,
    "or structured databases": 1.0,
    "structured databases .": 1.0,
    "<s> to upgrade": 0.125,
    "to upgrade a": 1.0,
    "upgrade a qa": 1.0,
    "qa system with": 0.2,
    "system with such": 1.0,
    "with such capabilities": 1.0,
    "such capabilities ,": 1.0,
    "capabilities , it": 1.0,
    ", it would": 0.041666666666666664,
    "would be necessary": 0.1111111111111111,
    "be necessary to": 0.5,
    "necessary to integrate": 0.5,
    "to integrate reasoning": 1.0,
    "integrate reasoning components": 1.0,
    "reasoning components operating": 1.0,
    "components operating on": 1.0,
    "operating on a": 1.0,
    "on a variety": 0.041666666666666664,
    "variety of knowledge": 0.125,
    "of knowledge bases": 0.3333333333333333,
    "knowledge bases ,": 1.0,
    "bases , encoding": 1.0,
    ", encoding world": 1.0,
    "encoding world knowledge": 1.0,
    "world knowledge and": 0.5,
    "knowledge and common-sense": 0.5,
    "and common-sense reasoning": 1.0,
    "common-sense reasoning mechanisms": 1.0,
    "reasoning mechanisms ,": 1.0,
    "mechanisms , as": 1.0,
    "well as knowledge": 0.07692307692307693,
    "as knowledge specific": 1.0,
    "knowledge specific to": 1.0,
    "specific to a": 1.0,
    "to a variety": 0.03571428571428571,
    "variety of domains": 0.125,
    "of domains .": 1.0,
    "<s> user profiling": 1.0,
    "user profiling for": 1.0,
    "profiling for qa": 1.0,
    "for qa the": 0.3333333333333333,
    "qa the user": 1.0,
    "the user profile": 0.16666666666666666,
    "user profile captures": 1.0,
    "profile captures data": 1.0,
    "captures data about": 1.0,
    "data about the": 1.0,
    "about the questioner": 0.125,
    "the questioner ,": 0.5,
    "questioner , comprising": 0.5,
    ", comprising context": 1.0,
    "comprising context data": 1.0,
    "context data ,": 1.0,
    "data , domain": 0.1,
    ", domain of": 1.0,
    "domain of interest": 0.5,
    "of interest ,": 0.3333333333333333,
    "interest , reasoning": 1.0,
    ", reasoning schemes": 1.0,
    "reasoning schemes frequently": 1.0,
    "schemes frequently used": 1.0,
    "frequently used by": 1.0,
    "used by the": 0.1111111111111111,
    "by the questioner": 0.03571428571428571,
    "questioner , common": 0.5,
    ", common ground": 1.0,
    "common ground established": 1.0,
    "ground established within": 1.0,
    "established within different": 1.0,
    "within different dialogues": 1.0,
    "different dialogues between": 1.0,
    "dialogues between the": 1.0,
    "between the system": 0.14285714285714285,
    "the system and": 0.038461538461538464,
    "system and the": 0.3333333333333333,
    "and the user": 0.024390243902439025,
    "the user ,": 0.16666666666666666,
    "user , and": 1.0,
    "and so forth": 0.16666666666666666,
    "so forth .": 1.0,
    "<s> the profile": 0.006802721088435374,
    "the profile may": 1.0,
    "profile may be": 1.0,
    "may be represented": 0.047619047619047616,
    "be represented as": 0.5,
    "represented as a": 0.5,
    "as a predefined": 0.027777777777777776,
    "a predefined template": 1.0,
    "predefined template ,": 1.0,
    "template , where": 1.0,
    ", where each": 0.06666666666666667,
    "where each template": 1.0,
    "each template slot": 1.0,
    "template slot represents": 1.0,
    "slot represents a": 1.0,
    "represents a different": 0.3333333333333333,
    "a different profile": 0.2,
    "different profile feature": 1.0,
    "profile feature .": 1.0,
    "<s> profile templates": 1.0,
    "profile templates may": 1.0,
    "templates may be": 1.0,
    "may be nested": 0.047619047619047616,
    "be nested one": 1.0,
    "nested one within": 1.0,
    "one within another": 1.0,
    "within another .": 1.0,
    "<s> history some": 0.5,
    "history some of": 1.0,
    "of the early": 0.010256410256410256,
    "the early ai": 0.6666666666666666,
    "early ai systems": 1.0,
    "ai systems were": 0.5,
    "systems were question": 0.16666666666666666,
    "were question answering": 1.0,
    "question answering systems": 0.08333333333333333,
    "answering systems .": 1.0,
    "<s> two of": 0.2857142857142857,
    "two of the": 1.0,
    "the most famous": 0.08333333333333333,
    "most famous qa": 0.5,
    "famous qa systems": 1.0,
    "qa systems of": 0.16666666666666666,
    "systems of that": 0.16666666666666666,
    "of that time": 0.5,
    "that time are": 1.0,
    "time are baseball": 1.0,
    "are baseball and": 1.0,
    "baseball and lunar": 1.0,
    "and lunar ,": 1.0,
    "lunar , both": 0.5,
    "of which were": 0.1,
    "which were developed": 0.5,
    "were developed in": 0.4,
    "the 1960s .": 0.5,
    "<s> baseball answered": 1.0,
    "baseball answered questions": 1.0,
    "answered questions about": 0.6666666666666666,
    "questions about the": 0.75,
    "about the us": 0.125,
    "the us baseball": 0.5,
    "us baseball league": 1.0,
    "baseball league over": 1.0,
    "league over a": 1.0,
    "over a period": 1.0,
    "a period of": 0.5,
    "period of one": 1.0,
    "of one year": 0.25,
    "one year .": 1.0,
    "<s> lunar ,": 1.0,
    "lunar , in": 0.5,
    ", in turn": 0.029411764705882353,
    "in turn ,": 0.2,
    "turn , answered": 1.0,
    ", answered questions": 1.0,
    "about the geological": 0.125,
    "the geological analysis": 1.0,
    "geological analysis of": 1.0,
    "analysis of rocks": 0.07692307692307693,
    "of rocks returned": 1.0,
    "rocks returned by": 1.0,
    "returned by the": 1.0,
    "by the apollo": 0.03571428571428571,
    "the apollo moon": 1.0,
    "apollo moon missions": 1.0,
    "moon missions .": 1.0,
    "<s> both qa": 0.5,
    "both qa systems": 1.0,
    "qa systems were": 0.3333333333333333,
    "systems were very": 0.16666666666666666,
    "were very effective": 0.5,
    "very effective in": 1.0,
    "effective in their": 0.5,
    "in their chosen": 0.25,
    "their chosen domains": 1.0,
    "chosen domains .": 1.0,
    "fact , lunar": 0.2,
    ", lunar was": 1.0,
    "lunar was demonstrated": 1.0,
    "was demonstrated at": 1.0,
    "demonstrated at a": 1.0,
    "at a lunar": 0.25,
    "a lunar science": 1.0,
    "lunar science convention": 1.0,
    "science convention in": 1.0,
    "convention in 1971": 1.0,
    "in 1971 and": 0.5,
    "1971 and it": 1.0,
    "and it was": 0.2,
    "it was able": 0.2,
    "able to answer": 0.0625,
    "to answer 90": 0.3333333333333333,
    "answer 90 %": 1.0,
    "of the questions": 0.005128205128205128,
    "the questions in": 1.0,
    "questions in its": 1.0,
    "in its domain": 0.5,
    "its domain posed": 0.5,
    "domain posed by": 1.0,
    "posed by people": 1.0,
    "by people untrained": 0.5,
    "people untrained on": 1.0,
    "untrained on the": 1.0,
    "on the system": 0.014925373134328358,
    "<s> further restricted-domain": 0.3333333333333333,
    "further restricted-domain qa": 1.0,
    "restricted-domain qa systems": 1.0,
    "the following years": 0.09090909090909091,
    "following years .": 1.0,
    "<s> the common": 0.006802721088435374,
    "the common feature": 0.5,
    "common feature of": 1.0,
    "feature of all": 0.3333333333333333,
    "of all these": 0.25,
    "all these systems": 1.0,
    "these systems is": 0.1111111111111111,
    "systems is that": 0.3333333333333333,
    "that they had": 0.14285714285714285,
    "they had a": 1.0,
    "had a core": 0.25,
    "a core database": 1.0,
    "core database or": 1.0,
    "database or knowledge": 0.5,
    "or knowledge system": 1.0,
    "knowledge system that": 1.0,
    "system that was": 0.3333333333333333,
    "that was hand-written": 0.3333333333333333,
    "was hand-written by": 1.0,
    "hand-written by experts": 1.0,
    "by experts of": 1.0,
    "experts of the": 1.0,
    "of the chosen": 0.005128205128205128,
    "the chosen domain": 1.0,
    "chosen domain .": 1.0,
    "ai systems included": 0.5,
    "systems included question-answering": 1.0,
    "included question-answering abilities": 1.0,
    "question-answering abilities .": 1.0,
    "most famous early": 0.5,
    "famous early systems": 1.0,
    "early systems are": 1.0,
    "systems are shrdlu": 0.07692307692307693,
    "are shrdlu and": 1.0,
    "shrdlu and eliza": 1.0,
    "and eliza .": 0.5,
    "<s> shrdlu simulated": 0.5,
    "shrdlu simulated the": 1.0,
    "simulated the operation": 1.0,
    "the operation of": 1.0,
    "operation of a": 1.0,
    "of a robot": 0.010869565217391304,
    "a robot in": 1.0,
    "robot in a": 1.0,
    "in a toy": 0.019230769230769232,
    "a toy world": 0.5,
    "toy world -lrb-": 1.0,
    "world -lrb- the": 1.0,
    "-lrb- the ``": 0.125,
    "the `` blocks": 0.14285714285714285,
    "`` blocks world": 0.5,
    "blocks world ''": 1.0,
    "world '' -rrb-": 1.0,
    "and it offered": 0.2,
    "it offered the": 1.0,
    "offered the possibility": 1.0,
    "the possibility to": 0.25,
    "possibility to ask": 1.0,
    "to ask the": 1.0,
    "ask the robot": 0.5,
    "the robot questions": 1.0,
    "robot questions about": 1.0,
    "about the state": 0.125,
    "the state of": 1.0,
    "the world .": 0.125,
    "<s> again ,": 1.0,
    "again , the": 1.0,
    ", the strength": 0.009523809523809525,
    "the strength of": 1.0,
    "strength of this": 0.3333333333333333,
    "of this system": 0.09090909090909091,
    "this system was": 0.5,
    "system was the": 0.4,
    "was the choice": 0.25,
    "choice of a": 0.5,
    "of a very": 0.010869565217391304,
    "a very specific": 0.08333333333333333,
    "very specific domain": 1.0,
    "specific domain and": 0.3333333333333333,
    "domain and a": 1.0,
    "and a very": 0.0625,
    "a very simple": 0.08333333333333333,
    "very simple world": 0.5,
    "simple world with": 1.0,
    "world with rules": 1.0,
    "with rules of": 1.0,
    "rules of physics": 0.25,
    "of physics that": 1.0,
    "physics that were": 1.0,
    "that were easy": 0.25,
    "were easy to": 1.0,
    "easy to encode": 0.3333333333333333,
    "to encode in": 1.0,
    "encode in a": 1.0,
    "in a computer": 0.019230769230769232,
    "<s> eliza ,": 0.3333333333333333,
    "eliza , in": 0.3333333333333333,
    ", in contrast": 0.029411764705882353,
    "contrast , simulated": 0.2,
    ", simulated a": 1.0,
    "simulated a conversation": 1.0,
    "a conversation with": 1.0,
    "with a psychologist": 0.05,
    "a psychologist .": 1.0,
    "<s> eliza was": 0.3333333333333333,
    "eliza was able": 1.0,
    "able to converse": 0.0625,
    "to converse on": 1.0,
    "converse on any": 1.0,
    "any topic by": 0.5,
    "topic by resorting": 1.0,
    "by resorting to": 1.0,
    "resorting to very": 1.0,
    "to very simple": 1.0,
    "very simple rules": 0.5,
    "simple rules that": 1.0,
    "rules that detected": 0.25,
    "that detected important": 1.0,
    "detected important words": 1.0,
    "important words in": 1.0,
    "in the person": 0.006535947712418301,
    "the person 's": 0.5,
    "person 's input": 0.25,
    "'s input .": 1.0,
    "<s> it had": 0.029411764705882353,
    "it had a": 1.0,
    "had a very": 0.25,
    "a very rudimentary": 0.08333333333333333,
    "very rudimentary way": 1.0,
    "rudimentary way to": 1.0,
    "way to answer": 0.1,
    "to answer questions": 0.3333333333333333,
    "answer questions ,": 1.0,
    "questions , and": 0.25,
    ", and on": 0.005291005291005291,
    "and on its": 0.5,
    "its own it": 0.2,
    "own it led": 1.0,
    "it led to": 1.0,
    "led to a": 0.5,
    "to a series": 0.03571428571428571,
    "series of chatterbots": 0.14285714285714285,
    "of chatterbots such": 1.0,
    "chatterbots such as": 1.0,
    "as the ones": 0.03571428571428571,
    "the ones that": 0.5,
    "ones that participate": 1.0,
    "that participate in": 1.0,
    "participate in the": 1.0,
    "in the annual": 0.006535947712418301,
    "the annual loebner": 0.5,
    "annual loebner prize": 1.0,
    "loebner prize .": 1.0,
    "<s> the 1970s": 0.006802721088435374,
    "and 1980s saw": 0.5,
    "1980s saw the": 1.0,
    "saw the development": 1.0,
    "development of comprehensive": 0.14285714285714285,
    "of comprehensive theories": 1.0,
    "comprehensive theories in": 1.0,
    "theories in computational": 1.0,
    "in computational linguistics": 0.5,
    "linguistics , which": 0.125,
    ", which led": 0.017857142857142856,
    "which led to": 1.0,
    "led to the": 0.5,
    "to the development": 0.012987012987012988,
    "development of ambitious": 0.14285714285714285,
    "of ambitious projects": 1.0,
    "ambitious projects in": 1.0,
    "projects in text": 1.0,
    "in text comprehension": 1.0,
    "text comprehension and": 1.0,
    "comprehension and question": 1.0,
    "and question answering": 1.0,
    "<s> one example": 0.08333333333333333,
    "one example of": 1.0,
    "such a system": 0.14285714285714285,
    "a system was": 0.1,
    "was the unix": 0.25,
    "the unix consultant": 0.5,
    "unix consultant -lrb-": 1.0,
    "consultant -lrb- uc": 1.0,
    "-lrb- uc -rrb-": 1.0,
    "uc -rrb- ,": 1.0,
    "a system that": 0.1,
    "system that answered": 0.3333333333333333,
    "that answered questions": 1.0,
    "answered questions pertaining": 0.3333333333333333,
    "questions pertaining to": 1.0,
    "pertaining to the": 1.0,
    "to the unix": 0.012987012987012988,
    "the unix operating": 0.5,
    "unix operating system": 1.0,
    "operating system .": 1.0,
    "the system had": 0.038461538461538464,
    "system had a": 1.0,
    "had a comprehensive": 0.25,
    "a comprehensive hand-crafted": 0.25,
    "comprehensive hand-crafted knowledge": 1.0,
    "hand-crafted knowledge base": 1.0,
    "knowledge base of": 0.25,
    "base of its": 1.0,
    "of its domain": 0.125,
    "its domain ,": 0.5,
    "domain , and": 0.3333333333333333,
    "and it aimed": 0.2,
    "it aimed at": 1.0,
    "aimed at phrasing": 0.5,
    "at phrasing the": 1.0,
    "phrasing the answer": 1.0,
    "answer to accommodate": 0.2,
    "to accommodate various": 0.5,
    "accommodate various types": 1.0,
    "types of users": 0.07142857142857142,
    "of users .": 0.5,
    "<s> another project": 0.07692307692307693,
    "another project was": 1.0,
    "project was lilog": 1.0,
    "was lilog ,": 1.0,
    "lilog , a": 1.0,
    ", a text-understanding": 0.020833333333333332,
    "a text-understanding system": 1.0,
    "text-understanding system that": 1.0,
    "system that operated": 0.3333333333333333,
    "that operated on": 1.0,
    "operated on the": 1.0,
    "on the domain": 0.014925373134328358,
    "the domain of": 0.5,
    "domain of tourism": 0.5,
    "of tourism information": 1.0,
    "tourism information in": 1.0,
    "information in a": 0.5,
    "in a german": 0.019230769230769232,
    "a german city": 1.0,
    "german city .": 1.0,
    "<s> the systems": 0.006802721088435374,
    "the systems developed": 0.25,
    "in the uc": 0.006535947712418301,
    "the uc and": 1.0,
    "uc and lilog": 1.0,
    "and lilog projects": 1.0,
    "lilog projects never": 1.0,
    "projects never went": 1.0,
    "never went past": 1.0,
    "went past the": 1.0,
    "past the stage": 1.0,
    "the stage of": 1.0,
    "stage of simple": 0.5,
    "of simple demonstrations": 0.5,
    "simple demonstrations ,": 1.0,
    "demonstrations , but": 1.0,
    "but they helped": 0.3333333333333333,
    "they helped the": 1.0,
    "helped the development": 1.0,
    "development of theories": 0.14285714285714285,
    "of theories on": 1.0,
    "theories on computational": 1.0,
    "on computational linguistics": 1.0,
    "computational linguistics and": 0.1111111111111111,
    "linguistics and reasoning": 1.0,
    "and reasoning .": 0.5,
    "<s> an increasing": 0.09090909090909091,
    "an increasing number": 1.0,
    "increasing number of": 1.0,
    "number of systems": 0.027777777777777776,
    "of systems include": 0.5,
    "systems include the": 1.0,
    "include the world": 0.2,
    "wide web as": 0.25,
    "web as one": 1.0,
    "as one more": 0.5,
    "one more corpus": 1.0,
    "more corpus of": 1.0,
    "corpus of text": 0.25,
    "text . .": 1.0,
    "however , these": 0.022727272727272728,
    ", these tools": 0.5,
    "these tools mostly": 1.0,
    "tools mostly work": 1.0,
    "mostly work by": 1.0,
    "work by using": 0.5,
    "by using shallow": 0.3333333333333333,
    "using shallow methods": 1.0,
    "shallow methods ,": 1.0,
    "methods , as": 0.25,
    ", as described": 0.043478260869565216,
    "described above --": 0.25,
    "above -- thus": 1.0,
    "-- thus returning": 1.0,
    "thus returning a": 1.0,
    "returning a list": 0.5,
    "list of documents": 0.1,
    "documents , usually": 0.1111111111111111,
    "usually with an": 0.5,
    "with an excerpt": 0.2,
    "an excerpt containing": 1.0,
    "excerpt containing the": 1.0,
    "containing the probable": 0.3333333333333333,
    "the probable answer": 1.0,
    "probable answer highlighted": 1.0,
    "answer highlighted ,": 1.0,
    "highlighted , plus": 1.0,
    ", plus some": 1.0,
    "plus some context": 1.0,
    "some context .": 1.0,
    "furthermore , highly-specialized": 0.16666666666666666,
    ", highly-specialized natural": 1.0,
    "highly-specialized natural language": 1.0,
    "natural language question-answering": 0.014492753623188406,
    "language question-answering engines": 1.0,
    "question-answering engines ,": 1.0,
    "engines , such": 1.0,
    "such as eagli": 0.011111111111111112,
    "as eagli for": 1.0,
    "eagli for health": 1.0,
    "for health and": 1.0,
    "health and life": 1.0,
    "and life scientists": 1.0,
    "life scientists ,": 1.0,
    "scientists , have": 1.0,
    ", have been": 0.5,
    "have been made": 0.038461538461538464,
    "been made available": 1.0,
    "made available .": 1.0,
    "<s> the future": 0.006802721088435374,
    "the future of": 0.3333333333333333,
    "future of question": 1.0,
    "of question answering": 0.25,
    "question answering qa": 0.08333333333333333,
    "answering qa systems": 1.0,
    "qa systems have": 0.16666666666666666,
    "have been extended": 0.038461538461538464,
    "been extended in": 1.0,
    "extended in recent": 1.0,
    "recent years to": 0.25,
    "years to explore": 1.0,
    "to explore critical": 0.5,
    "explore critical new": 1.0,
    "critical new scientific": 1.0,
    "new scientific and": 1.0,
    "scientific and practical": 1.0,
    "and practical dimensions": 1.0,
    "practical dimensions for": 1.0,
    "dimensions for example": 1.0,
    "example , systems": 0.018518518518518517,
    ", systems have": 0.5,
    "have been developed": 0.038461538461538464,
    "been developed to": 1.0,
    "developed to automatically": 1.0,
    "to automatically answer": 0.16666666666666666,
    "automatically answer temporal": 1.0,
    "answer temporal and": 1.0,
    "temporal and geospatial": 1.0,
    "and geospatial questions": 1.0,
    "geospatial questions ,": 1.0,
    "questions , definitional": 0.125,
    ", definitional questions": 1.0,
    "definitional questions ,": 1.0,
    "questions , biographical": 0.125,
    ", biographical questions": 1.0,
    "biographical questions ,": 1.0,
    "questions , multilingual": 0.125,
    ", multilingual questions": 1.0,
    "multilingual questions ,": 1.0,
    ", and questions": 0.005291005291005291,
    "and questions from": 1.0,
    "questions from multimedia": 1.0,
    "from multimedia -lrb-": 1.0,
    "multimedia -lrb- e.g.": 1.0,
    "e.g. , audio": 0.038461538461538464,
    ", audio ,": 1.0,
    "audio , imagery": 0.3333333333333333,
    ", imagery ,": 1.0,
    "imagery , video": 1.0,
    ", video -rrb-": 0.5,
    "video -rrb- .": 1.0,
    "<s> additional aspects": 1.0,
    "additional aspects such": 1.0,
    "aspects such as": 1.0,
    "such as interactivity": 0.011111111111111112,
    "as interactivity -lrb-": 1.0,
    "interactivity -lrb- often": 1.0,
    "-lrb- often required": 0.5,
    "often required for": 1.0,
    "required for clarification": 1.0,
    "for clarification of": 1.0,
    "clarification of questions": 0.5,
    "of questions or": 0.2,
    "questions or answers": 1.0,
    "or answers -rrb-": 1.0,
    "answers -rrb- ,": 1.0,
    "-rrb- , answer": 0.01282051282051282,
    ", answer reuse": 1.0,
    "answer reuse ,": 1.0,
    "reuse , and": 1.0,
    ", and knowledge": 0.005291005291005291,
    "and knowledge representation": 1.0,
    "knowledge representation and": 1.0,
    "representation and reasoning": 0.5,
    "and reasoning to": 0.5,
    "reasoning to support": 1.0,
    "to support question": 0.5,
    "support question answering": 1.0,
    "question answering have": 0.08333333333333333,
    "answering have been": 1.0,
    "have been explored": 0.038461538461538464,
    "been explored .": 1.0,
    "<s> future research": 1.0,
    "future research may": 1.0,
    "research may explore": 1.0,
    "may explore what": 1.0,
    "explore what kinds": 1.0,
    "what kinds of": 1.0,
    "kinds of questions": 1.0,
    "of questions can": 0.2,
    "questions can be": 1.0,
    "can be asked": 0.01098901098901099,
    "be asked and": 1.0,
    "asked and answered": 1.0,
    "and answered about": 1.0,
    "answered about social": 1.0,
    "about social media": 1.0,
    "media , including": 0.3333333333333333,
    ", including sentiment": 0.125,
    "including sentiment analysis": 1.0,
    "sentiment analysis .": 0.2631578947368421,
    "<s> a relationship": 0.022727272727272728,
    "a relationship extraction": 1.0,
    "relationship extraction task": 0.3333333333333333,
    "extraction task requires": 0.5,
    "task requires the": 1.0,
    "requires the detection": 0.3333333333333333,
    "the detection and": 1.0,
    "detection and classification": 1.0,
    "and classification of": 1.0,
    "classification of semantic": 1.0,
    "of semantic relationship": 0.2,
    "semantic relationship mentions": 1.0,
    "relationship mentions within": 1.0,
    "mentions within a": 1.0,
    "within a set": 0.2,
    "set of artifacts": 0.03571428571428571,
    "of artifacts ,": 1.0,
    "artifacts , typically": 1.0,
    ", typically from": 0.3333333333333333,
    "typically from text": 1.0,
    "from text or": 0.5,
    "text or xml": 0.3333333333333333,
    "or xml documents": 1.0,
    "xml documents .": 1.0,
    "task is very": 0.16666666666666666,
    "similar to that": 0.06666666666666667,
    "to that of": 0.5,
    "that of information": 0.125,
    "of information extraction": 0.2,
    "ie -rrb- ,": 0.5,
    ", but ie": 0.020833333333333332,
    "but ie additionally": 1.0,
    "ie additionally requires": 1.0,
    "additionally requires the": 1.0,
    "requires the removal": 0.3333333333333333,
    "the removal of": 1.0,
    "removal of repeated": 1.0,
    "of repeated relations": 1.0,
    "repeated relations -lrb-": 1.0,
    "relations -lrb- disambiguation": 1.0,
    "-lrb- disambiguation -rrb-": 1.0,
    "disambiguation -rrb- and": 0.5,
    "-rrb- and generally": 0.05,
    "and generally refers": 1.0,
    "generally refers to": 1.0,
    "to the extraction": 0.012987012987012988,
    "extraction of many": 0.3333333333333333,
    "many different relationships": 0.16666666666666666,
    "different relationships .": 1.0,
    "<s> approaches one": 0.3333333333333333,
    "approaches one approach": 1.0,
    "one approach to": 1.0,
    "approach to this": 0.16666666666666666,
    "to this problem": 0.16666666666666666,
    "this problem involves": 0.18181818181818182,
    "problem involves the": 0.5,
    "involves the use": 0.5,
    "use of domain": 0.045454545454545456,
    "of domain ontologies": 1.0,
    "domain ontologies .": 0.5,
    "<s> another approach": 0.15384615384615385,
    "another approach involves": 0.5,
    "approach involves visual": 1.0,
    "involves visual detection": 1.0,
    "visual detection of": 1.0,
    "detection of meaningful": 1.0,
    "of meaningful relationships": 1.0,
    "meaningful relationships in": 1.0,
    "relationships in parametric": 1.0,
    "in parametric values": 1.0,
    "parametric values of": 1.0,
    "values of objects": 0.25,
    "of objects listed": 1.0,
    "objects listed on": 1.0,
    "listed on a": 1.0,
    "on a data": 0.041666666666666664,
    "a data table": 1.0,
    "data table that": 1.0,
    "table that shift": 1.0,
    "that shift positions": 1.0,
    "shift positions as": 1.0,
    "positions as the": 1.0,
    "as the table": 0.03571428571428571,
    "the table is": 0.5,
    "table is permuted": 1.0,
    "is permuted automatically": 1.0,
    "permuted automatically as": 1.0,
    "automatically as controlled": 1.0,
    "as controlled by": 1.0,
    "controlled by the": 1.0,
    "by the software": 0.03571428571428571,
    "the software user": 0.25,
    "software user .": 1.0,
    "<s> the poor": 0.006802721088435374,
    "the poor coverage": 1.0,
    "poor coverage ,": 1.0,
    "coverage , rarity": 1.0,
    ", rarity and": 1.0,
    "rarity and development": 1.0,
    "and development cost": 0.3333333333333333,
    "development cost related": 1.0,
    "cost related to": 1.0,
    "related to structured": 0.25,
    "to structured resources": 1.0,
    "structured resources such": 1.0,
    "resources such as": 1.0,
    "such as semantic": 0.011111111111111112,
    "as semantic lexicons": 1.0,
    "semantic lexicons -lrb-": 1.0,
    "lexicons -lrb- e.g.": 1.0,
    "-lrb- e.g. wordnet": 0.02631578947368421,
    "e.g. wordnet ,": 1.0,
    "wordnet , umls": 1.0,
    ", umls -rrb-": 1.0,
    "umls -rrb- and": 1.0,
    "-rrb- and domain": 0.05,
    "and domain ontologies": 1.0,
    "domain ontologies -lrb-": 0.5,
    "ontologies -lrb- e.g.": 1.0,
    "e.g. the gene": 0.2,
    "the gene ontology": 1.0,
    "gene ontology -rrb-": 1.0,
    "ontology -rrb- has": 1.0,
    "-rrb- has given": 0.3333333333333333,
    "has given rise": 1.0,
    "given rise to": 1.0,
    "rise to new": 1.0,
    "to new approaches": 0.25,
    "new approaches based": 1.0,
    "approaches based on": 1.0,
    "based on broad": 0.021739130434782608,
    "on broad ,": 1.0,
    "broad , dynamic": 1.0,
    ", dynamic background": 1.0,
    "dynamic background knowledge": 1.0,
    "background knowledge on": 1.0,
    "on the web": 0.029850746268656716,
    "the web .": 0.25,
    ", the archiles": 0.009523809523809525,
    "the archiles technique": 1.0,
    "archiles technique uses": 1.0,
    "technique uses only": 1.0,
    "uses only wikipedia": 1.0,
    "only wikipedia and": 1.0,
    "wikipedia and search": 1.0,
    "and search engine": 1.0,
    "search engine page": 1.0,
    "engine page count": 1.0,
    "page count for": 1.0,
    "count for acquiring": 1.0,
    "for acquiring coarse-grained": 1.0,
    "acquiring coarse-grained relations": 1.0,
    "coarse-grained relations to": 1.0,
    "relations to construct": 1.0,
    "to construct lightweight": 1.0,
    "construct lightweight ontologies": 1.0,
    "lightweight ontologies .": 1.0,
    "<s> the relationships": 0.006802721088435374,
    "the relationships can": 0.5,
    "relationships can be": 1.0,
    "can be represented": 0.01098901098901099,
    "be represented using": 0.5,
    "represented using a": 1.0,
    "using a variety": 0.1,
    "variety of formalisms\\/languages": 0.125,
    "of formalisms\\/languages .": 1.0,
    "<s> one such": 0.08333333333333333,
    "one such representation": 1.0,
    "such representation language": 1.0,
    "representation language for": 0.5,
    "language for data": 0.3333333333333333,
    "for data on": 0.5,
    "data on the": 1.0,
    "the web is": 0.25,
    "web is rdf": 1.0,
    "is rdf .": 1.0,
    "<s> jump to": 1.0,
    "jump to :": 1.0,
    "to : navigation": 1.0,
    ": navigation ,": 1.0,
    "navigation , search": 1.0,
    ", search sentence": 0.5,
    "search sentence boundary": 1.0,
    "boundary disambiguation -lrb-": 0.5,
    "disambiguation -lrb- sbd": 1.0,
    "-lrb- sbd -rrb-": 1.0,
    "sbd -rrb- ,": 1.0,
    ", also known": 0.2,
    "as sentence breaking": 0.5,
    "sentence breaking ,": 0.5,
    "breaking , is": 1.0,
    "is the problem": 0.06666666666666667,
    "the problem in": 0.16666666666666666,
    "problem in natural": 0.5,
    "language processing of": 0.05555555555555555,
    "processing of deciding": 0.5,
    "of deciding where": 1.0,
    "deciding where sentences": 1.0,
    "where sentences begin": 0.5,
    "sentences begin and": 1.0,
    "begin and end": 1.0,
    "and end .": 1.0,
    "<s> often natural": 0.3333333333333333,
    "often natural language": 1.0,
    "language processing tools": 0.027777777777777776,
    "processing tools require": 1.0,
    "tools require their": 1.0,
    "require their input": 1.0,
    "their input to": 1.0,
    "input to be": 0.3333333333333333,
    "to be divided": 0.023255813953488372,
    "be divided into": 1.0,
    "divided into sentences": 0.5,
    "into sentences for": 1.0,
    "sentences for a": 1.0,
    "number of reasons": 0.027777777777777776,
    "of reasons .": 1.0,
    "<s> however sentence": 0.02702702702702703,
    "however sentence boundary": 1.0,
    "sentence boundary identification": 0.25,
    "boundary identification is": 1.0,
    "identification is challenging": 1.0,
    "is challenging because": 1.0,
    "challenging because punctuation": 1.0,
    "because punctuation marks": 1.0,
    "punctuation marks are": 0.5,
    "marks are often": 1.0,
    "are often ambiguous": 0.25,
    "often ambiguous .": 1.0,
    ", a period": 0.020833333333333332,
    "a period may": 0.5,
    "period may denote": 1.0,
    "may denote an": 1.0,
    "denote an abbreviation": 1.0,
    "an abbreviation ,": 1.0,
    "abbreviation , decimal": 1.0,
    ", decimal point": 1.0,
    "decimal point ,": 1.0,
    "point , an": 0.5,
    ", an ellipsis": 0.1,
    "an ellipsis ,": 1.0,
    "ellipsis , or": 1.0,
    ", or an": 0.030303030303030304,
    "or an email": 0.5,
    "an email address": 1.0,
    "email address -": 1.0,
    "address - not": 1.0,
    "- not the": 1.0,
    "not the end": 0.2,
    "the end of": 0.5,
    "end of a": 0.5,
    "a sentence .": 0.2857142857142857,
    "<s> about 47": 1.0,
    "about 47 %": 1.0,
    "47 % of": 1.0,
    "of the periods": 0.005128205128205128,
    "the periods in": 1.0,
    "periods in the": 1.0,
    "in the wall": 0.006535947712418301,
    "street journal corpus": 0.5,
    "journal corpus denote": 1.0,
    "corpus denote abbreviations": 1.0,
    "denote abbreviations .": 1.0,
    "<s> as well": 0.07142857142857142,
    "as well ,": 0.06666666666666667,
    "well , question": 1.0,
    ", question marks": 0.5,
    "question marks and": 1.0,
    "marks and exclamation": 1.0,
    "and exclamation marks": 1.0,
    "exclamation marks may": 1.0,
    "marks may appear": 1.0,
    "may appear in": 1.0,
    "appear in embedded": 0.14285714285714285,
    "in embedded quotations": 1.0,
    "embedded quotations ,": 1.0,
    "quotations , emoticons": 1.0,
    ", emoticons ,": 1.0,
    "emoticons , computer": 1.0,
    ", computer code": 0.3333333333333333,
    "computer code ,": 1.0,
    "code , and": 0.5,
    ", and slang": 0.005291005291005291,
    "and slang .": 1.0,
    "<s> languages like": 0.3333333333333333,
    "languages like japanese": 0.5,
    "like japanese and": 1.0,
    "japanese and chinese": 0.5,
    "and chinese have": 1.0,
    "chinese have unambiguous": 1.0,
    "have unambiguous sentence-ending": 1.0,
    "unambiguous sentence-ending markers": 1.0,
    "sentence-ending markers .": 1.0,
    "<s> -lrb- b": 0.05263157894736842,
    "-lrb- b -rrb-": 1.0,
    "b -rrb- if": 1.0,
    "-rrb- if the": 1.0,
    "if the preceding": 0.07142857142857142,
    "the preceding token": 1.0,
    "preceding token is": 1.0,
    "token is on": 0.5,
    "is on my": 0.5,
    "on my hand-compiled": 1.0,
    "my hand-compiled list": 1.0,
    "hand-compiled list of": 1.0,
    "list of abbreviations": 0.1,
    "of abbreviations ,": 0.5,
    "abbreviations , then": 0.5,
    ", then it": 0.18181818181818182,
    "then it does": 0.5,
    "it does n't": 1.0,
    "does n't end": 1.0,
    "n't end a": 1.0,
    "end a sentence": 1.0,
    "<s> -lrb- c": 0.05263157894736842,
    "-lrb- c -rrb-": 1.0,
    "c -rrb- if": 1.0,
    "if the next": 0.07142857142857142,
    "the next token": 0.14285714285714285,
    "next token is": 1.0,
    "token is capitalized": 0.5,
    "is capitalized ,": 1.0,
    "capitalized , then": 0.5,
    "then it ends": 0.5,
    "it ends a": 0.5,
    "ends a sentence": 1.0,
    "<s> this strategy": 0.019230769230769232,
    "this strategy gets": 1.0,
    "strategy gets about": 1.0,
    "gets about 95": 1.0,
    "about 95 %": 1.0,
    "95 % of": 0.25,
    "% of sentences": 0.125,
    "of sentences correct": 0.14285714285714285,
    "sentences correct .": 1.0,
    "another approach is": 0.5,
    "approach is to": 0.4,
    "is to automatically": 0.05263157894736842,
    "automatically learn a": 0.5,
    "learn a set": 0.3333333333333333,
    "set of rules": 0.03571428571428571,
    "of rules from": 0.3333333333333333,
    "rules from a": 1.0,
    "of documents where": 0.2,
    "documents where the": 1.0,
    "where the sentence": 0.07692307692307693,
    "the sentence breaks": 0.16666666666666666,
    "sentence breaks are": 1.0,
    "breaks are pre-marked": 1.0,
    "are pre-marked .": 1.0,
    "<s> solutions have": 1.0,
    "solutions have been": 1.0,
    "have been based": 0.038461538461538464,
    "been based on": 1.0,
    "on a maximum": 0.041666666666666664,
    "maximum entropy model": 0.2,
    "entropy model .": 1.0,
    "<s> the satz": 0.006802721088435374,
    "the satz architecture": 1.0,
    "satz architecture uses": 1.0,
    "architecture uses a": 1.0,
    "uses a neural": 0.25,
    "a neural network": 1.0,
    "neural network to": 0.16666666666666666,
    "network to disambiguate": 1.0,
    "to disambiguate sentence": 0.3333333333333333,
    "disambiguate sentence boundaries": 1.0,
    "sentence boundaries and": 0.2,
    "boundaries and achieves": 1.0,
    "and achieves 98.5": 1.0,
    "achieves 98.5 %": 1.0,
    "98.5 % accuracy": 1.0,
    "% accuracy .": 0.25,
    "sentiment analysis or": 0.05263157894736842,
    "analysis or opinion": 0.3333333333333333,
    "or opinion mining": 1.0,
    "opinion mining refers": 1.0,
    "mining refers to": 1.0,
    "to the application": 0.012987012987012988,
    "the application of": 1.0,
    "application of natural": 0.25,
    "processing , computational": 0.1111111111111111,
    ", computational linguistics": 1.0,
    "linguistics , and": 0.125,
    ", and text": 0.005291005291005291,
    "and text analytics": 0.25,
    "text analytics to": 1.0,
    "analytics to identify": 1.0,
    "to identify and": 0.2,
    "identify and extract": 1.0,
    "and extract subjective": 1.0,
    "subjective information in": 0.5,
    "information in source": 0.5,
    "in source materials": 1.0,
    "source materials .": 1.0,
    "speaking , sentiment": 0.2,
    ", sentiment analysis": 1.0,
    "sentiment analysis aims": 0.05263157894736842,
    "analysis aims to": 1.0,
    "aims to determine": 0.5,
    "determine the attitude": 0.1,
    "the attitude of": 0.5,
    "attitude of a": 1.0,
    "of a speaker": 0.021739130434782608,
    "a speaker or": 0.25,
    "speaker or a": 1.0,
    "or a writer": 0.05263157894736842,
    "a writer with": 1.0,
    "writer with respect": 1.0,
    "respect to some": 0.14285714285714285,
    "to some topic": 0.2,
    "some topic or": 1.0,
    "topic or the": 1.0,
    "or the overall": 0.1111111111111111,
    "the overall contextual": 0.3333333333333333,
    "overall contextual polarity": 1.0,
    "contextual polarity of": 1.0,
    "polarity of a": 0.5,
    "a document .": 0.125,
    "<s> the attitude": 0.006802721088435374,
    "the attitude may": 0.5,
    "attitude may be": 1.0,
    "may be his": 0.047619047619047616,
    "be his or": 1.0,
    "his or her": 1.0,
    "or her judgement": 0.5,
    "her judgement or": 1.0,
    "judgement or evaluation": 1.0,
    "or evaluation -lrb-": 1.0,
    "evaluation -lrb- see": 0.5,
    "-lrb- see appraisal": 0.0625,
    "see appraisal theory": 1.0,
    "appraisal theory -rrb-": 1.0,
    "theory -rrb- ,": 1.0,
    "-rrb- , affective": 0.01282051282051282,
    ", affective state": 1.0,
    "affective state -lrb-": 0.5,
    "state -lrb- that": 1.0,
    "that is to": 0.10526315789473684,
    "is to say": 0.10526315789473684,
    "to say ,": 0.6666666666666666,
    "say , the": 1.0,
    ", the emotional": 0.01904761904761905,
    "the emotional state": 0.5,
    "emotional state of": 1.0,
    "of the author": 0.005128205128205128,
    "the author when": 0.3333333333333333,
    "author when writing": 1.0,
    "when writing -rrb-": 0.5,
    "writing -rrb- ,": 0.5,
    ", or the": 0.06060606060606061,
    "or the intended": 0.1111111111111111,
    "the intended emotional": 0.5,
    "intended emotional communication": 1.0,
    "emotional communication -lrb-": 1.0,
    "communication -lrb- that": 0.5,
    "the emotional effect": 0.5,
    "emotional effect the": 1.0,
    "effect the author": 1.0,
    "the author wishes": 0.3333333333333333,
    "author wishes to": 1.0,
    "wishes to have": 1.0,
    "to have on": 0.1,
    "have on the": 1.0,
    "on the reader": 0.014925373134328358,
    "the reader -rrb-": 0.16666666666666666,
    "reader -rrb- .": 1.0,
    "<s> advanced ,": 0.3333333333333333,
    "advanced , ``": 1.0,
    ", `` beyond": 0.04,
    "`` beyond polarity": 1.0,
    "beyond polarity ''": 1.0,
    "polarity '' sentiment": 0.5,
    "'' sentiment classification": 1.0,
    "sentiment classification looks": 1.0,
    "classification looks ,": 1.0,
    "looks , for": 1.0,
    "instance , at": 0.1111111111111111,
    ", at emotional": 0.3333333333333333,
    "at emotional states": 1.0,
    "emotional states such": 1.0,
    "states such as": 1.0,
    "as `` angry": 0.07142857142857142,
    "`` angry ,": 1.0,
    "angry , ''": 1.0,
    ", '' ``": 0.3333333333333333,
    "'' `` sad": 1.0,
    "`` sad ,": 1.0,
    "sad , ''": 1.0,
    ", '' and": 0.3333333333333333,
    "and `` happy": 0.05,
    "`` happy .": 1.0,
    "happy . ''": 1.0,
    "<s> early work": 0.5,
    "early work in": 1.0,
    "work in that": 0.25,
    "in that area": 0.5,
    "that area includes": 1.0,
    "area includes turney": 1.0,
    "includes turney and": 1.0,
    "turney and pang": 0.5,
    "and pang who": 1.0,
    "pang who applied": 1.0,
    "who applied different": 1.0,
    "applied different methods": 1.0,
    "different methods for": 1.0,
    "methods for detecting": 0.25,
    "for detecting the": 1.0,
    "detecting the polarity": 1.0,
    "the polarity of": 1.0,
    "polarity of product": 0.5,
    "of product reviews": 1.0,
    "product reviews and": 1.0,
    "reviews and movie": 1.0,
    "and movie reviews": 1.0,
    "movie reviews respectively": 1.0,
    "reviews respectively .": 1.0,
    "work is at": 0.3333333333333333,
    "is at the": 1.0,
    "at the document": 0.0625,
    "the document level": 0.16666666666666666,
    "document level .": 1.0,
    "<s> one can": 0.08333333333333333,
    "one can also": 0.5,
    "can also classify": 0.125,
    "also classify a": 1.0,
    "classify a document": 1.0,
    "a document 's": 0.125,
    "document 's polarity": 1.0,
    "'s polarity on": 1.0,
    "polarity on a": 1.0,
    "on a multi-way": 0.041666666666666664,
    "a multi-way scale": 1.0,
    "multi-way scale ,": 1.0,
    "scale , which": 0.5,
    "which was attempted": 0.2,
    "was attempted by": 1.0,
    "attempted by pang": 1.0,
    "by pang and": 1.0,
    "pang and snyder": 1.0,
    "and snyder -lrb-": 1.0,
    "snyder -lrb- among": 1.0,
    "-lrb- among others": 0.5,
    "among others -rrb-": 1.0,
    "others -rrb- :": 1.0,
    "-rrb- : expanded": 0.1111111111111111,
    ": expanded the": 1.0,
    "expanded the basic": 1.0,
    "the basic task": 0.5,
    "basic task of": 1.0,
    "task of classifying": 0.1111111111111111,
    "of classifying a": 1.0,
    "classifying a movie": 0.5,
    "a movie review": 0.5,
    "movie review as": 1.0,
    "review as either": 1.0,
    "as either positive": 1.0,
    "either positive or": 1.0,
    "or negative to": 0.5,
    "negative to predicting": 1.0,
    "to predicting star": 1.0,
    "predicting star ratings": 1.0,
    "star ratings on": 1.0,
    "ratings on either": 1.0,
    "on either a": 1.0,
    "either a 3": 0.5,
    "a 3 or": 1.0,
    "3 or a": 1.0,
    "or a 4": 0.05263157894736842,
    "a 4 star": 1.0,
    "4 star scale": 1.0,
    "star scale ,": 1.0,
    "scale , while": 0.5,
    ", while snyder": 0.07142857142857142,
    "while snyder performed": 1.0,
    "snyder performed an": 1.0,
    "performed an in-depth": 1.0,
    "an in-depth analysis": 1.0,
    "in-depth analysis of": 1.0,
    "analysis of restaurant": 0.07692307692307693,
    "of restaurant reviews": 1.0,
    "restaurant reviews ,": 1.0,
    "reviews , predicting": 0.3333333333333333,
    ", predicting ratings": 1.0,
    "predicting ratings for": 1.0,
    "ratings for various": 1.0,
    "for various aspects": 1.0,
    "various aspects of": 1.0,
    "aspects of the": 0.16666666666666666,
    "the given restaurant": 0.5,
    "given restaurant ,": 1.0,
    "restaurant , such": 1.0,
    "as the food": 0.03571428571428571,
    "the food and": 1.0,
    "food and atmosphere": 1.0,
    "and atmosphere -lrb-": 1.0,
    "atmosphere -lrb- on": 1.0,
    "-lrb- on a": 0.5,
    "on a five-star": 0.041666666666666664,
    "a five-star scale": 1.0,
    "five-star scale -rrb-": 1.0,
    "scale -rrb- .": 1.0,
    "a different method": 0.2,
    "different method for": 1.0,
    "method for determining": 0.5,
    "for determining sentiment": 0.5,
    "determining sentiment is": 1.0,
    "sentiment is the": 1.0,
    "is the use": 0.022222222222222223,
    "of a scaling": 0.010869565217391304,
    "a scaling system": 1.0,
    "scaling system whereby": 1.0,
    "system whereby words": 1.0,
    "whereby words commonly": 1.0,
    "words commonly associated": 1.0,
    "commonly associated with": 1.0,
    "associated with having": 1.0,
    "with having a": 1.0,
    "having a negative": 1.0,
    "a negative ,": 1.0,
    "negative , neutral": 1.0,
    ", neutral or": 1.0,
    "neutral or positive": 1.0,
    "or positive sentiment": 1.0,
    "positive sentiment with": 1.0,
    "sentiment with them": 1.0,
    "with them are": 0.3333333333333333,
    "them are given": 0.5,
    "are given an": 0.3333333333333333,
    "given an associated": 0.5,
    "an associated number": 1.0,
    "associated number on": 1.0,
    "number on a": 1.0,
    "on a -5": 0.041666666666666664,
    "a -5 to": 1.0,
    "-5 to +5": 1.0,
    "to +5 scale": 1.0,
    "+5 scale -lrb-": 1.0,
    "scale -lrb- most": 1.0,
    "-lrb- most negative": 0.25,
    "most negative up": 1.0,
    "negative up to": 1.0,
    "up to most": 0.16666666666666666,
    "to most positive": 1.0,
    "most positive -rrb-": 1.0,
    "positive -rrb- and": 1.0,
    "-rrb- and when": 0.05,
    "and when a": 1.0,
    "when a piece": 0.2,
    "piece of unstructured": 0.3333333333333333,
    "of unstructured text": 1.0,
    "unstructured text is": 1.0,
    "text is analyzed": 0.25,
    "is analyzed using": 0.3333333333333333,
    "analyzed using natural": 1.0,
    "using natural language": 1.0,
    "processing , the": 0.1111111111111111,
    ", the subsequent": 0.009523809523809525,
    "the subsequent concepts": 1.0,
    "subsequent concepts are": 1.0,
    "concepts are analyzed": 0.5,
    "are analyzed for": 1.0,
    "analyzed for an": 1.0,
    "for an understanding": 1.0,
    "understanding of these": 0.2,
    "of these words": 0.09090909090909091,
    "these words and": 0.5,
    "words and how": 0.125,
    "how they relate": 0.3333333333333333,
    "they relate to": 1.0,
    "relate to the": 1.0,
    "to the concept": 0.025974025974025976,
    "the concept -lrb-": 0.5,
    "concept -lrb- citation": 1.0,
    "<s> each concept": 0.2,
    "each concept is": 1.0,
    "concept is then": 1.0,
    "is then given": 0.2,
    "then given a": 1.0,
    "given a score": 0.07142857142857142,
    "a score based": 1.0,
    "score based on": 1.0,
    "on the way": 0.014925373134328358,
    "the way sentiment": 0.25,
    "way sentiment words": 1.0,
    "sentiment words relate": 1.0,
    "words relate to": 1.0,
    "the concept ,": 0.5,
    "concept , and": 1.0,
    ", and their": 0.005291005291005291,
    "and their associated": 0.16666666666666666,
    "their associated score": 1.0,
    "associated score .": 1.0,
    "this allows movement": 0.5,
    "allows movement to": 1.0,
    "movement to a": 1.0,
    "to a more": 0.03571428571428571,
    "a more sophisticated": 0.2,
    "more sophisticated understanding": 0.2,
    "sophisticated understanding of": 1.0,
    "understanding of sentiment": 0.2,
    "of sentiment based": 0.2,
    "sentiment based on": 1.0,
    "based on an": 0.021739130434782608,
    "on an 11": 0.3333333333333333,
    "an 11 point": 1.0,
    "11 point scale": 1.0,
    "point scale .": 1.0,
    "alternatively , texts": 0.5,
    ", texts can": 1.0,
    "texts can be": 1.0,
    "can be given": 0.01098901098901099,
    "be given a": 1.0,
    "given a positive": 0.07142857142857142,
    "a positive and": 1.0,
    "and negative sentiment": 0.5,
    "negative sentiment strength": 1.0,
    "sentiment strength score": 1.0,
    "strength score if": 1.0,
    "score if the": 1.0,
    "if the goal": 0.07142857142857142,
    "is to determine": 0.05263157894736842,
    "determine the sentiment": 0.1,
    "the sentiment in": 0.5,
    "sentiment in a": 0.5,
    "a text rather": 0.07142857142857142,
    "text rather than": 1.0,
    "rather than the": 0.07142857142857142,
    "than the overall": 0.25,
    "the overall polarity": 0.3333333333333333,
    "overall polarity and": 1.0,
    "polarity and strength": 1.0,
    "and strength of": 1.0,
    "strength of the": 0.3333333333333333,
    "<s> another research": 0.07692307692307693,
    "another research direction": 1.0,
    "research direction is": 1.0,
    "direction is subjectivity\\/objectivity": 1.0,
    "is subjectivity\\/objectivity identification": 1.0,
    "subjectivity\\/objectivity identification .": 1.0,
    "task is commonly": 0.16666666666666666,
    "is commonly defined": 0.5,
    "commonly defined as": 1.0,
    "defined as classifying": 1.0,
    "as classifying a": 1.0,
    "classifying a given": 0.5,
    "a given text": 0.08333333333333333,
    "given text -lrb-": 1.0,
    "text -lrb- usually": 0.16666666666666666,
    "-lrb- usually a": 0.5,
    "usually a sentence": 1.0,
    "a sentence -rrb-": 0.07142857142857142,
    "sentence -rrb- into": 0.5,
    "-rrb- into one": 0.5,
    "into one of": 0.5,
    "one of two": 0.0625,
    "of two classes": 0.5,
    "two classes :": 1.0,
    "classes : objective": 1.0,
    ": objective or": 1.0,
    "objective or subjective": 1.0,
    "or subjective .": 0.5,
    "this problem can": 0.09090909090909091,
    "problem can sometimes": 1.0,
    "can sometimes be": 1.0,
    "sometimes be more": 1.0,
    "be more difficult": 0.2,
    "difficult than polarity": 0.3333333333333333,
    "than polarity classification": 1.0,
    "polarity classification :": 1.0,
    "classification : the": 1.0,
    ": the subjectivity": 0.16666666666666666,
    "the subjectivity of": 1.0,
    "subjectivity of words": 1.0,
    "and phrases may": 0.5,
    "phrases may depend": 1.0,
    "may depend on": 1.0,
    "depend on their": 0.3333333333333333,
    "on their context": 0.5,
    "their context and": 1.0,
    "context and an": 0.2,
    "and an objective": 0.3333333333333333,
    "an objective document": 1.0,
    "objective document may": 1.0,
    "document may contain": 1.0,
    "may contain subjective": 0.5,
    "contain subjective sentences": 1.0,
    "subjective sentences -lrb-": 1.0,
    "e.g. , a": 0.07692307692307693,
    ", a news": 0.020833333333333332,
    "a news article": 0.5,
    "news article quoting": 0.5,
    "article quoting people": 1.0,
    "quoting people 's": 1.0,
    "people 's opinions": 1.0,
    "'s opinions -rrb-": 1.0,
    "opinions -rrb- .": 1.0,
    "moreover , as": 0.25,
    ", as mentioned": 0.043478260869565216,
    "as mentioned by": 0.25,
    "mentioned by su": 1.0,
    "by su ,": 1.0,
    "su , results": 1.0,
    ", results are": 1.0,
    "results are largely": 0.25,
    "are largely dependent": 1.0,
    "largely dependent on": 1.0,
    "dependent on the": 0.5,
    "on the definition": 0.014925373134328358,
    "definition of subjectivity": 0.3333333333333333,
    "of subjectivity used": 1.0,
    "subjectivity used when": 1.0,
    "used when annotating": 0.5,
    "when annotating texts": 1.0,
    "annotating texts .": 1.0,
    "however , pang": 0.022727272727272728,
    ", pang showed": 1.0,
    "pang showed that": 1.0,
    "showed that removing": 0.3333333333333333,
    "that removing objective": 1.0,
    "removing objective sentences": 1.0,
    "objective sentences from": 1.0,
    "sentences from a": 0.5,
    "from a document": 0.08333333333333333,
    "a document before": 0.125,
    "document before classifying": 1.0,
    "before classifying its": 1.0,
    "classifying its polarity": 1.0,
    "its polarity helped": 1.0,
    "polarity helped improve": 1.0,
    "helped improve performance": 1.0,
    "improve performance .": 1.0,
    "<s> the more": 0.006802721088435374,
    "the more fine-grained": 0.16666666666666666,
    "more fine-grained analysis": 1.0,
    "fine-grained analysis model": 1.0,
    "analysis model is": 1.0,
    "model is called": 0.3333333333333333,
    "is called the": 0.16666666666666666,
    "called the feature\\/aspect-based": 0.5,
    "the feature\\/aspect-based sentiment": 1.0,
    "feature\\/aspect-based sentiment analysis": 1.0,
    "<s> it refers": 0.029411764705882353,
    "it refers to": 1.0,
    "refers to determining": 0.2,
    "to determining the": 1.0,
    "determining the opinions": 0.25,
    "the opinions or": 1.0,
    "opinions or sentiments": 1.0,
    "or sentiments expressed": 1.0,
    "sentiments expressed on": 1.0,
    "expressed on different": 0.5,
    "on different features": 1.0,
    "different features or": 1.0,
    "features or aspects": 1.0,
    "or aspects of": 1.0,
    "aspects of entities": 0.16666666666666666,
    "of entities ,": 1.0,
    "entities , e.g.": 0.5,
    "e.g. , of": 0.038461538461538464,
    ", of a": 0.25,
    "of a cell": 0.021739130434782608,
    "a cell phone": 1.0,
    "cell phone ,": 1.0,
    "phone , a": 0.5,
    ", a digital": 0.020833333333333332,
    "a digital camera": 0.5,
    "digital camera ,": 1.0,
    "camera , or": 1.0,
    "or a bank": 0.05263157894736842,
    "a bank .": 1.0,
    "<s> a feature": 0.022727272727272728,
    "a feature or": 0.3333333333333333,
    "feature or aspect": 1.0,
    "or aspect is": 1.0,
    "aspect is an": 1.0,
    "is an attribute": 0.1,
    "an attribute or": 1.0,
    "attribute or component": 1.0,
    "or component of": 1.0,
    "component of an": 0.3333333333333333,
    "of an entity": 0.07692307692307693,
    "an entity ,": 1.0,
    "entity , e.g.": 0.5,
    ", the screen": 0.009523809523809525,
    "the screen of": 1.0,
    "screen of a": 1.0,
    "phone , or": 0.5,
    "or the picture": 0.1111111111111111,
    "the picture quality": 0.5,
    "picture quality of": 1.0,
    "of a camera": 0.010869565217391304,
    "a camera .": 1.0,
    "problem involves several": 0.5,
    "involves several sub-problems": 1.0,
    "several sub-problems ,": 1.0,
    "sub-problems , e.g.": 1.0,
    "e.g. , identifying": 0.038461538461538464,
    ", identifying relevant": 0.3333333333333333,
    "identifying relevant entities": 1.0,
    "relevant entities ,": 1.0,
    "entities , extracting": 0.5,
    ", extracting their": 1.0,
    "extracting their features\\/aspects": 1.0,
    "their features\\/aspects ,": 1.0,
    "features\\/aspects , and": 1.0,
    ", and determining": 0.005291005291005291,
    "and determining whether": 1.0,
    "determining whether an": 1.0,
    "whether an opinion": 1.0,
    "an opinion expressed": 1.0,
    "opinion expressed on": 1.0,
    "expressed on each": 0.5,
    "on each feature\\/aspect": 1.0,
    "each feature\\/aspect is": 1.0,
    "feature\\/aspect is positive": 1.0,
    "is positive ,": 1.0,
    "positive , negative": 1.0,
    ", negative or": 1.0,
    "negative or neutral": 1.0,
    "or neutral .": 1.0,
    "<s> more detailed": 0.125,
    "more detailed discussions": 1.0,
    "detailed discussions about": 1.0,
    "discussions about this": 1.0,
    "about this level": 1.0,
    "this level of": 1.0,
    "level of sentiment": 0.14285714285714285,
    "of sentiment analysis": 0.6,
    "sentiment analysis can": 0.05263157894736842,
    "analysis can be": 0.5,
    "be found in": 0.3333333333333333,
    "found in liu": 0.3333333333333333,
    "in liu 's": 1.0,
    "liu 's nlp": 1.0,
    "'s nlp handbook": 1.0,
    "nlp handbook chapter": 1.0,
    "handbook chapter ,": 1.0,
    "chapter , ``": 1.0,
    ", `` sentiment": 0.04,
    "`` sentiment analysis": 1.0,
    "sentiment analysis and": 0.10526315789473684,
    "analysis and subjectivity": 0.3333333333333333,
    "and subjectivity ''": 1.0,
    "subjectivity '' .": 1.0,
    "<s> methods computers": 0.3333333333333333,
    "methods computers can": 1.0,
    "computers can perform": 1.0,
    "can perform automated": 1.0,
    "perform automated sentiment": 1.0,
    "automated sentiment analysis": 1.0,
    "sentiment analysis of": 0.05263157894736842,
    "analysis of digital": 0.07692307692307693,
    "of digital texts": 1.0,
    "digital texts ,": 1.0,
    "texts , using": 0.5,
    ", using elements": 0.1,
    "using elements from": 1.0,
    "elements from machine": 1.0,
    "machine learning such": 0.047619047619047616,
    "learning such as": 1.0,
    "such as latent": 0.011111111111111112,
    "as latent semantic": 1.0,
    "latent semantic analysis": 1.0,
    "semantic analysis ,": 0.3333333333333333,
    "analysis , support": 0.14285714285714285,
    ", support vector": 1.0,
    "support vector machines": 1.0,
    "vector machines ,": 1.0,
    "machines , ``": 1.0,
    ", `` bag": 0.04,
    "`` bag of": 1.0,
    "bag of words": 1.0,
    "of words ''": 0.06666666666666667,
    "words '' and": 0.5,
    "'' and semantic": 0.07692307692307693,
    "and semantic orientation": 0.25,
    "semantic orientation --": 1.0,
    "orientation -- pointwise": 1.0,
    "-- pointwise mutual": 1.0,
    "pointwise mutual information": 1.0,
    "mutual information -lrb-": 1.0,
    "information -lrb- see": 0.5,
    "-lrb- see peter": 0.0625,
    "see peter turney": 1.0,
    "peter turney 's": 1.0,
    "turney 's work": 0.25,
    "'s work in": 1.0,
    "work in this": 0.25,
    "this area -rrb-": 0.3333333333333333,
    "area -rrb- .": 1.0,
    "<s> more sophisticated": 0.25,
    "more sophisticated methods": 0.2,
    "sophisticated methods try": 1.0,
    "methods try to": 1.0,
    "try to detect": 0.3333333333333333,
    "to detect the": 1.0,
    "detect the holder": 1.0,
    "the holder of": 1.0,
    "holder of a": 1.0,
    "of a sentiment": 0.021739130434782608,
    "a sentiment -lrb-": 0.5,
    "sentiment -lrb- i.e.": 1.0,
    "i.e. the person": 0.2,
    "the person who": 0.25,
    "person who maintains": 1.0,
    "who maintains that": 1.0,
    "maintains that affective": 1.0,
    "that affective state": 1.0,
    "affective state -rrb-": 0.5,
    "state -rrb- and": 1.0,
    "and the target": 0.024390243902439025,
    "the target -lrb-": 0.1,
    "target -lrb- i.e.": 1.0,
    "i.e. the entity": 0.2,
    "the entity about": 1.0,
    "entity about which": 1.0,
    "about which the": 1.0,
    "which the affect": 0.125,
    "the affect is": 1.0,
    "affect is felt": 1.0,
    "is felt -rrb-": 1.0,
    "felt -rrb- .": 1.0,
    "<s> to mine": 0.125,
    "to mine the": 1.0,
    "mine the opinion": 1.0,
    "the opinion in": 1.0,
    "opinion in context": 0.5,
    "in context and": 0.25,
    "context and get": 0.2,
    "and get the": 1.0,
    "get the feature": 0.5,
    "the feature which": 1.0,
    "feature which has": 1.0,
    "has been opinionated": 0.03571428571428571,
    "been opinionated ,": 1.0,
    "opinionated , the": 1.0,
    ", the grammatical": 0.009523809523809525,
    "the grammatical relationships": 0.3333333333333333,
    "grammatical relationships of": 1.0,
    "relationships of words": 1.0,
    "of words are": 0.06666666666666667,
    "words are used": 0.2,
    "are used .": 0.125,
    "<s> grammatical dependency": 1.0,
    "grammatical dependency relations": 1.0,
    "dependency relations are": 1.0,
    "relations are obtained": 1.0,
    "are obtained by": 1.0,
    "obtained by deep": 0.25,
    "by deep parsing": 1.0,
    "deep parsing of": 1.0,
    "parsing of the": 0.5,
    "<s> open source": 1.0,
    "open source software": 1.0,
    "source software tools": 1.0,
    "software tools deploy": 1.0,
    "tools deploy machine": 1.0,
    "deploy machine learning": 1.0,
    "learning , statistics": 0.25,
    ", statistics ,": 0.5,
    "statistics , and": 1.0,
    ", and natural": 0.005291005291005291,
    "techniques to automate": 0.25,
    "to automate sentiment": 0.5,
    "automate sentiment analysis": 1.0,
    "sentiment analysis on": 0.05263157894736842,
    "analysis on large": 1.0,
    "on large collections": 1.0,
    "large collections of": 1.0,
    "collections of texts": 1.0,
    "of texts ,": 0.5,
    "texts , including": 0.5,
    ", including web": 0.125,
    "including web pages": 1.0,
    "web pages ,": 0.3333333333333333,
    "pages , online": 0.3333333333333333,
    ", online news": 0.3333333333333333,
    "online news ,": 1.0,
    "news , internet": 1.0,
    ", internet discussion": 1.0,
    "internet discussion groups": 1.0,
    "discussion groups ,": 1.0,
    "groups , online": 1.0,
    ", online reviews": 0.3333333333333333,
    "online reviews ,": 0.5,
    "reviews , web": 0.3333333333333333,
    ", web blogs": 1.0,
    "web blogs ,": 1.0,
    "blogs , and": 1.0,
    ", and social": 0.005291005291005291,
    "and social media": 0.3333333333333333,
    "social media .": 0.25,
    "<s> evaluation the": 0.2,
    "evaluation the accuracy": 1.0,
    "accuracy of a": 0.14285714285714285,
    "a sentiment analysis": 0.5,
    "sentiment analysis system": 0.05263157894736842,
    "analysis system is": 1.0,
    "system is ,": 0.1111111111111111,
    "is , in": 0.1111111111111111,
    ", in principle": 0.029411764705882353,
    "in principle ,": 1.0,
    "principle , how": 1.0,
    ", how well": 0.5,
    "well it agrees": 0.5,
    "it agrees with": 1.0,
    "agrees with human": 1.0,
    "with human judgments": 0.5,
    "human judgments .": 1.0,
    "is usually measured": 0.125,
    "usually measured by": 1.0,
    "measured by precision": 0.3333333333333333,
    "by precision and": 1.0,
    "however , human": 0.022727272727272728,
    ", human raters": 0.16666666666666666,
    "human raters typically": 1.0,
    "raters typically agree": 1.0,
    "typically agree about": 1.0,
    "agree about 70": 1.0,
    "70 % -lrb-": 0.3333333333333333,
    "% -lrb- citation": 0.3333333333333333,
    "needed -rrb- of": 0.07692307692307693,
    "the time -lrb-": 0.16666666666666666,
    "time -lrb- see": 0.5,
    "-lrb- see inter-rater": 0.0625,
    "see inter-rater reliability": 1.0,
    "inter-rater reliability -rrb-": 1.0,
    "reliability -rrb- .": 1.0,
    ", a 70": 0.020833333333333332,
    "a 70 %": 1.0,
    "70 % accurate": 0.3333333333333333,
    "% accurate program": 0.5,
    "accurate program is": 1.0,
    "program is doing": 1.0,
    "is doing as": 1.0,
    "doing as well": 1.0,
    "well as humans": 0.07692307692307693,
    "as humans ,": 1.0,
    "humans , even": 0.5,
    ", even though": 0.14285714285714285,
    "even though such": 0.3333333333333333,
    "though such accuracy": 1.0,
    "such accuracy may": 1.0,
    "accuracy may not": 1.0,
    "may not sound": 0.2,
    "not sound impressive": 1.0,
    "sound impressive .": 1.0,
    "<s> if a": 0.125,
    "if a program": 0.5,
    "a program were": 0.25,
    "program were ``": 1.0,
    "were `` right": 1.0,
    "`` right ''": 1.0,
    "right '' 100": 1.0,
    "'' 100 %": 1.0,
    "100 % of": 0.5,
    "time , humans": 0.09090909090909091,
    ", humans would": 1.0,
    "humans would still": 1.0,
    "would still disagree": 1.0,
    "still disagree with": 1.0,
    "disagree with it": 1.0,
    "with it about": 0.3333333333333333,
    "it about 30": 1.0,
    "about 30 %": 1.0,
    "30 % of": 1.0,
    "time , since": 0.09090909090909091,
    ", since they": 0.2,
    "since they disagree": 1.0,
    "they disagree that": 1.0,
    "disagree that much": 1.0,
    "that much about": 1.0,
    "much about any": 1.0,
    "about any answer": 1.0,
    "any answer .": 1.0,
    "more sophisticated measures": 0.2,
    "sophisticated measures can": 1.0,
    "be applied ,": 0.3333333333333333,
    "applied , but": 1.0,
    ", but evaluation": 0.020833333333333332,
    "but evaluation of": 1.0,
    "evaluation of sentiment": 0.2,
    "sentiment analysis systems": 0.05263157894736842,
    "analysis systems remains": 1.0,
    "systems remains a": 1.0,
    "remains a complex": 1.0,
    "a complex matter": 0.2,
    "complex matter .": 1.0,
    "<s> for sentiment": 0.017543859649122806,
    "for sentiment analysis": 1.0,
    "sentiment analysis tasks": 0.05263157894736842,
    "analysis tasks returning": 1.0,
    "tasks returning a": 1.0,
    "returning a scale": 0.5,
    "a scale rather": 1.0,
    "scale rather than": 1.0,
    "rather than a": 0.21428571428571427,
    "than a binary": 0.2,
    "a binary judgement": 0.5,
    "binary judgement ,": 1.0,
    "judgement , correlation": 1.0,
    ", correlation is": 1.0,
    "correlation is a": 1.0,
    "is a better": 0.018518518518518517,
    "a better measure": 0.5,
    "better measure than": 1.0,
    "measure than precision": 1.0,
    "than precision because": 1.0,
    "precision because it": 1.0,
    "because it takes": 0.3333333333333333,
    "it takes into": 1.0,
    "takes into account": 1.0,
    "into account how": 0.3333333333333333,
    "account how close": 1.0,
    "how close the": 1.0,
    "close the predicted": 1.0,
    "the predicted value": 1.0,
    "predicted value is": 1.0,
    "value is to": 1.0,
    "is to the": 0.05263157894736842,
    "to the target": 0.012987012987012988,
    "the target value": 0.1,
    "target value .": 1.0,
    "sentiment analysis was": 0.05263157894736842,
    "analysis was used": 0.5,
    "was used to": 0.25,
    "used to test": 0.045454545454545456,
    "to test the": 0.5,
    "test the relationship": 1.0,
    "the relationship between": 1.0,
    "relationship between internet": 1.0,
    "between internet financial": 1.0,
    "internet financial message": 1.0,
    "financial message boards": 1.0,
    "message boards and": 1.0,
    "boards and the": 1.0,
    "and the behavior": 0.024390243902439025,
    "the behavior of": 1.0,
    "behavior of the": 1.0,
    "of the stock": 0.005128205128205128,
    "the stock market": 1.0,
    "stock market to": 1.0,
    "market to find": 1.0,
    "to find a": 0.1111111111111111,
    "find a strong": 0.5,
    "a strong correlation": 0.5,
    "strong correlation between": 1.0,
    "correlation between posts": 1.0,
    "between posts and": 1.0,
    "posts and volume": 1.0,
    "and volume of": 1.0,
    "volume of stock": 0.5,
    "of stock .": 1.0,
    "analysis and web": 0.3333333333333333,
    "and web 2.0": 1.0,
    "web 2.0 the": 0.5,
    "2.0 the rise": 1.0,
    "the rise of": 1.0,
    "rise of social": 1.0,
    "of social media": 0.5,
    "social media such": 0.25,
    "media such as": 1.0,
    "such as blogs": 0.011111111111111112,
    "as blogs and": 1.0,
    "blogs and social": 1.0,
    "and social networks": 0.3333333333333333,
    "social networks has": 0.3333333333333333,
    "networks has fueled": 1.0,
    "has fueled interest": 1.0,
    "fueled interest in": 1.0,
    "interest in sentiment": 0.14285714285714285,
    "in sentiment analysis": 1.0,
    "with the proliferation": 0.03333333333333333,
    "the proliferation of": 1.0,
    "proliferation of reviews": 1.0,
    "of reviews ,": 1.0,
    "reviews , ratings": 0.3333333333333333,
    ", ratings ,": 1.0,
    "ratings , recommendations": 1.0,
    ", recommendations and": 1.0,
    "recommendations and other": 1.0,
    "and other forms": 0.1111111111111111,
    "other forms of": 1.0,
    "forms of online": 0.5,
    "of online expression": 1.0,
    "online expression ,": 1.0,
    "expression , online": 0.5,
    ", online opinion": 0.3333333333333333,
    "online opinion has": 1.0,
    "opinion has turned": 1.0,
    "has turned into": 1.0,
    "turned into a": 1.0,
    "into a kind": 0.058823529411764705,
    "a kind of": 1.0,
    "kind of virtual": 0.125,
    "of virtual currency": 1.0,
    "virtual currency for": 1.0,
    "currency for businesses": 1.0,
    "for businesses looking": 1.0,
    "businesses looking to": 1.0,
    "looking to market": 0.5,
    "to market their": 1.0,
    "market their products": 1.0,
    "their products ,": 1.0,
    "products , identify": 0.5,
    ", identify new": 0.5,
    "identify new opportunities": 1.0,
    "new opportunities and": 1.0,
    "opportunities and manage": 1.0,
    "and manage their": 1.0,
    "manage their reputations": 1.0,
    "their reputations .": 1.0,
    "<s> as businesses": 0.07142857142857142,
    "as businesses look": 1.0,
    "businesses look to": 1.0,
    "look to automate": 1.0,
    "to automate the": 0.5,
    "automate the process": 1.0,
    "process of filtering": 0.08333333333333333,
    "of filtering out": 1.0,
    "filtering out the": 1.0,
    "out the noise": 0.3333333333333333,
    "the noise ,": 1.0,
    "noise , understanding": 1.0,
    ", understanding the": 1.0,
    "understanding the conversations": 0.25,
    "the conversations ,": 1.0,
    "conversations , identifying": 1.0,
    "identifying the relevant": 0.25,
    "the relevant content": 1.0,
    "relevant content and": 1.0,
    "content and actioning": 0.5,
    "and actioning it": 1.0,
    "actioning it appropriately": 1.0,
    "it appropriately ,": 1.0,
    "appropriately , many": 1.0,
    ", many are": 0.14285714285714285,
    "many are now": 1.0,
    "are now looking": 0.25,
    "now looking to": 1.0,
    "looking to the": 0.5,
    "field of sentiment": 0.08333333333333333,
    "<s> if web": 0.125,
    "if web 2.0": 1.0,
    "web 2.0 was": 0.5,
    "2.0 was all": 1.0,
    "was all about": 1.0,
    "all about democratizing": 1.0,
    "about democratizing publishing": 1.0,
    "democratizing publishing ,": 1.0,
    "publishing , then": 1.0,
    "then the next": 0.25,
    "next stage of": 0.5,
    "stage of the": 0.5,
    "of the web": 0.005128205128205128,
    "the web may": 0.25,
    "web may well": 1.0,
    "may well be": 1.0,
    "well be based": 1.0,
    "be based on": 1.0,
    "based on democratizing": 0.021739130434782608,
    "on democratizing data": 1.0,
    "democratizing data mining": 1.0,
    "data mining of": 0.5,
    "mining of all": 1.0,
    "all the content": 0.14285714285714285,
    "the content that": 0.3333333333333333,
    "content that is": 1.0,
    "that is getting": 0.05263157894736842,
    "is getting published": 0.5,
    "getting published .": 1.0,
    "<s> one step": 0.08333333333333333,
    "one step towards": 1.0,
    "step towards this": 1.0,
    "towards this aim": 1.0,
    "this aim is": 1.0,
    "aim is accomplished": 1.0,
    "is accomplished in": 1.0,
    "accomplished in research": 1.0,
    "in research .": 1.0,
    "<s> several research": 0.3333333333333333,
    "several research teams": 1.0,
    "research teams in": 1.0,
    "teams in universities": 1.0,
    "in universities around": 1.0,
    "universities around the": 1.0,
    "around the world": 0.25,
    "the world currently": 0.125,
    "world currently focus": 1.0,
    "currently focus on": 1.0,
    "focus on understanding": 0.25,
    "on understanding the": 1.0,
    "understanding the dynamics": 0.25,
    "the dynamics of": 1.0,
    "dynamics of sentiment": 1.0,
    "of sentiment in": 0.2,
    "sentiment in e-communities": 0.5,
    "in e-communities through": 1.0,
    "e-communities through sentiment": 1.0,
    "through sentiment analysis": 1.0,
    "<s> the cyberemotions": 0.006802721088435374,
    "the cyberemotions project": 1.0,
    "cyberemotions project ,": 1.0,
    "project , for": 0.16666666666666666,
    "instance , recently": 0.1111111111111111,
    ", recently identified": 1.0,
    "recently identified the": 1.0,
    "identified the role": 1.0,
    "the role of": 0.5,
    "role of negative": 1.0,
    "of negative emotions": 1.0,
    "negative emotions in": 1.0,
    "emotions in driving": 1.0,
    "in driving social": 1.0,
    "driving social networks": 1.0,
    "social networks discussions": 0.3333333333333333,
    "networks discussions .": 1.0,
    "sentiment analysis could": 0.05263157894736842,
    "analysis could therefore": 1.0,
    "could therefore help": 1.0,
    "therefore help understand": 1.0,
    "help understand why": 1.0,
    "understand why certain": 1.0,
    "why certain e-communities": 1.0,
    "certain e-communities die": 1.0,
    "e-communities die or": 1.0,
    "die or fade": 1.0,
    "or fade away": 1.0,
    "fade away -lrb-": 1.0,
    "away -lrb- e.g.": 1.0,
    "e.g. , myspace": 0.038461538461538464,
    ", myspace -rrb-": 1.0,
    "myspace -rrb- while": 1.0,
    "-rrb- while others": 1.0,
    "while others seem": 0.25,
    "others seem to": 1.0,
    "seem to grow": 1.0,
    "to grow without": 1.0,
    "grow without limits": 1.0,
    "without limits -lrb-": 1.0,
    "limits -lrb- e.g.": 1.0,
    "e.g. , facebook": 0.038461538461538464,
    ", facebook -rrb-": 1.0,
    "facebook -rrb- .": 1.0,
    "the problem is": 0.16666666666666666,
    "problem is that": 0.2,
    "is that most": 0.08333333333333333,
    "that most sentiment": 1.0,
    "most sentiment analysis": 1.0,
    "sentiment analysis algorithms": 0.05263157894736842,
    "analysis algorithms use": 1.0,
    "algorithms use simple": 1.0,
    "use simple terms": 1.0,
    "simple terms to": 1.0,
    "terms to express": 1.0,
    "to express sentiment": 1.0,
    "express sentiment about": 1.0,
    "sentiment about a": 1.0,
    "about a product": 1.0,
    "a product or": 1.0,
    "product or service": 1.0,
    "or service .": 1.0,
    "however , cultural": 0.022727272727272728,
    ", cultural factors": 1.0,
    "cultural factors ,": 1.0,
    "factors , linguistic": 1.0,
    ", linguistic nuances": 1.0,
    "linguistic nuances and": 1.0,
    "nuances and differing": 1.0,
    "and differing contexts": 1.0,
    "differing contexts make": 0.5,
    "contexts make it": 1.0,
    "make it extremely": 0.5,
    "it extremely difficult": 1.0,
    "extremely difficult to": 0.3333333333333333,
    "difficult to turn": 0.09090909090909091,
    "to turn a": 1.0,
    "turn a string": 1.0,
    "a string of": 1.0,
    "string of written": 0.5,
    "of written text": 0.25,
    "written text into": 0.6666666666666666,
    "text into a": 0.14285714285714285,
    "into a simple": 0.058823529411764705,
    "a simple pro": 1.0,
    "simple pro or": 1.0,
    "pro or con": 1.0,
    "or con sentiment": 1.0,
    "con sentiment .": 1.0,
    "<s> the fact": 0.006802721088435374,
    "fact that humans": 0.2,
    "that humans often": 0.5,
    "humans often disagree": 1.0,
    "often disagree on": 1.0,
    "disagree on the": 1.0,
    "on the sentiment": 0.014925373134328358,
    "the sentiment of": 0.5,
    "sentiment of text": 1.0,
    "of text illustrates": 0.041666666666666664,
    "text illustrates how": 1.0,
    "illustrates how big": 1.0,
    "how big a": 1.0,
    "big a task": 1.0,
    "a task it": 0.3333333333333333,
    "task it is": 1.0,
    "it is for": 0.02127659574468085,
    "is for computers": 1.0,
    "for computers to": 1.0,
    "computers to get": 1.0,
    "to get this": 0.25,
    "get this right": 1.0,
    "this right .": 1.0,
    "<s> the shorter": 0.006802721088435374,
    "the shorter the": 1.0,
    "shorter the string": 1.0,
    "the string of": 1.0,
    "string of text": 0.25,
    "text , the": 0.03333333333333333,
    ", the harder": 0.009523809523809525,
    "the harder it": 0.3333333333333333,
    "harder it becomes": 1.0,
    "it becomes .": 0.25,
    "<s> n computer": 0.5,
    "n computer science": 1.0,
    "science , speech": 0.2,
    ", speech recognition": 0.45454545454545453,
    "speech recognition is": 0.10526315789473684,
    "recognition is the": 0.1,
    "is the translation": 0.022222222222222223,
    "translation of spoken": 0.09090909090909091,
    "of spoken words": 0.5,
    "spoken words into": 1.0,
    "words into text": 0.5,
    "into text .": 0.6666666666666666,
    "is also known": 0.1,
    "known as ``": 0.1,
    "as `` automatic": 0.07142857142857142,
    "`` automatic speech": 1.0,
    "speech recognition ''": 0.05263157894736842,
    "recognition '' ,": 0.4,
    ", `` asr": 0.04,
    "`` asr ''": 1.0,
    "asr '' ,": 1.0,
    ", `` computer": 0.04,
    "`` computer speech": 1.0,
    "computer speech recognition": 0.3333333333333333,
    ", `` speech": 0.04,
    "`` speech to": 0.5,
    "speech to text": 0.3333333333333333,
    "to text ''": 0.5,
    "text '' ,": 1.0,
    "'' , or": 0.03333333333333333,
    ", or just": 0.030303030303030304,
    "or just ``": 1.0,
    "just `` stt": 1.0,
    "`` stt ''": 1.0,
    "stt '' .": 1.0,
    "recognition is technology": 0.1,
    "is technology that": 1.0,
    "technology that can": 1.0,
    "that can translate": 0.07692307692307693,
    "can translate spoken": 1.0,
    "translate spoken words": 1.0,
    "<s> some sr": 0.0625,
    "some sr systems": 1.0,
    "sr systems use": 1.0,
    "systems use ``": 0.16666666666666666,
    "use `` training": 1.0,
    "`` training ''": 1.0,
    "training '' where": 1.0,
    "'' where an": 1.0,
    "where an individual": 1.0,
    "an individual speaker": 1.0,
    "individual speaker reads": 1.0,
    "speaker reads sections": 1.0,
    "reads sections of": 1.0,
    "sections of text": 0.5,
    "text into the": 0.14285714285714285,
    "into the sr": 0.125,
    "the sr system": 1.0,
    "sr system .": 1.0,
    "these systems analyze": 0.1111111111111111,
    "systems analyze the": 1.0,
    "analyze the person": 1.0,
    "person 's specific": 0.25,
    "'s specific voice": 1.0,
    "specific voice and": 1.0,
    "voice and use": 1.0,
    "and use it": 0.3333333333333333,
    "it to fine": 0.2,
    "to fine tune": 1.0,
    "fine tune the": 1.0,
    "tune the recognition": 1.0,
    "the recognition of": 0.6666666666666666,
    "recognition of that": 0.09090909090909091,
    "of that person": 0.5,
    "that person 's": 1.0,
    "person 's speech": 0.25,
    "'s speech ,": 1.0,
    "speech , resulting": 0.09090909090909091,
    ", resulting in": 1.0,
    "resulting in more": 1.0,
    "in more accurate": 1.0,
    "more accurate transcription": 0.3333333333333333,
    "accurate transcription .": 1.0,
    "systems that do": 0.09090909090909091,
    "that do not": 1.0,
    "do not use": 0.07692307692307693,
    "not use training": 0.5,
    "use training are": 1.0,
    "training are called": 1.0,
    "are called ``": 1.0,
    "called `` speaker": 0.4,
    "`` speaker independent": 0.5,
    "speaker independent ''": 0.3333333333333333,
    "independent '' systems": 1.0,
    "'' systems .": 0.6666666666666666,
    "that use training": 0.5,
    "`` speaker dependent": 0.5,
    "speaker dependent ''": 0.5,
    "dependent '' systems": 1.0,
    "speech recognition applications": 0.013157894736842105,
    "recognition applications include": 1.0,
    "applications include voice": 0.3333333333333333,
    "include voice user": 1.0,
    "voice user interfaces": 1.0,
    "user interfaces such": 0.5,
    "interfaces such as": 1.0,
    "such as voice": 0.011111111111111112,
    "as voice dialing": 1.0,
    "voice dialing -lrb-": 1.0,
    "dialing -lrb- e.g.": 1.0,
    ", `` call": 0.04,
    "`` call home": 1.0,
    "call home ''": 1.0,
    "home '' -rrb-": 1.0,
    "-rrb- , call": 0.01282051282051282,
    ", call routing": 1.0,
    "call routing -lrb-": 1.0,
    "routing -lrb- e.g.": 1.0,
    ", `` i": 0.04,
    "`` i would": 1.0,
    "i would like": 1.0,
    "like to make": 0.5,
    "make a collect": 0.25,
    "a collect call": 1.0,
    "collect call ''": 1.0,
    "call '' -rrb-": 1.0,
    "-rrb- , domotic": 0.01282051282051282,
    ", domotic appliance": 1.0,
    "domotic appliance control": 1.0,
    "appliance control ,": 1.0,
    "control , search": 1.0,
    ", search -lrb-": 0.5,
    "search -lrb- e.g.": 1.0,
    "e.g. , find": 0.038461538461538464,
    ", find a": 0.5,
    "find a podcast": 0.5,
    "a podcast where": 1.0,
    "podcast where particular": 1.0,
    "where particular words": 1.0,
    "particular words were": 1.0,
    "words were spoken": 0.5,
    "were spoken -rrb-": 1.0,
    "spoken -rrb- ,": 1.0,
    "-rrb- , simple": 0.01282051282051282,
    ", simple data": 0.5,
    "simple data entry": 1.0,
    "data entry -lrb-": 0.3333333333333333,
    "entry -lrb- e.g.": 1.0,
    "e.g. , entering": 0.038461538461538464,
    ", entering a": 0.5,
    "entering a credit": 1.0,
    "credit card number": 0.3333333333333333,
    "card number -rrb-": 1.0,
    "number -rrb- ,": 0.5,
    "-rrb- , preparation": 0.01282051282051282,
    ", preparation of": 1.0,
    "preparation of structured": 1.0,
    "of structured documents": 1.0,
    "structured documents -lrb-": 1.0,
    "documents -lrb- e.g.": 0.2,
    ", a radiology": 0.020833333333333332,
    "a radiology report": 1.0,
    "radiology report -rrb-": 1.0,
    "report -rrb- ,": 1.0,
    "-rrb- , speech-to-text": 0.01282051282051282,
    ", speech-to-text processing": 1.0,
    "speech-to-text processing -lrb-": 1.0,
    "processing -lrb- e.g.": 0.14285714285714285,
    "e.g. , word": 0.038461538461538464,
    ", word processors": 1.0,
    "word processors or": 1.0,
    "processors or emails": 1.0,
    "or emails -rrb-": 1.0,
    "emails -rrb- ,": 1.0,
    ", and aircraft": 0.005291005291005291,
    "and aircraft -lrb-": 1.0,
    "aircraft -lrb- usually": 0.5,
    "-lrb- usually termed": 0.5,
    "usually termed direct": 1.0,
    "termed direct voice": 1.0,
    "direct voice input": 1.0,
    "voice input -rrb-": 1.0,
    "input -rrb- .": 0.5,
    "the term voice": 0.1111111111111111,
    "term voice recognition": 1.0,
    "voice recognition refers": 1.0,
    "recognition refers to": 1.0,
    "refers to finding": 0.2,
    "to finding the": 1.0,
    "finding the identity": 0.5,
    "identity of ``": 0.25,
    "of `` who": 0.125,
    "`` who ''": 0.3333333333333333,
    "who '' is": 1.0,
    "'' is speaking": 0.1111111111111111,
    "is speaking ,": 1.0,
    "speaking , rather": 0.2,
    "rather than what": 0.07142857142857142,
    "than what they": 1.0,
    "what they are": 1.0,
    "they are saying": 0.14285714285714285,
    "are saying .": 1.0,
    "<s> recognizing the": 1.0,
    "recognizing the speaker": 1.0,
    "the speaker can": 0.5,
    "speaker can simplify": 1.0,
    "can simplify the": 1.0,
    "simplify the task": 1.0,
    "task of translating": 0.1111111111111111,
    "of translating speech": 1.0,
    "translating speech in": 1.0,
    "speech in systems": 0.5,
    "in systems that": 0.5,
    "systems that have": 0.09090909090909091,
    "have been trained": 0.038461538461538464,
    "been trained on": 1.0,
    "trained on specific": 1.0,
    "on specific person": 1.0,
    "specific person 's": 1.0,
    "person 's voices": 0.25,
    "'s voices or": 1.0,
    "voices or it": 1.0,
    "or it can": 1.0,
    "it can be": 0.3333333333333333,
    "used to authenticate": 0.045454545454545456,
    "to authenticate or": 1.0,
    "authenticate or verify": 1.0,
    "or verify the": 1.0,
    "verify the identity": 1.0,
    "identity of a": 0.25,
    "a speaker as": 0.25,
    "speaker as part": 1.0,
    "of a security": 0.010869565217391304,
    "a security process": 1.0,
    "security process .": 1.0,
    "<s> front-end speech": 1.0,
    "front-end speech recognition": 1.0,
    "recognition is where": 0.2,
    "is where the": 1.0,
    "where the provider": 0.15384615384615385,
    "the provider dictates": 1.0,
    "provider dictates into": 1.0,
    "dictates into a": 1.0,
    "into a speech-recognition": 0.058823529411764705,
    "a speech-recognition engine": 0.6666666666666666,
    "speech-recognition engine ,": 0.5,
    "engine , the": 1.0,
    ", the recognized": 0.009523809523809525,
    "the recognized words": 0.5,
    "recognized words are": 1.0,
    "words are displayed": 0.1,
    "are displayed as": 1.0,
    "displayed as they": 1.0,
    "they are spoken": 0.14285714285714285,
    "are spoken ,": 1.0,
    "spoken , and": 0.5,
    "and the dictator": 0.024390243902439025,
    "the dictator is": 1.0,
    "dictator is responsible": 1.0,
    "is responsible for": 1.0,
    "responsible for editing": 1.0,
    "for editing and": 1.0,
    "editing and signing": 1.0,
    "and signing off": 1.0,
    "signing off on": 1.0,
    "off on the": 1.0,
    "on the document": 0.014925373134328358,
    "<s> back-end or": 1.0,
    "back-end or deferred": 1.0,
    "or deferred speech": 1.0,
    "deferred speech recognition": 1.0,
    "into a digital": 0.058823529411764705,
    "a digital dictation": 0.5,
    "digital dictation system": 1.0,
    "dictation system ,": 1.0,
    ", the voice": 0.009523809523809525,
    "the voice is": 1.0,
    "voice is routed": 1.0,
    "is routed through": 0.5,
    "routed through a": 1.0,
    "through a speech-recognition": 0.5,
    "a speech-recognition machine": 0.3333333333333333,
    "speech-recognition machine and": 1.0,
    "machine and the": 1.0,
    "and the recognized": 0.024390243902439025,
    "the recognized draft": 0.5,
    "recognized draft document": 1.0,
    "draft document is": 1.0,
    "document is routed": 1.0,
    "is routed along": 0.5,
    "routed along with": 1.0,
    "along with the": 0.5,
    "with the original": 0.03333333333333333,
    "the original voice": 0.1,
    "original voice file": 1.0,
    "voice file to": 1.0,
    "file to the": 1.0,
    "to the editor": 0.012987012987012988,
    "the editor ,": 1.0,
    "editor , where": 1.0,
    "where the draft": 0.07692307692307693,
    "the draft is": 1.0,
    "draft is edited": 1.0,
    "is edited and": 1.0,
    "edited and report": 1.0,
    "and report finalized": 1.0,
    "report finalized .": 1.0,
    "<s> deferred speech": 1.0,
    "recognition is widely": 0.1,
    "in the industry": 0.006535947712418301,
    "the industry currently": 1.0,
    "industry currently .": 1.0,
    "<s> many electronic": 0.09090909090909091,
    "many electronic medical": 1.0,
    "medical records -lrb-": 0.3333333333333333,
    "records -lrb- emr": 1.0,
    "-lrb- emr -rrb-": 1.0,
    "emr -rrb- applications": 1.0,
    "-rrb- applications can": 1.0,
    "applications can be": 1.0,
    "can be more": 0.01098901098901099,
    "be more effective": 0.2,
    "more effective and": 1.0,
    "effective and may": 1.0,
    "and may be": 0.5,
    "may be performed": 0.047619047619047616,
    "be performed more": 0.5,
    "performed more easily": 1.0,
    "more easily when": 1.0,
    "easily when deployed": 1.0,
    "when deployed in": 1.0,
    "deployed in conjunction": 1.0,
    "in conjunction with": 1.0,
    "conjunction with a": 0.5,
    "with a speech-recognition": 0.05,
    "speech-recognition engine .": 0.5,
    "<s> searches ,": 1.0,
    "searches , queries": 1.0,
    ", queries ,": 1.0,
    "queries , and": 1.0,
    ", and form": 0.005291005291005291,
    "and form filling": 1.0,
    "form filling may": 1.0,
    "filling may all": 1.0,
    "may all be": 1.0,
    "all be faster": 1.0,
    "be faster to": 1.0,
    "faster to perform": 1.0,
    "to perform by": 0.2,
    "perform by voice": 1.0,
    "by voice than": 0.5,
    "voice than by": 1.0,
    "than by using": 1.0,
    "by using a": 0.3333333333333333,
    "using a keyboard": 0.1,
    "a keyboard .": 1.0,
    "of the major": 0.005128205128205128,
    "the major issues": 0.5,
    "major issues relating": 0.5,
    "issues relating to": 1.0,
    "relating to the": 1.0,
    "use of speech": 0.09090909090909091,
    "speech recognition in": 0.039473684210526314,
    "recognition in healthcare": 0.3333333333333333,
    "in healthcare is": 1.0,
    "healthcare is that": 1.0,
    "that the american": 0.043478260869565216,
    "the american recovery": 0.5,
    "american recovery and": 1.0,
    "recovery and reinvestment": 1.0,
    "and reinvestment act": 1.0,
    "reinvestment act of": 1.0,
    "act of 2009": 1.0,
    "of 2009 -lrb-": 1.0,
    "2009 -lrb- arra": 1.0,
    "-lrb- arra -rrb-": 1.0,
    "arra -rrb- provides": 1.0,
    "-rrb- provides for": 1.0,
    "provides for substantial": 1.0,
    "for substantial financial": 1.0,
    "substantial financial benefits": 1.0,
    "financial benefits to": 1.0,
    "benefits to physicians": 1.0,
    "to physicians who": 1.0,
    "physicians who utilize": 1.0,
    "who utilize an": 1.0,
    "utilize an emr": 1.0,
    "an emr according": 1.0,
    "emr according to": 1.0,
    "according to ``": 0.16666666666666666,
    "to `` meaningful": 0.25,
    "`` meaningful use": 1.0,
    "meaningful use ''": 1.0,
    "use '' standards": 1.0,
    "'' standards .": 1.0,
    "<s> these standards": 0.0625,
    "these standards require": 1.0,
    "standards require that": 1.0,
    "require that a": 1.0,
    "that a substantial": 0.3333333333333333,
    "a substantial amount": 1.0,
    "substantial amount of": 1.0,
    "amount of data": 0.2,
    "of data be": 0.14285714285714285,
    "data be maintained": 1.0,
    "be maintained by": 1.0,
    "maintained by the": 1.0,
    "by the emr": 0.03571428571428571,
    "the emr -lrb-": 1.0,
    "emr -lrb- now": 1.0,
    "-lrb- now more": 0.3333333333333333,
    "now more commonly": 1.0,
    "more commonly referred": 0.5,
    "commonly referred to": 1.0,
    "as an electronic": 0.06666666666666667,
    "an electronic health": 1.0,
    "electronic health record": 1.0,
    "health record or": 1.0,
    "record or ehr": 1.0,
    "or ehr -rrb-": 1.0,
    "ehr -rrb- .": 1.0,
    "<s> unfortunately ,": 1.0,
    "unfortunately , in": 0.5,
    ", in many": 0.029411764705882353,
    "in many instances": 0.1,
    "many instances ,": 1.0,
    "instances , the": 1.0,
    ", the use": 0.009523809523809525,
    "speech recognition within": 0.013157894736842105,
    "recognition within an": 1.0,
    "within an ehr": 1.0,
    "an ehr will": 1.0,
    "ehr will not": 1.0,
    "will not lead": 0.25,
    "not lead to": 1.0,
    "lead to data": 0.5,
    "to data maintained": 0.5,
    "data maintained within": 1.0,
    "maintained within a": 1.0,
    "within a database": 0.2,
    "a database ,": 0.3333333333333333,
    "database , but": 1.0,
    "but rather to": 0.5,
    "rather to narrative": 1.0,
    "to narrative text": 1.0,
    "narrative text .": 1.0,
    "for this reason": 0.25,
    "this reason ,": 1.0,
    "reason , substantial": 0.5,
    ", substantial resources": 1.0,
    "substantial resources are": 1.0,
    "resources are being": 1.0,
    "are being expended": 0.5,
    "being expended to": 1.0,
    "expended to allow": 1.0,
    "to allow for": 0.3333333333333333,
    "allow for the": 1.0,
    "for the use": 0.03125,
    "use of front-end": 0.045454545454545456,
    "of front-end sr": 1.0,
    "front-end sr while": 1.0,
    "sr while capturing": 1.0,
    "while capturing data": 1.0,
    "capturing data within": 1.0,
    "data within the": 1.0,
    "within the ehr": 0.3333333333333333,
    "the ehr .": 1.0,
    "<s> military high-performance": 1.0,
    "military high-performance fighter": 1.0,
    "high-performance fighter aircraft": 1.0,
    "fighter aircraft substantial": 0.3333333333333333,
    "aircraft substantial efforts": 1.0,
    "substantial efforts have": 1.0,
    "efforts have been": 0.5,
    "have been devoted": 0.038461538461538464,
    "been devoted in": 1.0,
    "devoted in the": 1.0,
    "the last decade": 0.6666666666666666,
    "last decade to": 0.5,
    "decade to the": 1.0,
    "the test and": 0.5,
    "test and evaluation": 1.0,
    "and evaluation of": 0.3333333333333333,
    "evaluation of speech": 0.2,
    "recognition in fighter": 0.3333333333333333,
    "in fighter aircraft": 0.6666666666666666,
    "fighter aircraft .": 0.3333333333333333,
    "<s> of particular": 1.0,
    "of particular note": 1.0,
    "particular note is": 1.0,
    "note is the": 1.0,
    "is the u.s.": 0.022222222222222223,
    "the u.s. program": 0.25,
    "u.s. program in": 1.0,
    "program in speech": 0.5,
    "in speech recognition": 0.875,
    "speech recognition for": 0.013157894736842105,
    "recognition for the": 1.0,
    "for the advanced": 0.03125,
    "the advanced fighter": 1.0,
    "advanced fighter technology": 1.0,
    "fighter technology integration": 1.0,
    "technology integration -lrb-": 1.0,
    "integration -lrb- afti": 1.0,
    "-lrb- afti -rrb-": 1.0,
    "afti -rrb- \\/": 1.0,
    "-rrb- \\/ f-16": 1.0,
    "\\/ f-16 aircraft": 1.0,
    "f-16 aircraft -lrb-": 1.0,
    "aircraft -lrb- f-16": 0.5,
    "-lrb- f-16 vista": 1.0,
    "f-16 vista -rrb-": 1.0,
    "vista -rrb- ,": 1.0,
    "and a program": 0.0625,
    "a program in": 0.25,
    "program in france": 0.5,
    "in france installing": 0.25,
    "france installing speech": 1.0,
    "installing speech recognition": 1.0,
    "recognition systems on": 0.1,
    "systems on mirage": 1.0,
    "on mirage aircraft": 1.0,
    "mirage aircraft ,": 1.0,
    "aircraft , and": 0.5,
    ", and also": 0.005291005291005291,
    "and also programs": 1.0,
    "also programs in": 1.0,
    "programs in the": 1.0,
    "the uk dealing": 0.25,
    "uk dealing with": 1.0,
    "dealing with a": 0.5,
    "with a variety": 0.05,
    "variety of aircraft": 0.125,
    "of aircraft platforms": 1.0,
    "aircraft platforms .": 1.0,
    "<s> in these": 0.010309278350515464,
    "in these programs": 0.25,
    "these programs ,": 1.0,
    "programs , speech": 0.5,
    ", speech recognizers": 0.09090909090909091,
    "speech recognizers have": 1.0,
    "recognizers have been": 1.0,
    "have been operated": 0.038461538461538464,
    "been operated successfully": 1.0,
    "operated successfully in": 1.0,
    "successfully in fighter": 1.0,
    "fighter aircraft ,": 0.3333333333333333,
    "aircraft , with": 0.5,
    ", with applications": 0.125,
    "with applications including": 1.0,
    "applications including :": 1.0,
    "including : setting": 0.5,
    ": setting radio": 1.0,
    "setting radio frequencies": 1.0,
    "radio frequencies ,": 1.0,
    "frequencies , commanding": 1.0,
    ", commanding an": 1.0,
    "commanding an autopilot": 1.0,
    "an autopilot system": 1.0,
    "autopilot system ,": 1.0,
    "system , setting": 0.1,
    ", setting steer-point": 0.5,
    "setting steer-point coordinates": 1.0,
    "steer-point coordinates and": 1.0,
    "coordinates and weapons": 1.0,
    "and weapons release": 1.0,
    "weapons release parameters": 1.0,
    "release parameters ,": 1.0,
    "parameters , and": 1.0,
    ", and controlling": 0.005291005291005291,
    "and controlling flight": 1.0,
    "controlling flight displays": 1.0,
    "flight displays .": 1.0,
    "<s> working with": 1.0,
    "working with swedish": 1.0,
    "with swedish pilots": 1.0,
    "swedish pilots flying": 1.0,
    "pilots flying in": 1.0,
    "flying in the": 1.0,
    "in the jas-39": 0.006535947712418301,
    "the jas-39 gripen": 1.0,
    "jas-39 gripen cockpit": 1.0,
    "gripen cockpit ,": 1.0,
    "cockpit , englund": 1.0,
    ", englund -lrb-": 1.0,
    "englund -lrb- 2004": 1.0,
    "-lrb- 2004 -rrb-": 1.0,
    "2004 -rrb- found": 1.0,
    "-rrb- found recognition": 1.0,
    "found recognition deteriorated": 1.0,
    "recognition deteriorated with": 1.0,
    "deteriorated with increasing": 1.0,
    "with increasing g-loads": 1.0,
    "increasing g-loads .": 1.0,
    "<s> it was": 0.058823529411764705,
    "it was also": 0.2,
    "was also concluded": 0.5,
    "also concluded that": 1.0,
    "concluded that adaptation": 0.5,
    "that adaptation greatly": 1.0,
    "adaptation greatly improved": 1.0,
    "greatly improved the": 1.0,
    "improved the results": 1.0,
    "the results in": 0.2,
    "results in all": 1.0,
    "in all cases": 0.25,
    "all cases and": 1.0,
    "cases and introducing": 1.0,
    "and introducing models": 1.0,
    "introducing models for": 1.0,
    "models for breathing": 0.16666666666666666,
    "for breathing was": 1.0,
    "breathing was shown": 1.0,
    "was shown to": 0.5,
    "shown to improve": 0.5,
    "to improve recognition": 0.2222222222222222,
    "improve recognition scores": 0.5,
    "recognition scores significantly": 1.0,
    "scores significantly .": 1.0,
    "contrary to what": 0.5,
    "to what might": 0.25,
    "what might be": 1.0,
    "might be expected": 0.16666666666666666,
    "be expected ,": 0.3333333333333333,
    "expected , no": 1.0,
    ", no effects": 0.3333333333333333,
    "no effects of": 1.0,
    "effects of the": 1.0,
    "of the broken": 0.005128205128205128,
    "the broken english": 1.0,
    "broken english of": 1.0,
    "english of the": 1.0,
    "of the speakers": 0.005128205128205128,
    "the speakers were": 1.0,
    "speakers were found": 1.0,
    "were found .": 0.5,
    "it was evident": 0.2,
    "was evident that": 1.0,
    "evident that spontaneous": 1.0,
    "that spontaneous speech": 1.0,
    "spontaneous speech caused": 0.25,
    "speech caused problems": 1.0,
    "caused problems for": 1.0,
    "problems for the": 1.0,
    "for the recognizer": 0.03125,
    "the recognizer ,": 1.0,
    "recognizer , as": 1.0,
    ", as could": 0.043478260869565216,
    "as could be": 1.0,
    "could be expected": 0.25,
    "be expected .": 0.3333333333333333,
    "<s> a restricted": 0.022727272727272728,
    "a restricted vocabulary": 0.5,
    "restricted vocabulary ,": 1.0,
    "vocabulary , and": 1.0,
    ", and above": 0.005291005291005291,
    "and above all": 1.0,
    "above all ,": 1.0,
    "all , a": 0.3333333333333333,
    ", a proper": 0.020833333333333332,
    "a proper syntax": 1.0,
    "proper syntax ,": 1.0,
    "syntax , could": 0.2,
    ", could thus": 1.0,
    "could thus be": 1.0,
    "thus be expected": 1.0,
    "be expected to": 0.3333333333333333,
    "expected to improve": 0.5,
    "improve recognition accuracy": 0.5,
    "recognition accuracy substantially": 0.14285714285714285,
    "accuracy substantially .": 1.0,
    "<s> the eurofighter": 0.006802721088435374,
    "the eurofighter typhoon": 1.0,
    "eurofighter typhoon currently": 1.0,
    "typhoon currently in": 1.0,
    "currently in service": 1.0,
    "in service with": 1.0,
    "service with the": 1.0,
    "with the uk": 0.03333333333333333,
    "the uk raf": 0.25,
    "uk raf employs": 1.0,
    "raf employs a": 1.0,
    "employs a speaker-dependent": 1.0,
    "a speaker-dependent system": 1.0,
    "speaker-dependent system ,": 1.0,
    "system , i.e.": 0.1,
    ", i.e. it": 0.14285714285714285,
    "i.e. it requires": 1.0,
    "it requires each": 0.5,
    "requires each pilot": 1.0,
    "each pilot to": 1.0,
    "pilot to create": 0.5,
    "create a template": 0.14285714285714285,
    "a template .": 0.5,
    "system is not": 0.1111111111111111,
    "not used for": 0.5,
    "used for any": 0.06666666666666667,
    "for any safety": 1.0,
    "any safety critical": 1.0,
    "safety critical or": 1.0,
    "critical or weapon": 1.0,
    "or weapon critical": 1.0,
    "weapon critical tasks": 1.0,
    "critical tasks ,": 1.0,
    "tasks , such": 0.25,
    "such as weapon": 0.011111111111111112,
    "as weapon release": 1.0,
    "weapon release or": 1.0,
    "release or lowering": 1.0,
    "or lowering of": 1.0,
    "lowering of the": 1.0,
    "of the undercarriage": 0.005128205128205128,
    "the undercarriage ,": 1.0,
    "undercarriage , but": 1.0,
    "but is used": 0.5,
    "is used for": 0.07692307692307693,
    "for a wide": 0.03225806451612903,
    "range of other": 0.25,
    "of other cockpit": 0.25,
    "other cockpit functions": 1.0,
    "cockpit functions .": 1.0,
    "<s> voice commands": 1.0,
    "voice commands are": 0.5,
    "commands are confirmed": 1.0,
    "are confirmed by": 1.0,
    "confirmed by visual": 1.0,
    "by visual and\\/or": 1.0,
    "visual and\\/or aural": 1.0,
    "and\\/or aural feedback": 1.0,
    "aural feedback .": 1.0,
    "system is seen": 0.1111111111111111,
    "is seen as": 1.0,
    "as a major": 0.027777777777777776,
    "a major design": 0.2,
    "major design feature": 1.0,
    "design feature in": 1.0,
    "feature in the": 1.0,
    "in the reduction": 0.006535947712418301,
    "the reduction of": 1.0,
    "reduction of pilot": 1.0,
    "of pilot workload": 1.0,
    "pilot workload ,": 1.0,
    "workload , and": 1.0,
    "and even allows": 0.16666666666666666,
    "even allows the": 1.0,
    "allows the pilot": 0.3333333333333333,
    "the pilot to": 1.0,
    "pilot to assign": 0.5,
    "to assign targets": 0.3333333333333333,
    "assign targets to": 1.0,
    "targets to himself": 1.0,
    "to himself with": 1.0,
    "himself with two": 1.0,
    "with two simple": 0.5,
    "two simple voice": 1.0,
    "simple voice commands": 1.0,
    "voice commands or": 0.5,
    "commands or to": 1.0,
    "or to any": 0.5,
    "to any of": 0.3333333333333333,
    "any of his": 0.5,
    "of his wingmen": 0.3333333333333333,
    "his wingmen with": 1.0,
    "wingmen with only": 1.0,
    "with only five": 1.0,
    "only five commands": 1.0,
    "five commands .": 1.0,
    "<s> speaker independent": 0.5,
    "speaker independent systems": 0.3333333333333333,
    "independent systems are": 1.0,
    "systems are also": 0.07692307692307693,
    "are also being": 0.125,
    "also being developed": 1.0,
    "being developed and": 1.0,
    "developed and are": 1.0,
    "and are in": 0.2,
    "are in testing": 0.3333333333333333,
    "in testing for": 1.0,
    "testing for the": 1.0,
    "for the f35": 0.03125,
    "the f35 lightning": 1.0,
    "f35 lightning ii": 1.0,
    "lightning ii -lrb-": 1.0,
    "ii -lrb- jsf": 1.0,
    "-lrb- jsf -rrb-": 1.0,
    "jsf -rrb- and": 1.0,
    "and the alenia": 0.024390243902439025,
    "the alenia aermacchi": 1.0,
    "alenia aermacchi m-346": 1.0,
    "aermacchi m-346 master": 1.0,
    "m-346 master lead-in": 1.0,
    "master lead-in fighter": 1.0,
    "lead-in fighter trainer": 1.0,
    "fighter trainer .": 1.0,
    "these systems have": 0.1111111111111111,
    "systems have produced": 0.2,
    "have produced word": 1.0,
    "produced word accuracies": 1.0,
    "word accuracies in": 1.0,
    "accuracies in excess": 1.0,
    "in excess of": 1.0,
    "excess of 98": 0.5,
    "of 98 %": 1.0,
    "98 % .": 0.3333333333333333,
    "<s> helicopters the": 1.0,
    "helicopters the problems": 1.0,
    "the problems of": 1.0,
    "problems of achieving": 1.0,
    "of achieving high": 0.5,
    "achieving high recognition": 1.0,
    "high recognition accuracy": 1.0,
    "recognition accuracy under": 0.14285714285714285,
    "accuracy under stress": 1.0,
    "under stress and": 1.0,
    "stress and noise": 1.0,
    "and noise pertain": 1.0,
    "noise pertain strongly": 1.0,
    "pertain strongly to": 1.0,
    "strongly to the": 1.0,
    "to the helicopter": 0.012987012987012988,
    "the helicopter environment": 0.6666666666666666,
    "helicopter environment as": 0.5,
    "environment as well": 1.0,
    "well as to": 0.07692307692307693,
    "as to the": 0.25,
    "to the jet": 0.012987012987012988,
    "the jet fighter": 1.0,
    "jet fighter environment": 1.0,
    "fighter environment .": 1.0,
    "<s> the acoustic": 0.006802721088435374,
    "the acoustic noise": 0.5,
    "acoustic noise problem": 0.5,
    "noise problem is": 1.0,
    "problem is actually": 0.2,
    "is actually more": 0.5,
    "actually more severe": 1.0,
    "more severe in": 1.0,
    "severe in the": 1.0,
    "in the helicopter": 0.006535947712418301,
    "helicopter environment ,": 0.5,
    "environment , not": 1.0,
    "not only because": 0.14285714285714285,
    "only because of": 1.0,
    "of the high": 0.005128205128205128,
    "the high noise": 0.5,
    "high noise levels": 1.0,
    "noise levels but": 1.0,
    "levels but also": 1.0,
    "but also because": 0.16666666666666666,
    "also because the": 1.0,
    "because the helicopter": 0.25,
    "the helicopter pilot": 0.3333333333333333,
    "helicopter pilot ,": 1.0,
    "pilot , in": 1.0,
    ", in general": 0.029411764705882353,
    "general , does": 0.16666666666666666,
    ", does not": 0.5,
    "does not wear": 0.2,
    "not wear a": 1.0,
    "wear a facemask": 1.0,
    "a facemask ,": 1.0,
    "facemask , which": 1.0,
    "which would reduce": 0.5,
    "would reduce acoustic": 1.0,
    "reduce acoustic noise": 1.0,
    "acoustic noise in": 0.5,
    "noise in the": 0.5,
    "in the microphone": 0.006535947712418301,
    "the microphone .": 1.0,
    "<s> substantial test": 1.0,
    "substantial test and": 1.0,
    "and evaluation programs": 0.3333333333333333,
    "evaluation programs have": 1.0,
    "programs have been": 1.0,
    "have been carried": 0.038461538461538464,
    "been carried out": 1.0,
    "carried out in": 1.0,
    "out in the": 0.5,
    "in the past": 0.006535947712418301,
    "the past decade": 0.5,
    "past decade in": 1.0,
    "decade in speech": 1.0,
    "recognition systems applications": 0.1,
    "systems applications in": 1.0,
    "applications in helicopters": 0.5,
    "in helicopters ,": 0.5,
    "helicopters , notably": 1.0,
    ", notably by": 1.0,
    "notably by the": 1.0,
    "the u.s. army": 0.25,
    "u.s. army avionics": 1.0,
    "army avionics research": 1.0,
    "avionics research and": 1.0,
    "and development activity": 0.3333333333333333,
    "development activity -lrb-": 1.0,
    "activity -lrb- avrada": 1.0,
    "-lrb- avrada -rrb-": 1.0,
    "avrada -rrb- and": 1.0,
    "-rrb- and by": 0.05,
    "and by the": 1.0,
    "by the royal": 0.03571428571428571,
    "the royal aerospace": 0.5,
    "royal aerospace establishment": 1.0,
    "aerospace establishment -lrb-": 1.0,
    "establishment -lrb- rae": 1.0,
    "-lrb- rae -rrb-": 1.0,
    "rae -rrb- in": 1.0,
    "<s> work in": 0.5,
    "work in france": 0.25,
    "in france has": 0.25,
    "france has included": 1.0,
    "has included speech": 1.0,
    "included speech recognition": 1.0,
    "recognition in the": 0.3333333333333333,
    "in the puma": 0.006535947712418301,
    "the puma helicopter": 1.0,
    "puma helicopter .": 1.0,
    "<s> there has": 0.2222222222222222,
    "there has also": 1.0,
    "also been much": 0.25,
    "been much useful": 1.0,
    "much useful work": 1.0,
    "useful work in": 1.0,
    "work in canada": 0.25,
    "in canada .": 1.0,
    "<s> results have": 1.0,
    "results have been": 1.0,
    "have been encouraging": 0.038461538461538464,
    "been encouraging ,": 1.0,
    "encouraging , and": 1.0,
    ", and voice": 0.005291005291005291,
    "and voice applications": 1.0,
    "voice applications have": 1.0,
    "applications have included": 0.5,
    "have included :": 1.0,
    "included : control": 1.0,
    ": control of": 1.0,
    "control of communication": 0.3333333333333333,
    "of communication radios": 0.5,
    "communication radios ,": 1.0,
    "radios , setting": 1.0,
    ", setting of": 0.5,
    "setting of navigation": 1.0,
    "of navigation systems": 1.0,
    "navigation systems ,": 0.5,
    "systems , and": 0.16666666666666666,
    ", and control": 0.005291005291005291,
    "and control of": 0.6666666666666666,
    "control of an": 0.3333333333333333,
    "of an automated": 0.07692307692307693,
    "an automated target": 0.5,
    "automated target handover": 1.0,
    "target handover system": 1.0,
    "handover system .": 1.0,
    "as in fighter": 0.08333333333333333,
    "in fighter applications": 0.3333333333333333,
    "fighter applications ,": 1.0,
    "applications , the": 0.25,
    ", the overriding": 0.009523809523809525,
    "the overriding issue": 1.0,
    "overriding issue for": 1.0,
    "issue for voice": 1.0,
    "for voice in": 1.0,
    "voice in helicopters": 1.0,
    "in helicopters is": 0.5,
    "helicopters is the": 1.0,
    "is the impact": 0.022222222222222223,
    "the impact on": 0.5,
    "impact on pilot": 1.0,
    "on pilot effectiveness": 1.0,
    "pilot effectiveness .": 1.0,
    "<s> encouraging results": 1.0,
    "encouraging results are": 1.0,
    "results are reported": 0.25,
    "are reported for": 1.0,
    "reported for the": 1.0,
    "for the avrada": 0.03125,
    "the avrada tests": 1.0,
    "avrada tests ,": 1.0,
    "tests , although": 1.0,
    ", although these": 0.25,
    "although these represent": 0.5,
    "these represent only": 1.0,
    "represent only a": 1.0,
    "only a feasibility": 0.5,
    "a feasibility demonstration": 1.0,
    "feasibility demonstration in": 1.0,
    "demonstration in a": 1.0,
    "in a test": 0.019230769230769232,
    "a test environment": 0.3333333333333333,
    "test environment .": 1.0,
    "<s> much remains": 0.3333333333333333,
    "much remains to": 1.0,
    "remains to be": 1.0,
    "be done both": 0.2,
    "done both in": 1.0,
    "both in speech": 1.0,
    "recognition and in": 0.14285714285714285,
    "and in overall": 0.14285714285714285,
    "in overall speech": 1.0,
    "overall speech recognition": 1.0,
    "speech recognition technology": 0.013157894736842105,
    "recognition technology ,": 1.0,
    "technology , in": 0.3333333333333333,
    "order to consistently": 0.125,
    "to consistently achieve": 1.0,
    "consistently achieve performance": 1.0,
    "achieve performance improvements": 1.0,
    "performance improvements in": 1.0,
    "improvements in operational": 1.0,
    "in operational settings": 1.0,
    "operational settings .": 1.0,
    "<s> battle management": 1.0,
    "battle management question": 0.25,
    "management question book-new": 1.0,
    "question book-new .": 1.0,
    "<s> svg this": 1.0,
    "svg this unreferenced": 1.0,
    "this unreferenced section": 1.0,
    "unreferenced section requires": 1.0,
    "section requires citations": 0.5,
    "requires citations to": 1.0,
    "citations to ensure": 0.5,
    "to ensure verifiability": 1.0,
    "ensure verifiability .": 1.0,
    "general , battle": 0.16666666666666666,
    ", battle management": 1.0,
    "battle management command": 0.25,
    "management command centres": 1.0,
    "command centres require": 1.0,
    "centres require rapid": 1.0,
    "require rapid access": 1.0,
    "rapid access to": 1.0,
    "access to and": 0.3333333333333333,
    "to and control": 1.0,
    "control of large": 0.3333333333333333,
    "of large ,": 0.25,
    "large , rapidly": 1.0,
    ", rapidly changing": 1.0,
    "rapidly changing information": 1.0,
    "changing information databases": 1.0,
    "information databases .": 1.0,
    "<s> commanders and": 1.0,
    "commanders and system": 1.0,
    "and system operators": 1.0,
    "system operators need": 1.0,
    "operators need to": 1.0,
    "need to query": 0.1,
    "to query these": 1.0,
    "query these databases": 1.0,
    "these databases as": 1.0,
    "databases as conveniently": 1.0,
    "as conveniently as": 1.0,
    "conveniently as possible": 1.0,
    "as possible ,": 0.2,
    "possible , in": 0.3333333333333333,
    ", in an": 0.029411764705882353,
    "in an eyes-busy": 0.125,
    "an eyes-busy environment": 1.0,
    "eyes-busy environment where": 1.0,
    "environment where much": 1.0,
    "where much of": 1.0,
    "much of the": 0.3333333333333333,
    "the information is": 0.16666666666666666,
    "information is presented": 0.5,
    "is presented in": 0.5,
    "in a display": 0.019230769230769232,
    "a display format": 1.0,
    "display format .": 1.0,
    "<s> human-machine interaction": 1.0,
    "human-machine interaction by": 1.0,
    "interaction by voice": 1.0,
    "by voice has": 0.5,
    "voice has the": 1.0,
    "has the potential": 0.5,
    "the potential to": 0.6666666666666666,
    "potential to be": 0.5,
    "to be very": 0.023255813953488372,
    "be very useful": 0.3333333333333333,
    "very useful in": 0.5,
    "useful in these": 0.5,
    "in these environments": 0.25,
    "these environments .": 1.0,
    "number of efforts": 0.027777777777777776,
    "of efforts have": 1.0,
    "have been undertaken": 0.038461538461538464,
    "been undertaken to": 1.0,
    "undertaken to interface": 1.0,
    "to interface commercially": 1.0,
    "interface commercially available": 1.0,
    "commercially available isolated-word": 0.5,
    "available isolated-word recognizers": 1.0,
    "isolated-word recognizers into": 1.0,
    "recognizers into battle": 1.0,
    "into battle management": 1.0,
    "battle management environments": 0.25,
    "management environments .": 1.0,
    "<s> in one": 0.010309278350515464,
    "in one feasibility": 0.2,
    "one feasibility study": 1.0,
    "feasibility study ,": 1.0,
    "study , speech": 1.0,
    "speech recognition equipment": 0.013157894736842105,
    "recognition equipment was": 1.0,
    "equipment was tested": 1.0,
    "was tested in": 1.0,
    "tested in conjunction": 1.0,
    "conjunction with an": 0.5,
    "with an integrated": 0.2,
    "an integrated information": 1.0,
    "integrated information display": 1.0,
    "information display for": 1.0,
    "display for naval": 1.0,
    "for naval battle": 1.0,
    "naval battle management": 1.0,
    "battle management applications": 0.25,
    "management applications .": 1.0,
    "<s> users were": 1.0,
    "users were very": 1.0,
    "were very optimistic": 0.5,
    "very optimistic about": 1.0,
    "optimistic about the": 1.0,
    "about the potential": 0.125,
    "the potential of": 0.3333333333333333,
    "potential of the": 0.5,
    "system , although": 0.1,
    ", although capabilities": 0.25,
    "although capabilities were": 1.0,
    "capabilities were limited": 1.0,
    "were limited .": 1.0,
    "<s> speech understanding": 0.06666666666666667,
    "speech understanding programs": 1.0,
    "understanding programs sponsored": 1.0,
    "programs sponsored by": 1.0,
    "sponsored by the": 1.0,
    "by the defense": 0.03571428571428571,
    "the defense advanced": 1.0,
    "defense advanced research": 1.0,
    "advanced research projects": 1.0,
    "research projects agency": 1.0,
    "projects agency -lrb-": 1.0,
    "agency -lrb- darpa": 1.0,
    "-lrb- darpa -rrb-": 1.0,
    "darpa -rrb- in": 1.0,
    "in the u.s.": 0.006535947712418301,
    "the u.s. has": 0.25,
    "u.s. has focused": 1.0,
    "focused on this": 0.1,
    "on this problem": 0.3333333333333333,
    "this problem of": 0.09090909090909091,
    "of natural speech": 0.043478260869565216,
    "natural speech interface": 0.5,
    "speech interface .": 1.0,
    "speech recognition efforts": 0.013157894736842105,
    "recognition efforts have": 1.0,
    "focused on a": 0.1,
    "on a database": 0.041666666666666664,
    "database of continuous": 0.5,
    "of continuous speech": 0.5,
    "continuous speech recognition": 0.25,
    "recognition -lrb- csr": 0.14285714285714285,
    "-lrb- csr -rrb-": 1.0,
    "csr -rrb- ,": 0.5,
    "-rrb- , large-vocabulary": 0.01282051282051282,
    ", large-vocabulary speech": 1.0,
    "large-vocabulary speech designed": 0.5,
    "speech designed to": 1.0,
    "designed to be": 0.2,
    "to be representative": 0.023255813953488372,
    "be representative of": 1.0,
    "representative of the": 1.0,
    "of the naval": 0.005128205128205128,
    "the naval resource": 1.0,
    "naval resource management": 1.0,
    "resource management task": 0.5,
    "management task .": 1.0,
    "<s> significant advances": 1.0,
    "significant advances in": 1.0,
    "advances in the": 1.0,
    "in the state-of-the-art": 0.006535947712418301,
    "the state-of-the-art in": 0.5,
    "state-of-the-art in csr": 1.0,
    "in csr have": 1.0,
    "csr have been": 1.0,
    "been achieved ,": 0.5,
    "achieved , and": 0.5,
    ", and current": 0.005291005291005291,
    "and current efforts": 1.0,
    "current efforts are": 1.0,
    "efforts are focused": 1.0,
    "are focused on": 1.0,
    "focused on integrating": 0.1,
    "on integrating speech": 1.0,
    "integrating speech recognition": 1.0,
    "recognition and natural": 0.14285714285714285,
    "language processing to": 0.027777777777777776,
    "processing to allow": 1.0,
    "to allow spoken": 0.3333333333333333,
    "allow spoken language": 1.0,
    "spoken language interaction": 0.3333333333333333,
    "language interaction with": 1.0,
    "interaction with a": 1.0,
    "with a naval": 0.05,
    "a naval resource": 1.0,
    "resource management system": 0.5,
    "management system .": 1.0,
    "<s> training air": 1.0,
    "training air traffic": 1.0,
    "air traffic controllers": 1.0,
    "traffic controllers training": 0.3333333333333333,
    "controllers training for": 1.0,
    "training for air": 1.0,
    "for air traffic": 1.0,
    "traffic controllers -lrb-": 0.3333333333333333,
    "controllers -lrb- atc": 1.0,
    "-lrb- atc -rrb-": 1.0,
    "atc -rrb- represents": 1.0,
    "-rrb- represents an": 1.0,
    "represents an excellent": 1.0,
    "an excellent application": 1.0,
    "excellent application for": 1.0,
    "application for speech": 1.0,
    "for speech recognition": 1.0,
    "recognition systems .": 0.1,
    "<s> many atc": 0.09090909090909091,
    "many atc training": 1.0,
    "atc training systems": 0.5,
    "training systems currently": 1.0,
    "systems currently require": 1.0,
    "currently require a": 1.0,
    "require a person": 0.2,
    "a person to": 0.18181818181818182,
    "person to act": 1.0,
    "to act as": 1.0,
    "act as a": 0.3333333333333333,
    "as a ``": 0.027777777777777776,
    "a `` pseudo-pilot": 0.16666666666666666,
    "`` pseudo-pilot ''": 1.0,
    "pseudo-pilot '' ,": 1.0,
    "'' , engaging": 0.03333333333333333,
    ", engaging in": 1.0,
    "engaging in a": 1.0,
    "in a voice": 0.019230769230769232,
    "a voice dialog": 1.0,
    "voice dialog with": 1.0,
    "dialog with the": 1.0,
    "with the trainee": 0.03333333333333333,
    "the trainee controller": 1.0,
    "trainee controller ,": 1.0,
    "controller , which": 0.5,
    ", which simulates": 0.017857142857142856,
    "which simulates the": 1.0,
    "simulates the dialog": 1.0,
    "the dialog that": 1.0,
    "dialog that the": 1.0,
    "that the controller": 0.043478260869565216,
    "the controller would": 0.5,
    "controller would have": 1.0,
    "would have to": 0.3333333333333333,
    "have to conduct": 0.5,
    "to conduct with": 1.0,
    "conduct with pilots": 1.0,
    "with pilots in": 1.0,
    "pilots in a": 1.0,
    "in a real": 0.019230769230769232,
    "a real atc": 0.5,
    "real atc situation": 1.0,
    "atc situation .": 1.0,
    "recognition and synthesis": 0.14285714285714285,
    "and synthesis techniques": 1.0,
    "synthesis techniques offer": 1.0,
    "techniques offer the": 1.0,
    "offer the potential": 1.0,
    "potential to eliminate": 0.5,
    "to eliminate the": 0.5,
    "eliminate the need": 1.0,
    "need for a": 0.3333333333333333,
    "for a person": 0.03225806451612903,
    "act as pseudo-pilot": 0.3333333333333333,
    "as pseudo-pilot ,": 1.0,
    "pseudo-pilot , thus": 1.0,
    ", thus reducing": 0.5,
    "thus reducing training": 1.0,
    "reducing training and": 1.0,
    "training and support": 1.0,
    "and support personnel": 1.0,
    "support personnel .": 1.0,
    "theory , air": 0.25,
    ", air controller": 1.0,
    "air controller tasks": 1.0,
    "controller tasks are": 1.0,
    "tasks are also": 0.25,
    "are also characterized": 0.125,
    "also characterized by": 1.0,
    "characterized by highly": 0.5,
    "by highly structured": 1.0,
    "highly structured speech": 1.0,
    "structured speech as": 1.0,
    "speech as the": 0.5,
    "as the primary": 0.03571428571428571,
    "the primary output": 0.5,
    "primary output of": 1.0,
    "of the controller": 0.005128205128205128,
    "the controller ,": 0.5,
    "controller , hence": 0.5,
    ", hence reducing": 1.0,
    "hence reducing the": 1.0,
    "reducing the difficulty": 1.0,
    "difficulty of the": 0.3333333333333333,
    "the speech recognition": 0.1,
    "speech recognition task": 0.013157894736842105,
    "recognition task should": 0.5,
    "task should be": 1.0,
    "should be possible": 0.1111111111111111,
    "be possible .": 0.5,
    "<s> in practice": 0.010309278350515464,
    "in practice ,": 1.0,
    "practice , this": 1.0,
    "this is rarely": 0.038461538461538464,
    "is rarely the": 1.0,
    "rarely the case": 1.0,
    "<s> the faa": 0.006802721088435374,
    "the faa document": 1.0,
    "faa document 7110.65": 1.0,
    "document 7110.65 details": 1.0,
    "7110.65 details the": 1.0,
    "details the phrases": 1.0,
    "the phrases that": 1.0,
    "phrases that should": 1.0,
    "that should be": 0.5,
    "be used by": 0.05263157894736842,
    "used by air": 0.1111111111111111,
    "by air traffic": 0.5,
    "traffic controllers .": 0.3333333333333333,
    "<s> while this": 0.3333333333333333,
    "while this document": 1.0,
    "this document gives": 1.0,
    "document gives less": 1.0,
    "gives less than": 1.0,
    "less than 150": 0.3333333333333333,
    "than 150 examples": 1.0,
    "150 examples of": 1.0,
    "of such phrases": 0.2,
    "such phrases ,": 1.0,
    "phrases , the": 0.3333333333333333,
    "number of phrases": 0.027777777777777776,
    "of phrases supported": 1.0,
    "phrases supported by": 1.0,
    "supported by one": 1.0,
    "by one of": 1.0,
    "of the simulation": 0.005128205128205128,
    "the simulation vendors": 1.0,
    "simulation vendors speech": 1.0,
    "vendors speech recognition": 1.0,
    "recognition systems is": 0.2,
    "systems is in": 0.3333333333333333,
    "is in excess": 0.3333333333333333,
    "excess of 500,000": 0.5,
    "of 500,000 .": 1.0,
    "<s> the usaf": 0.006802721088435374,
    "the usaf ,": 1.0,
    "usaf , usmc": 1.0,
    ", usmc ,": 1.0,
    "usmc , us": 1.0,
    ", us army": 0.5,
    "us army ,": 1.0,
    "army , us": 1.0,
    ", us navy": 0.5,
    "us navy ,": 1.0,
    "navy , and": 1.0,
    ", and faa": 0.005291005291005291,
    "and faa as": 1.0,
    "faa as well": 1.0,
    "well as a": 0.07692307692307693,
    "as a number": 0.027777777777777776,
    "number of international": 0.027777777777777776,
    "of international atc": 1.0,
    "international atc training": 1.0,
    "atc training organizations": 0.5,
    "training organizations such": 1.0,
    "organizations such as": 1.0,
    "as the royal": 0.03571428571428571,
    "the royal australian": 0.5,
    "royal australian air": 1.0,
    "australian air force": 1.0,
    "air force and": 0.5,
    "force and civil": 1.0,
    "and civil aviation": 1.0,
    "civil aviation authorities": 1.0,
    "aviation authorities in": 1.0,
    "authorities in italy": 1.0,
    "italy , brazil": 0.5,
    ", brazil ,": 1.0,
    "brazil , and": 1.0,
    ", and canada": 0.005291005291005291,
    "and canada are": 1.0,
    "canada are currently": 1.0,
    "are currently using": 0.5,
    "currently using atc": 1.0,
    "using atc simulators": 1.0,
    "atc simulators with": 1.0,
    "simulators with speech": 1.0,
    "with speech recognition": 1.0,
    "speech recognition from": 0.02631578947368421,
    "recognition from a": 0.5,
    "from a number": 0.08333333333333333,
    "number of different": 0.027777777777777776,
    "of different vendors": 0.5,
    "different vendors .": 1.0,
    "<s> telephony and": 1.0,
    "telephony and other": 1.0,
    "and other domains": 0.1111111111111111,
    "other domains asr": 1.0,
    "domains asr in": 1.0,
    "asr in the": 1.0,
    "field of telephony": 0.08333333333333333,
    "of telephony is": 1.0,
    "telephony is now": 1.0,
    "is now commonplace": 0.3333333333333333,
    "now commonplace and": 1.0,
    "commonplace and in": 1.0,
    "and in the": 0.14285714285714285,
    "of computer gaming": 0.25,
    "computer gaming and": 1.0,
    "gaming and simulation": 1.0,
    "and simulation is": 1.0,
    "simulation is becoming": 1.0,
    "is becoming more": 1.0,
    "becoming more widespread": 1.0,
    "more widespread .": 1.0,
    "<s> despite the": 1.0,
    "despite the high": 0.5,
    "the high level": 0.5,
    "level of integration": 0.14285714285714285,
    "of integration with": 1.0,
    "integration with word": 1.0,
    "with word processing": 0.3333333333333333,
    "word processing in": 1.0,
    "processing in general": 0.5,
    "in general personal": 0.125,
    "general personal computing": 1.0,
    "personal computing .": 1.0,
    "however , asr": 0.022727272727272728,
    ", asr in": 1.0,
    "field of document": 0.08333333333333333,
    "of document production": 1.0,
    "document production has": 1.0,
    "production has not": 1.0,
    "has not seen": 0.5,
    "not seen the": 1.0,
    "seen the expected": 1.0,
    "the expected -lrb-": 0.5,
    "expected -lrb- by": 1.0,
    "-lrb- by whom": 0.5,
    "by whom ?": 1.0,
    "whom ? -rrb-": 1.0,
    "<s> increases in": 1.0,
    "increases in use": 0.5,
    "in use .": 0.5,
    "<s> the improvement": 0.006802721088435374,
    "improvement of mobile": 0.5,
    "of mobile processor": 1.0,
    "mobile processor speeds": 1.0,
    "processor speeds made": 1.0,
    "speeds made feasible": 1.0,
    "made feasible the": 1.0,
    "feasible the speech-enabled": 1.0,
    "the speech-enabled symbian": 1.0,
    "speech-enabled symbian and": 1.0,
    "symbian and windows": 1.0,
    "and windows mobile": 1.0,
    "windows mobile smartphones": 1.0,
    "mobile smartphones .": 1.0,
    "<s> speech is": 0.13333333333333333,
    "speech is used": 0.3333333333333333,
    "is used mostly": 0.07692307692307693,
    "used mostly as": 1.0,
    "mostly as a": 1.0,
    "as a part": 0.027777777777777776,
    "part of user": 0.045454545454545456,
    "of user interface": 1.0,
    "user interface ,": 0.5,
    "interface , for": 1.0,
    ", for creating": 0.045454545454545456,
    "for creating pre-defined": 1.0,
    "creating pre-defined or": 1.0,
    "pre-defined or custom": 1.0,
    "or custom speech": 1.0,
    "custom speech commands": 1.0,
    "speech commands .": 1.0,
    "<s> leading software": 1.0,
    "leading software vendors": 1.0,
    "software vendors in": 1.0,
    "vendors in this": 1.0,
    "this field are": 0.5,
    "field are :": 1.0,
    "are : microsoft": 0.5,
    ": microsoft corporation": 1.0,
    "microsoft corporation -lrb-": 1.0,
    "corporation -lrb- microsoft": 0.5,
    "-lrb- microsoft voice": 1.0,
    "microsoft voice command": 1.0,
    "voice command -rrb-": 1.0,
    "command -rrb- ,": 1.0,
    "-rrb- , digital": 0.01282051282051282,
    ", digital syphon": 1.0,
    "digital syphon -lrb-": 1.0,
    "syphon -lrb- sonic": 1.0,
    "-lrb- sonic extractor": 1.0,
    "sonic extractor -rrb-": 1.0,
    "extractor -rrb- ,": 1.0,
    "-rrb- , nuance": 0.01282051282051282,
    ", nuance communications": 1.0,
    "communications -lrb- nuance": 0.5,
    "-lrb- nuance voice": 1.0,
    "nuance voice control": 1.0,
    "voice control -rrb-": 1.0,
    "control -rrb- ,": 1.0,
    "-rrb- , speech": 0.02564102564102564,
    ", speech technology": 0.09090909090909091,
    "speech technology center": 1.0,
    "technology center ,": 1.0,
    "center , vito": 0.5,
    ", vito technology": 1.0,
    "vito technology -lrb-": 1.0,
    "technology -lrb- vito": 1.0,
    "-lrb- vito voice2go": 1.0,
    "vito voice2go -rrb-": 1.0,
    "voice2go -rrb- ,": 1.0,
    "-rrb- , speereo": 0.01282051282051282,
    ", speereo software": 1.0,
    "speereo software -lrb-": 1.0,
    "software -lrb- speereo": 0.5,
    "-lrb- speereo voice": 1.0,
    "speereo voice translator": 1.0,
    "voice translator -rrb-": 1.0,
    "translator -rrb- ,": 1.0,
    "-rrb- , verbyx": 0.01282051282051282,
    ", verbyx vrx": 1.0,
    "verbyx vrx and": 1.0,
    "vrx and svox": 1.0,
    "and svox .": 1.0,
    "<s> further applications": 0.3333333333333333,
    "further applications aerospace": 1.0,
    "applications aerospace -lrb-": 1.0,
    "aerospace -lrb- e.g.": 1.0,
    "-lrb- e.g. space": 0.02631578947368421,
    "e.g. space exploration": 1.0,
    "space exploration ,": 1.0,
    "exploration , spacecraft": 1.0,
    ", spacecraft ,": 1.0,
    "spacecraft , etc.": 1.0,
    "etc. -rrb- nasa": 0.1111111111111111,
    "-rrb- nasa 's": 1.0,
    "nasa 's mars": 1.0,
    "'s mars polar": 1.0,
    "mars polar lander": 1.0,
    "polar lander used": 1.0,
    "lander used speech": 1.0,
    "used speech recognition": 1.0,
    "recognition from technology": 0.5,
    "from technology sensory": 1.0,
    "technology sensory ,": 1.0,
    "sensory , inc.": 1.0,
    ", inc. in": 0.5,
    "inc. in the": 1.0,
    "in the mars": 0.006535947712418301,
    "the mars microphone": 1.0,
    "mars microphone on": 1.0,
    "microphone on the": 1.0,
    "on the lander": 0.014925373134328358,
    "the lander automatic": 1.0,
    "lander automatic translation": 1.0,
    "automatic translation automotive": 0.3333333333333333,
    "translation automotive speech": 1.0,
    "automotive speech recognition": 1.0,
    "recognition -lrb- e.g.": 0.14285714285714285,
    "e.g. , onstar": 0.038461538461538464,
    ", onstar ,": 1.0,
    "onstar , ford": 1.0,
    ", ford sync": 1.0,
    "ford sync -rrb-": 1.0,
    "sync -rrb- court": 1.0,
    "-rrb- court reporting": 1.0,
    "court reporting -lrb-": 0.5,
    "reporting -lrb- realtime": 1.0,
    "-lrb- realtime speech": 1.0,
    "realtime speech writing": 1.0,
    "speech writing -rrb-": 1.0,
    "writing -rrb- hands-free": 0.5,
    "-rrb- hands-free computing": 1.0,
    "hands-free computing :": 1.0,
    "computing : speech": 1.0,
    ": speech recognition": 1.0,
    "speech recognition computer": 0.013157894736842105,
    "recognition computer user": 0.5,
    "computer user interface": 1.0,
    "user interface home": 0.5,
    "interface home automation": 1.0,
    "home automation interactive": 1.0,
    "automation interactive voice": 1.0,
    "interactive voice response": 1.0,
    "voice response mobile": 1.0,
    "response mobile telephony": 1.0,
    "mobile telephony ,": 1.0,
    "telephony , including": 0.5,
    ", including mobile": 0.125,
    "including mobile email": 1.0,
    "mobile email multimodal": 1.0,
    "email multimodal interaction": 1.0,
    "multimodal interaction pronunciation": 1.0,
    "interaction pronunciation evaluation": 1.0,
    "pronunciation evaluation in": 1.0,
    "evaluation in computer-aided": 0.25,
    "in computer-aided language": 1.0,
    "computer-aided language learning": 1.0,
    "language learning applications": 1.0,
    "learning applications robotics": 1.0,
    "applications robotics speech-to-text": 1.0,
    "robotics speech-to-text reporter": 1.0,
    "speech-to-text reporter -lrb-": 1.0,
    "reporter -lrb- transcription": 1.0,
    "-lrb- transcription of": 1.0,
    "transcription of speech": 1.0,
    "of speech into": 0.02127659574468085,
    "speech into text": 0.5,
    "into text ,": 0.3333333333333333,
    "text , video": 0.03333333333333333,
    ", video captioning": 0.5,
    "video captioning ,": 1.0,
    "captioning , court": 1.0,
    ", court reporting": 1.0,
    "court reporting -rrb-": 0.5,
    "reporting -rrb- telematics": 1.0,
    "-rrb- telematics -lrb-": 1.0,
    "telematics -lrb- e.g.": 1.0,
    "e.g. , vehicle": 0.038461538461538464,
    ", vehicle navigation": 1.0,
    "vehicle navigation systems": 1.0,
    "navigation systems -rrb-": 0.5,
    "systems -rrb- transcription": 0.5,
    "-rrb- transcription -lrb-": 1.0,
    "transcription -lrb- digital": 1.0,
    "-lrb- digital speech-to-text": 1.0,
    "digital speech-to-text -rrb-": 1.0,
    "speech-to-text -rrb- video": 1.0,
    "-rrb- video games": 1.0,
    "video games ,": 1.0,
    "games , with": 1.0,
    ", with tom": 0.125,
    "with tom clancy": 1.0,
    "tom clancy 's": 1.0,
    "clancy 's endwar": 1.0,
    "'s endwar and": 1.0,
    "endwar and lifeline": 1.0,
    "and lifeline as": 1.0,
    "lifeline as working": 1.0,
    "as working examples": 1.0,
    "working examples performance": 1.0,
    "examples performance the": 1.0,
    "performance the performance": 1.0,
    "the performance of": 1.0,
    "performance of speech": 0.5,
    "systems is usually": 0.3333333333333333,
    "is usually evaluated": 0.125,
    "usually evaluated in": 1.0,
    "evaluated in terms": 1.0,
    "terms of accuracy": 0.14285714285714285,
    "of accuracy and": 0.5,
    "accuracy and speed": 1.0,
    "and speed .": 1.0,
    "<s> accuracy is": 0.2,
    "accuracy is usually": 1.0,
    "is usually rated": 0.125,
    "usually rated with": 1.0,
    "rated with word": 1.0,
    "with word error": 0.3333333333333333,
    "word error rate": 0.6666666666666666,
    "error rate -lrb-": 0.3333333333333333,
    "rate -lrb- wer": 0.3333333333333333,
    "-lrb- wer -rrb-": 1.0,
    "wer -rrb- ,": 1.0,
    "-rrb- , whereas": 0.01282051282051282,
    ", whereas speed": 0.5,
    "whereas speed is": 1.0,
    "speed is measured": 1.0,
    "is measured with": 0.3333333333333333,
    "measured with the": 1.0,
    "with the real": 0.03333333333333333,
    "the real time": 0.3333333333333333,
    "real time factor": 0.5,
    "time factor .": 1.0,
    "<s> other measures": 0.14285714285714285,
    "other measures of": 1.0,
    "measures of accuracy": 1.0,
    "of accuracy include": 0.5,
    "accuracy include single": 1.0,
    "include single word": 1.0,
    "single word error": 0.5,
    "rate -lrb- swer": 0.3333333333333333,
    "-lrb- swer -rrb-": 1.0,
    "swer -rrb- and": 1.0,
    "-rrb- and command": 0.05,
    "and command success": 1.0,
    "command success rate": 1.0,
    "success rate -lrb-": 1.0,
    "rate -lrb- csr": 0.3333333333333333,
    "csr -rrb- .": 0.5,
    "however , speech": 0.022727272727272728,
    "recognition -lrb- by": 0.14285714285714285,
    "-lrb- by a": 0.5,
    "by a machine": 0.1111111111111111,
    "a machine -rrb-": 0.125,
    "machine -rrb- is": 1.0,
    "a very complex": 0.08333333333333333,
    "very complex problem": 1.0,
    "complex problem .": 1.0,
    "<s> vocalizations vary": 1.0,
    "vocalizations vary in": 1.0,
    "vary in terms": 0.3333333333333333,
    "terms of accent": 0.14285714285714285,
    "of accent ,": 1.0,
    "accent , pronunciation": 1.0,
    ", pronunciation ,": 1.0,
    "pronunciation , articulation": 1.0,
    ", articulation ,": 1.0,
    "articulation , roughness": 1.0,
    ", roughness ,": 1.0,
    "roughness , nasality": 1.0,
    ", nasality ,": 1.0,
    "nasality , pitch": 1.0,
    ", pitch ,": 1.0,
    "pitch , volume": 1.0,
    ", volume ,": 1.0,
    "volume , and": 1.0,
    ", and speed": 0.005291005291005291,
    "speech is distorted": 0.3333333333333333,
    "is distorted by": 0.5,
    "distorted by a": 1.0,
    "by a background": 0.05555555555555555,
    "a background noise": 1.0,
    "background noise and": 1.0,
    "noise and echoes": 1.0,
    "and echoes ,": 1.0,
    "echoes , electrical": 0.5,
    ", electrical characteristics": 1.0,
    "electrical characteristics .": 1.0,
    "accuracy of speech": 0.42857142857142855,
    "speech recognition vary": 0.013157894736842105,
    "recognition vary with": 1.0,
    "vary with the": 1.0,
    "with the following": 0.03333333333333333,
    "the following :": 0.09090909090909091,
    "following : vocabulary": 0.5,
    ": vocabulary size": 1.0,
    "vocabulary size and": 0.3333333333333333,
    "size and confusability": 0.5,
    "and confusability speaker": 1.0,
    "confusability speaker dependence": 1.0,
    "speaker dependence vs.": 1.0,
    "dependence vs. independence": 1.0,
    "vs. independence isolated": 0.5,
    "independence isolated ,": 1.0,
    "isolated , discontinuous": 1.0,
    ", discontinuous ,": 0.5,
    "discontinuous , or": 1.0,
    ", or continuous": 0.030303030303030304,
    "or continuous speech": 1.0,
    "continuous speech task": 0.25,
    "speech task and": 1.0,
    "task and language": 1.0,
    "and language constraints": 0.2857142857142857,
    "language constraints read": 0.5,
    "constraints read vs.": 1.0,
    "read vs. spontaneous": 1.0,
    "vs. spontaneous speech": 1.0,
    "spontaneous speech adverse": 0.25,
    "speech adverse conditions": 1.0,
    "adverse conditions accuracy": 0.5,
    "conditions accuracy of": 1.0,
    "speech recognition as": 0.013157894736842105,
    "recognition as mentioned": 1.0,
    "mentioned earlier in": 0.5,
    "earlier in this": 1.0,
    "this article accuracy": 0.2,
    "article accuracy of": 1.0,
    "of speech recogniton": 0.02127659574468085,
    "speech recogniton vary": 0.5,
    "recogniton vary in": 1.0,
    "vary in following": 0.3333333333333333,
    "in following :": 1.0,
    "following : error": 0.5,
    ": error rates": 1.0,
    "error rates increase": 0.25,
    "rates increase as": 1.0,
    "increase as the": 1.0,
    "as the vocabulary": 0.03571428571428571,
    "the vocabulary size": 0.5,
    "vocabulary size grows": 0.3333333333333333,
    "size grows :": 1.0,
    "grows : e.g.": 1.0,
    ": e.g. the": 1.0,
    "e.g. the 10": 0.2,
    "the 10 digits": 1.0,
    "10 digits ``": 1.0,
    "digits `` zero": 1.0,
    "`` zero ''": 1.0,
    "zero '' to": 1.0,
    "'' to ``": 0.3333333333333333,
    "to `` nine": 0.25,
    "`` nine ''": 1.0,
    "nine '' can": 1.0,
    "can be recognized": 0.01098901098901099,
    "be recognized essentially": 0.5,
    "recognized essentially perfectly": 1.0,
    "essentially perfectly ,": 1.0,
    "perfectly , but": 1.0,
    ", but vocabulary": 0.020833333333333332,
    "but vocabulary sizes": 1.0,
    "vocabulary sizes of": 1.0,
    "sizes of 200": 0.5,
    "of 200 ,": 1.0,
    "200 , 5000": 1.0,
    ", 5000 or": 1.0,
    "5000 or 100000": 1.0,
    "or 100000 may": 1.0,
    "100000 may have": 1.0,
    "may have error": 0.5,
    "have error rates": 1.0,
    "error rates of": 0.25,
    "rates of 3": 0.3333333333333333,
    "of 3 %": 1.0,
    "3 % ,": 1.0,
    "% , 7": 0.5,
    ", 7 %": 1.0,
    "7 % or": 1.0,
    "% or 45": 1.0,
    "or 45 %": 1.0,
    "45 % .": 1.0,
    "<s> vocabulary is": 1.0,
    "vocabulary is hard": 1.0,
    "hard to recognize": 0.3333333333333333,
    "to recognize if": 0.14285714285714285,
    "recognize if it": 1.0,
    "if it contains": 0.3333333333333333,
    "it contains confusable": 1.0,
    "contains confusable words": 1.0,
    "confusable words :": 0.5,
    "words : e.g.": 1.0,
    "e.g. the 26": 0.2,
    "the 26 letters": 1.0,
    "26 letters of": 1.0,
    "english alphabet are": 0.5,
    "alphabet are difficult": 1.0,
    "are difficult to": 1.0,
    "difficult to discriminate": 0.09090909090909091,
    "to discriminate because": 0.5,
    "discriminate because they": 1.0,
    "because they are": 0.25,
    "they are confusable": 0.14285714285714285,
    "are confusable words": 1.0,
    "confusable words -lrb-": 0.5,
    "words -lrb- most": 0.3333333333333333,
    "-lrb- most notoriously": 0.25,
    "most notoriously ,": 1.0,
    "notoriously , the": 1.0,
    ", the e-set": 0.009523809523809525,
    "the e-set :": 1.0,
    "e-set : ``": 1.0,
    ": `` b": 0.5,
    "`` b ,": 1.0,
    "b , c": 1.0,
    ", c ,": 1.0,
    "c , d": 1.0,
    ", d ,": 1.0,
    "d , e": 1.0,
    ", e ,": 1.0,
    "e , g": 1.0,
    ", g ,": 1.0,
    "g , p": 1.0,
    ", p ,": 1.0,
    "p , t": 1.0,
    ", t ,": 1.0,
    "t , v": 1.0,
    ", v ,": 1.0,
    "v , z": 1.0,
    ", z ''": 1.0,
    "z '' -rrb-": 1.0,
    "-rrb- ; an": 0.125,
    "; an 8": 1.0,
    "an 8 %": 1.0,
    "8 % error": 1.0,
    "% error rate": 1.0,
    "error rate is": 0.16666666666666666,
    "rate is considered": 0.5,
    "is considered good": 0.5,
    "considered good for": 1.0,
    "good for this": 1.0,
    "for this vocabulary": 0.125,
    "this vocabulary .": 1.0,
    "<s> speaker dependence": 0.5,
    "vs. independence :": 0.5,
    "independence : a": 1.0,
    ": a speaker": 1.0,
    "a speaker dependent": 0.25,
    "speaker dependent system": 0.5,
    "dependent system is": 1.0,
    "system is intended": 0.2222222222222222,
    "is intended for": 1.0,
    "intended for use": 1.0,
    "for use by": 1.0,
    "use by a": 0.5,
    "by a single": 0.05555555555555555,
    "a single speaker": 0.1111111111111111,
    "single speaker .": 1.0,
    "<s> a speaker": 0.022727272727272728,
    "a speaker independent": 0.25,
    "speaker independent system": 0.3333333333333333,
    "independent system is": 1.0,
    "use by any": 0.5,
    "by any speaker": 1.0,
    "any speaker ,": 1.0,
    "speaker , more": 1.0,
    ", more difficult": 0.25,
    "more difficult .": 0.14285714285714285,
    "<s> isolated ,": 1.0,
    ", discontinuous or": 0.5,
    "discontinuous or continuous": 1.0,
    "continuous speech with": 0.25,
    "speech with isolated": 1.0,
    "with isolated speech": 1.0,
    "isolated speech single": 0.5,
    "speech single words": 1.0,
    "single words are": 1.0,
    "are used ,": 0.375,
    "used , therefore": 0.375,
    ", therefore it": 1.0,
    "therefore it becomes": 1.0,
    "it becomes easier": 0.5,
    "becomes easier to": 1.0,
    "easier to recognize": 1.0,
    "to recognize the": 0.5714285714285714,
    "recognize the speech": 1.0,
    "<s> with discontinuous": 0.2,
    "with discontinuous speech": 1.0,
    "discontinuous speech full": 0.5,
    "speech full sentenced": 1.0,
    "full sentenced separated": 1.0,
    "sentenced separated by": 1.0,
    "separated by silence": 0.5,
    "by silence are": 1.0,
    "silence are used": 1.0,
    "the speech as": 0.1,
    "speech as well": 0.5,
    "well as with": 0.07692307692307693,
    "as with isolated": 0.3333333333333333,
    "isolated speech .": 0.5,
    "<s> with continuous": 0.2,
    "with continuous speech": 1.0,
    "continuous speech naturally": 0.25,
    "speech naturally spoken": 1.0,
    "naturally spoken sentences": 1.0,
    "spoken sentences are": 1.0,
    "sentences are used": 0.14285714285714285,
    "it becomes harder": 0.25,
    "becomes harder to": 1.0,
    "harder to recognize": 0.5,
    "the speech ,": 0.1,
    "speech , different": 0.09090909090909091,
    ", different from": 0.3333333333333333,
    "different from both": 0.16666666666666666,
    "from both isloated": 1.0,
    "both isloated and": 1.0,
    "isloated and discontinuous": 1.0,
    "and discontinuous speech": 1.0,
    "discontinuous speech .": 0.5,
    "<s> task and": 1.0,
    "language constraints e.g.": 0.5,
    "constraints e.g. querying": 1.0,
    "e.g. querying application": 1.0,
    "querying application may": 1.0,
    "application may dismiss": 1.0,
    "may dismiss the": 1.0,
    "dismiss the hypothesis": 1.0,
    "the hypothesis ``": 1.0,
    "hypothesis `` the": 1.0,
    "`` the apple": 0.25,
    "the apple is": 0.6666666666666666,
    "apple is red": 0.5,
    "is red .": 1.0,
    "red . ''": 1.0,
    "<s> e.g. constraints": 0.5,
    "e.g. constraints may": 1.0,
    "constraints may be": 1.0,
    "may be semantic": 0.047619047619047616,
    "be semantic ;": 1.0,
    "semantic ; rejecting": 1.0,
    "; rejecting ``": 1.0,
    "rejecting `` the": 0.5,
    "apple is angry": 0.5,
    "is angry .": 1.0,
    "angry . ''": 1.0,
    "<s> e.g. syntactic": 0.5,
    "e.g. syntactic ;": 1.0,
    "syntactic ; rejecting": 1.0,
    "rejecting `` red": 0.5,
    "`` red is": 1.0,
    "red is apple": 1.0,
    "is apple the": 1.0,
    "apple the .": 1.0,
    "the . ''": 1.0,
    "<s> constraints are": 1.0,
    "constraints are often": 0.5,
    "are often represented": 0.25,
    "often represented by": 1.0,
    "represented by a": 0.5,
    "a grammar .": 0.5,
    "<s> read vs.": 1.0,
    "spontaneous speech when": 0.25,
    "speech when a": 1.0,
    "when a person": 0.4,
    "a person reads": 0.09090909090909091,
    "person reads it": 1.0,
    "reads it 's": 1.0,
    "it 's usually": 0.3333333333333333,
    "'s usually in": 1.0,
    "usually in a": 0.3333333333333333,
    "in a context": 0.019230769230769232,
    "a context that": 0.5,
    "context that has": 1.0,
    "has been previously": 0.03571428571428571,
    "been previously prepared": 1.0,
    "previously prepared ,": 1.0,
    "prepared , but": 1.0,
    ", but when": 0.020833333333333332,
    "but when a": 1.0,
    "a person uses": 0.09090909090909091,
    "person uses spontaneous": 1.0,
    "uses spontaneous speech": 1.0,
    "spontaneous speech ,": 0.25,
    "speech , it": 0.09090909090909091,
    "difficult to recognize": 0.09090909090909091,
    "<s> because of": 0.3333333333333333,
    "of the disfluences": 0.005128205128205128,
    "the disfluences -lrb-": 1.0,
    "disfluences -lrb- like": 1.0,
    "-lrb- like ``": 1.0,
    "like `` uh": 0.3333333333333333,
    "`` uh ''": 1.0,
    "uh '' and": 1.0,
    "and `` um": 0.05,
    "`` um ''": 1.0,
    "um '' ,": 1.0,
    "'' , false": 0.03333333333333333,
    ", false starts": 1.0,
    "false starts ,": 1.0,
    "starts , incomplete": 1.0,
    ", incomplete sentences": 1.0,
    "incomplete sentences ,": 1.0,
    "sentences , stutering": 0.125,
    ", stutering ,": 1.0,
    "stutering , coughing": 1.0,
    ", coughing ,": 1.0,
    "coughing , and": 1.0,
    ", and laughter": 0.005291005291005291,
    "and laughter -rrb-": 1.0,
    "laughter -rrb- and": 1.0,
    "-rrb- and limited": 0.05,
    "and limited vocabulary": 1.0,
    "limited vocabulary .": 1.0,
    "<s> adverse conditions": 1.0,
    "adverse conditions environmental": 0.5,
    "conditions environmental noise": 1.0,
    "environmental noise -lrb-": 1.0,
    "noise -lrb- e.g.": 1.0,
    "-lrb- e.g. noise": 0.02631578947368421,
    "e.g. noise in": 1.0,
    "noise in a": 0.5,
    "in a car": 0.019230769230769232,
    "a car or": 1.0,
    "car or a": 1.0,
    "or a factory": 0.05263157894736842,
    "a factory -rrb-": 1.0,
    "factory -rrb- acoustical": 1.0,
    "-rrb- acoustical distortions": 1.0,
    "acoustical distortions -lrb-": 1.0,
    "distortions -lrb- e.g.": 1.0,
    "-lrb- e.g. echoes": 0.02631578947368421,
    "e.g. echoes ,": 1.0,
    "echoes , room": 0.5,
    ", room acoustics": 1.0,
    "room acoustics -rrb-": 1.0,
    "acoustics -rrb- speech": 1.0,
    "-rrb- speech recognition": 1.0,
    "recognition is a": 0.1,
    "is a multileveled": 0.018518518518518517,
    "a multileveled pattern": 1.0,
    "multileveled pattern recognition": 1.0,
    "pattern recognition task": 0.25,
    "recognition task .": 0.5,
    "<s> acoustical signals": 1.0,
    "acoustical signals are": 1.0,
    "signals are structured": 0.5,
    "are structured into": 1.0,
    "structured into a": 1.0,
    "into a hierarchy": 0.058823529411764705,
    "a hierarchy of": 1.0,
    "hierarchy of units": 0.5,
    "of units ;": 1.0,
    "units ; e.g.": 1.0,
    "; e.g. phonemes": 0.5,
    "e.g. phonemes ,": 1.0,
    "phonemes , words": 1.0,
    ", words ,": 0.3333333333333333,
    "phrases , and": 0.3333333333333333,
    ", and sentences": 0.005291005291005291,
    "and sentences ;": 0.3333333333333333,
    "sentences ; each": 1.0,
    "; each level": 1.0,
    "each level provides": 1.0,
    "level provides additional": 1.0,
    "provides additional constraints": 1.0,
    "additional constraints ;": 1.0,
    "constraints ; e.g.": 1.0,
    "; e.g. known": 0.5,
    "e.g. known word": 1.0,
    "known word pronunciations": 0.5,
    "word pronunciations or": 1.0,
    "pronunciations or legal": 1.0,
    "or legal word": 1.0,
    "legal word sequences": 1.0,
    "word sequences ,": 1.0,
    "sequences , which": 1.0,
    "which can compensate": 0.2,
    "can compensate for": 1.0,
    "compensate for errors": 1.0,
    "for errors or": 1.0,
    "errors or uncertainties": 1.0,
    "or uncertainties at": 1.0,
    "uncertainties at lower": 1.0,
    "at lower level": 1.0,
    "lower level ;": 0.5,
    "level ; this": 0.5,
    "; this hierarchy": 0.25,
    "this hierarchy of": 1.0,
    "hierarchy of constraints": 0.5,
    "of constraints are": 1.0,
    "constraints are exploited": 0.5,
    "are exploited ;": 1.0,
    "exploited ; by": 1.0,
    "; by combining": 1.0,
    "by combining decisions": 0.5,
    "combining decisions probabilistically": 1.0,
    "decisions probabilistically at": 1.0,
    "probabilistically at all": 1.0,
    "at all lower": 0.2,
    "all lower levels": 1.0,
    "lower levels ,": 0.5,
    "levels , and": 1.0,
    "and making more": 0.5,
    "making more deterministic": 1.0,
    "more deterministic decisions": 0.5,
    "deterministic decisions only": 1.0,
    "decisions only at": 1.0,
    "only at the": 1.0,
    "at the highest": 0.0625,
    "the highest level": 1.0,
    "highest level ;": 1.0,
    "level ; speech": 0.5,
    "; speech recogniton": 1.0,
    "speech recogniton by": 0.5,
    "recogniton by a": 1.0,
    "a machine is": 0.125,
    "machine is a": 1.0,
    "is a process": 0.018518518518518517,
    "a process broken": 0.25,
    "process broken into": 1.0,
    "broken into several": 0.3333333333333333,
    "into several phases": 1.0,
    "several phases .": 1.0,
    "<s> computationally ,": 1.0,
    "computationally , it": 1.0,
    "is a problem": 0.018518518518518517,
    "a problem in": 0.25,
    "problem in which": 0.25,
    "in which a": 0.25,
    "which a sound": 0.5,
    "a sound pattern": 0.14285714285714285,
    "sound pattern has": 1.0,
    "pattern has to": 1.0,
    "to be recognized": 0.023255813953488372,
    "be recognized or": 0.5,
    "recognized or classified": 1.0,
    "or classified into": 1.0,
    "classified into a": 1.0,
    "into a category": 0.058823529411764705,
    "a category that": 1.0,
    "category that represents": 1.0,
    "that represents a": 1.0,
    "represents a meaning": 0.3333333333333333,
    "a meaning to": 1.0,
    "meaning to a": 0.5,
    "<s> every acoustic": 1.0,
    "every acoustic signal": 1.0,
    "acoustic signal can": 1.0,
    "signal can be": 1.0,
    "can be broken": 0.01098901098901099,
    "be broken in": 1.0,
    "broken in smaller": 1.0,
    "in smaller more": 1.0,
    "smaller more basic": 1.0,
    "more basic sub-signals": 0.5,
    "basic sub-signals .": 1.0,
    "<s> as the": 0.07142857142857142,
    "as the more": 0.03571428571428571,
    "the more complex": 0.16666666666666666,
    "more complex sound": 0.2222222222222222,
    "complex sound signal": 0.3333333333333333,
    "sound signal is": 1.0,
    "signal is broken": 1.0,
    "is broken into": 1.0,
    "broken into the": 0.3333333333333333,
    "into the smaller": 0.125,
    "the smaller sub-sounds": 1.0,
    "smaller sub-sounds ,": 1.0,
    "sub-sounds , different": 1.0,
    ", different levels": 0.3333333333333333,
    "different levels are": 1.0,
    "levels are created": 1.0,
    "created , where": 0.5,
    ", where at": 0.06666666666666667,
    "where at the": 1.0,
    "at the top": 0.0625,
    "the top level": 0.25,
    "top level we": 1.0,
    "level we have": 1.0,
    "we have complex": 0.25,
    "have complex sounds": 1.0,
    "complex sounds ,": 1.0,
    "sounds , which": 0.5,
    "which are made": 0.08333333333333333,
    "are made of": 0.3333333333333333,
    "made of simpler": 0.3333333333333333,
    "of simpler sounds": 0.5,
    "simpler sounds on": 0.5,
    "sounds on lower": 1.0,
    "on lower level": 1.0,
    "lower level ,": 0.5,
    "level , and": 0.25,
    ", and going": 0.005291005291005291,
    "and going to": 1.0,
    "going to lower": 1.0,
    "to lower levels": 1.0,
    "lower levels even": 0.5,
    "levels even more": 1.0,
    "even more ,": 1.0,
    "more , we": 1.0,
    ", we create": 0.058823529411764705,
    "we create more": 0.5,
    "create more basic": 1.0,
    "more basic and": 0.5,
    "basic and shorter": 1.0,
    "and shorter and": 1.0,
    "shorter and simpler": 1.0,
    "and simpler sounds": 1.0,
    "simpler sounds .": 0.5,
    "<s> the lowest": 0.006802721088435374,
    "the lowest level": 1.0,
    "lowest level ,": 1.0,
    "level , where": 0.25,
    "where the sounds": 0.07692307692307693,
    "the sounds are": 0.5,
    "sounds are the": 0.5,
    "are the most": 0.09090909090909091,
    "the most fundamental": 0.041666666666666664,
    "most fundamental ,": 1.0,
    "fundamental , a": 1.0,
    "machine would check": 0.5,
    "would check for": 1.0,
    "check for simple": 1.0,
    "for simple and": 1.0,
    "simple and more": 0.5,
    "and more probabilistic": 0.2,
    "more probabilistic rules": 1.0,
    "probabilistic rules of": 1.0,
    "rules of what": 0.25,
    "of what sound": 0.25,
    "what sound should": 1.0,
    "sound should represent": 1.0,
    "should represent .": 1.0,
    "<s> once these": 0.2,
    "once these sounds": 1.0,
    "these sounds are": 1.0,
    "sounds are put": 0.5,
    "are put together": 1.0,
    "put together into": 1.0,
    "together into more": 1.0,
    "into more complex": 0.5,
    "complex sound on": 0.3333333333333333,
    "sound on upper": 1.0,
    "on upper level": 1.0,
    "upper level ,": 0.5,
    "level , a": 0.25,
    ", a new": 0.020833333333333332,
    "a new set": 0.16666666666666666,
    "new set of": 1.0,
    "of more deterministic": 0.25,
    "more deterministic rules": 0.5,
    "deterministic rules should": 1.0,
    "rules should predict": 1.0,
    "should predict what": 1.0,
    "predict what new": 1.0,
    "what new complex": 1.0,
    "new complex sound": 1.0,
    "complex sound should": 0.3333333333333333,
    "the most upper": 0.041666666666666664,
    "most upper level": 1.0,
    "upper level of": 0.5,
    "level of a": 0.14285714285714285,
    "of a deterministic": 0.010869565217391304,
    "a deterministic rule": 0.5,
    "deterministic rule should": 1.0,
    "rule should figure": 1.0,
    "should figure out": 1.0,
    "figure out the": 1.0,
    "out the meaning": 0.3333333333333333,
    "meaning of complex": 0.14285714285714285,
    "of complex expressions": 1.0,
    "complex expressions .": 1.0,
    "order to expand": 0.125,
    "to expand our": 1.0,
    "expand our knowledge": 1.0,
    "our knowledge about": 1.0,
    "knowledge about speech": 0.3333333333333333,
    "about speech recognition": 1.0,
    "speech recognition we": 0.013157894736842105,
    "recognition we need": 1.0,
    "take into a": 0.3333333333333333,
    "into a consideration": 0.058823529411764705,
    "a consideration neural": 1.0,
    "consideration neural networks": 1.0,
    "neural networks .": 0.18181818181818182,
    "there are four": 0.047619047619047616,
    "are four steps": 1.0,
    "four steps of": 1.0,
    "steps of neural": 1.0,
    "of neural network": 1.0,
    "neural network approaches": 0.3333333333333333,
    "network approaches :": 0.5,
    "approaches : digitize": 0.25,
    ": digitize the": 1.0,
    "digitize the speech": 0.5,
    "the speech that": 0.1,
    "speech that we": 1.0,
    "that we want": 0.3333333333333333,
    "want to recognize": 0.2,
    "to recognize for": 0.14285714285714285,
    "recognize for telephone": 1.0,
    "for telephone speech": 1.0,
    "telephone speech the": 1.0,
    "speech the sampling": 1.0,
    "the sampling rate": 1.0,
    "sampling rate is": 1.0,
    "rate is 8000": 0.5,
    "is 8000 samples": 1.0,
    "8000 samples per": 1.0,
    "samples per second": 1.0,
    "per second ;": 0.5,
    "second ; compute": 1.0,
    "; compute features": 1.0,
    "compute features of": 1.0,
    "features of spectral-domain": 0.25,
    "of spectral-domain of": 1.0,
    "spectral-domain of the": 1.0,
    "the speech -lrb-": 0.2,
    "speech -lrb- with": 0.25,
    "-lrb- with fourier": 0.3333333333333333,
    "with fourier transform": 1.0,
    "fourier transform -rrb-": 0.3333333333333333,
    "transform -rrb- ;": 1.0,
    "-rrb- ; computed": 0.125,
    "; computed every": 1.0,
    "computed every 10msec": 1.0,
    "every 10msec ,": 1.0,
    "10msec , with": 1.0,
    ", with one": 0.125,
    "with one 10msec": 1.0,
    "one 10msec section": 1.0,
    "10msec section called": 1.0,
    "section called a": 1.0,
    "called a frame": 1.0,
    "a frame ;": 1.0,
    "frame ; analysis": 1.0,
    "; analysis of": 1.0,
    "analysis of four": 0.07692307692307693,
    "of four step": 1.0,
    "four step neural": 1.0,
    "step neural network": 1.0,
    "network approaches can": 0.5,
    "approaches can be": 1.0,
    "can be explained": 0.01098901098901099,
    "be explained by": 1.0,
    "explained by further": 1.0,
    "by further information": 1.0,
    "further information .": 0.5,
    "<s> sound is": 0.5,
    "sound is produced": 1.0,
    "is produced by": 0.5,
    "produced by air": 0.3333333333333333,
    "by air -lrb-": 0.5,
    "air -lrb- or": 1.0,
    "-lrb- or some": 0.1,
    "some other medium": 0.14285714285714285,
    "other medium -rrb-": 1.0,
    "medium -rrb- vibration": 1.0,
    "-rrb- vibration ,": 1.0,
    "vibration , which": 1.0,
    ", which we": 0.017857142857142856,
    "which we register": 1.0,
    "we register by": 1.0,
    "register by ears": 1.0,
    "by ears ,": 1.0,
    "ears , but": 1.0,
    ", but machines": 0.020833333333333332,
    "but machines by": 1.0,
    "machines by receivers": 1.0,
    "by receivers .": 1.0,
    "<s> basic sound": 1.0,
    "basic sound creates": 0.3333333333333333,
    "sound creates a": 1.0,
    "creates a wave": 1.0,
    "a wave which": 0.25,
    "wave which has": 1.0,
    "which has 2": 0.14285714285714285,
    "has 2 descriptions": 1.0,
    "2 descriptions ;": 1.0,
    "descriptions ; amplitude": 1.0,
    "; amplitude -lrb-": 1.0,
    "amplitude -lrb- how": 1.0,
    "-lrb- how strong": 0.3333333333333333,
    "how strong is": 1.0,
    "strong is it": 1.0,
    "is it -rrb-": 1.0,
    "it -rrb- ,": 1.0,
    ", and frequency": 0.005291005291005291,
    "and frequency -lrb-": 1.0,
    "frequency -lrb- how": 1.0,
    "-lrb- how often": 0.3333333333333333,
    "how often it": 1.0,
    "often it vibrates": 1.0,
    "it vibrates per": 1.0,
    "vibrates per second": 1.0,
    "per second -rrb-": 0.5,
    "second -rrb- .": 1.0,
    "<s> digitized sound": 1.0,
    "digitized sound graph": 1.0,
    "sound graph this": 1.0,
    "graph this is": 1.0,
    "is the same": 0.022222222222222223,
    "as the wave": 0.03571428571428571,
    "the wave in": 1.0,
    "wave in the": 1.0,
    "in the water": 0.006535947712418301,
    "the water .": 1.0,
    "<s> big wave": 1.0,
    "big wave is": 1.0,
    "wave is strong": 0.5,
    "is strong and": 1.0,
    "strong and smaller": 1.0,
    "and smaller ones": 1.0,
    "smaller ones are": 1.0,
    "ones are usually": 1.0,
    "are usually faster": 0.3333333333333333,
    "usually faster but": 1.0,
    "faster but weaker": 1.0,
    "but weaker .": 1.0,
    "that is how": 0.05263157894736842,
    "is how air": 0.5,
    "how air is": 1.0,
    "air is distorted": 1.0,
    "is distorted ,": 0.5,
    "distorted , but": 1.0,
    ", but we": 0.020833333333333332,
    "but we do": 1.0,
    "we do n't": 1.0,
    "do n't see": 0.5,
    "n't see it": 1.0,
    "see it easily": 1.0,
    "it easily ,": 1.0,
    "easily , in": 1.0,
    "in order for": 0.1111111111111111,
    "order for sound": 1.0,
    "for sound to": 1.0,
    "sound to travel": 1.0,
    "to travel .": 1.0,
    "<s> these waves": 0.0625,
    "these waves can": 1.0,
    "waves can be": 1.0,
    "can be digitalized": 0.01098901098901099,
    "be digitalized :": 1.0,
    "digitalized : sample": 1.0,
    ": sample a": 1.0,
    "sample a strength": 1.0,
    "a strength at": 1.0,
    "strength at short": 1.0,
    "at short intervals": 1.0,
    "short intervals like": 1.0,
    "intervals like in": 1.0,
    "like in picture": 1.0,
    "in picture above": 1.0,
    "picture above to": 1.0,
    "above to get": 1.0,
    "to get bunch": 0.25,
    "get bunch of": 1.0,
    "bunch of numbers": 1.0,
    "of numbers that": 0.5,
    "numbers that approximate": 1.0,
    "that approximate at": 1.0,
    "approximate at each": 1.0,
    "at each time": 1.0,
    "each time step": 1.0,
    "time step the": 1.0,
    "step the strength": 1.0,
    "strength of a": 0.3333333333333333,
    "of a wave": 0.021739130434782608,
    "a wave .": 0.25,
    "<s> collection of": 1.0,
    "collection of these": 0.3333333333333333,
    "of these numbers": 0.09090909090909091,
    "these numbers represent": 0.5,
    "numbers represent analog": 1.0,
    "represent analog wave": 1.0,
    "analog wave .": 1.0,
    "<s> this new": 0.019230769230769232,
    "this new wave": 1.0,
    "new wave is": 1.0,
    "wave is digital": 0.5,
    "is digital .": 1.0,
    "<s> sound waves": 0.5,
    "sound waves are": 0.5,
    "waves are complicated": 1.0,
    "are complicated because": 1.0,
    "complicated because they": 1.0,
    "because they superimpose": 0.25,
    "they superimpose one": 1.0,
    "superimpose one on": 1.0,
    "one on top": 1.0,
    "on top of": 1.0,
    "top of each": 1.0,
    "of each other": 0.14285714285714285,
    "each other .": 0.3333333333333333,
    "<s> like the": 1.0,
    "like the waves": 1.0,
    "the waves would": 1.0,
    "waves would .": 1.0,
    "<s> this way": 0.019230769230769232,
    "this way they": 0.3333333333333333,
    "way they create": 1.0,
    "they create odd": 1.0,
    "create odd looking": 1.0,
    "odd looking waves": 0.5,
    "looking waves .": 1.0,
    ", if there": 0.1,
    "there are two": 0.09523809523809523,
    "are two waves": 0.5,
    "two waves that": 1.0,
    "waves that interact": 1.0,
    "that interact with": 1.0,
    "interact with each": 1.0,
    "with each other": 1.0,
    "each other we": 0.16666666666666666,
    "other we can": 1.0,
    "we can add": 0.2,
    "can add them": 1.0,
    "add them which": 1.0,
    "them which creates": 1.0,
    "which creates new": 1.0,
    "creates new odd": 1.0,
    "new odd looking": 1.0,
    "odd looking wave": 0.5,
    "looking wave as": 1.0,
    "wave as is": 1.0,
    "as is shown": 0.25,
    "is shown in": 1.0,
    "shown in the": 0.5,
    "in the picture": 0.006535947712418301,
    "the picture on": 0.5,
    "picture on the": 1.0,
    "on the right": 0.014925373134328358,
    "the right .": 0.3333333333333333,
    "<s> neural network": 0.5,
    "neural network classifies": 0.16666666666666666,
    "network classifies features": 1.0,
    "classifies features into": 1.0,
    "features into phonetic-based": 1.0,
    "into phonetic-based categories": 1.0,
    "phonetic-based categories ;": 1.0,
    "categories ; given": 1.0,
    "; given basic": 1.0,
    "given basic sound": 1.0,
    "basic sound blocks": 0.3333333333333333,
    "sound blocks ,": 1.0,
    "blocks , that": 1.0,
    ", that machine": 0.25,
    "that machine digitized": 0.3333333333333333,
    "machine digitized ,": 1.0,
    "digitized , we": 1.0,
    ", we have": 0.058823529411764705,
    "we have a": 0.25,
    "have a bunch": 0.07692307692307693,
    "a bunch of": 1.0,
    "of numbers which": 0.5,
    "numbers which describe": 1.0,
    "which describe a": 1.0,
    "describe a wave": 1.0,
    "a wave and": 0.25,
    "wave and waves": 1.0,
    "and waves describe": 1.0,
    "waves describe words": 1.0,
    "describe words .": 1.0,
    "<s> each frame": 0.2,
    "each frame has": 1.0,
    "frame has a": 1.0,
    "has a unit": 0.25,
    "a unit block": 1.0,
    "unit block of": 1.0,
    "block of sound": 1.0,
    "of sound ,": 0.5,
    "sound , which": 0.5,
    "which are broken": 0.08333333333333333,
    "are broken into": 1.0,
    "broken into basic": 0.3333333333333333,
    "into basic sound": 1.0,
    "basic sound waves": 0.3333333333333333,
    "sound waves and": 0.5,
    "waves and represented": 1.0,
    "and represented by": 1.0,
    "represented by numbers": 0.5,
    "by numbers after": 1.0,
    "numbers after fourier": 1.0,
    "after fourier transform": 1.0,
    "fourier transform ,": 0.3333333333333333,
    "transform , can": 0.3333333333333333,
    "can be statistically": 0.01098901098901099,
    "be statistically evaluated": 1.0,
    "statistically evaluated to": 1.0,
    "evaluated to set": 0.5,
    "to set to": 0.3333333333333333,
    "set to which": 1.0,
    "to which class": 0.2,
    "which class of": 1.0,
    "class of sounds": 0.3333333333333333,
    "of sounds it": 1.0,
    "sounds it belongs": 1.0,
    "it belongs to": 1.0,
    "belongs to .": 1.0,
    "<s> the nodes": 0.006802721088435374,
    "the nodes in": 1.0,
    "nodes in the": 1.0,
    "in the figure": 0.006535947712418301,
    "the figure on": 1.0,
    "figure on a": 1.0,
    "on a slide": 0.041666666666666664,
    "a slide represent": 1.0,
    "slide represent a": 1.0,
    "represent a feature": 0.5,
    "a feature of": 0.6666666666666666,
    "feature of a": 0.6666666666666666,
    "of a sound": 0.021739130434782608,
    "a sound in": 0.14285714285714285,
    "sound in which": 1.0,
    "which a feature": 0.5,
    "a wave from": 0.25,
    "wave from first": 1.0,
    "from first layer": 1.0,
    "first layer of": 1.0,
    "layer of nodes": 1.0,
    "of nodes to": 0.25,
    "nodes to a": 1.0,
    "to a second": 0.03571428571428571,
    "a second layer": 0.5,
    "second layer of": 1.0,
    "of nodes based": 0.25,
    "nodes based on": 1.0,
    "on some statistical": 0.1111111111111111,
    "some statistical analysis": 1.0,
    "statistical analysis .": 1.0,
    "<s> this analysis": 0.019230769230769232,
    "this analysis depends": 1.0,
    "analysis depends on": 1.0,
    "depends on programer": 0.14285714285714285,
    "on programer 's": 1.0,
    "programer 's instructions": 1.0,
    "'s instructions .": 1.0,
    "<s> at this": 0.3333333333333333,
    "at this point": 1.0,
    "this point ,": 1.0,
    "point , a": 0.5,
    ", a second": 0.020833333333333332,
    "of nodes represents": 0.25,
    "nodes represents a": 1.0,
    "represents a higher": 0.3333333333333333,
    "a higher level": 0.5,
    "higher level features": 1.0,
    "level features of": 1.0,
    "features of a": 0.25,
    "a sound input": 0.14285714285714285,
    "sound input which": 1.0,
    "input which is": 1.0,
    "which is again": 0.07692307692307693,
    "is again statistically": 1.0,
    "again statistically evaluated": 1.0,
    "evaluated to see": 0.5,
    "to see what": 0.5,
    "see what class": 1.0,
    "what class they": 1.0,
    "class they belong": 1.0,
    "they belong to": 1.0,
    "belong to .": 1.0,
    "<s> last level": 1.0,
    "last level of": 1.0,
    "level of nodes": 0.14285714285714285,
    "of nodes should": 0.25,
    "nodes should be": 1.0,
    "should be output": 0.1111111111111111,
    "be output nodes": 1.0,
    "output nodes that": 0.5,
    "nodes that tell": 1.0,
    "that tell us": 1.0,
    "tell us with": 1.0,
    "us with high": 1.0,
    "with high probability": 0.5,
    "high probability what": 1.0,
    "probability what original": 1.0,
    "what original sound": 1.0,
    "original sound really": 1.0,
    "sound really was": 1.0,
    "really was .": 1.0,
    "<s> search to": 0.5,
    "search to match": 1.0,
    "to match the": 0.5,
    "match the neural-network": 0.5,
    "the neural-network output": 1.0,
    "neural-network output scores": 1.0,
    "output scores for": 1.0,
    "scores for the": 1.0,
    "for the best": 0.03125,
    "the best word": 0.07142857142857142,
    "best word ,": 1.0,
    "word , to": 0.5,
    "determine the word": 0.1,
    "the word that": 0.125,
    "word that was": 0.5,
    "that was most": 0.3333333333333333,
    "was most likely": 1.0,
    "most likely uttered": 0.3333333333333333,
    "likely uttered ;": 1.0,
    "uttered ; a": 1.0,
    "; a machine": 0.5,
    "a machine speech": 0.125,
    "machine speech recognition": 1.0,
    "speech recognition using": 0.013157894736842105,
    "recognition using neural": 1.0,
    "using neural network": 1.0,
    "neural network is": 0.16666666666666666,
    "network is still": 1.0,
    "is still just": 0.25,
    "still just a": 1.0,
    "just a fancy": 0.5,
    "a fancy statistics": 1.0,
    "fancy statistics .": 1.0,
    "<s> artificial neural": 1.0,
    "artificial neural network": 0.5,
    "neural network has": 0.16666666666666666,
    "network has specialized": 1.0,
    "has specialized output": 1.0,
    "specialized output nodes": 1.0,
    "output nodes for": 0.5,
    "nodes for results": 1.0,
    "for results ,": 1.0,
    "results , unlike": 0.5,
    ", unlike brain": 1.0,
    "unlike brain .": 1.0,
    "<s> our brain": 0.6666666666666666,
    "our brain recognizes": 0.5,
    "brain recognizes the": 1.0,
    "recognizes the meaning": 0.3333333333333333,
    "meaning of words": 0.14285714285714285,
    "words in fundamentally": 0.09090909090909091,
    "in fundamentally different": 1.0,
    "fundamentally different way": 1.0,
    "different way .": 1.0,
    "our brain is": 0.5,
    "brain is entirely": 1.0,
    "is entirely committed": 1.0,
    "entirely committed into": 1.0,
    "committed into the": 1.0,
    "into the perception": 0.125,
    "the perception of": 1.0,
    "perception of sound": 1.0,
    "of sound .": 0.5,
    "<s> when we": 0.16666666666666666,
    "when we hear": 0.3333333333333333,
    "we hear sound": 1.0,
    "hear sound ,": 1.0,
    "sound , our": 0.5,
    ", our life": 1.0,
    "our life experience": 1.0,
    "life experience is": 1.0,
    "experience is brought": 1.0,
    "is brought together": 1.0,
    "brought together to": 1.0,
    "together to action": 1.0,
    "to action of": 1.0,
    "action of listening": 1.0,
    "of listening to": 1.0,
    "listening to set": 1.0,
    "set a sound": 0.5,
    "a sound into": 0.14285714285714285,
    "sound into a": 1.0,
    "into a appropriate": 0.058823529411764705,
    "a appropriate perspective": 1.0,
    "appropriate perspective so": 1.0,
    "perspective so it": 1.0,
    "so it is": 0.5,
    "it is meaningful": 0.02127659574468085,
    "is meaningful .": 1.0,
    "<s> brain has": 1.0,
    "brain has a": 1.0,
    "has a purpose": 0.25,
    "a purpose when": 1.0,
    "purpose when it": 1.0,
    "when it listens": 1.0,
    "it listens for": 1.0,
    "listens for a": 1.0,
    "for a sound": 0.03225806451612903,
    "a sound that": 0.14285714285714285,
    "sound that is": 1.0,
    "that is steered": 0.05263157894736842,
    "is steered toward": 1.0,
    "steered toward actions": 1.0,
    "toward actions .": 1.0,
    "<s> in 1982": 0.010309278350515464,
    "in 1982 ,": 0.5,
    "1982 , kurzweil": 1.0,
    ", kurzweil applied": 0.3333333333333333,
    "kurzweil applied intelligence": 1.0,
    "applied intelligence and": 1.0,
    "intelligence and dragon": 0.5,
    "and dragon systems": 1.0,
    "dragon systems released": 1.0,
    "systems released speech": 0.5,
    "released speech recognition": 1.0,
    "speech recognition products": 0.013157894736842105,
    "recognition products .": 1.0,
    "<s> by 1985": 1.0,
    "by 1985 ,": 1.0,
    "1985 , kurzweil": 1.0,
    ", kurzweil 's": 0.3333333333333333,
    "kurzweil 's software": 1.0,
    "'s software had": 1.0,
    "software had a": 1.0,
    "had a vocabulary": 0.25,
    "a vocabulary of": 1.0,
    "vocabulary of 1,000": 1.0,
    "of 1,000 words": 1.0,
    "1,000 words --": 1.0,
    "words -- if": 1.0,
    "-- if uttered": 0.5,
    "if uttered one": 1.0,
    "uttered one word": 1.0,
    "one word at": 0.5,
    "word at a": 1.0,
    ", in 1987": 0.029411764705882353,
    "1987 , its": 0.5,
    ", its lexicon": 1.0,
    "its lexicon reached": 1.0,
    "lexicon reached 20,000": 1.0,
    "reached 20,000 words": 1.0,
    "20,000 words ,": 1.0,
    "words , entering": 0.0625,
    ", entering the": 0.5,
    "entering the realm": 1.0,
    "the realm of": 1.0,
    "realm of human": 1.0,
    "of human vocabularies": 0.2,
    "human vocabularies ,": 1.0,
    "vocabularies , which": 0.5,
    ", which range": 0.017857142857142856,
    "which range from": 1.0,
    "range from 10,000": 0.5,
    "from 10,000 to": 1.0,
    "10,000 to 150,000": 1.0,
    "to 150,000 words": 1.0,
    "150,000 words .": 1.0,
    "<s> but recognition": 0.16666666666666666,
    "but recognition accuracy": 1.0,
    "recognition accuracy was": 0.14285714285714285,
    "accuracy was only": 1.0,
    "was only 10": 1.0,
    "only 10 %": 1.0,
    "10 % in": 0.5,
    "% in 1993": 1.0,
    "in 1993 .": 0.5,
    ", the error": 0.009523809523809525,
    "the error rate": 1.0,
    "error rate crossed": 0.16666666666666666,
    "rate crossed below": 1.0,
    "crossed below 50": 1.0,
    "below 50 %": 1.0,
    "50 % .": 1.0,
    "<s> dragon systems": 1.0,
    "systems released ``": 0.5,
    "released `` naturally": 1.0,
    "`` naturally speaking": 1.0,
    "naturally speaking ''": 1.0,
    "speaking '' in": 1.0,
    "'' in 1997": 0.14285714285714285,
    "in 1997 ,": 0.5,
    "1997 , which": 1.0,
    ", which recognized": 0.017857142857142856,
    "which recognized normal": 1.0,
    "recognized normal human": 1.0,
    "normal human speech": 1.0,
    "human speech .": 1.0,
    "<s> progress mainly": 1.0,
    "progress mainly came": 1.0,
    "mainly came from": 1.0,
    "came from improved": 1.0,
    "from improved computer": 1.0,
    "improved computer performance": 1.0,
    "computer performance and": 1.0,
    "performance and larger": 0.5,
    "and larger source": 0.5,
    "larger source text": 1.0,
    "source text databases": 0.2,
    "text databases .": 1.0,
    "corpus was the": 0.5,
    "was the first": 0.25,
    "first major database": 0.5,
    "major database available": 1.0,
    "database available ,": 1.0,
    "available , containing": 0.25,
    ", containing several": 0.5,
    "containing several million": 1.0,
    "several million words": 1.0,
    "million words .": 1.0,
    "<s> in 2006": 0.010309278350515464,
    "in 2006 ,": 0.5,
    "2006 , google": 1.0,
    ", google published": 1.0,
    "google published a": 1.0,
    "published a trillion-word": 0.5,
    "a trillion-word corpus": 1.0,
    "trillion-word corpus ,": 1.0,
    "corpus , while": 0.3333333333333333,
    ", while carnegie": 0.07142857142857142,
    "while carnegie mellon": 1.0,
    "carnegie mellon university": 1.0,
    "mellon university researchers": 0.5,
    "university researchers found": 1.0,
    "researchers found no": 1.0,
    "found no significant": 1.0,
    "no significant increase": 1.0,
    "significant increase in": 1.0,
    "increase in recognition": 0.3333333333333333,
    "<s> algorithms both": 0.5,
    "algorithms both acoustic": 1.0,
    "both acoustic modeling": 1.0,
    "acoustic modeling and": 0.5,
    "modeling and language": 1.0,
    "and language modeling": 0.14285714285714285,
    "language modeling are": 0.5,
    "modeling are important": 1.0,
    "are important parts": 1.0,
    "important parts of": 1.0,
    "parts of modern": 0.0625,
    "of modern statistically-based": 1.0,
    "modern statistically-based speech": 1.0,
    "statistically-based speech recognition": 1.0,
    "speech recognition algorithms": 0.013157894736842105,
    "recognition algorithms .": 1.0,
    "hmms -rrb- are": 0.5,
    "-rrb- are widely": 0.3333333333333333,
    "are widely used": 1.0,
    "in many systems": 0.1,
    "many systems .": 0.5,
    "<s> language modeling": 1.0,
    "language modeling has": 0.5,
    "modeling has many": 1.0,
    "has many other": 0.5,
    "many other applications": 0.2,
    "other applications such": 1.0,
    "applications such as": 1.0,
    "such as smart": 0.011111111111111112,
    "as smart keyboard": 1.0,
    "smart keyboard and": 1.0,
    "keyboard and document": 1.0,
    "and document classification": 0.5,
    "document classification .": 1.0,
    "markov models main": 0.1111111111111111,
    "models main article": 1.0,
    "article : hidden": 0.07692307692307693,
    ": hidden markov": 1.0,
    "markov model modern": 0.125,
    "model modern general-purpose": 1.0,
    "modern general-purpose speech": 1.0,
    "general-purpose speech recognition": 1.0,
    "based on hidden": 0.021739130434782608,
    "on hidden markov": 1.0,
    "these are statistical": 0.25,
    "are statistical models": 1.0,
    "statistical models that": 0.125,
    "models that output": 0.3333333333333333,
    "that output a": 1.0,
    "output a sequence": 1.0,
    "sequence of symbols": 0.14285714285714285,
    "of symbols or": 1.0,
    "symbols or quantities": 1.0,
    "or quantities .": 1.0,
    "<s> hmms are": 0.3333333333333333,
    "hmms are used": 0.5,
    "used in speech": 0.043478260869565216,
    "speech recognition because": 0.013157894736842105,
    "recognition because a": 1.0,
    "because a speech": 1.0,
    "a speech signal": 0.5,
    "speech signal can": 1.0,
    "viewed as a": 0.25,
    "as a piecewise": 0.027777777777777776,
    "a piecewise stationary": 1.0,
    "piecewise stationary signal": 1.0,
    "stationary signal or": 0.5,
    "signal or a": 1.0,
    "or a short-time": 0.05263157894736842,
    "a short-time stationary": 1.0,
    "short-time stationary signal": 1.0,
    "stationary signal .": 0.5,
    "in a short": 0.019230769230769232,
    "a short time-scales": 0.2,
    "short time-scales -lrb-": 1.0,
    "time-scales -lrb- e.g.": 1.0,
    "e.g. , 10": 0.038461538461538464,
    ", 10 milliseconds": 0.5,
    "10 milliseconds -rrb-": 0.5,
    "milliseconds -rrb- ,": 1.0,
    ", speech can": 0.09090909090909091,
    "speech can be": 0.6666666666666666,
    "can be approximated": 0.01098901098901099,
    "be approximated as": 1.0,
    "approximated as a": 1.0,
    "as a stationary": 0.027777777777777776,
    "a stationary process": 0.5,
    "stationary process .": 1.0,
    "<s> speech can": 0.06666666666666667,
    "can be thought": 0.01098901098901099,
    "be thought of": 1.0,
    "of as a": 0.5,
    "as a markov": 0.027777777777777776,
    "a markov model": 1.0,
    "markov model for": 0.25,
    "model for many": 0.5,
    "for many stochastic": 0.5,
    "many stochastic purposes": 1.0,
    "stochastic purposes .": 1.0,
    "<s> another reason": 0.07692307692307693,
    "another reason why": 1.0,
    "reason why hmms": 1.0,
    "why hmms are": 1.0,
    "hmms are popular": 0.5,
    "are popular is": 1.0,
    "popular is because": 1.0,
    "is because they": 1.0,
    "because they can": 0.25,
    "can be trained": 0.01098901098901099,
    "be trained automatically": 1.0,
    "trained automatically and": 1.0,
    "automatically and are": 0.5,
    "and are simple": 0.2,
    "are simple and": 1.0,
    "simple and computationally": 0.5,
    "and computationally feasible": 1.0,
    "computationally feasible to": 1.0,
    "feasible to use": 1.0,
    "to use .": 0.1,
    "<s> in speech": 0.010309278350515464,
    "recognition , the": 0.07142857142857142,
    ", the hidden": 0.009523809523809525,
    "the hidden markov": 1.0,
    "markov model would": 0.125,
    "model would output": 0.3333333333333333,
    "would output a": 1.0,
    "sequence of n-dimensional": 0.14285714285714285,
    "of n-dimensional real-valued": 1.0,
    "n-dimensional real-valued vectors": 1.0,
    "real-valued vectors -lrb-": 1.0,
    "vectors -lrb- with": 1.0,
    "-lrb- with n": 0.3333333333333333,
    "with n being": 1.0,
    "n being a": 1.0,
    "being a small": 0.5,
    "a small integer": 0.5,
    "small integer ,": 1.0,
    "integer , such": 1.0,
    "such as 10": 0.011111111111111112,
    "as 10 -rrb-": 1.0,
    "10 -rrb- ,": 1.0,
    "-rrb- , outputting": 0.01282051282051282,
    ", outputting one": 1.0,
    "outputting one of": 1.0,
    "one of these": 0.0625,
    "of these every": 0.09090909090909091,
    "these every 10": 1.0,
    "every 10 milliseconds": 1.0,
    "10 milliseconds .": 0.5,
    "<s> the vectors": 0.006802721088435374,
    "the vectors would": 1.0,
    "vectors would consist": 1.0,
    "would consist of": 1.0,
    "consist of cepstral": 1.0,
    "of cepstral coefficients": 1.0,
    "cepstral coefficients ,": 1.0,
    "coefficients , which": 1.0,
    "which are obtained": 0.08333333333333333,
    "obtained by taking": 0.25,
    "by taking a": 1.0,
    "taking a fourier": 1.0,
    "a fourier transform": 1.0,
    "fourier transform of": 0.3333333333333333,
    "transform of a": 1.0,
    "of a short": 0.010869565217391304,
    "a short time": 0.2,
    "short time window": 1.0,
    "time window of": 1.0,
    "window of speech": 0.5,
    "of speech and": 0.02127659574468085,
    "speech and decorrelating": 0.14285714285714285,
    "and decorrelating the": 1.0,
    "decorrelating the spectrum": 1.0,
    "the spectrum using": 1.0,
    "spectrum using a": 1.0,
    "using a cosine": 0.1,
    "a cosine transform": 1.0,
    "cosine transform ,": 1.0,
    "transform , then": 0.3333333333333333,
    ", then taking": 0.09090909090909091,
    "then taking the": 1.0,
    "taking the first": 0.3333333333333333,
    "the first -lrb-": 0.045454545454545456,
    "first -lrb- most": 1.0,
    "-lrb- most significant": 0.25,
    "most significant -rrb-": 1.0,
    "significant -rrb- coefficients": 1.0,
    "-rrb- coefficients .": 1.0,
    "<s> the hidden": 0.006802721088435374,
    "markov model will": 0.125,
    "model will tend": 1.0,
    "will tend to": 1.0,
    "tend to have": 0.5,
    "to have in": 0.1,
    "have in each": 0.5,
    "in each state": 1.0,
    "each state a": 1.0,
    "state a statistical": 1.0,
    "a statistical distribution": 0.3333333333333333,
    "statistical distribution that": 1.0,
    "distribution that is": 0.5,
    "that is a": 0.05263157894736842,
    "is a mixture": 0.018518518518518517,
    "a mixture of": 1.0,
    "mixture of diagonal": 1.0,
    "of diagonal covariance": 1.0,
    "diagonal covariance gaussians": 1.0,
    "covariance gaussians ,": 1.0,
    "gaussians , which": 1.0,
    ", which will": 0.017857142857142856,
    "which will give": 0.3333333333333333,
    "will give a": 1.0,
    "give a likelihood": 1.0,
    "a likelihood for": 1.0,
    "likelihood for each": 1.0,
    "for each observed": 0.14285714285714285,
    "each observed vector": 1.0,
    "observed vector .": 1.0,
    "<s> each word": 0.2,
    "each word ,": 0.16666666666666666,
    "word , or": 0.5,
    ", or -lrb-": 0.030303030303030304,
    "or -lrb- for": 1.0,
    "-lrb- for more": 0.1111111111111111,
    "for more general": 0.5,
    "more general speech": 0.3333333333333333,
    "general speech recognition": 1.0,
    "recognition systems -rrb-": 0.1,
    "systems -rrb- ,": 0.5,
    "-rrb- , each": 0.01282051282051282,
    ", each phoneme": 0.16666666666666666,
    "each phoneme ,": 1.0,
    "phoneme , will": 1.0,
    ", will have": 0.5,
    "have a different": 0.07692307692307693,
    "a different output": 0.2,
    "different output distribution": 1.0,
    "output distribution ;": 1.0,
    "distribution ; a": 1.0,
    "; a hidden": 0.5,
    "a hidden markov": 1.0,
    "model for a": 0.5,
    "for a sequence": 0.03225806451612903,
    "sequence of words": 0.14285714285714285,
    "of words or": 0.06666666666666667,
    "words or phonemes": 0.14285714285714285,
    "or phonemes is": 0.5,
    "phonemes is made": 1.0,
    "is made by": 0.5,
    "made by concatenating": 1.0,
    "by concatenating the": 1.0,
    "concatenating the individual": 1.0,
    "the individual trained": 0.5,
    "individual trained hidden": 1.0,
    "trained hidden markov": 1.0,
    "markov models for": 0.1111111111111111,
    "models for the": 0.16666666666666666,
    "for the separate": 0.03125,
    "the separate words": 1.0,
    "separate words and": 0.25,
    "words and phonemes": 0.125,
    "and phonemes .": 1.0,
    "<s> described above": 1.0,
    "described above are": 0.25,
    "above are the": 1.0,
    "are the core": 0.09090909090909091,
    "the core elements": 1.0,
    "core elements of": 1.0,
    "elements of the": 1.0,
    "most common ,": 0.16666666666666666,
    "common , hmm-based": 0.5,
    ", hmm-based approach": 1.0,
    "hmm-based approach to": 0.5,
    "approach to speech": 0.16666666666666666,
    "to speech recognition": 0.6666666666666666,
    "speech recognition .": 0.06578947368421052,
    "<s> modern speech": 1.0,
    "modern speech recognition": 1.0,
    "recognition systems use": 0.1,
    "systems use various": 0.16666666666666666,
    "use various combinations": 1.0,
    "various combinations of": 1.0,
    "combinations of a": 1.0,
    "number of standard": 0.027777777777777776,
    "of standard techniques": 1.0,
    "standard techniques in": 1.0,
    "techniques in order": 1.0,
    "order to improve": 0.125,
    "to improve results": 0.1111111111111111,
    "improve results over": 1.0,
    "results over the": 1.0,
    "over the basic": 0.3333333333333333,
    "the basic approach": 0.5,
    "basic approach described": 1.0,
    "approach described above": 1.0,
    "described above .": 0.25,
    "a typical large-vocabulary": 0.25,
    "typical large-vocabulary system": 1.0,
    "large-vocabulary system would": 1.0,
    "system would need": 0.5,
    "would need context": 1.0,
    "need context dependency": 1.0,
    "context dependency for": 1.0,
    "dependency for the": 1.0,
    "for the phonemes": 0.03125,
    "the phonemes -lrb-": 0.5,
    "phonemes -lrb- so": 1.0,
    "-lrb- so phonemes": 0.5,
    "so phonemes with": 1.0,
    "phonemes with different": 1.0,
    "with different left": 0.5,
    "different left and": 1.0,
    "and right context": 0.5,
    "right context have": 1.0,
    "context have different": 1.0,
    "have different realizations": 0.5,
    "different realizations as": 1.0,
    "realizations as hmm": 1.0,
    "as hmm states": 1.0,
    "hmm states -rrb-": 1.0,
    "states -rrb- ;": 1.0,
    "-rrb- ; it": 0.125,
    "; it would": 1.0,
    "it would use": 0.25,
    "would use cepstral": 1.0,
    "use cepstral normalization": 1.0,
    "cepstral normalization to": 1.0,
    "normalization to normalize": 1.0,
    "to normalize for": 1.0,
    "normalize for different": 1.0,
    "for different speaker": 1.0,
    "different speaker and": 1.0,
    "speaker and recording": 1.0,
    "and recording conditions": 1.0,
    "recording conditions ;": 1.0,
    "conditions ; for": 1.0,
    "; for further": 0.5,
    "for further speaker": 0.3333333333333333,
    "further speaker normalization": 1.0,
    "speaker normalization it": 1.0,
    "normalization it might": 1.0,
    "it might use": 1.0,
    "might use vocal": 0.5,
    "use vocal tract": 1.0,
    "vocal tract length": 1.0,
    "tract length normalization": 1.0,
    "length normalization -lrb-": 1.0,
    "normalization -lrb- vtln": 1.0,
    "-lrb- vtln -rrb-": 1.0,
    "vtln -rrb- for": 1.0,
    "-rrb- for male-female": 0.5,
    "for male-female normalization": 1.0,
    "male-female normalization and": 1.0,
    "normalization and maximum": 1.0,
    "and maximum likelihood": 1.0,
    "maximum likelihood linear": 1.0,
    "likelihood linear regression": 0.5,
    "linear regression -lrb-": 1.0,
    "regression -lrb- mllr": 1.0,
    "-lrb- mllr -rrb-": 1.0,
    "mllr -rrb- for": 1.0,
    "-rrb- for more": 0.5,
    "more general speaker": 0.3333333333333333,
    "general speaker adaptation": 1.0,
    "speaker adaptation .": 1.0,
    "<s> the features": 0.006802721088435374,
    "the features would": 0.16666666666666666,
    "features would have": 1.0,
    "would have so-called": 0.3333333333333333,
    "have so-called delta": 1.0,
    "so-called delta and": 1.0,
    "delta and delta-delta": 1.0,
    "and delta-delta coefficients": 1.0,
    "delta-delta coefficients to": 0.5,
    "coefficients to capture": 1.0,
    "to capture speech": 1.0,
    "capture speech dynamics": 1.0,
    "speech dynamics and": 1.0,
    "dynamics and in": 1.0,
    "and in addition": 0.14285714285714285,
    "in addition might": 0.16666666666666666,
    "addition might use": 1.0,
    "might use heteroscedastic": 0.5,
    "use heteroscedastic linear": 1.0,
    "heteroscedastic linear discriminant": 1.0,
    "linear discriminant analysis": 1.0,
    "discriminant analysis -lrb-": 0.5,
    "analysis -lrb- hlda": 0.25,
    "-lrb- hlda -rrb-": 1.0,
    "hlda -rrb- ;": 1.0,
    "-rrb- ; or": 0.125,
    "; or might": 1.0,
    "or might skip": 1.0,
    "might skip the": 1.0,
    "skip the delta": 1.0,
    "the delta and": 1.0,
    "delta-delta coefficients and": 0.5,
    "coefficients and use": 1.0,
    "and use splicing": 0.3333333333333333,
    "use splicing and": 1.0,
    "splicing and an": 1.0,
    "and an lda-based": 0.3333333333333333,
    "an lda-based projection": 1.0,
    "lda-based projection followed": 1.0,
    "projection followed perhaps": 1.0,
    "followed perhaps by": 1.0,
    "perhaps by heteroscedastic": 1.0,
    "by heteroscedastic linear": 1.0,
    "discriminant analysis or": 0.5,
    "analysis or a": 0.3333333333333333,
    "or a global": 0.05263157894736842,
    "a global semitied": 1.0,
    "global semitied covariance": 1.0,
    "semitied covariance transform": 1.0,
    "covariance transform -lrb-": 1.0,
    "transform -lrb- also": 1.0,
    "known as maximum": 0.1,
    "as maximum likelihood": 1.0,
    "likelihood linear transform": 0.5,
    "linear transform ,": 1.0,
    "transform , or": 0.3333333333333333,
    ", or mllt": 0.030303030303030304,
    "or mllt -rrb-": 1.0,
    "mllt -rrb- .": 1.0,
    "<s> many systems": 0.09090909090909091,
    "many systems use": 0.5,
    "systems use so-called": 0.16666666666666666,
    "use so-called discriminative": 1.0,
    "so-called discriminative training": 1.0,
    "discriminative training techniques": 0.5,
    "training techniques that": 1.0,
    "techniques that dispense": 0.5,
    "that dispense with": 1.0,
    "dispense with a": 1.0,
    "with a purely": 0.05,
    "a purely statistical": 1.0,
    "purely statistical approach": 1.0,
    "statistical approach to": 1.0,
    "approach to hmm": 0.16666666666666666,
    "to hmm parameter": 1.0,
    "hmm parameter estimation": 1.0,
    "parameter estimation and": 1.0,
    "estimation and instead": 1.0,
    "and instead optimize": 1.0,
    "instead optimize some": 1.0,
    "optimize some classification-related": 1.0,
    "some classification-related measure": 1.0,
    "classification-related measure of": 1.0,
    "measure of the": 0.5,
    "of the training": 0.005128205128205128,
    "examples are maximum": 0.3333333333333333,
    "are maximum mutual": 1.0,
    "maximum mutual information": 1.0,
    "information -lrb- mmi": 0.5,
    "-lrb- mmi -rrb-": 1.0,
    "mmi -rrb- ,": 1.0,
    "-rrb- , minimum": 0.01282051282051282,
    ", minimum classification": 1.0,
    "minimum classification error": 1.0,
    "classification error -lrb-": 1.0,
    "error -lrb- mce": 0.5,
    "-lrb- mce -rrb-": 1.0,
    "mce -rrb- and": 1.0,
    "-rrb- and minimum": 0.05,
    "and minimum phone": 1.0,
    "minimum phone error": 1.0,
    "phone error -lrb-": 1.0,
    "error -lrb- mpe": 0.5,
    "-lrb- mpe -rrb-": 1.0,
    "mpe -rrb- .": 1.0,
    "<s> decoding of": 1.0,
    "decoding of the": 1.0,
    "speech -lrb- the": 0.25,
    "-lrb- the term": 0.125,
    "the term for": 0.1111111111111111,
    "term for what": 0.3333333333333333,
    "for what happens": 0.3333333333333333,
    "what happens when": 1.0,
    "happens when the": 1.0,
    "when the system": 0.2,
    "system is presented": 0.1111111111111111,
    "is presented with": 0.5,
    "presented with a": 1.0,
    "with a new": 0.05,
    "a new utterance": 0.16666666666666666,
    "new utterance and": 1.0,
    "utterance and must": 1.0,
    "and must compute": 1.0,
    "must compute the": 1.0,
    "compute the most": 1.0,
    "most likely source": 0.3333333333333333,
    "likely source sentence": 1.0,
    "source sentence -rrb-": 0.5,
    "sentence -rrb- would": 0.5,
    "-rrb- would probably": 0.5,
    "would probably use": 1.0,
    "probably use the": 1.0,
    "use the viterbi": 1.0,
    "viterbi algorithm to": 0.25,
    "algorithm to find": 0.5,
    "find the best": 0.25,
    "the best path": 0.07142857142857142,
    "best path ,": 1.0,
    "path , and": 1.0,
    ", and here": 0.005291005291005291,
    "and here there": 1.0,
    "here there is": 1.0,
    "is a choice": 0.018518518518518517,
    "a choice between": 1.0,
    "choice between dynamically": 1.0,
    "between dynamically creating": 1.0,
    "dynamically creating a": 1.0,
    "creating a combination": 0.5,
    "a combination hidden": 0.5,
    "combination hidden markov": 1.0,
    "markov model ,": 0.125,
    "model , which": 0.3333333333333333,
    "which includes both": 0.5,
    "includes both the": 1.0,
    "both the acoustic": 0.5,
    "the acoustic and": 0.5,
    "acoustic and language": 1.0,
    "and language model": 0.14285714285714285,
    "language model information": 1.0,
    "model information ,": 1.0,
    ", and combining": 0.005291005291005291,
    "and combining it": 1.0,
    "combining it statically": 1.0,
    "it statically beforehand": 1.0,
    "statically beforehand -lrb-": 1.0,
    "beforehand -lrb- the": 1.0,
    "-lrb- the finite": 0.125,
    "the finite state": 1.0,
    "finite state transducer": 0.5,
    "state transducer ,": 0.5,
    "transducer , or": 1.0,
    ", or fst": 0.030303030303030304,
    "or fst ,": 1.0,
    "fst , approach": 1.0,
    ", approach -rrb-": 1.0,
    "approach -rrb- .": 0.5,
    "<s> a possible": 0.022727272727272728,
    "a possible improvement": 1.0,
    "possible improvement to": 1.0,
    "improvement to decoding": 1.0,
    "to decoding is": 1.0,
    "decoding is to": 1.0,
    "is to keep": 0.05263157894736842,
    "to keep a": 0.5,
    "keep a set": 1.0,
    "set of good": 0.03571428571428571,
    "of good candidates": 1.0,
    "good candidates instead": 0.3333333333333333,
    "candidates instead of": 1.0,
    "instead of just": 0.14285714285714285,
    "of just keeping": 1.0,
    "just keeping the": 1.0,
    "keeping the best": 1.0,
    "the best candidate": 0.07142857142857142,
    "best candidate ,": 1.0,
    "candidate , and": 1.0,
    "and to use": 0.18181818181818182,
    "to use a": 0.1,
    "use a better": 0.25,
    "a better scoring": 0.5,
    "better scoring function": 1.0,
    "scoring function -lrb-": 1.0,
    "function -lrb- rescoring": 1.0,
    "-lrb- rescoring -rrb-": 1.0,
    "rescoring -rrb- to": 1.0,
    "-rrb- to rate": 0.25,
    "to rate these": 0.5,
    "rate these good": 1.0,
    "these good candidates": 1.0,
    "good candidates so": 0.3333333333333333,
    "candidates so that": 1.0,
    "so that we": 0.16666666666666666,
    "that we may": 0.3333333333333333,
    "we may pick": 1.0,
    "may pick the": 1.0,
    "pick the best": 1.0,
    "the best one": 0.07142857142857142,
    "best one according": 1.0,
    "one according to": 1.0,
    "according to this": 0.16666666666666666,
    "to this refined": 0.16666666666666666,
    "this refined score": 1.0,
    "refined score .": 1.0,
    "<s> the set": 0.006802721088435374,
    "set of candidates": 0.03571428571428571,
    "of candidates can": 1.0,
    "candidates can be": 1.0,
    "can be kept": 0.01098901098901099,
    "be kept either": 1.0,
    "kept either as": 1.0,
    "either as a": 0.3333333333333333,
    "as a list": 0.027777777777777776,
    "a list -lrb-": 0.14285714285714285,
    "list -lrb- the": 1.0,
    "-lrb- the n-best": 0.125,
    "the n-best list": 1.0,
    "n-best list approach": 1.0,
    "list approach -rrb-": 1.0,
    "approach -rrb- or": 0.5,
    "-rrb- or as": 0.25,
    "or as a": 0.5,
    "as a subset": 0.027777777777777776,
    "subset of the": 0.3333333333333333,
    "of the models": 0.005128205128205128,
    "the models -lrb-": 1.0,
    "models -lrb- a": 0.3333333333333333,
    "-lrb- a lattice": 0.2,
    "a lattice -rrb-": 1.0,
    "lattice -rrb- .": 1.0,
    "<s> rescoring is": 1.0,
    "rescoring is usually": 1.0,
    "usually done by": 0.5,
    "done by trying": 0.5,
    "by trying to": 1.0,
    "trying to minimize": 0.2,
    "to minimize the": 1.0,
    "minimize the bayes": 1.0,
    "the bayes risk": 1.0,
    "bayes risk -lrb-": 1.0,
    "risk -lrb- or": 1.0,
    "-lrb- or an": 0.1,
    "or an approximation": 0.5,
    "an approximation thereof": 0.5,
    "approximation thereof -rrb-": 1.0,
    "thereof -rrb- :": 1.0,
    "-rrb- : instead": 0.1111111111111111,
    ": instead of": 1.0,
    "instead of taking": 0.14285714285714285,
    "of taking the": 1.0,
    "taking the source": 0.3333333333333333,
    "the source sentence": 0.08333333333333333,
    "source sentence with": 0.5,
    "sentence with maximal": 1.0,
    "with maximal probability": 1.0,
    "maximal probability ,": 1.0,
    "probability , we": 1.0,
    ", we try": 0.058823529411764705,
    "we try to": 1.0,
    "try to take": 0.3333333333333333,
    "to take the": 0.2,
    "take the sentence": 1.0,
    "the sentence that": 0.3333333333333333,
    "sentence that minimizes": 1.0,
    "that minimizes the": 1.0,
    "minimizes the expectancy": 0.5,
    "the expectancy of": 1.0,
    "expectancy of a": 1.0,
    "a given loss": 0.08333333333333333,
    "given loss function": 1.0,
    "loss function with": 0.5,
    "function with regards": 1.0,
    "with regards to": 1.0,
    "regards to all": 1.0,
    "to all possible": 0.3333333333333333,
    "all possible transcriptions": 0.3333333333333333,
    "possible transcriptions -lrb-": 0.5,
    "transcriptions -lrb- i.e.": 1.0,
    "i.e. , we": 0.14285714285714285,
    ", we take": 0.058823529411764705,
    "we take the": 1.0,
    "minimizes the average": 0.5,
    "the average distance": 1.0,
    "average distance to": 1.0,
    "distance to other": 1.0,
    "to other possible": 1.0,
    "other possible sentences": 1.0,
    "possible sentences weighted": 1.0,
    "sentences weighted by": 1.0,
    "weighted by their": 1.0,
    "by their estimated": 1.0,
    "their estimated probability": 1.0,
    "estimated probability -rrb-": 1.0,
    "probability -rrb- .": 0.5,
    "<s> the loss": 0.006802721088435374,
    "the loss function": 1.0,
    "loss function is": 0.5,
    "function is usually": 1.0,
    "is usually the": 0.125,
    "usually the levenshtein": 1.0,
    "the levenshtein distance": 1.0,
    "levenshtein distance ,": 1.0,
    "distance , though": 0.5,
    ", though it": 0.16666666666666666,
    "though it can": 0.5,
    "can be different": 0.01098901098901099,
    "be different distances": 1.0,
    "different distances for": 1.0,
    "distances for specific": 1.0,
    "for specific tasks": 1.0,
    "specific tasks ;": 1.0,
    "tasks ; the": 1.0,
    "; the set": 0.25,
    "set of possible": 0.03571428571428571,
    "of possible transcriptions": 0.3333333333333333,
    "possible transcriptions is": 0.5,
    "transcriptions is ,": 1.0,
    "is , of": 0.1111111111111111,
    ", of course": 0.25,
    "of course ,": 0.5,
    "course , pruned": 1.0,
    ", pruned to": 1.0,
    "pruned to maintain": 1.0,
    "to maintain tractability": 1.0,
    "maintain tractability .": 1.0,
    "<s> efficient algorithms": 1.0,
    "efficient algorithms have": 1.0,
    "have been devised": 0.038461538461538464,
    "been devised to": 1.0,
    "devised to rescore": 1.0,
    "to rescore lattices": 1.0,
    "rescore lattices represented": 1.0,
    "lattices represented as": 1.0,
    "represented as weighted": 0.5,
    "as weighted finite": 1.0,
    "weighted finite state": 1.0,
    "finite state transducers": 0.25,
    "state transducers with": 1.0,
    "transducers with edit": 1.0,
    "with edit distances": 1.0,
    "edit distances represented": 1.0,
    "distances represented themselves": 1.0,
    "represented themselves as": 1.0,
    "themselves as a": 1.0,
    "as a finite": 0.027777777777777776,
    "a finite state": 0.5,
    "state transducer verifying": 0.5,
    "transducer verifying certain": 1.0,
    "verifying certain assumptions": 1.0,
    "certain assumptions .": 1.0,
    "<s> dynamic time": 0.6666666666666666,
    "dynamic time warping": 1.0,
    "time warping -lrb-": 0.25,
    "warping -lrb- dtw": 1.0,
    "-lrb- dtw -rrb-": 1.0,
    "dtw -rrb- -": 1.0,
    "-rrb- - based": 1.0,
    "- based speech": 0.3333333333333333,
    "based speech recognition": 1.0,
    "speech recognition main": 0.013157894736842105,
    "recognition main article": 1.0,
    "article : dynamic": 0.07692307692307693,
    ": dynamic time": 1.0,
    "time warping dynamic": 0.25,
    "warping dynamic time": 1.0,
    "time warping is": 0.5,
    "warping is an": 1.0,
    "is an approach": 0.1,
    "an approach that": 0.25,
    "approach that was": 0.5,
    "that was historically": 0.3333333333333333,
    "was historically used": 1.0,
    "historically used for": 1.0,
    "used for speech": 0.06666666666666667,
    "speech recognition but": 0.013157894736842105,
    "recognition but has": 1.0,
    "but has now": 1.0,
    "has now largely": 1.0,
    "now largely been": 1.0,
    "largely been displaced": 1.0,
    "been displaced by": 1.0,
    "displaced by the": 1.0,
    "by the more": 0.03571428571428571,
    "more successful hmm-based": 0.3333333333333333,
    "successful hmm-based approach": 1.0,
    "hmm-based approach .": 0.5,
    "an algorithm for": 0.3333333333333333,
    "algorithm for measuring": 0.5,
    "for measuring similarity": 1.0,
    "measuring similarity between": 1.0,
    "similarity between two": 0.5,
    "between two sequences": 0.5,
    "two sequences that": 1.0,
    "sequences that may": 1.0,
    "that may vary": 0.5,
    "may vary in": 1.0,
    "vary in time": 0.3333333333333333,
    "in time or": 1.0,
    "time or speed": 1.0,
    "or speed .": 1.0,
    "instance , similarities": 0.1111111111111111,
    ", similarities in": 1.0,
    "similarities in walking": 1.0,
    "in walking patterns": 1.0,
    "walking patterns would": 1.0,
    "patterns would be": 1.0,
    "would be detected": 0.1111111111111111,
    "be detected ,": 1.0,
    "detected , even": 1.0,
    "even if in": 0.3333333333333333,
    "if in one": 0.5,
    "in one video": 0.2,
    "one video the": 1.0,
    "video the person": 1.0,
    "the person was": 0.25,
    "person was walking": 1.0,
    "was walking slowly": 1.0,
    "walking slowly and": 1.0,
    "slowly and if": 1.0,
    "and if in": 1.0,
    "if in another": 0.5,
    "in another he": 0.25,
    "another he or": 1.0,
    "he or she": 1.0,
    "or she were": 1.0,
    "she were walking": 1.0,
    "were walking more": 1.0,
    "walking more quickly": 1.0,
    "more quickly ,": 1.0,
    "quickly , or": 1.0,
    ", or even": 0.06060606060606061,
    "or even if": 0.2,
    "even if there": 0.3333333333333333,
    "if there were": 0.3333333333333333,
    "there were accelerations": 0.3333333333333333,
    "were accelerations and": 1.0,
    "accelerations and decelerations": 1.0,
    "and decelerations during": 1.0,
    "decelerations during the": 1.0,
    "during the course": 0.16666666666666666,
    "the course of": 1.0,
    "course of one": 1.0,
    "of one observation": 0.25,
    "one observation .": 1.0,
    "<s> dtw has": 1.0,
    "dtw has been": 1.0,
    "applied to video": 0.09090909090909091,
    "to video ,": 1.0,
    "video , audio": 1.0,
    "audio , and": 0.3333333333333333,
    ", and graphics": 0.005291005291005291,
    "and graphics --": 1.0,
    "graphics -- indeed": 1.0,
    "-- indeed ,": 1.0,
    "indeed , any": 1.0,
    ", any data": 1.0,
    "any data that": 1.0,
    "data that can": 0.5,
    "can be turned": 0.01098901098901099,
    "be turned into": 1.0,
    "into a linear": 0.058823529411764705,
    "a linear representation": 0.5,
    "linear representation can": 1.0,
    "representation can be": 1.0,
    "can be analyzed": 0.01098901098901099,
    "be analyzed with": 1.0,
    "analyzed with dtw": 1.0,
    "with dtw .": 1.0,
    "<s> a well-known": 0.022727272727272728,
    "a well-known application": 1.0,
    "well-known application has": 1.0,
    "application has been": 1.0,
    "has been automatic": 0.03571428571428571,
    "been automatic speech": 1.0,
    "recognition , to": 0.07142857142857142,
    ", to cope": 0.07692307692307693,
    "to cope with": 1.0,
    "cope with different": 1.0,
    "with different speaking": 0.5,
    "different speaking speeds": 1.0,
    "speaking speeds .": 1.0,
    "general , it": 0.16666666666666666,
    "is a method": 0.018518518518518517,
    "a method that": 0.25,
    "method that allows": 1.0,
    "that allows a": 1.0,
    "allows a computer": 1.0,
    "computer to find": 0.5,
    "to find an": 0.1111111111111111,
    "find an optimal": 0.5,
    "an optimal match": 1.0,
    "optimal match between": 1.0,
    "match between two": 1.0,
    "between two given": 0.5,
    "two given sequences": 1.0,
    "given sequences -lrb-": 1.0,
    "sequences -lrb- e.g.": 1.0,
    "e.g. , time": 0.038461538461538464,
    ", time series": 1.0,
    "time series -rrb-": 1.0,
    "series -rrb- with": 1.0,
    "-rrb- with certain": 0.3333333333333333,
    "with certain restrictions": 1.0,
    "certain restrictions .": 1.0,
    "is , the": 0.1111111111111111,
    ", the sequences": 0.009523809523809525,
    "the sequences are": 1.0,
    "sequences are ``": 1.0,
    "are `` warped": 1.0,
    "`` warped ''": 1.0,
    "warped '' non-linearly": 1.0,
    "'' non-linearly to": 1.0,
    "non-linearly to match": 1.0,
    "to match each": 0.5,
    "match each other": 1.0,
    "<s> this sequence": 0.019230769230769232,
    "this sequence alignment": 1.0,
    "sequence alignment method": 1.0,
    "alignment method is": 1.0,
    "method is often": 1.0,
    "is often used": 0.09090909090909091,
    "often used in": 0.5,
    "context of hidden": 0.2,
    "markov models ...": 0.1111111111111111,
    "models ... .": 1.0,
    "<s> neural networks": 0.5,
    "neural networks main": 0.09090909090909091,
    "networks main article": 1.0,
    "article : neural": 0.07692307692307693,
    ": neural networks": 1.0,
    "neural networks neural": 0.09090909090909091,
    "networks neural networks": 1.0,
    "neural networks emerged": 0.09090909090909091,
    "networks emerged as": 1.0,
    "emerged as an": 1.0,
    "as an attractive": 0.06666666666666667,
    "an attractive acoustic": 1.0,
    "attractive acoustic modeling": 1.0,
    "acoustic modeling approach": 0.5,
    "modeling approach in": 1.0,
    "approach in asr": 1.0,
    "in asr in": 0.5,
    "late 1980s .": 0.25,
    "<s> since then": 0.25,
    "since then ,": 1.0,
    "then , neural": 0.2,
    ", neural networks": 1.0,
    "neural networks have": 0.09090909090909091,
    "networks have been": 1.0,
    "been used in": 0.2,
    "in many aspects": 0.1,
    "many aspects of": 1.0,
    "aspects of speech": 0.16666666666666666,
    "speech recognition such": 0.013157894736842105,
    "recognition such as": 1.0,
    "such as phoneme": 0.011111111111111112,
    "as phoneme classification": 1.0,
    "phoneme classification ,": 1.0,
    "classification , isolated": 1.0,
    ", isolated word": 1.0,
    "isolated word recognition": 1.0,
    "word recognition ,": 1.0,
    ", and speaker": 0.005291005291005291,
    "and speaker adaptation": 1.0,
    "in contrast to": 0.16666666666666666,
    "contrast to hmms": 0.5,
    "to hmms ,": 1.0,
    "hmms , neural": 1.0,
    "neural networks make": 0.09090909090909091,
    "networks make no": 1.0,
    "make no assumptions": 1.0,
    "no assumptions about": 1.0,
    "assumptions about feature": 1.0,
    "about feature statistical": 1.0,
    "feature statistical properties": 1.0,
    "statistical properties and": 1.0,
    "properties and have": 1.0,
    "and have several": 1.0,
    "have several qualities": 1.0,
    "several qualities making": 1.0,
    "qualities making them": 1.0,
    "making them attractive": 1.0,
    "them attractive recognition": 1.0,
    "attractive recognition models": 1.0,
    "recognition models for": 1.0,
    "models for speech": 0.16666666666666666,
    "<s> when used": 0.16666666666666666,
    "when used to": 1.0,
    "used to estimate": 0.045454545454545456,
    "estimate the probabilities": 0.5,
    "probabilities of a": 0.3333333333333333,
    "of a speech": 0.010869565217391304,
    "a speech feature": 0.5,
    "speech feature segment": 1.0,
    "feature segment ,": 1.0,
    "segment , neural": 0.5,
    "neural networks allow": 0.09090909090909091,
    "networks allow discriminative": 1.0,
    "allow discriminative training": 1.0,
    "discriminative training in": 0.5,
    "training in a": 1.0,
    "in a natural": 0.019230769230769232,
    "a natural and": 0.2,
    "natural and efficient": 0.5,
    "and efficient manner": 0.5,
    "efficient manner .": 1.0,
    "<s> few assumptions": 1.0,
    "few assumptions on": 1.0,
    "assumptions on the": 1.0,
    "on the statistics": 0.014925373134328358,
    "the statistics of": 1.0,
    "statistics of input": 1.0,
    "of input features": 0.3333333333333333,
    "input features are": 1.0,
    "features are made": 0.3333333333333333,
    "are made with": 0.3333333333333333,
    "made with neural": 1.0,
    "with neural networks": 1.0,
    ", in spite": 0.029411764705882353,
    "in spite of": 1.0,
    "spite of their": 1.0,
    "of their effectiveness": 0.5,
    "their effectiveness in": 1.0,
    "effectiveness in classifying": 1.0,
    "in classifying short-time": 1.0,
    "classifying short-time units": 1.0,
    "short-time units such": 1.0,
    "units such as": 1.0,
    "such as individual": 0.011111111111111112,
    "as individual phones": 1.0,
    "individual phones and": 1.0,
    "phones and isolated": 1.0,
    "and isolated words": 1.0,
    "isolated words ,": 1.0,
    "words , neural": 0.0625,
    "neural networks are": 0.09090909090909091,
    "networks are rarely": 1.0,
    "are rarely successful": 1.0,
    "rarely successful for": 1.0,
    "successful for continuous": 1.0,
    "for continuous recognition": 1.0,
    "continuous recognition tasks": 1.0,
    "recognition tasks ,": 0.5,
    "tasks , largely": 0.25,
    ", largely because": 1.0,
    "largely because of": 1.0,
    "because of their": 0.16666666666666666,
    "of their lack": 0.5,
    "their lack of": 1.0,
    "lack of ability": 1.0,
    "of ability to": 1.0,
    "ability to model": 0.3333333333333333,
    "to model temporal": 1.0,
    "model temporal dependencies": 1.0,
    "temporal dependencies .": 1.0,
    "thus , one": 0.09090909090909091,
    ", one alternative": 0.16666666666666666,
    "one alternative approach": 1.0,
    "alternative approach is": 1.0,
    "is to use": 0.05263157894736842,
    "to use neural": 0.1,
    "use neural networks": 1.0,
    "neural networks as": 0.09090909090909091,
    "networks as a": 1.0,
    "as a pre-processing": 0.027777777777777776,
    "a pre-processing e.g.": 1.0,
    "pre-processing e.g. feature": 1.0,
    "e.g. feature transformation": 1.0,
    "feature transformation ,": 1.0,
    "transformation , dimensionality": 1.0,
    ", dimensionality reduction": 1.0,
    "dimensionality reduction ,": 1.0,
    "reduction , for": 1.0,
    "for the hmm": 0.03125,
    "the hmm based": 1.0,
    "hmm based recognition": 1.0,
    "based recognition .": 1.0,
    "<s> further information": 0.3333333333333333,
    "further information popular": 0.5,
    "information popular speech": 1.0,
    "popular speech recognition": 1.0,
    "speech recognition conferences": 0.013157894736842105,
    "recognition conferences held": 1.0,
    "conferences held each": 1.0,
    "held each year": 1.0,
    "each year or": 1.0,
    "year or two": 1.0,
    "or two include": 0.5,
    "two include speechtek": 1.0,
    "include speechtek and": 1.0,
    "speechtek and speechtek": 1.0,
    "and speechtek europe": 1.0,
    "speechtek europe ,": 1.0,
    "europe , icassp": 0.3333333333333333,
    ", icassp ,": 1.0,
    "icassp , eurospeech\\/icslp": 1.0,
    ", eurospeech\\/icslp -lrb-": 1.0,
    "eurospeech\\/icslp -lrb- now": 1.0,
    "-lrb- now named": 0.6666666666666666,
    "now named interspeech": 0.5,
    "named interspeech -rrb-": 1.0,
    "interspeech -rrb- and": 1.0,
    "and the ieee": 0.024390243902439025,
    "the ieee asru": 0.5,
    "ieee asru .": 1.0,
    "<s> conferences in": 1.0,
    "conferences in the": 1.0,
    "processing , such": 0.1111111111111111,
    "such as acl": 0.011111111111111112,
    "as acl ,": 1.0,
    "acl , naacl": 1.0,
    ", naacl ,": 1.0,
    "naacl , emnlp": 1.0,
    ", emnlp ,": 1.0,
    "emnlp , and": 1.0,
    ", and hlt": 0.005291005291005291,
    "and hlt ,": 1.0,
    "hlt , are": 1.0,
    ", are beginning": 0.5,
    "are beginning to": 1.0,
    "beginning to include": 1.0,
    "to include papers": 0.14285714285714285,
    "include papers on": 1.0,
    "papers on speech": 0.5,
    "on speech processing": 0.5,
    "speech processing .": 0.5,
    "<s> important journals": 1.0,
    "important journals include": 1.0,
    "journals include the": 1.0,
    "include the ieee": 0.2,
    "the ieee transactions": 0.5,
    "ieee transactions on": 1.0,
    "transactions on speech": 0.5,
    "on speech and": 0.5,
    "speech and audio": 0.14285714285714285,
    "and audio processing": 1.0,
    "audio processing -lrb-": 1.0,
    "processing -lrb- now": 0.14285714285714285,
    "now named ieee": 0.5,
    "named ieee transactions": 1.0,
    "transactions on audio": 0.5,
    "on audio ,": 1.0,
    "audio , speech": 0.3333333333333333,
    ", speech and": 0.09090909090909091,
    "speech and language": 0.42857142857142855,
    "and language processing": 0.2857142857142857,
    "language processing -rrb-": 0.027777777777777776,
    "processing -rrb- ,": 1.0,
    "-rrb- , computer": 0.01282051282051282,
    ", computer speech": 0.3333333333333333,
    "computer speech and": 0.3333333333333333,
    "and language ,": 0.14285714285714285,
    "language , and": 0.14285714285714285,
    ", and speech": 0.005291005291005291,
    "and speech communication": 0.5,
    "speech communication .": 1.0,
    "<s> books like": 1.0,
    "books like ``": 1.0,
    "like `` fundamentals": 0.3333333333333333,
    "`` fundamentals of": 1.0,
    "fundamentals of speech": 0.5,
    "recognition '' by": 0.6,
    "'' by lawrence": 0.2,
    "by lawrence rabiner": 1.0,
    "lawrence rabiner can": 1.0,
    "rabiner can be": 1.0,
    "useful to acquire": 0.5,
    "to acquire basic": 1.0,
    "acquire basic knowledge": 1.0,
    "basic knowledge but": 1.0,
    "knowledge but may": 1.0,
    "but may not": 0.5,
    "may not be": 0.4,
    "not be fully": 0.08333333333333333,
    "be fully up": 0.5,
    "fully up to": 1.0,
    "up to date": 0.3333333333333333,
    "to date -lrb-": 0.5,
    "date -lrb- 1993": 0.5,
    "-lrb- 1993 -rrb-": 1.0,
    "1993 -rrb- .": 1.0,
    "<s> a very": 0.022727272727272728,
    "a very recent": 0.08333333333333333,
    "very recent book": 1.0,
    "recent book -lrb-": 1.0,
    "book -lrb- dec.": 0.5,
    "-lrb- dec. 2011": 1.0,
    "dec. 2011 -rrb-": 1.0,
    "2011 -rrb- ,": 1.0,
    "-rrb- , ``": 0.01282051282051282,
    ", `` fundamentals": 0.04,
    "fundamentals of speaker": 0.5,
    "of speaker recognition": 1.0,
    "speaker recognition ''": 0.5,
    "'' by homayoon": 0.2,
    "by homayoon beigi": 1.0,
    "homayoon beigi covers": 1.0,
    "beigi covers the": 1.0,
    "covers the more": 0.5,
    "the more recent": 0.16666666666666666,
    "more recent developments": 1.0,
    "recent developments in": 1.0,
    "developments in some": 0.5,
    "in some detail": 0.125,
    "some detail .": 1.0,
    "although the title": 0.3333333333333333,
    "the title concentrates": 1.0,
    "title concentrates on": 1.0,
    "concentrates on speaker": 1.0,
    "on speaker recognition": 1.0,
    "speaker recognition ,": 0.5,
    "recognition , but": 0.07142857142857142,
    ", but a": 0.020833333333333332,
    "but a large": 1.0,
    "a large portion": 0.1111111111111111,
    "large portion of": 1.0,
    "of the book": 0.005128205128205128,
    "the book applies": 0.5,
    "book applies directly": 1.0,
    "applies directly to": 1.0,
    "directly to speech": 0.5,
    "recognition , with": 0.07142857142857142,
    ", with a": 0.125,
    "with a lot": 0.05,
    "a lot of": 0.3333333333333333,
    "lot of valuable": 1.0,
    "of valuable detailed": 1.0,
    "valuable detailed background": 1.0,
    "detailed background material": 1.0,
    "background material .": 1.0,
    "<s> another good": 0.07692307692307693,
    "another good source": 1.0,
    "good source can": 1.0,
    "source can be": 1.0,
    "can be ``": 0.01098901098901099,
    "be `` statistical": 1.0,
    "`` statistical methods": 1.0,
    "statistical methods for": 0.2,
    "methods for speech": 0.25,
    "'' by frederick": 0.2,
    "by frederick jelinek": 1.0,
    "frederick jelinek and": 1.0,
    "jelinek and ``": 1.0,
    "and `` spoken": 0.05,
    "`` spoken language": 1.0,
    "spoken language processing": 0.3333333333333333,
    "processing -lrb- 2001": 0.14285714285714285,
    "-lrb- 2001 -rrb-": 1.0,
    "2001 -rrb- ''": 1.0,
    "-rrb- '' by": 1.0,
    "'' by xuedong": 0.2,
    "by xuedong huang": 1.0,
    "xuedong huang etc.": 1.0,
    "huang etc. .": 1.0,
    "<s> more up": 0.125,
    "more up to": 1.0,
    "to date is": 0.5,
    "date is ``": 1.0,
    "is `` computer": 0.5,
    "computer speech ''": 0.3333333333333333,
    "speech '' ,": 1.0,
    "'' , by": 0.03333333333333333,
    ", by manfred": 0.2,
    "by manfred r.": 1.0,
    "manfred r. schroeder": 1.0,
    "r. schroeder ,": 1.0,
    "schroeder , second": 1.0,
    ", second edition": 1.0,
    "second edition published": 1.0,
    "edition published in": 1.0,
    "published in 2004": 1.0,
    "in 2004 .": 0.5,
    "<s> the recently": 0.006802721088435374,
    "the recently updated": 1.0,
    "recently updated textbook": 1.0,
    "updated textbook of": 1.0,
    "textbook of ``": 1.0,
    "of `` speech": 0.125,
    "`` speech and": 0.5,
    "processing -lrb- 2008": 0.14285714285714285,
    "-lrb- 2008 -rrb-": 1.0,
    "2008 -rrb- ''": 1.0,
    "'' by jurafsky": 0.2,
    "by jurafsky and": 1.0,
    "jurafsky and martin": 1.0,
    "and martin presents": 1.0,
    "martin presents the": 1.0,
    "presents the basics": 1.0,
    "the basics and": 1.0,
    "basics and the": 1.0,
    "and the state": 0.024390243902439025,
    "the art for": 0.5,
    "art for asr": 1.0,
    "for asr .": 1.0,
    "<s> a good": 0.022727272727272728,
    "a good insight": 0.2,
    "good insight into": 1.0,
    "insight into the": 1.0,
    "into the techniques": 0.125,
    "the techniques used": 1.0,
    "techniques used in": 1.0,
    "in the best": 0.006535947712418301,
    "the best modern": 0.07142857142857142,
    "best modern systems": 1.0,
    "modern systems can": 1.0,
    "can be gained": 0.01098901098901099,
    "be gained by": 1.0,
    "gained by paying": 1.0,
    "by paying attention": 1.0,
    "paying attention to": 1.0,
    "attention to government": 1.0,
    "to government sponsored": 1.0,
    "government sponsored evaluations": 1.0,
    "sponsored evaluations such": 1.0,
    "evaluations such as": 1.0,
    "as those organised": 0.2,
    "those organised by": 1.0,
    "organised by darpa": 1.0,
    "by darpa -lrb-": 1.0,
    "darpa -lrb- the": 1.0,
    "-lrb- the largest": 0.125,
    "the largest speech": 1.0,
    "largest speech recognition-related": 1.0,
    "speech recognition-related project": 1.0,
    "recognition-related project ongoing": 1.0,
    "project ongoing as": 1.0,
    "ongoing as of": 1.0,
    "as of 2007": 0.5,
    "of 2007 is": 0.5,
    "2007 is the": 1.0,
    "is the gale": 0.022222222222222223,
    "the gale project": 1.0,
    "gale project ,": 1.0,
    "project , which": 0.5,
    ", which involves": 0.017857142857142856,
    "which involves both": 1.0,
    "involves both speech": 1.0,
    "both speech recognition": 1.0,
    "recognition and translation": 0.14285714285714285,
    "and translation components": 0.3333333333333333,
    "translation components -rrb-": 1.0,
    "components -rrb- .": 1.0,
    "<s> in terms": 0.010309278350515464,
    "terms of freely": 0.14285714285714285,
    "of freely available": 1.0,
    "freely available resources": 1.0,
    "available resources ,": 1.0,
    "resources , carnegie": 0.5,
    ", carnegie mellon": 1.0,
    "mellon university 's": 0.5,
    "university 's sphinx": 1.0,
    "'s sphinx toolkit": 1.0,
    "sphinx toolkit is": 1.0,
    "toolkit is one": 1.0,
    "is one place": 0.16666666666666666,
    "one place to": 1.0,
    "place to start": 1.0,
    "to start to": 0.5,
    "start to both": 1.0,
    "to both learn": 0.3333333333333333,
    "both learn about": 1.0,
    "learn about speech": 1.0,
    "recognition and to": 0.14285714285714285,
    "and to start": 0.09090909090909091,
    "to start experimenting": 0.5,
    "start experimenting .": 1.0,
    "<s> another resource": 0.07692307692307693,
    "another resource -lrb-": 1.0,
    "resource -lrb- free": 1.0,
    "-lrb- free as": 1.0,
    "free as in": 1.0,
    "as in free": 0.16666666666666666,
    "in free beer": 0.5,
    "free beer ,": 1.0,
    "beer , not": 1.0,
    ", not as": 0.14285714285714285,
    "not as in": 1.0,
    "in free speech": 0.5,
    "free speech -rrb-": 1.0,
    "speech -rrb- is": 0.25,
    "is the htk": 0.022222222222222223,
    "the htk book": 1.0,
    "htk book -lrb-": 1.0,
    "book -lrb- and": 0.5,
    "and the accompanying": 0.024390243902439025,
    "the accompanying htk": 1.0,
    "accompanying htk toolkit": 1.0,
    "htk toolkit -rrb-": 1.0,
    "toolkit -rrb- .": 1.0,
    "<s> the at&t": 0.006802721088435374,
    "the at&t libraries": 1.0,
    "at&t libraries grm": 1.0,
    "libraries grm library": 1.0,
    "grm library ,": 1.0,
    "library , and": 1.0,
    ", and dcd": 0.005291005291005291,
    "and dcd library": 1.0,
    "dcd library are": 1.0,
    "library are also": 1.0,
    "are also general": 0.125,
    "also general software": 1.0,
    "general software libraries": 1.0,
    "software libraries for": 1.0,
    "libraries for large-vocabulary": 1.0,
    "for large-vocabulary speech": 1.0,
    "large-vocabulary speech recognition": 0.5,
    "for more software": 0.25,
    "more software resources": 1.0,
    "software resources ,": 1.0,
    "resources , see": 0.5,
    ", see list": 0.5,
    "see list of": 1.0,
    "list of speech": 0.1,
    "speech recognition software": 0.02631578947368421,
    "recognition software .": 0.3333333333333333,
    "<s> a useful": 0.022727272727272728,
    "a useful review": 0.5,
    "useful review of": 1.0,
    "review of the": 1.0,
    "of the area": 0.005128205128205128,
    "the area of": 0.5,
    "area of robustness": 0.2,
    "of robustness in": 1.0,
    "robustness in asr": 1.0,
    "in asr is": 0.5,
    "asr is provided": 1.0,
    "is provided by": 1.0,
    "provided by junqua": 0.5,
    "by junqua and": 1.0,
    "junqua and haton": 1.0,
    "and haton -lrb-": 1.0,
    "haton -lrb- 1995": 1.0,
    "-lrb- 1995 -rrb-": 1.0,
    "1995 -rrb- .": 1.0,
    "<s> people with": 1.0,
    "people with disabilities": 1.0,
    "with disabilities people": 0.5,
    "disabilities people with": 1.0,
    "with disabilities can": 0.5,
    "disabilities can benefit": 1.0,
    "can benefit from": 1.0,
    "benefit from speech": 0.3333333333333333,
    "from speech recognition": 1.0,
    "speech recognition programs": 0.013157894736842105,
    "recognition programs .": 1.0,
    "<s> for individuals": 0.017543859649122806,
    "for individuals that": 1.0,
    "individuals that are": 1.0,
    "that are deaf": 0.06666666666666667,
    "are deaf or": 1.0,
    "deaf or hard": 1.0,
    "or hard of": 1.0,
    "hard of hearing": 1.0,
    "of hearing ,": 1.0,
    "hearing , speech": 1.0,
    "recognition software is": 0.3333333333333333,
    "software is used": 0.5,
    "used to automatically": 0.045454545454545456,
    "to automatically generate": 0.16666666666666666,
    "automatically generate a": 1.0,
    "generate a closed-captioning": 0.16666666666666666,
    "a closed-captioning of": 1.0,
    "closed-captioning of conversations": 1.0,
    "of conversations such": 1.0,
    "conversations such as": 1.0,
    "such as discussions": 0.011111111111111112,
    "as discussions in": 1.0,
    "discussions in conference": 1.0,
    "in conference rooms": 1.0,
    "conference rooms ,": 1.0,
    "rooms , classroom": 1.0,
    ", classroom lectures": 1.0,
    "classroom lectures ,": 1.0,
    "lectures , and\\/or": 1.0,
    ", and\\/or religious": 1.0,
    "and\\/or religious services": 1.0,
    "religious services .": 1.0,
    "also very useful": 0.5,
    "very useful for": 0.5,
    "useful for people": 0.3333333333333333,
    "for people who": 0.5,
    "people who have": 0.5,
    "who have difficulty": 0.5,
    "have difficulty using": 1.0,
    "difficulty using their": 1.0,
    "using their hands": 1.0,
    "their hands ,": 1.0,
    "hands , ranging": 1.0,
    "ranging from mild": 0.5,
    "from mild repetitive": 1.0,
    "mild repetitive stress": 1.0,
    "repetitive stress injuries": 1.0,
    "stress injuries to": 1.0,
    "injuries to involved": 1.0,
    "to involved disabilities": 1.0,
    "involved disabilities that": 1.0,
    "disabilities that preclude": 1.0,
    "that preclude using": 1.0,
    "preclude using conventional": 1.0,
    "using conventional computer": 1.0,
    "conventional computer input": 1.0,
    "computer input devices": 1.0,
    "input devices .": 0.5,
    "fact , people": 0.2,
    ", people who": 1.0,
    "people who used": 0.5,
    "who used the": 1.0,
    "used the keyboard": 1.0,
    "the keyboard a": 1.0,
    "keyboard a lot": 1.0,
    "a lot and": 0.3333333333333333,
    "lot and developed": 1.0,
    "and developed rsi": 0.5,
    "developed rsi became": 1.0,
    "rsi became an": 1.0,
    "became an urgent": 1.0,
    "an urgent early": 1.0,
    "urgent early market": 1.0,
    "early market for": 1.0,
    "market for speech": 1.0,
    "recognition is used": 0.1,
    "used in deaf": 0.043478260869565216,
    "in deaf telephony": 1.0,
    "deaf telephony ,": 1.0,
    "telephony , such": 0.5,
    "such as voicemail": 0.011111111111111112,
    "as voicemail to": 1.0,
    "voicemail to text": 1.0,
    "to text ,": 0.5,
    "text , relay": 0.03333333333333333,
    ", relay services": 1.0,
    "relay services ,": 1.0,
    "services , and": 1.0,
    ", and captioned": 0.005291005291005291,
    "and captioned telephone": 1.0,
    "captioned telephone .": 1.0,
    "<s> individuals with": 1.0,
    "individuals with learning": 1.0,
    "with learning disabilities": 1.0,
    "learning disabilities who": 1.0,
    "disabilities who have": 1.0,
    "who have problems": 0.5,
    "have problems with": 1.0,
    "problems with thought-to-paper": 1.0,
    "with thought-to-paper communication": 1.0,
    "thought-to-paper communication -lrb-": 1.0,
    "communication -lrb- essentially": 0.5,
    "-lrb- essentially they": 1.0,
    "essentially they think": 1.0,
    "they think of": 1.0,
    "think of an": 1.0,
    "of an idea": 0.07692307692307693,
    "an idea but": 1.0,
    "idea but it": 1.0,
    "but it is": 0.25,
    "it is processed": 0.02127659574468085,
    "is processed incorrectly": 1.0,
    "processed incorrectly causing": 1.0,
    "incorrectly causing it": 1.0,
    "causing it to": 1.0,
    "it to end": 0.2,
    "to end up": 0.5,
    "end up differently": 0.5,
    "up differently on": 1.0,
    "differently on paper": 1.0,
    "on paper -rrb-": 1.0,
    "paper -rrb- can": 1.0,
    "-rrb- can benefit": 0.3333333333333333,
    "benefit from the": 0.3333333333333333,
    "from the software": 0.045454545454545456,
    "the software -lrb-": 0.25,
    "software -lrb- citation": 0.5,
    "<s> -lrb- icon": 0.05263157894736842,
    "-lrb- icon -rrb-": 1.0,
    "icon -rrb- this": 1.0,
    "-rrb- this section": 1.0,
    "this section requires": 0.5,
    "section requires expansion": 0.5,
    "requires expansion .": 1.0,
    "<s> current research": 0.3333333333333333,
    "research and funding": 0.16666666666666666,
    "and funding measuring": 1.0,
    "funding measuring progress": 1.0,
    "measuring progress in": 1.0,
    "progress in speech": 1.0,
    "speech recognition performance": 0.039473684210526314,
    "recognition performance is": 0.25,
    "performance is difficult": 0.5,
    "is difficult and": 0.25,
    "difficult and controversial": 1.0,
    "and controversial .": 1.0,
    "<s> some speech": 0.0625,
    "some speech recognition": 1.0,
    "speech recognition tasks": 0.013157894736842105,
    "recognition tasks are": 0.5,
    "tasks are much": 0.25,
    "are much more": 0.5,
    "difficult than others": 0.3333333333333333,
    "<s> word error": 0.2,
    "word error rates": 0.3333333333333333,
    "error rates on": 0.25,
    "rates on some": 1.0,
    "on some tasks": 0.1111111111111111,
    "some tasks are": 1.0,
    "tasks are less": 0.25,
    "are less than": 1.0,
    "less than 1": 0.3333333333333333,
    "than 1 %": 1.0,
    "1 % .": 0.5,
    "<s> on others": 0.2,
    "on others they": 1.0,
    "others they can": 1.0,
    "be as high": 0.3333333333333333,
    "as high as": 1.0,
    "high as 50": 1.0,
    "as 50 %": 1.0,
    "<s> sometimes it": 1.0,
    "sometimes it even": 1.0,
    "it even appears": 1.0,
    "even appears that": 1.0,
    "appears that performance": 1.0,
    "that performance is": 0.3333333333333333,
    "performance is going": 0.5,
    "is going backward": 1.0,
    "going backward ,": 1.0,
    "backward , as": 1.0,
    ", as researchers": 0.043478260869565216,
    "as researchers undertake": 1.0,
    "researchers undertake harder": 1.0,
    "undertake harder tasks": 1.0,
    "harder tasks that": 1.0,
    "tasks that have": 1.0,
    "that have higher": 0.16666666666666666,
    "have higher error": 1.0,
    "higher error rates": 1.0,
    "error rates .": 0.25,
    "<s> because progress": 0.3333333333333333,
    "because progress is": 1.0,
    "progress is slow": 1.0,
    "is slow and": 1.0,
    "slow and is": 1.0,
    "and is difficult": 0.16666666666666666,
    "difficult to measure": 0.09090909090909091,
    "to measure ,": 0.25,
    "measure , there": 1.0,
    "there is some": 0.058823529411764705,
    "is some perception": 1.0,
    "some perception that": 1.0,
    "perception that performance": 1.0,
    "that performance has": 0.3333333333333333,
    "performance has plateaued": 1.0,
    "has plateaued and": 1.0,
    "plateaued and that": 0.5,
    "and that funding": 0.5,
    "that funding has": 1.0,
    "funding has dried": 1.0,
    "has dried up": 1.0,
    "dried up or": 1.0,
    "up or shifted": 1.0,
    "or shifted priorities": 1.0,
    "shifted priorities .": 1.0,
    "<s> such perceptions": 0.125,
    "such perceptions are": 1.0,
    "perceptions are not": 1.0,
    "are not new": 0.2,
    "not new .": 1.0,
    "in 1969 ,": 0.5,
    "1969 , john": 1.0,
    ", john pierce": 0.2,
    "john pierce wrote": 1.0,
    "pierce wrote an": 1.0,
    "wrote an open": 0.5,
    "an open letter": 0.5,
    "open letter that": 1.0,
    "letter that did": 1.0,
    "that did cause": 0.5,
    "did cause much": 1.0,
    "cause much funding": 1.0,
    "much funding to": 1.0,
    "funding to dry": 1.0,
    "to dry up": 1.0,
    "dry up for": 1.0,
    "up for several": 0.5,
    "several years .": 0.5,
    "<s> in 1993": 0.010309278350515464,
    "in 1993 there": 0.5,
    "1993 there was": 1.0,
    "was a strong": 0.3333333333333333,
    "a strong feeling": 0.5,
    "strong feeling that": 1.0,
    "feeling that performance": 1.0,
    "that performance had": 0.3333333333333333,
    "performance had plateaued": 1.0,
    "had plateaued and": 1.0,
    "plateaued and there": 0.5,
    "and there were": 0.25,
    "there were workshops": 0.3333333333333333,
    "were workshops dedicated": 1.0,
    "workshops dedicated to": 1.0,
    "dedicated to the": 0.5,
    "to the issue": 0.012987012987012988,
    "the 1990s ,": 0.5,
    "1990s , funding": 1.0,
    ", funding continued": 0.3333333333333333,
    "funding continued more": 1.0,
    "continued more or": 1.0,
    "or less uninterrupted": 0.25,
    "less uninterrupted and": 1.0,
    "uninterrupted and performance": 1.0,
    "and performance continued": 1.0,
    "performance continued ,": 1.0,
    "continued , slowly": 1.0,
    ", slowly but": 1.0,
    "slowly but steadily": 1.0,
    "but steadily ,": 1.0,
    "steadily , to": 1.0,
    "to improve .": 0.1111111111111111,
    "<s> for the": 0.017543859649122806,
    "for the past": 0.03125,
    "the past thirty": 0.5,
    "past thirty years": 1.0,
    "thirty years ,": 1.0,
    "years , speech": 0.2,
    "speech recognition research": 0.013157894736842105,
    "recognition research has": 1.0,
    "research has been": 0.16666666666666666,
    "has been characterized": 0.03571428571428571,
    "been characterized by": 1.0,
    "characterized by the": 0.5,
    "by the steady": 0.03571428571428571,
    "the steady accumulation": 0.5,
    "steady accumulation of": 1.0,
    "accumulation of small": 1.0,
    "of small incremental": 1.0,
    "small incremental improvements": 1.0,
    "incremental improvements .": 1.0,
    "also been a": 0.25,
    "been a trend": 0.5,
    "a trend to": 1.0,
    "trend to change": 0.5,
    "to change focus": 1.0,
    "change focus to": 1.0,
    "focus to more": 1.0,
    "to more difficult": 1.0,
    "more difficult tasks": 0.2857142857142857,
    "difficult tasks due": 0.5,
    "tasks due both": 1.0,
    "both to progress": 0.25,
    "to progress in": 1.0,
    "recognition performance and": 0.25,
    "performance and to": 0.5,
    "and to the": 0.09090909090909091,
    "to the availability": 0.012987012987012988,
    "the availability of": 1.0,
    "availability of faster": 1.0,
    "of faster computers": 1.0,
    "faster computers .": 1.0,
    "particular , this": 0.3333333333333333,
    ", this shifting": 0.16666666666666666,
    "this shifting to": 1.0,
    "shifting to more": 1.0,
    "difficult tasks has": 0.5,
    "tasks has characterized": 1.0,
    "has characterized darpa": 1.0,
    "characterized darpa funding": 1.0,
    "darpa funding of": 1.0,
    "funding of speech": 1.0,
    "speech recognition since": 0.013157894736842105,
    "recognition since the": 1.0,
    "since the 1980s": 0.5,
    "the 1980s .": 0.5,
    "last decade ,": 0.5,
    "decade , it": 1.0,
    ", it has": 0.041666666666666664,
    "it has continued": 0.25,
    "has continued with": 1.0,
    "continued with the": 1.0,
    "with the ears": 0.03333333333333333,
    "the ears project": 1.0,
    "ears project ,": 1.0,
    ", which undertook": 0.017857142857142856,
    "which undertook recognition": 1.0,
    "undertook recognition of": 1.0,
    "recognition of mandarin": 0.09090909090909091,
    "of mandarin and": 1.0,
    "mandarin and arabic": 1.0,
    "and arabic in": 0.5,
    "arabic in addition": 1.0,
    "addition to english": 0.3333333333333333,
    "to english ,": 1.0,
    "english , and": 0.16666666666666666,
    "and the gale": 0.024390243902439025,
    ", which focused": 0.017857142857142856,
    "which focused solely": 1.0,
    "focused solely on": 1.0,
    "solely on mandarin": 1.0,
    "on mandarin and": 1.0,
    "and arabic and": 0.5,
    "arabic and required": 1.0,
    "and required translation": 1.0,
    "required translation simultaneously": 1.0,
    "translation simultaneously with": 1.0,
    "simultaneously with speech": 1.0,
    "<s> commercial research": 0.5,
    "commercial research and": 1.0,
    "research and other": 0.16666666666666666,
    "and other academic": 0.1111111111111111,
    "other academic research": 1.0,
    "academic research also": 1.0,
    "research also continue": 1.0,
    "also continue to": 1.0,
    "continue to focus": 1.0,
    "to focus on": 1.0,
    "focus on increasingly": 0.25,
    "on increasingly difficult": 1.0,
    "increasingly difficult problems": 1.0,
    "difficult problems .": 0.3333333333333333,
    "<s> one key": 0.08333333333333333,
    "one key area": 1.0,
    "key area is": 0.5,
    "area is to": 0.5,
    "is to improve": 0.05263157894736842,
    "to improve robustness": 0.1111111111111111,
    "improve robustness of": 1.0,
    "robustness of speech": 1.0,
    "recognition performance ,": 0.25,
    "performance , not": 0.5,
    ", not just": 0.14285714285714285,
    "not just robustness": 1.0,
    "just robustness against": 1.0,
    "robustness against noise": 0.5,
    "against noise but": 1.0,
    "noise but robustness": 1.0,
    "but robustness against": 1.0,
    "robustness against any": 0.5,
    "against any condition": 1.0,
    "any condition that": 1.0,
    "condition that causes": 1.0,
    "that causes a": 1.0,
    "causes a major": 1.0,
    "a major degradation": 0.2,
    "major degradation in": 1.0,
    "degradation in performance": 1.0,
    "in performance .": 1.0,
    "<s> another key": 0.07692307692307693,
    "another key area": 1.0,
    "key area of": 0.5,
    "of research is": 0.25,
    "research is focused": 0.5,
    "is focused on": 1.0,
    "focused on an": 0.1,
    "on an opportunity": 0.3333333333333333,
    "an opportunity rather": 1.0,
    "opportunity rather than": 1.0,
    "than a problem": 0.2,
    "a problem .": 0.25,
    "<s> this research": 0.019230769230769232,
    "this research attempts": 1.0,
    "attempts to take": 0.3333333333333333,
    "fact that in": 0.2,
    "that in many": 0.5,
    "in many applications": 0.1,
    "many applications there": 0.5,
    "applications there is": 1.0,
    "is a large": 0.018518518518518517,
    "a large quantity": 0.1111111111111111,
    "large quantity of": 1.0,
    "quantity of speech": 1.0,
    "of speech data": 0.02127659574468085,
    "speech data available": 1.0,
    "data available ,": 0.3333333333333333,
    "available , up": 0.25,
    ", up to": 1.0,
    "up to millions": 0.16666666666666666,
    "to millions of": 1.0,
    "millions of hours": 0.5,
    "of hours .": 1.0,
    "it is too": 0.02127659574468085,
    "is too expensive": 1.0,
    "too expensive to": 0.5,
    "expensive to have": 1.0,
    "to have humans": 0.1,
    "have humans transcribe": 1.0,
    "humans transcribe such": 1.0,
    "transcribe such large": 1.0,
    "such large quantities": 1.0,
    "large quantities of": 1.0,
    "quantities of speech": 0.5,
    "speech , so": 0.09090909090909091,
    "so the research": 0.14285714285714285,
    "the research focus": 0.3333333333333333,
    "research focus is": 1.0,
    "focus is on": 1.0,
    "is on developing": 0.5,
    "on developing new": 1.0,
    "developing new methods": 1.0,
    "new methods of": 1.0,
    "methods of machine": 0.5,
    "machine learning that": 0.047619047619047616,
    "learning that can": 1.0,
    "that can effectively": 0.07692307692307693,
    "can effectively utilize": 1.0,
    "effectively utilize large": 1.0,
    "utilize large quantities": 1.0,
    "quantities of unlabeled": 0.5,
    "of unlabeled data": 1.0,
    "unlabeled data .": 1.0,
    "<s> another area": 0.07692307692307693,
    "another area of": 1.0,
    "research is better": 0.5,
    "is better understanding": 1.0,
    "better understanding of": 1.0,
    "understanding of human": 0.2,
    "of human capabilities": 0.2,
    "human capabilities and": 1.0,
    "capabilities and to": 1.0,
    "to use this": 0.1,
    "use this understanding": 0.5,
    "this understanding to": 1.0,
    "understanding to improve": 0.5,
    "to improve machine": 0.1111111111111111,
    "improve machine recognition": 1.0,
    "machine recognition performance": 1.0,
    "recognition performance .": 0.25,
    "segmentation is the": 0.4444444444444444,
    "process of identifying": 0.08333333333333333,
    "of identifying the": 1.0,
    "identifying the boundaries": 0.25,
    "the boundaries between": 0.6666666666666666,
    "boundaries between words": 0.5,
    "between words ,": 0.5,
    "words , syllables": 0.0625,
    ", syllables ,": 1.0,
    "syllables , or": 1.0,
    ", or phonemes": 0.030303030303030304,
    "or phonemes in": 0.5,
    "phonemes in spoken": 1.0,
    "in spoken natural": 0.5,
    "spoken natural languages": 1.0,
    "the term applies": 0.2222222222222222,
    "term applies both": 1.0,
    "applies both to": 1.0,
    "to the mental": 0.012987012987012988,
    "the mental processes": 1.0,
    "mental processes used": 1.0,
    "processes used by": 1.0,
    "used by humans": 0.2222222222222222,
    "by humans ,": 0.5,
    "humans , and": 0.5,
    "and to artificial": 0.18181818181818182,
    "to artificial processes": 1.0,
    "artificial processes of": 0.5,
    "processes of natural": 1.0,
    "segmentation is an": 0.1111111111111111,
    "is an important": 0.1,
    "an important subproblem": 0.25,
    "important subproblem of": 1.0,
    "subproblem of speech": 1.0,
    "and can not": 0.125,
    "not be adequately": 0.08333333333333333,
    "be adequately solved": 1.0,
    "adequately solved in": 1.0,
    "solved in isolation": 1.0,
    "in isolation .": 1.0,
    "as in most": 0.08333333333333333,
    "language processing problems": 0.027777777777777776,
    "processing problems ,": 1.0,
    "problems , one": 0.16666666666666666,
    ", one must": 0.16666666666666666,
    "one must take": 1.0,
    "must take into": 1.0,
    "into account context": 0.3333333333333333,
    "account context ,": 1.0,
    "context , grammar": 0.25,
    ", grammar ,": 1.0,
    ", and semantics": 0.005291005291005291,
    "and semantics ,": 0.3333333333333333,
    "and even so": 0.16666666666666666,
    "even so the": 1.0,
    "so the result": 0.14285714285714285,
    "result is often": 0.5,
    "is often a": 0.09090909090909091,
    "often a probabilistic": 0.5,
    "a probabilistic division": 1.0,
    "probabilistic division rather": 1.0,
    "division rather than": 1.0,
    "than a categorical": 0.2,
    "a categorical .": 1.0,
    "<s> a comprehensive": 0.022727272727272728,
    "a comprehensive survey": 0.25,
    "comprehensive survey of": 1.0,
    "survey of speech": 1.0,
    "of speech segmentation": 0.02127659574468085,
    "speech segmentation problems": 0.125,
    "segmentation problems and": 0.5,
    "problems and techniques": 0.5,
    "and techniques can": 1.0,
    "techniques can be": 1.0,
    "be seen in": 0.3333333333333333,
    "seen in .": 1.0,
    "<s> some writing": 0.0625,
    "some writing systems": 1.0,
    "writing systems indicate": 0.5,
    "systems indicate speech": 1.0,
    "indicate speech segmentation": 1.0,
    "speech segmentation between": 0.125,
    "segmentation between words": 1.0,
    "between words by": 0.5,
    "words by a": 1.0,
    "by a word": 0.05555555555555555,
    "a word divider": 0.08333333333333333,
    "word divider ,": 1.0,
    "divider , such": 1.0,
    "as the space": 0.03571428571428571,
    "the space .": 0.3333333333333333,
    "of this problem": 0.09090909090909091,
    "this problem is": 0.18181818181818182,
    "problem is compounded": 0.2,
    "is compounded by": 1.0,
    "compounded by the": 1.0,
    "by the phenomenon": 0.03571428571428571,
    "phenomenon of co-articulation": 0.3333333333333333,
    "of co-articulation of": 1.0,
    "co-articulation of speech": 1.0,
    "of speech sounds": 0.02127659574468085,
    "speech sounds ,": 1.0,
    "sounds , where": 0.5,
    ", where one": 0.06666666666666667,
    "where one may": 1.0,
    "one may be": 1.0,
    "may be modified": 0.047619047619047616,
    "be modified in": 1.0,
    "modified in various": 1.0,
    "various ways by": 0.5,
    "ways by the": 1.0,
    "by the adjacent": 0.03571428571428571,
    "the adjacent sounds": 1.0,
    "adjacent sounds :": 1.0,
    "sounds : it": 1.0,
    ": it may": 1.0,
    "it may blend": 0.5,
    "may blend smoothly": 1.0,
    "blend smoothly with": 0.5,
    "smoothly with them": 1.0,
    "with them ,": 0.6666666666666666,
    "them , fuse": 0.25,
    ", fuse with": 1.0,
    "fuse with them": 0.5,
    "them , split": 0.25,
    ", split ,": 1.0,
    "split , or": 1.0,
    "or even disappear": 0.2,
    "even disappear .": 1.0,
    "this phenomenon may": 0.5,
    "phenomenon may happen": 1.0,
    "may happen between": 1.0,
    "happen between adjacent": 1.0,
    "between adjacent words": 1.0,
    "adjacent words just": 0.5,
    "words just as": 1.0,
    "as easily as": 0.5,
    "easily as within": 1.0,
    "as within a": 1.0,
    "within a single": 0.2,
    "a single word": 0.1111111111111111,
    "single word .": 0.5,
    "the notion that": 0.25,
    "notion that speech": 1.0,
    "that speech is": 1.0,
    "speech is produced": 0.3333333333333333,
    "is produced like": 0.5,
    "produced like writing": 1.0,
    "like writing ,": 1.0,
    "writing , as": 0.5,
    ", as a": 0.043478260869565216,
    "as a sequence": 0.027777777777777776,
    "sequence of distinct": 0.14285714285714285,
    "of distinct vowels": 1.0,
    "distinct vowels and": 1.0,
    "vowels and consonants": 1.0,
    "and consonants ,": 1.0,
    "consonants , is": 1.0,
    "is a relic": 0.018518518518518517,
    "a relic of": 1.0,
    "relic of our": 1.0,
    "of our alphabetic": 1.0,
    "our alphabetic heritage": 1.0,
    "alphabetic heritage -lrb-": 1.0,
    "heritage -lrb- citation": 1.0,
    "fact , the": 0.2,
    ", the way": 0.009523809523809525,
    "the way we": 0.5,
    "way we produce": 1.0,
    "we produce vowels": 0.5,
    "produce vowels depends": 1.0,
    "vowels depends on": 1.0,
    "on the surrounding": 0.029850746268656716,
    "the surrounding consonants": 0.5,
    "surrounding consonants and": 1.0,
    "consonants and the": 1.0,
    "and the way": 0.024390243902439025,
    "we produce consonants": 0.5,
    "produce consonants depends": 1.0,
    "consonants depends on": 1.0,
    "the surrounding vowels": 0.5,
    "surrounding vowels .": 1.0,
    ", when we": 0.16666666666666666,
    "when we say": 0.6666666666666666,
    "we say `": 1.0,
    "say ` kit": 0.5,
    "` kit '": 1.0,
    "kit ' ,": 1.0,
    "' , the": 0.16666666666666666,
    ", the -lrb-": 0.009523809523809525,
    "the -lrb- k": 1.0,
    "-lrb- k -rrb-": 1.0,
    "k -rrb- is": 1.0,
    "-rrb- is farther": 0.09090909090909091,
    "is farther forward": 1.0,
    "farther forward than": 1.0,
    "forward than when": 1.0,
    "than when we": 1.0,
    "say ` caught": 0.5,
    "` caught '": 1.0,
    "caught ' .": 1.0,
    "<s> but also": 0.16666666666666666,
    "also the vowel": 0.5,
    "the vowel in": 1.0,
    "vowel in `": 1.0,
    "in ` kick": 0.5,
    "` kick '": 1.0,
    "kick ' is": 1.0,
    "' is phonetically": 1.0,
    "is phonetically different": 1.0,
    "phonetically different from": 1.0,
    "different from the": 0.16666666666666666,
    "from the vowel": 0.045454545454545456,
    "in ` kit": 0.5,
    "' , though": 0.16666666666666666,
    ", though we": 0.16666666666666666,
    "though we normally": 1.0,
    "we normally do": 1.0,
    "normally do not": 1.0,
    "do not hear": 0.07692307692307693,
    "not hear this": 1.0,
    "hear this .": 1.0,
    "addition , there": 0.5,
    "there are language-specific": 0.047619047619047616,
    "are language-specific changes": 1.0,
    "language-specific changes which": 1.0,
    "changes which occur": 1.0,
    "which occur on": 1.0,
    "occur on casual": 1.0,
    "on casual speech": 1.0,
    "casual speech which": 1.0,
    "speech which makes": 1.0,
    "makes it quite": 0.5,
    "it quite different": 1.0,
    "different from spelling": 0.16666666666666666,
    "from spelling .": 1.0,
    ", in english": 0.029411764705882353,
    "in english ,": 0.14285714285714285,
    "english , the": 0.16666666666666666,
    ", the phrase": 0.009523809523809525,
    "the phrase `": 0.25,
    "phrase ` hit": 1.0,
    "` hit you": 1.0,
    "hit you '": 1.0,
    "you ' could": 1.0,
    "' could often": 1.0,
    "could often be": 1.0,
    "often be more": 1.0,
    "be more appropriately": 0.2,
    "more appropriately spelled": 1.0,
    "appropriately spelled `": 1.0,
    "spelled ` hitcha": 1.0,
    "` hitcha '": 1.0,
    "hitcha ' .": 1.0,
    "therefore , even": 0.5,
    ", even with": 0.14285714285714285,
    "even with the": 1.0,
    "with the best": 0.03333333333333333,
    "the best algorithms": 0.07142857142857142,
    "best algorithms ,": 1.0,
    ", the result": 0.009523809523809525,
    "result of phonetic": 0.3333333333333333,
    "of phonetic segmentation": 1.0,
    "phonetic segmentation will": 1.0,
    "segmentation will usually": 1.0,
    "will usually be": 1.0,
    "usually be very": 1.0,
    "be very distant": 0.3333333333333333,
    "very distant from": 1.0,
    "distant from the": 1.0,
    "from the standard": 0.045454545454545456,
    "the standard written": 0.3333333333333333,
    "standard written language": 1.0,
    "written language .": 0.3333333333333333,
    "reason , the": 0.5,
    ", the lexical": 0.009523809523809525,
    "the lexical and": 1.0,
    "and syntactic parsing": 0.5,
    "syntactic parsing of": 1.0,
    "parsing of spoken": 0.5,
    "of spoken text": 0.5,
    "spoken text normally": 1.0,
    "text normally requires": 1.0,
    "normally requires specialized": 1.0,
    "requires specialized algorithms": 1.0,
    "specialized algorithms ,": 1.0,
    "algorithms , distinct": 0.2,
    ", distinct from": 1.0,
    "distinct from those": 0.3333333333333333,
    "from those used": 0.5,
    "those used for": 0.3333333333333333,
    "used for parsing": 0.06666666666666667,
    "for parsing written": 1.0,
    "parsing written text": 1.0,
    "written text .": 0.3333333333333333,
    "<s> statistical models": 0.3333333333333333,
    "statistical models can": 0.125,
    "models can be": 1.0,
    "used to segment": 0.045454545454545456,
    "to segment and": 0.3333333333333333,
    "segment and align": 1.0,
    "and align recorded": 1.0,
    "align recorded speech": 1.0,
    "recorded speech to": 1.0,
    "speech to words": 0.3333333333333333,
    "to words or": 1.0,
    "words or phones": 0.14285714285714285,
    "or phones .": 1.0,
    "<s> applications include": 0.5,
    "applications include automatic": 0.3333333333333333,
    "include automatic lip-synch": 1.0,
    "automatic lip-synch timing": 1.0,
    "lip-synch timing for": 1.0,
    "timing for cartoon": 1.0,
    "for cartoon animation": 1.0,
    "cartoon animation ,": 1.0,
    "animation , follow-the-bouncing-ball": 1.0,
    ", follow-the-bouncing-ball video": 1.0,
    "follow-the-bouncing-ball video sub-titling": 1.0,
    "video sub-titling ,": 1.0,
    "sub-titling , and": 1.0,
    ", and linguistic": 0.005291005291005291,
    "and linguistic research": 1.0,
    "linguistic research .": 1.0,
    "<s> automatic segmentation": 0.2857142857142857,
    "automatic segmentation and": 0.3333333333333333,
    "segmentation and alignment": 0.5,
    "and alignment software": 1.0,
    "alignment software is": 1.0,
    "software is commercially": 0.5,
    "is commercially available": 1.0,
    "commercially available .": 0.5,
    "<s> lexical segmentation": 0.5,
    "lexical segmentation in": 0.5,
    "segmentation in all": 0.5,
    "in all natural": 0.25,
    "all natural languages": 1.0,
    ", the meaning": 0.009523809523809525,
    "meaning of a": 0.14285714285714285,
    "a complex spoken": 0.2,
    "complex spoken sentence": 1.0,
    "spoken sentence -lrb-": 1.0,
    "sentence -lrb- which": 1.0,
    "-lrb- which often": 0.3333333333333333,
    "which often has": 1.0,
    "often has never": 0.5,
    "never been heard": 0.5,
    "been heard or": 1.0,
    "heard or uttered": 1.0,
    "or uttered before": 1.0,
    "uttered before -rrb-": 1.0,
    "before -rrb- can": 0.5,
    "-rrb- can be": 0.3333333333333333,
    "can be understood": 0.01098901098901099,
    "be understood only": 1.0,
    "understood only by": 1.0,
    "only by decomposing": 0.5,
    "by decomposing it": 1.0,
    "decomposing it into": 1.0,
    "it into smaller": 0.2,
    "into smaller lexical": 1.0,
    "smaller lexical segments": 1.0,
    "lexical segments -lrb-": 1.0,
    "segments -lrb- roughly": 1.0,
    "-lrb- roughly ,": 1.0,
    "roughly , the": 1.0,
    ", the words": 0.009523809523809525,
    "the words of": 0.16666666666666666,
    "the language -rrb-": 0.25,
    "language -rrb- ,": 0.5,
    "-rrb- , associating": 0.01282051282051282,
    ", associating a": 1.0,
    "associating a meaning": 1.0,
    "meaning to each": 0.5,
    "to each segment": 0.2,
    "each segment ,": 0.5,
    "segment , and": 0.5,
    "and then combining": 0.14285714285714285,
    "then combining those": 1.0,
    "combining those meanings": 1.0,
    "those meanings according": 1.0,
    "meanings according to": 1.0,
    "the grammar rules": 0.09090909090909091,
    "grammar rules of": 0.2,
    "rules of the": 0.25,
    "<s> the recognition": 0.006802721088435374,
    "recognition of each": 0.09090909090909091,
    "of each lexical": 0.14285714285714285,
    "each lexical segment": 1.0,
    "lexical segment in": 1.0,
    "segment in turn": 1.0,
    "in turn requires": 0.2,
    "turn requires its": 1.0,
    "requires its decomposition": 1.0,
    "its decomposition into": 1.0,
    "decomposition into a": 1.0,
    "into a sequence": 0.058823529411764705,
    "sequence of discrete": 0.14285714285714285,
    "of discrete phonetic": 1.0,
    "discrete phonetic segments": 1.0,
    "phonetic segments and": 1.0,
    "segments and mapping": 1.0,
    "and mapping each": 1.0,
    "mapping each segment": 1.0,
    "each segment to": 0.5,
    "segment to one": 1.0,
    "to one element": 0.5,
    "one element of": 1.0,
    "element of a": 1.0,
    "of a finite": 0.010869565217391304,
    "a finite set": 0.5,
    "finite set of": 1.0,
    "set of elementary": 0.03571428571428571,
    "of elementary sounds": 1.0,
    "elementary sounds -lrb-": 1.0,
    "sounds -lrb- roughly": 0.5,
    ", the phonemes": 0.009523809523809525,
    "the phonemes of": 0.5,
    "phonemes of the": 1.0,
    "language -rrb- ;": 0.5,
    "-rrb- ; the": 0.125,
    "; the meaning": 0.25,
    "the meaning then": 0.1,
    "meaning then can": 1.0,
    "then can be": 1.0,
    "be found by": 0.3333333333333333,
    "found by standard": 1.0,
    "by standard table": 1.0,
    "standard table lookup": 1.0,
    "table lookup algorithms": 1.0,
    "lookup algorithms .": 1.0,
    "<s> for most": 0.017543859649122806,
    "for most spoken": 0.3333333333333333,
    ", the boundaries": 0.009523809523809525,
    "boundaries between lexical": 0.5,
    "between lexical units": 0.5,
    "lexical units are": 1.0,
    "units are surprisingly": 0.5,
    "are surprisingly difficult": 1.0,
    "surprisingly difficult to": 1.0,
    "difficult to identify": 0.09090909090909091,
    "to identify .": 0.2,
    "<s> one might": 0.08333333333333333,
    "one might expect": 1.0,
    "might expect that": 1.0,
    "expect that the": 1.0,
    "that the inter-word": 0.043478260869565216,
    "the inter-word spaces": 1.0,
    "inter-word spaces used": 0.5,
    "spaces used by": 1.0,
    "used by many": 0.1111111111111111,
    "by many written": 1.0,
    "many written languages": 1.0,
    "written languages ,": 0.2,
    "languages , like": 0.09090909090909091,
    ", like english": 0.3333333333333333,
    "like english or": 0.5,
    "english or spanish": 1.0,
    "or spanish ,": 1.0,
    "spanish , would": 1.0,
    ", would correspond": 0.3333333333333333,
    "would correspond to": 1.0,
    "correspond to pauses": 0.5,
    "to pauses in": 1.0,
    "pauses in their": 1.0,
    "in their spoken": 0.25,
    "their spoken version": 1.0,
    "spoken version ;": 1.0,
    "version ; but": 1.0,
    "; but that": 0.5,
    "but that is": 0.3333333333333333,
    "that is true": 0.05263157894736842,
    "is true only": 1.0,
    "true only in": 1.0,
    "in very slow": 0.3333333333333333,
    "very slow speech": 1.0,
    "slow speech ,": 1.0,
    "when the speaker": 0.2,
    "the speaker deliberately": 0.5,
    "speaker deliberately inserts": 1.0,
    "deliberately inserts those": 1.0,
    "inserts those pauses": 1.0,
    "those pauses .": 1.0,
    "<s> in normal": 0.010309278350515464,
    "in normal speech": 1.0,
    "normal speech ,": 1.0,
    "speech , one": 0.09090909090909091,
    ", one typically": 0.16666666666666666,
    "one typically finds": 1.0,
    "typically finds many": 1.0,
    "finds many consecutive": 1.0,
    "many consecutive words": 1.0,
    "consecutive words being": 1.0,
    "words being said": 1.0,
    "being said with": 1.0,
    "said with no": 1.0,
    "with no pauses": 0.5,
    "no pauses between": 1.0,
    "pauses between them": 0.5,
    "between them ,": 0.5,
    "them , and": 0.25,
    ", and often": 0.010582010582010581,
    "and often the": 0.3333333333333333,
    "often the final": 0.5,
    "the final sounds": 0.2,
    "final sounds of": 1.0,
    "sounds of one": 0.5,
    "of one word": 0.25,
    "one word blend": 0.5,
    "word blend smoothly": 1.0,
    "blend smoothly or": 0.5,
    "smoothly or fuse": 1.0,
    "or fuse with": 1.0,
    "fuse with the": 0.5,
    "with the initial": 0.03333333333333333,
    "the initial sounds": 1.0,
    "initial sounds of": 1.0,
    "sounds of the": 0.5,
    "of the next": 0.005128205128205128,
    "next word .": 0.5,
    "moreover , an": 0.25,
    ", an utterance": 0.1,
    "an utterance can": 0.5,
    "utterance can have": 1.0,
    "can have different": 0.5,
    "have different meanings": 0.5,
    "different meanings depending": 1.0,
    "meanings depending on": 1.0,
    "depending on how": 0.25,
    "how it is": 0.5,
    "it is split": 0.02127659574468085,
    "split into words": 0.5,
    "<s> a popular": 0.022727272727272728,
    "a popular example": 1.0,
    "popular example ,": 1.0,
    "example , often": 0.018518518518518517,
    ", often quoted": 0.3333333333333333,
    "often quoted in": 1.0,
    "quoted in the": 1.0,
    "the field ,": 0.058823529411764705,
    "field , is": 1.0,
    "is the phrase": 0.022222222222222223,
    "the phrase how": 0.25,
    "phrase how to": 1.0,
    "how to wreck": 0.2,
    "to wreck a": 1.0,
    "wreck a nice": 1.0,
    "a nice beach": 0.5,
    "nice beach ,": 1.0,
    "beach , which": 1.0,
    ", which sounds": 0.017857142857142856,
    "which sounds very": 1.0,
    "sounds very similar": 1.0,
    "similar to how": 0.06666666666666667,
    "to how to": 1.0,
    "how to recognize": 0.2,
    "to recognize speech": 0.14285714285714285,
    "recognize speech .": 1.0,
    "<s> as this": 0.07142857142857142,
    "as this example": 1.0,
    "this example shows": 1.0,
    "example shows ,": 1.0,
    "shows , proper": 1.0,
    ", proper lexical": 1.0,
    "proper lexical segmentation": 1.0,
    "lexical segmentation depends": 0.5,
    "segmentation depends on": 1.0,
    "depends on context": 0.14285714285714285,
    "on context and": 1.0,
    "context and semantics": 0.2,
    "and semantics which": 0.3333333333333333,
    "semantics which draws": 0.5,
    "which draws on": 1.0,
    "draws on the": 1.0,
    "on the whole": 0.014925373134328358,
    "the whole of": 1.0,
    "whole of human": 1.0,
    "of human knowledge": 0.2,
    "human knowledge and": 1.0,
    "knowledge and experience": 0.5,
    "and experience ,": 1.0,
    "experience , and": 1.0,
    ", and would": 0.005291005291005291,
    "and would thus": 1.0,
    "would thus require": 1.0,
    "thus require advanced": 1.0,
    "require advanced pattern": 1.0,
    "advanced pattern recognition": 1.0,
    "pattern recognition and": 0.25,
    "recognition and artificial": 0.14285714285714285,
    "and artificial intelligence": 1.0,
    "artificial intelligence technologies": 0.125,
    "intelligence technologies to": 1.0,
    "technologies to be": 1.0,
    "to be implemented": 0.023255813953488372,
    "be implemented on": 0.5,
    "implemented on a": 1.0,
    "on a computer": 0.041666666666666664,
    "this problem overlaps": 0.09090909090909091,
    "problem overlaps to": 1.0,
    "overlaps to some": 1.0,
    "to some extent": 0.2,
    "some extent with": 1.0,
    "extent with the": 1.0,
    "with the problem": 0.03333333333333333,
    "problem of text": 0.125,
    "of text segmentation": 0.041666666666666664,
    "text segmentation that": 0.1111111111111111,
    "segmentation that occurs": 1.0,
    "that occurs in": 1.0,
    "occurs in some": 0.3333333333333333,
    "in some languages": 0.125,
    "some languages which": 0.5,
    "languages which are": 0.5,
    "which are traditionally": 0.08333333333333333,
    "are traditionally written": 0.5,
    "traditionally written without": 1.0,
    "written without inter-word": 1.0,
    "without inter-word spaces": 1.0,
    "inter-word spaces ,": 0.5,
    "spaces , like": 1.0,
    ", like chinese": 0.3333333333333333,
    "like chinese and": 0.5,
    "chinese and japanese": 1.0,
    "and japanese .": 1.0,
    "however , even": 0.022727272727272728,
    ", even for": 0.14285714285714285,
    "even for those": 1.0,
    "for those languages": 0.5,
    "those languages ,": 0.5,
    "languages , text": 0.09090909090909091,
    ", text segmentation": 0.3333333333333333,
    "segmentation is often": 0.1111111111111111,
    "is often much": 0.09090909090909091,
    "often much easier": 1.0,
    "much easier than": 1.0,
    "easier than speech": 0.5,
    "than speech segmentation": 1.0,
    "speech segmentation ,": 0.25,
    "segmentation , because": 0.25,
    "because the written": 0.25,
    "the written language": 1.0,
    "written language usually": 0.3333333333333333,
    "language usually has": 1.0,
    "usually has little": 1.0,
    "has little interference": 1.0,
    "little interference between": 1.0,
    "interference between adjacent": 1.0,
    "adjacent words ,": 0.5,
    "and often contains": 0.3333333333333333,
    "often contains additional": 1.0,
    "contains additional clues": 1.0,
    "additional clues not": 1.0,
    "clues not present": 1.0,
    "present in speech": 0.2,
    "in speech -lrb-": 0.125,
    "speech -lrb- such": 0.25,
    "as the use": 0.03571428571428571,
    "use of chinese": 0.045454545454545456,
    "of chinese characters": 1.0,
    "chinese characters for": 1.0,
    "characters for word": 1.0,
    "for word stems": 1.0,
    "word stems in": 1.0,
    "stems in japanese": 1.0,
    "in japanese -rrb-": 1.0,
    "japanese -rrb- .": 1.0,
    "<s> text segmentation": 0.5,
    "process of dividing": 0.16666666666666666,
    "of dividing written": 0.3333333333333333,
    "dividing written text": 1.0,
    "text into meaningful": 0.14285714285714285,
    "into meaningful units": 0.5,
    "meaningful units ,": 1.0,
    "units , such": 1.0,
    "such as words": 0.011111111111111112,
    "as words ,": 1.0,
    "words , sentences": 0.0625,
    ", sentences ,": 0.5,
    "sentences , or": 0.125,
    ", or topics": 0.030303030303030304,
    "or topics .": 1.0,
    "both to mental": 0.25,
    "to mental processes": 1.0,
    "by humans when": 0.5,
    "humans when reading": 1.0,
    "when reading text": 1.0,
    "reading text ,": 1.0,
    "artificial processes implemented": 0.5,
    "processes implemented in": 1.0,
    "implemented in computers": 1.0,
    "in computers ,": 1.0,
    "computers , which": 0.5,
    "which are the": 0.08333333333333333,
    "are the subject": 0.09090909090909091,
    "subject of natural": 0.5,
    "problem is non-trivial": 0.2,
    "is non-trivial ,": 1.0,
    "non-trivial , because": 1.0,
    ", because while": 0.125,
    "because while some": 1.0,
    "while some written": 0.5,
    "written languages have": 0.2,
    "languages have explicit": 0.5,
    "have explicit word": 1.0,
    "explicit word boundary": 1.0,
    "word boundary markers": 1.0,
    "boundary markers ,": 1.0,
    "markers , such": 1.0,
    "as the word": 0.03571428571428571,
    "the word spaces": 0.125,
    "word spaces of": 1.0,
    "spaces of written": 1.0,
    "of written english": 0.25,
    "written english and": 1.0,
    "english and the": 0.3333333333333333,
    "and the distinctive": 0.024390243902439025,
    "the distinctive initial": 1.0,
    "distinctive initial ,": 1.0,
    "initial , medial": 1.0,
    ", medial and": 1.0,
    "medial and final": 1.0,
    "and final letter": 1.0,
    "final letter shapes": 1.0,
    "letter shapes of": 0.5,
    "shapes of arabic": 0.5,
    "of arabic ,": 1.0,
    "arabic , such": 1.0,
    ", such signals": 0.02857142857142857,
    "such signals are": 1.0,
    "signals are sometimes": 0.5,
    "are sometimes ambiguous": 1.0,
    "sometimes ambiguous and": 1.0,
    "ambiguous and not": 0.5,
    "and not present": 0.125,
    "present in all": 0.2,
    "in all written": 0.5,
    "all written languages": 0.6666666666666666,
    "written languages .": 0.2,
    "<s> compare speech": 1.0,
    "compare speech segmentation": 1.0,
    "segmentation , the": 0.25,
    ", the process": 0.009523809523809525,
    "of dividing speech": 0.3333333333333333,
    "dividing speech into": 1.0,
    "speech into linguistically": 0.5,
    "into linguistically meaningful": 1.0,
    "linguistically meaningful portions": 1.0,
    "meaningful portions .": 1.0,
    "<s> in english": 0.020618556701030927,
    "in english and": 0.2857142857142857,
    "english and many": 0.3333333333333333,
    "and many other": 1.0,
    "other languages using": 0.2,
    "languages using some": 1.0,
    "using some form": 0.5,
    "form of the": 0.14285714285714285,
    "of the latin": 0.005128205128205128,
    "the latin alphabet": 1.0,
    "latin alphabet ,": 1.0,
    "alphabet , the": 0.5,
    ", the space": 0.009523809523809525,
    "the space is": 0.3333333333333333,
    "space is a": 1.0,
    "is a good": 0.018518518518518517,
    "a good approximation": 0.2,
    "good approximation of": 1.0,
    "approximation of a": 1.0,
    "a word delimiter": 0.08333333333333333,
    "word delimiter .": 1.0,
    "<s> -lrb- some": 0.05263157894736842,
    "-lrb- some examples": 0.5,
    "some examples where": 1.0,
    "examples where the": 1.0,
    "where the space": 0.07692307692307693,
    "the space character": 0.3333333333333333,
    "space character alone": 1.0,
    "character alone may": 1.0,
    "alone may not": 1.0,
    "not be sufficient": 0.08333333333333333,
    "be sufficient include": 1.0,
    "sufficient include contractions": 1.0,
    "include contractions like": 1.0,
    "contractions like ca": 1.0,
    "like ca n't": 1.0,
    "ca n't for": 1.0,
    "n't for can": 1.0,
    "for can not": 1.0,
    "not . -rrb-": 1.0,
    "<s> however the": 0.02702702702702703,
    "however the equivalent": 1.0,
    "the equivalent to": 1.0,
    "equivalent to this": 1.0,
    "to this character": 0.16666666666666666,
    "this character is": 1.0,
    "character is not": 0.5,
    "is not found": 0.05263157894736842,
    "not found in": 1.0,
    "found in all": 0.3333333333333333,
    "all written scripts": 0.3333333333333333,
    "written scripts ,": 1.0,
    "scripts , and": 1.0,
    "and without it": 0.5,
    "without it word": 1.0,
    "it word segmentation": 1.0,
    "word segmentation is": 0.25,
    "is a difficult": 0.018518518518518517,
    "a difficult problem": 1.0,
    "difficult problem .": 1.0,
    "<s> languages which": 0.3333333333333333,
    "languages which do": 0.5,
    "which do not": 1.0,
    "not have a": 0.5,
    "have a trivial": 0.07692307692307693,
    "a trivial word": 1.0,
    "trivial word segmentation": 1.0,
    "word segmentation process": 0.25,
    "segmentation process include": 1.0,
    "process include chinese": 1.0,
    "include chinese ,": 1.0,
    ", japanese ,": 0.5,
    "japanese , where": 1.0,
    ", where sentences": 0.06666666666666667,
    "where sentences but": 0.5,
    "sentences but not": 1.0,
    "but not words": 0.75,
    "not words are": 1.0,
    "words are delimited": 0.3,
    "are delimited ,": 0.6666666666666666,
    "delimited , thai": 0.5,
    ", thai and": 1.0,
    "thai and lao": 1.0,
    "and lao ,": 1.0,
    "lao , where": 1.0,
    ", where phrases": 0.06666666666666667,
    "where phrases and": 1.0,
    "phrases and sentences": 0.3333333333333333,
    "and sentences but": 0.3333333333333333,
    "delimited , and": 0.5,
    ", and vietnamese": 0.005291005291005291,
    "and vietnamese ,": 1.0,
    "vietnamese , where": 1.0,
    ", where syllables": 0.06666666666666667,
    "where syllables but": 1.0,
    "syllables but not": 1.0,
    "are delimited .": 0.3333333333333333,
    "in some writing": 0.125,
    "writing systems however": 0.5,
    "systems however ,": 1.0,
    "as the ge'ez": 0.03571428571428571,
    "the ge'ez script": 1.0,
    "ge'ez script used": 1.0,
    "script used for": 1.0,
    "used for amharic": 0.06666666666666667,
    "for amharic and": 1.0,
    "amharic and tigrinya": 1.0,
    "and tigrinya among": 1.0,
    "tigrinya among other": 1.0,
    "among other languages": 0.3333333333333333,
    "other languages ,": 0.4,
    "languages , words": 0.09090909090909091,
    ", words are": 0.3333333333333333,
    "words are explicitly": 0.1,
    "are explicitly delimited": 1.0,
    "explicitly delimited -lrb-": 1.0,
    "delimited -lrb- at": 1.0,
    "-lrb- at least": 1.0,
    "at least historically": 0.2,
    "least historically -rrb-": 1.0,
    "historically -rrb- with": 1.0,
    "-rrb- with a": 0.3333333333333333,
    "with a non-whitespace": 0.05,
    "a non-whitespace character": 1.0,
    "non-whitespace character .": 1.0,
    "<s> the unicode": 0.006802721088435374,
    "the unicode consortium": 1.0,
    "unicode consortium has": 1.0,
    "consortium has published": 1.0,
    "has published a": 1.0,
    "published a standard": 0.5,
    "a standard annex": 0.3333333333333333,
    "standard annex on": 1.0,
    "annex on text": 1.0,
    "on text segmentation": 0.5,
    "text segmentation ,": 0.1111111111111111,
    "segmentation , exploring": 0.25,
    ", exploring the": 1.0,
    "exploring the issues": 1.0,
    "the issues of": 1.0,
    "issues of segmentation": 1.0,
    "of segmentation in": 1.0,
    "segmentation in multiscript": 0.5,
    "in multiscript texts": 1.0,
    "multiscript texts .": 1.0,
    "<s> word splitting": 0.4,
    "word splitting is": 0.5,
    "splitting is the": 1.0,
    "process of parsing": 0.08333333333333333,
    "of parsing concatenated": 0.5,
    "parsing concatenated text": 1.0,
    "concatenated text -lrb-": 1.0,
    "text -lrb- i.e.": 0.16666666666666666,
    "-lrb- i.e. text": 0.09090909090909091,
    "i.e. text that": 1.0,
    "text that contains": 0.25,
    "that contains no": 0.3333333333333333,
    "contains no spaces": 1.0,
    "no spaces or": 1.0,
    "spaces or other": 1.0,
    "or other word": 0.5,
    "other word separators": 1.0,
    "word separators -rrb-": 1.0,
    "separators -rrb- to": 1.0,
    "-rrb- to infer": 0.25,
    "to infer where": 1.0,
    "infer where word": 1.0,
    "where word breaks": 1.0,
    "word breaks exist": 1.0,
    "breaks exist .": 1.0,
    "word splitting may": 0.5,
    "splitting may also": 1.0,
    "may also refer": 1.0,
    "also refer to": 1.0,
    "to the process": 0.012987012987012988,
    "process of hyphenation": 0.08333333333333333,
    "of hyphenation .": 1.0,
    "<s> sentence segmentation": 0.3333333333333333,
    "sentence segmentation sentence": 0.5,
    "segmentation sentence segmentation": 1.0,
    "sentence segmentation is": 0.5,
    "problem of dividing": 0.125,
    "of dividing a": 0.3333333333333333,
    "dividing a string": 1.0,
    "of written language": 0.25,
    "written language into": 0.3333333333333333,
    "language into its": 1.0,
    "into its component": 1.0,
    "its component sentences": 1.0,
    "component sentences .": 1.0,
    "english and some": 0.3333333333333333,
    "and some other": 0.5,
    "some other languages": 0.14285714285714285,
    "languages , using": 0.09090909090909091,
    ", using punctuation": 0.1,
    "using punctuation ,": 1.0,
    "punctuation , particularly": 0.5,
    ", particularly the": 0.5,
    "particularly the full": 1.0,
    "the full stop": 0.6666666666666666,
    "full stop character": 1.0,
    "stop character is": 0.5,
    "character is a": 0.5,
    "is a reasonable": 0.018518518518518517,
    "a reasonable approximation": 0.5,
    "reasonable approximation .": 1.0,
    "<s> however even": 0.02702702702702703,
    "however even in": 1.0,
    "even in english": 0.5,
    "in english this": 0.14285714285714285,
    "english this problem": 1.0,
    "problem is not": 0.2,
    "is not trivial": 0.05263157894736842,
    "not trivial due": 1.0,
    "trivial due to": 1.0,
    "use of the": 0.045454545454545456,
    "of the full": 0.005128205128205128,
    "stop character for": 0.5,
    "character for abbreviations": 1.0,
    "for abbreviations ,": 1.0,
    "abbreviations , which": 0.5,
    ", which may": 0.017857142857142856,
    "which may or": 1.0,
    "may or may": 1.0,
    "or may not": 0.5,
    "may not also": 0.2,
    "not also terminate": 1.0,
    "also terminate a": 1.0,
    "terminate a sentence": 1.0,
    "for example mr.": 0.017857142857142856,
    "example mr. is": 1.0,
    "mr. is not": 1.0,
    "is not its": 0.05263157894736842,
    "not its own": 1.0,
    "its own sentence": 0.2,
    "own sentence in": 1.0,
    "sentence in ``": 0.5,
    "in `` mr.": 0.3333333333333333,
    "`` mr. smith": 1.0,
    "mr. smith went": 1.0,
    "smith went to": 1.0,
    "went to the": 0.5,
    "to the shops": 0.012987012987012988,
    "the shops in": 1.0,
    "shops in jones": 1.0,
    "in jones street": 1.0,
    "jones street .": 1.0,
    "street . ''": 1.0,
    "<s> when processing": 0.16666666666666666,
    "when processing plain": 1.0,
    "processing plain text": 1.0,
    "plain text ,": 1.0,
    "text , tables": 0.03333333333333333,
    ", tables of": 1.0,
    "tables of abbreviations": 1.0,
    "of abbreviations that": 0.5,
    "abbreviations that contain": 1.0,
    "that contain periods": 0.3333333333333333,
    "contain periods can": 1.0,
    "periods can help": 1.0,
    "can help prevent": 1.0,
    "help prevent incorrect": 1.0,
    "prevent incorrect assignment": 1.0,
    "incorrect assignment of": 1.0,
    "assignment of sentence": 1.0,
    "of sentence boundaries": 1.0,
    "<s> as with": 0.07142857142857142,
    "as with word": 0.3333333333333333,
    "with word segmentation": 0.3333333333333333,
    "word segmentation ,": 0.25,
    "segmentation , not": 0.25,
    "not all written": 0.5,
    "written languages contain": 0.2,
    "languages contain punctuation": 1.0,
    "contain punctuation characters": 1.0,
    "punctuation characters which": 1.0,
    "characters which are": 0.5,
    "which are useful": 0.08333333333333333,
    "are useful for": 1.0,
    "useful for approximating": 0.3333333333333333,
    "for approximating sentence": 1.0,
    "approximating sentence boundaries": 1.0,
    "<s> other segmentation": 0.14285714285714285,
    "other segmentation problems": 1.0,
    "segmentation problems processes": 0.5,
    "problems processes may": 1.0,
    "processes may be": 1.0,
    "may be required": 0.047619047619047616,
    "be required to": 1.0,
    "required to segment": 1.0,
    "to segment text": 0.6666666666666666,
    "segment text into": 0.5,
    "text into segments": 0.14285714285714285,
    "into segments besides": 0.5,
    "segments besides words": 1.0,
    "besides words ,": 1.0,
    "words , including": 0.0625,
    ", including morphemes": 0.125,
    "including morphemes -lrb-": 1.0,
    "morphemes -lrb- a": 1.0,
    "-lrb- a task": 0.2,
    "a task usually": 0.3333333333333333,
    "task usually called": 1.0,
    "usually called morphological": 1.0,
    "called morphological analysis": 1.0,
    "morphological analysis -rrb-": 1.0,
    "analysis -rrb- ,": 0.5,
    "-rrb- , paragraphs": 0.01282051282051282,
    ", paragraphs ,": 1.0,
    "paragraphs , topics": 1.0,
    ", topics or": 1.0,
    "topics or discourse": 1.0,
    "or discourse turns": 0.5,
    "discourse turns .": 1.0,
    "<s> a document": 0.022727272727272728,
    "a document may": 0.125,
    "may contain multiple": 0.5,
    "contain multiple topics": 1.0,
    "multiple topics ,": 1.0,
    "topics , and": 1.0,
    "and the task": 0.024390243902439025,
    "task of computerized": 0.1111111111111111,
    "of computerized text": 0.5,
    "computerized text segmentation": 1.0,
    "text segmentation may": 0.1111111111111111,
    "segmentation may be": 1.0,
    "may be to": 0.047619047619047616,
    "be to discover": 0.5,
    "to discover these": 1.0,
    "discover these topics": 1.0,
    "these topics automatically": 1.0,
    "topics automatically and": 1.0,
    "automatically and segment": 0.5,
    "and segment the": 1.0,
    "segment the text": 1.0,
    "the text accordingly": 0.038461538461538464,
    "text accordingly .": 1.0,
    "<s> the topic": 0.006802721088435374,
    "the topic boundaries": 0.3333333333333333,
    "topic boundaries may": 1.0,
    "boundaries may be": 1.0,
    "may be apparent": 0.047619047619047616,
    "be apparent from": 1.0,
    "apparent from section": 1.0,
    "from section titles": 1.0,
    "section titles and": 1.0,
    "titles and paragraphs": 1.0,
    "and paragraphs .": 1.0,
    "in other cases": 0.14285714285714285,
    "other cases one": 0.5,
    "cases one needs": 1.0,
    "one needs to": 1.0,
    "needs to use": 0.25,
    "to use techniques": 0.1,
    "use techniques similar": 1.0,
    "techniques similar to": 1.0,
    "to those used": 0.5,
    "those used in": 0.3333333333333333,
    "used in document": 0.043478260869565216,
    "in document classification": 0.5,
    "many different approaches": 0.16666666666666666,
    "different approaches have": 1.0,
    "have been tried": 0.038461538461538464,
    "been tried .": 0.5,
    "automatic segmentation approaches": 0.3333333333333333,
    "segmentation approaches automatic": 1.0,
    "approaches automatic segmentation": 1.0,
    "automatic segmentation is": 0.3333333333333333,
    "processing of implementing": 0.5,
    "of implementing a": 1.0,
    "implementing a computer": 1.0,
    "a computer process": 0.0625,
    "computer process to": 1.0,
    "process to segment": 0.25,
    "segment text .": 0.5,
    "<s> when punctuation": 0.16666666666666666,
    "when punctuation and": 1.0,
    "punctuation and similar": 0.5,
    "and similar clues": 1.0,
    "similar clues are": 1.0,
    "clues are not": 1.0,
    "are not consistently": 0.2,
    "not consistently available": 0.5,
    "consistently available ,": 1.0,
    "available , the": 0.25,
    ", the segmentation": 0.009523809523809525,
    "the segmentation task": 1.0,
    "segmentation task often": 1.0,
    "task often requires": 1.0,
    "often requires fairly": 1.0,
    "requires fairly non-trivial": 1.0,
    "fairly non-trivial techniques": 1.0,
    "non-trivial techniques ,": 1.0,
    "techniques , such": 0.5,
    "such as statistical": 0.011111111111111112,
    "as statistical decision-making": 1.0,
    "statistical decision-making ,": 1.0,
    "decision-making , large": 1.0,
    ", large dictionaries": 1.0,
    "large dictionaries ,": 1.0,
    "dictionaries , as": 1.0,
    "well as consideration": 0.07692307692307693,
    "as consideration of": 1.0,
    "consideration of syntactic": 1.0,
    "of syntactic and": 0.5,
    "and semantic constraints": 0.25,
    "semantic constraints .": 1.0,
    "<s> effective natural": 1.0,
    "effective natural language": 1.0,
    "processing systems and": 0.3333333333333333,
    "systems and text": 1.0,
    "and text segmentation": 0.25,
    "text segmentation tools": 0.2222222222222222,
    "segmentation tools usually": 0.5,
    "tools usually operate": 1.0,
    "usually operate on": 1.0,
    "operate on text": 1.0,
    "on text in": 0.5,
    "text in specific": 0.125,
    "in specific domains": 0.5,
    "specific domains and": 1.0,
    "domains and sources": 0.5,
    "and sources .": 1.0,
    "example , processing": 0.018518518518518517,
    ", processing text": 1.0,
    "processing text used": 1.0,
    "text used in": 1.0,
    "used in medical": 0.043478260869565216,
    "in medical records": 1.0,
    "medical records is": 0.3333333333333333,
    "records is a": 1.0,
    "a very different": 0.08333333333333333,
    "very different problem": 0.3333333333333333,
    "different problem than": 1.0,
    "problem than processing": 1.0,
    "than processing news": 1.0,
    "processing news articles": 1.0,
    "news articles or": 0.3333333333333333,
    "articles or real": 0.5,
    "or real estate": 1.0,
    "real estate advertisements": 1.0,
    "estate advertisements .": 1.0,
    "process of developing": 0.08333333333333333,
    "of developing text": 1.0,
    "developing text segmentation": 1.0,
    "segmentation tools starts": 0.5,
    "tools starts with": 1.0,
    "starts with collecting": 1.0,
    "with collecting a": 1.0,
    "collecting a large": 1.0,
    "a large corpus": 0.1111111111111111,
    "large corpus of": 1.0,
    "of text in": 0.041666666666666664,
    "text in an": 0.125,
    "in an application": 0.125,
    "an application domain": 0.5,
    "application domain .": 1.0,
    "are two general": 0.5,
    "two general approaches": 1.0,
    "general approaches :": 1.0,
    "approaches : manual": 0.25,
    ": manual analysis": 1.0,
    "manual analysis of": 1.0,
    "analysis of text": 0.07692307692307693,
    "of text and": 0.041666666666666664,
    "text and writing": 0.3333333333333333,
    "and writing custom": 1.0,
    "writing custom software": 1.0,
    "custom software annotate": 1.0,
    "software annotate the": 1.0,
    "annotate the sample": 1.0,
    "the sample corpus": 1.0,
    "sample corpus with": 1.0,
    "corpus with boundary": 1.0,
    "with boundary information": 1.0,
    "boundary information and": 1.0,
    "information and use": 1.0,
    "and use machine": 0.3333333333333333,
    "use machine learning": 1.0,
    "machine learning some": 0.047619047619047616,
    "learning some text": 1.0,
    "some text segmentation": 1.0,
    "text segmentation systems": 0.1111111111111111,
    "segmentation systems take": 1.0,
    "systems take advantage": 1.0,
    "advantage of any": 0.25,
    "of any markup": 0.3333333333333333,
    "any markup like": 1.0,
    "markup like html": 1.0,
    "like html and": 1.0,
    "html and know": 1.0,
    "and know document": 1.0,
    "know document formats": 1.0,
    "document formats like": 1.0,
    "formats like pdf": 1.0,
    "like pdf to": 1.0,
    "pdf to provide": 1.0,
    "to provide additional": 0.25,
    "provide additional evidence": 1.0,
    "additional evidence for": 1.0,
    "evidence for sentence": 1.0,
    "for sentence and": 1.0,
    "sentence and paragraph": 1.0,
    "and paragraph boundaries": 1.0,
    "paragraph boundaries .": 1.0
}